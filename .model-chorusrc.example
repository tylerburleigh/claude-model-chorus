# ModelChorus Configuration Example
#
# Place this file as .modelchorusrc in your project root to configure
# default settings for ModelChorus workflows.
#
# Supported formats: YAML (.modelchorusrc, .modelchorusrc.yaml, .modelchorusrc.yml)
#                    JSON (.modelchorusrc.json)
#
# Configuration Precedence:
#   CLI arguments > Workflow-specific config > Global defaults > Hardcoded defaults

# ============================================================================
# Global Defaults
# ============================================================================

# Default provider for all workflows (unless overridden)
# Options: claude, gemini, codex, cursor-agent
default_provider: claude

# Provider-specific model configuration
# Each provider can have a default model specified
providers:
  claude:
    model: sonnet              # Options: opus, sonnet, haiku
  gemini:
    model: gemini-2.5-pro      # Gemini Pro model
  codex:
    model: gpt-5-codex         # GPT-5 Codex model
  cursor-agent:
    model: composer-1          # Options: default, fast, premium, composer-1

# Global generation parameters (apply to all workflows unless overridden)
generation:
  timeout: 600.0               # Timeout in seconds per provider (10 minutes)

# ============================================================================
# Workflow-Specific Configuration
# ============================================================================
# Override global defaults for specific workflows
# Available workflows: chat, consensus, thinkdeep, argument, ideate, research

workflows:

  # CHAT - Interactive conversation with a single model
  chat:
    provider: claude
    fallback_providers:        # Fallback chain if primary fails (tries in order)
      - gemini
      - codex
      - cursor-agent

  # CONSENSUS - Get responses from multiple models
  consensus:
    providers:                 # List of providers for multi-model consensus
      - claude
      - gemini
      - codex
    strategy: all_responses    # Options: all_responses, synthesize, vote
    timeout: 180.0             # Longer timeout for multiple providers

  # THINKDEEP - Extended reasoning with chain-of-thought
  thinkdeep:
    provider: claude
    fallback_providers:        # Fallback chain if primary fails (tries in order)
      - gemini
      - codex
      - cursor-agent
    thinking_mode: medium      # Options: low, medium, high

  # ARGUMENT - Generate arguments for/against a position
  argument:
    provider: claude
    fallback_providers:        # Fallback chain if primary fails (tries in order)
      - gemini
      - codex
      - cursor-agent

  # IDEATE - Creative ideation and brainstorming
  ideate:
    provider: claude
    fallback_providers:        # Fallback chain if primary fails (tries in order)
      - gemini
      - codex
      - cursor-agent

  # RESEARCH - Multi-source research with citations
  research:
    provider: claude
    fallback_providers:        # Fallback chain if primary fails (tries in order)
      - gemini
      - codex
      - cursor-agent
    citation_style: academic   # Options: informal, academic, apa, mla
    depth: thorough            # Options: quick, thorough, comprehensive

# ============================================================================
# Example Configurations for Different Use Cases
# ============================================================================

# Example 1: Prefer Gemini by default
# ---
# default_provider: gemini
# providers:
#   gemini:
#     model: gemini-2.5-pro

# Example 2: Multi-provider consensus with specific models
# ---
# providers:
#   claude:
#     model: opus
#   gemini:
#     model: gemini-2.5-pro
#   codex:
#     model: gpt-5-codex
# workflows:
#   consensus:
#     providers: [claude, gemini, codex]
#     strategy: synthesize

# Example 3: Fast timeout for quick responses
# ---
# generation:
#   timeout: 60.0
# workflows:
#   chat:
#     timeout: 30.0

# ============================================================================
# Provider Fallback
# ============================================================================
# Workflows support automatic fallback if the primary provider fails.
#
# fallback_providers: List of providers to try if primary fails
#   - Tried in order
#   - Workflow succeeds if any provider succeeds
#   - Useful for resilience and reliability
#
# Example: If claude CLI is not installed, will automatically use gemini
#
# To disable provider checking (faster startup):
#   modelchorus research "topic" --skip-provider-check

# ============================================================================
# Provider Models
# ============================================================================
# Each provider supports different models:
#
# Claude:
#   - opus: Most capable, best for complex tasks
#   - sonnet: Balanced performance and speed (default)
#   - haiku: Fastest, good for simple tasks
#
# Gemini:
#   - gemini-2.5-pro: Latest Gemini Pro model (default)
#   - gemini-pro: Standard Gemini Pro
#
# Codex:
#   - gpt-5-codex: GPT-5 optimized for code (default)
#   - gpt-5-pro: GPT-5 Pro model
#   - gpt-5: Standard GPT-5 model
#
# Cursor Agent:
#   - composer-1: Advanced composer model (default)
#   - default: Standard cursor model
#   - fast: Faster responses
#   - premium: Highest quality
#
# Models are configured in the providers section above.
