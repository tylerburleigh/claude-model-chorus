{
  "metadata": {
    "project_name": "claude-model-chorus",
    "version": "1.0.0",
    "generated_at": "2025-11-13T18:58:22.825665Z",
    "languages": [
      "python"
    ],
    "schema_version": "2.0"
  },
  "statistics": {
    "total_files": 103,
    "total_lines": 43345,
    "total_classes": 237,
    "total_functions": 196,
    "avg_complexity": 4.52,
    "max_complexity": 56,
    "high_complexity_functions": [
      "thinkdeep (56)",
      "start (43)",
      "study_next (34)",
      "study_view (31)",
      "chat (27)"
    ],
    "by_language": {
      "python": {
        "files": 103,
        "lines": 43345,
        "classes": 237,
        "functions": 196,
        "avg_complexity": 4.52
      }
    }
  },
  "modules": [
    {
      "name": "__init__",
      "file": "examples/__init__.py",
      "language": "python",
      "docstring": "ModelChorus Examples Package\n\nThis package contains example scripts demonstrating ModelChorus workflows.",
      "classes": [],
      "functions": [],
      "imports": [],
      "exports": [],
      "lines": 7
    },
    {
      "name": "workflow_examples",
      "file": "examples/workflow_examples.py",
      "language": "python",
      "docstring": "ModelChorus Workflow Examples\n\nThis module provides comprehensive examples for using ModelChorus workflows:\n- ARGUMENT: Structured dialectical reasoning and argument analysis\n- IDEATE: Creative brainstorming with configurable parameters\n\nEach workflow demonstrates:\n- Basic usage patterns\n- Advanced features (continuation, file context, parameters)\n- Error handling\n- Best practices\n\nRequirements:\n- ModelChorus installed: pip install model-chorus\n- Provider CLI tools configured (claude, gemini, codex, etc.)\n- API keys set in environment variables",
      "classes": [],
      "functions": [
        "example_argument_basic",
        "example_argument_with_files",
        "example_argument_continuation",
        "example_argument_custom_config",
        "example_ideate_basic",
        "example_ideate_high_creativity",
        "example_ideate_with_constraints",
        "example_ideate_refine",
        "example_error_handling",
        "example_output_management",
        "example_provider_comparison",
        "run_all_examples",
        "run_specific_example",
        "main"
      ],
      "imports": [
        "asyncio",
        "sys",
        "pathlib.Path",
        "typing.Optional",
        "model_chorus.workflows.ArgumentWorkflow",
        "model_chorus.workflows.IdeateWorkflow",
        "model_chorus.providers.ClaudeProvider",
        "model_chorus.providers.GeminiProvider",
        "model_chorus.core.conversation.ConversationMemory"
      ],
      "exports": [],
      "lines": 589
    },
    {
      "name": "basic_workflow",
      "file": "model_chorus/examples/basic_workflow.py",
      "language": "python",
      "docstring": "Basic workflow example for ModelChorus.\n\nThis example demonstrates how to create and execute a simple workflow\nusing the ModelChorus framework.",
      "classes": [
        "ExampleWorkflow"
      ],
      "functions": [
        "main"
      ],
      "imports": [
        "asyncio",
        "model_chorus.core.BaseWorkflow",
        "model_chorus.core.WorkflowResult",
        "model_chorus.core.WorkflowRegistry",
        "model_chorus.core.WorkflowRequest"
      ],
      "exports": [],
      "lines": 105
    },
    {
      "name": "chat_example",
      "file": "model_chorus/examples/chat_example.py",
      "language": "python",
      "docstring": "Multi-turn conversation example using ChatWorkflow.\n\nThis example demonstrates how to:\n1. Create a new conversation\n2. Continue an existing conversation\n3. Include file context in conversations\n4. Track conversation history",
      "classes": [],
      "functions": [
        "basic_chat_example",
        "multi_turn_conversation_example",
        "chat_with_file_context_example",
        "conversation_tracking_example",
        "main"
      ],
      "imports": [
        "asyncio",
        "pathlib.Path",
        "model_chorus.providers.ClaudeProvider",
        "model_chorus.workflows.ChatWorkflow",
        "model_chorus.core.conversation.ConversationMemory"
      ],
      "exports": [],
      "lines": 216
    },
    {
      "name": "provider_integration",
      "file": "model_chorus/examples/provider_integration.py",
      "language": "python",
      "docstring": "Provider integration example for ModelChorus.\n\nThis example demonstrates how to integrate and use different AI providers\nwith ModelChorus.",
      "classes": [
        "ExampleProvider"
      ],
      "functions": [
        "main"
      ],
      "imports": [
        "asyncio",
        "model_chorus.providers.ModelProvider",
        "model_chorus.providers.ModelConfig",
        "model_chorus.providers.ModelCapability",
        "model_chorus.providers.GenerationRequest",
        "model_chorus.providers.GenerationResponse"
      ],
      "exports": [],
      "lines": 157
    },
    {
      "name": "thinkdeep_example",
      "file": "model_chorus/examples/thinkdeep_example.py",
      "language": "python",
      "docstring": "Multi-step investigation example using ThinkDeepWorkflow.\n\nThis example demonstrates how to:\n1. Start a systematic investigation with ThinkDeep\n2. Continue multi-turn investigations with hypothesis tracking\n3. Track confidence progression across investigation steps\n4. Accumulate findings and evidence\n5. Use expert validation for additional insights\n6. Inspect investigation state and progress",
      "classes": [],
      "functions": [
        "basic_investigation_example",
        "multi_step_investigation_example",
        "investigation_with_expert_validation",
        "hypothesis_management_example",
        "confidence_progression_example",
        "main"
      ],
      "imports": [
        "asyncio",
        "pathlib.Path",
        "model_chorus.providers.ClaudeProvider",
        "model_chorus.providers.GeminiProvider",
        "model_chorus.workflows.ThinkDeepWorkflow",
        "model_chorus.workflows.ConfidenceLevel",
        "model_chorus.workflows.Hypothesis",
        "model_chorus.workflows.InvestigationStep",
        "model_chorus.workflows.ThinkDeepState",
        "model_chorus.core.conversation.ConversationMemory"
      ],
      "exports": [],
      "lines": 467
    },
    {
      "name": "__init__",
      "file": "model_chorus/src/model_chorus/__init__.py",
      "language": "python",
      "docstring": "ModelChorus - Standalone Multi-Model Workflow Package\n\nA flexible orchestration engine for multi-model AI workflows including\nthinking, debugging, consensus building, code review, and more.",
      "classes": [],
      "functions": [],
      "imports": [],
      "exports": [],
      "lines": 12
    },
    {
      "name": "__init__",
      "file": "model_chorus/src/model_chorus/cli/__init__.py",
      "language": "python",
      "docstring": "Command-line interface for ModelChorus.\n\nThis module provides CLI commands for running workflows and\nmanaging ModelChorus operations.",
      "classes": [],
      "functions": [],
      "imports": [
        "main.app",
        "main.main"
      ],
      "exports": [],
      "lines": 10
    },
    {
      "name": "main",
      "file": "model_chorus/src/model_chorus/cli/main.py",
      "language": "python",
      "docstring": "CLI interface for ModelChorus.\n\nTyper-based command-line application for running multi-model workflows.",
      "classes": [],
      "functions": [
        "_find_project_root",
        "_format_path_for_display",
        "resolve_context_files",
        "get_config",
        "get_install_command",
        "get_provider_by_name",
        "chat",
        "argument",
        "ideate",
        "construct_prompt_with_files",
        "consensus",
        "thinkdeep",
        "thinkdeep_status",
        "config_cmd",
        "_config_show",
        "_config_validate",
        "_config_init",
        "list_providers",
        "version",
        "main"
      ],
      "imports": [
        "asyncio",
        "json",
        "sys",
        "pathlib.Path",
        "typing.List",
        "typing.Optional",
        "typing.Sequence",
        "typing.Tuple",
        "typing.Union",
        "typer",
        "rich.console.Console",
        "rich.table.Table",
        "rich.print",
        "providers.ClaudeProvider",
        "providers.CodexProvider",
        "providers.GeminiProvider",
        "providers.CursorAgentProvider",
        "providers.GenerationRequest",
        "providers.cli_provider.ProviderUnavailableError",
        "workflows.ArgumentWorkflow",
        "workflows.ChatWorkflow",
        "workflows.ConsensusWorkflow",
        "workflows.ConsensusStrategy",
        "workflows.IdeateWorkflow",
        "workflows.ThinkDeepWorkflow",
        "core.conversation.ConversationMemory",
        "core.config.get_config_loader",
        "core.progress.set_progress_enabled",
        "model_chorus.__version__",
        "study_commands.study_app"
      ],
      "exports": [],
      "lines": 1771
    },
    {
      "name": "setup",
      "file": "model_chorus/src/model_chorus/cli/setup.py",
      "language": "python",
      "docstring": "Setup helper commands for ModelChorus.\n\nProvides commands for /model-chorus-setup slash command.",
      "classes": [],
      "functions": [
        "check_package_installed",
        "install_package",
        "check_version_compatibility",
        "check_available_providers",
        "check_config_exists",
        "create_config_file",
        "create_express_config",
        "create_tiered_config",
        "validate_config",
        "check_permissions",
        "add_to_gitignore",
        "add_permissions",
        "main"
      ],
      "imports": [
        "asyncio",
        "json",
        "subprocess",
        "sys",
        "pathlib.Path",
        "typing.Optional",
        "typing.Dict",
        "typing.Any",
        "typing.List"
      ],
      "exports": [],
      "lines": 956
    },
    {
      "name": "study_commands",
      "file": "model_chorus/src/model_chorus/cli/study_commands.py",
      "language": "python",
      "docstring": "CLI commands for STUDY workflow.\n\nThis module provides Typer commands for persona-based collaborative research\nusing the StudyWorkflow. Supports new investigations and continuation of\nexisting research sessions.",
      "classes": [],
      "functions": [
        "get_config",
        "get_install_command",
        "get_provider_by_name",
        "start",
        "study_next",
        "study_view"
      ],
      "imports": [
        "asyncio",
        "json",
        "sys",
        "pathlib.Path",
        "typing.List",
        "typing.Optional",
        "typer",
        "rich.console.Console",
        "rich.print",
        "providers.ClaudeProvider",
        "providers.CodexProvider",
        "providers.GeminiProvider",
        "providers.CursorAgentProvider",
        "providers.cli_provider.ProviderUnavailableError",
        "workflows.study.StudyWorkflow",
        "core.conversation.ConversationMemory",
        "core.config.get_config_loader"
      ],
      "exports": [],
      "lines": 777
    },
    {
      "name": "__init__",
      "file": "model_chorus/src/model_chorus/core/__init__.py",
      "language": "python",
      "docstring": "Core orchestration logic for ModelChorus workflows.\n\nThis module contains the main workflow engine and model orchestration\ncomponents that power multi-model AI workflows.",
      "classes": [],
      "functions": [],
      "imports": [
        "base_workflow.BaseWorkflow",
        "base_workflow.WorkflowResult",
        "base_workflow.WorkflowStep",
        "registry.WorkflowRegistry",
        "prompts.get_read_only_system_prompt",
        "prompts.prepend_system_constraints",
        "models.ConfidenceLevel",
        "models.WorkflowRequest",
        "models.WorkflowResponse",
        "models.ModelSelection",
        "models.WorkflowStep",
        "models.ModelResponse",
        "models.ConsensusConfig",
        "models.ConversationMessage",
        "models.ConversationThread",
        "models.ConversationState",
        "models.Hypothesis",
        "models.InvestigationStep",
        "models.ThinkDeepState",
        "conversation.ConversationMemory",
        "gap_analysis.Gap",
        "gap_analysis.GapType",
        "gap_analysis.GapSeverity",
        "gap_analysis.detect_gaps",
        "gap_analysis.detect_missing_evidence",
        "gap_analysis.detect_logical_gaps",
        "gap_analysis.detect_unsupported_claims",
        "gap_analysis.assess_gap_severity",
        "gap_analysis.generate_gap_recommendation",
        "contradiction.Contradiction",
        "contradiction.ContradictionSeverity",
        "contradiction.detect_contradiction",
        "contradiction.detect_contradictions_batch",
        "contradiction.detect_polarity_opposition",
        "contradiction.assess_contradiction_severity",
        "contradiction.generate_contradiction_explanation",
        "contradiction.generate_reconciliation_suggestion"
      ],
      "exports": [],
      "lines": 89
    },
    {
      "name": "base_workflow",
      "file": "model_chorus/src/model_chorus/core/base_workflow.py",
      "language": "python",
      "docstring": "Base workflow abstract class for ModelChorus.\n\nThis module defines the abstract base class that all workflow implementations\nmust inherit from, providing a consistent interface for multi-model orchestration.",
      "classes": [
        "WorkflowStep",
        "WorkflowResult",
        "BaseWorkflow"
      ],
      "functions": [],
      "imports": [
        "asyncio",
        "logging",
        "abc.ABC",
        "abc.abstractmethod",
        "typing.Any",
        "typing.Dict",
        "typing.List",
        "typing.Optional",
        "typing.TYPE_CHECKING",
        "dataclasses.dataclass",
        "dataclasses.field",
        "datetime.datetime",
        "conversation.ConversationMemory",
        "models.ConversationThread",
        "models.ConversationMessage"
      ],
      "exports": [],
      "lines": 426
    },
    {
      "name": "clustering",
      "file": "model_chorus/src/model_chorus/core/clustering.py",
      "language": "python",
      "docstring": "Theme clustering algorithm for grouping similar ideas, claims, or hypotheses.\n\nThis module provides clustering capabilities for semantic grouping of textual content,\nparticularly for workflows like ARGUMENT, IDEATE, and RESEARCH where multiple claims\nor ideas need to be organized into coherent themes.\n\nKey Features:\n- Semantic similarity computation using sentence transformers\n- K-means and hierarchical clustering algorithms\n- Automatic cluster naming and summarization\n- Cluster quality scoring and metrics",
      "classes": [
        "ClusterResult",
        "SemanticClustering"
      ],
      "functions": [],
      "imports": [
        "typing.List",
        "typing.Dict",
        "typing.Any",
        "typing.Optional",
        "typing.Tuple",
        "numpy",
        "dataclasses.dataclass",
        "dataclasses.field"
      ],
      "exports": [],
      "lines": 465
    },
    {
      "name": "config",
      "file": "model_chorus/src/model_chorus/core/config.py",
      "language": "python",
      "docstring": "Configuration management for ModelChorus.\n\nThis module provides support for project-level configuration via .model-chorusrc files.\nConfig files can be in YAML or JSON format and support workflow-specific defaults.",
      "classes": [
        "GenerationDefaults",
        "ProviderConfig",
        "WorkflowConfig",
        "ModelChorusConfig",
        "ConfigLoader"
      ],
      "functions": [
        "get_config_loader",
        "load_config",
        "get_config"
      ],
      "imports": [
        "json",
        "os",
        "pathlib.Path",
        "typing.Any",
        "typing.Dict",
        "typing.List",
        "typing.Optional",
        "pydantic.BaseModel",
        "pydantic.Field",
        "pydantic.field_validator"
      ],
      "exports": [],
      "lines": 413
    },
    {
      "name": "contradiction",
      "file": "model_chorus/src/model_chorus/core/contradiction.py",
      "language": "python",
      "docstring": "Contradiction detection models and logic for ARGUMENT workflow.\n\nProvides data models for tracking contradictions between claims across\nsources, with severity classification and resolution tracking.\n\nUsed in ARGUMENT workflow to identify and analyze conflicting claims,\nassess contradiction severity, and suggest resolutions.\n\nPublic API:\n    - Contradiction: Pydantic model for contradiction representation\n    - ContradictionSeverity: Enum for severity levels (MINOR/MODERATE/MAJOR/CRITICAL)\n    - detect_contradiction: Main entry point for detecting contradictions between two claims\n    - detect_contradictions_batch: Detect contradictions across multiple claims efficiently\n    - generate_contradiction_explanation: Generate human-readable explanation for contradictions\n    - generate_reconciliation_suggestion: Generate suggestions for resolving contradictions\n    - assess_contradiction_severity: Assess severity based on semantic and polarity analysis\n    - detect_polarity_opposition: Detect opposing polarity between claims",
      "classes": [
        "ContradictionSeverity",
        "Contradiction"
      ],
      "functions": [
        "_import_semantic_functions",
        "_import_citation_map",
        "detect_polarity_opposition",
        "assess_contradiction_severity",
        "generate_contradiction_explanation",
        "generate_reconciliation_suggestion",
        "detect_contradiction",
        "detect_contradictions_batch"
      ],
      "imports": [
        "enum.Enum",
        "typing.Any",
        "typing.Dict",
        "typing.Optional",
        "typing.List",
        "typing.Tuple",
        "pydantic.BaseModel",
        "pydantic.Field",
        "pydantic.ConfigDict",
        "pydantic.field_validator",
        "re"
      ],
      "exports": [],
      "lines": 624
    },
    {
      "name": "conversation",
      "file": "model_chorus/src/model_chorus/core/conversation.py",
      "language": "python",
      "docstring": "Conversation memory management for ModelChorus.\n\nProvides file-based persistence for multi-turn conversations with continuation support.\nBased on Zen MCP patterns but adapted for CLI-based orchestration architecture.\n\nKey Features:\n- UUID-based thread identification (continuation_id)\n- File-based persistence (survives process restarts)\n- Thread-safe operations with file locking\n- TTL-based automatic cleanup\n- Context window management for long conversations",
      "classes": [
        "ConversationMemory"
      ],
      "functions": [],
      "imports": [
        "json",
        "uuid",
        "logging",
        "pathlib.Path",
        "datetime.datetime",
        "datetime.timezone",
        "datetime.timedelta",
        "typing.Optional",
        "typing.List",
        "typing.Tuple",
        "typing.Dict",
        "typing.Any",
        "filelock",
        "models.ConversationMessage",
        "models.ConversationThread",
        "models.ConversationState"
      ],
      "exports": [],
      "lines": 694
    },
    {
      "name": "gap_analysis",
      "file": "model_chorus/src/model_chorus/core/gap_analysis.py",
      "language": "python",
      "docstring": "Gap analysis models and logic for ARGUMENT workflow.\n\nProvides data models for identifying and tracking gaps in arguments,\nincluding missing evidence, unsupported claims, and logical gaps.\n\nUsed in ARGUMENT workflow to identify weaknesses, assess coverage,\nand suggest improvements for argument completeness.\n\nPublic API:\n    - Gap: Pydantic model for gap representation\n    - GapType: Enum for gap categories (EVIDENCE/LOGICAL/SUPPORT/ASSUMPTION)\n    - GapSeverity: Enum for severity levels (MINOR/MODERATE/MAJOR/CRITICAL)\n    - detect_gaps: Main entry point for detecting gaps in a set of claims\n    - detect_missing_evidence: Identify claims lacking evidential support\n    - detect_logical_gaps: Identify logical inconsistencies or missing steps\n    - detect_unsupported_claims: Find claims without adequate citations\n    - assess_gap_severity: Assess severity based on gap type and context\n    - generate_gap_recommendation: Generate suggestions for filling gaps",
      "classes": [
        "GapType",
        "GapSeverity",
        "Gap"
      ],
      "functions": [
        "_import_citation_map",
        "assess_gap_severity",
        "generate_gap_recommendation",
        "detect_missing_evidence",
        "detect_logical_gaps",
        "detect_unsupported_claims",
        "detect_gaps"
      ],
      "imports": [
        "enum.Enum",
        "typing.Any",
        "typing.Dict",
        "typing.Optional",
        "typing.List",
        "pydantic.BaseModel",
        "pydantic.Field",
        "pydantic.ConfigDict",
        "pydantic.field_validator"
      ],
      "exports": [],
      "lines": 585
    },
    {
      "name": "models",
      "file": "model_chorus/src/model_chorus/core/models.py",
      "language": "python",
      "docstring": "Pydantic models for ModelChorus workflow requests and responses.\n\nThis module defines the data models used for workflow communication,\nproviding validation and serialization for workflow inputs and outputs.\n\nAdditionally defines conversation infrastructure models for multi-turn\nconversations with continuation support, adapted from Zen MCP patterns.",
      "classes": [
        "ConfidenceLevel",
        "InvestigationPhase",
        "WorkflowRequest",
        "WorkflowResponse",
        "ModelSelection",
        "WorkflowStep",
        "ModelResponse",
        "ConsensusConfig",
        "ConversationMessage",
        "ConversationThread",
        "Hypothesis",
        "InvestigationStep",
        "ThinkDeepState",
        "StudyState",
        "ConversationState",
        "Citation",
        "CitationMap",
        "Claim",
        "Evidence",
        "ArgumentPerspective",
        "ArgumentMap",
        "Idea",
        "IdeaCluster",
        "IdeationState",
        "Source"
      ],
      "functions": [],
      "imports": [
        "enum.Enum",
        "typing.Any",
        "typing.Dict",
        "typing.List",
        "typing.Optional",
        "typing.Literal",
        "pydantic.BaseModel",
        "pydantic.Field",
        "pydantic.ConfigDict"
      ],
      "exports": [],
      "lines": 2152
    },
    {
      "name": "progress",
      "file": "model_chorus/src/model_chorus/core/progress.py",
      "language": "python",
      "docstring": "Progress reporting utilities for ModelChorus workflows.\n\nProvides simple stderr-based progress reporting to enable real-time\nfeedback during multi-step workflow execution.",
      "classes": [],
      "functions": [
        "set_progress_enabled",
        "is_progress_enabled",
        "emit_progress",
        "emit_stage",
        "emit_provider_start",
        "emit_provider_complete",
        "emit_workflow_start",
        "emit_workflow_complete"
      ],
      "imports": [
        "sys",
        "typing.Optional",
        "rich.console.Console"
      ],
      "exports": [],
      "lines": 148
    },
    {
      "name": "prompts",
      "file": "model_chorus/src/model_chorus/core/prompts.py",
      "language": "python",
      "docstring": "Common prompt utilities for ModelChorus workflows.\n\nThis module provides reusable prompt generation and enhancement functions\nfor all ModelChorus workflows, particularly those that invoke external\nCLI tools in read-only mode.",
      "classes": [],
      "functions": [
        "get_read_only_system_prompt",
        "prepend_system_constraints"
      ],
      "imports": [
        "typing.Optional"
      ],
      "exports": [],
      "lines": 70
    },
    {
      "name": "registry",
      "file": "model_chorus/src/model_chorus/core/registry.py",
      "language": "python",
      "docstring": "Workflow registry for ModelChorus plugin system.\n\nThis module provides a registry for dynamically registering and loading\nworkflow implementations, enabling a flexible plugin architecture.",
      "classes": [
        "WorkflowRegistry"
      ],
      "functions": [],
      "imports": [
        "typing.Dict",
        "typing.Type",
        "typing.Optional",
        "typing.Callable",
        "inspect",
        "base_workflow.BaseWorkflow"
      ],
      "exports": [],
      "lines": 220
    },
    {
      "name": "role_orchestration",
      "file": "model_chorus/src/model_chorus/core/role_orchestration.py",
      "language": "python",
      "docstring": "Role-based orchestration framework for sequential and parallel model execution.\n\nProvides infrastructure for coordinating multiple AI models in different roles,\nenabling workflows like ARGUMENT (multi-perspective debate), IDEATE (creative\nbrainstorming with diverse viewpoints), and RESEARCH (multi-source investigation).\n\nThis module defines the core abstractions for role assignment, stance configuration,\nand orchestration patterns that enable sophisticated multi-model workflows.\n\nPublic API:\n    - ModelRole: Data class defining a model's role, stance, and prompt customization\n    - RoleOrchestrator: Coordinator for executing models in assigned roles\n    - OrchestrationPattern: Enum for execution patterns (sequential/parallel/hybrid)\n    - OrchestrationResult: Result data structure from orchestrated execution\n    - SynthesisStrategy: Enum for strategies to combine role outputs",
      "classes": [
        "OrchestrationPattern",
        "SynthesisStrategy",
        "ModelRole",
        "OrchestrationResult",
        "RoleOrchestrator"
      ],
      "functions": [],
      "imports": [
        "asyncio",
        "logging",
        "enum.Enum",
        "typing.Any",
        "typing.Dict",
        "typing.Optional",
        "typing.List",
        "dataclasses.dataclass",
        "dataclasses.field",
        "pydantic.BaseModel",
        "pydantic.Field",
        "pydantic.ConfigDict",
        "pydantic.field_validator"
      ],
      "exports": [],
      "lines": 874
    },
    {
      "name": "state",
      "file": "model_chorus/src/model_chorus/core/state.py",
      "language": "python",
      "docstring": "State persistence layer for ModelChorus workflows.\n\nProvides thread-safe in-memory and optional file-based persistence\nfor workflow state. Complements ConversationMemory by focusing on\nworkflow execution state rather than conversation history.\n\nKey Features:\n- Thread-safe in-memory state storage\n- JSON serialization for Pydantic models\n- Optional file-based persistence\n- State isolation per workflow instance",
      "classes": [
        "StateManager"
      ],
      "functions": [
        "get_default_state_manager"
      ],
      "imports": [
        "json",
        "logging",
        "threading",
        "pathlib.Path",
        "typing.Any",
        "typing.Dict",
        "typing.Optional",
        "datetime.datetime",
        "datetime.timezone",
        "models.ConversationState"
      ],
      "exports": [],
      "lines": 532
    },
    {
      "name": "__init__",
      "file": "model_chorus/src/model_chorus/providers/__init__.py",
      "language": "python",
      "docstring": "Provider integrations for ModelChorus.\n\nThis module contains abstractions and implementations for different\nAI model providers via CLI tools.",
      "classes": [],
      "functions": [],
      "imports": [
        "base_provider.ModelProvider",
        "base_provider.ModelConfig",
        "base_provider.ModelCapability",
        "base_provider.GenerationRequest",
        "base_provider.GenerationResponse",
        "cli_provider.CLIProvider",
        "claude_provider.ClaudeProvider",
        "codex_provider.CodexProvider",
        "gemini_provider.GeminiProvider",
        "cursor_agent_provider.CursorAgentProvider"
      ],
      "exports": [],
      "lines": 32
    },
    {
      "name": "base_provider",
      "file": "model_chorus/src/model_chorus/providers/base_provider.py",
      "language": "python",
      "docstring": "Base provider abstract class for ModelChorus.\n\nThis module defines the abstract base class that all model provider implementations\nmust inherit from, providing a consistent interface for different AI providers\n(Anthropic, OpenAI, Google, etc.).",
      "classes": [
        "ModelCapability",
        "ModelConfig",
        "GenerationRequest",
        "TokenUsage",
        "GenerationResponse",
        "ModelProvider"
      ],
      "functions": [],
      "imports": [
        "abc.ABC",
        "abc.abstractmethod",
        "typing.Any",
        "typing.Dict",
        "typing.List",
        "typing.Optional",
        "dataclasses.dataclass",
        "dataclasses.field",
        "enum.Enum"
      ],
      "exports": [],
      "lines": 345
    },
    {
      "name": "claude_provider",
      "file": "model_chorus/src/model_chorus/providers/claude_provider.py",
      "language": "python",
      "docstring": "Claude CLI provider for ModelChorus.\n\nThis module provides integration with Anthropic's Claude models via the `claude` CLI tool.",
      "classes": [
        "ClaudeProvider"
      ],
      "functions": [],
      "imports": [
        "json",
        "logging",
        "typing.Any",
        "typing.Dict",
        "typing.List",
        "typing.Optional",
        "cli_provider.CLIProvider",
        "base_provider.GenerationRequest",
        "base_provider.GenerationResponse",
        "base_provider.ModelConfig",
        "base_provider.ModelCapability",
        "base_provider.TokenUsage"
      ],
      "exports": [],
      "lines": 278
    },
    {
      "name": "cli_provider",
      "file": "model_chorus/src/model_chorus/providers/cli_provider.py",
      "language": "python",
      "docstring": "CLI-based provider for ModelChorus.\n\nThis module provides the base class for providers that interact with AI models\nvia command-line interface tools (e.g., claude CLI, gemini CLI, codex CLI).",
      "classes": [
        "ProviderUnavailableError",
        "CLIProvider"
      ],
      "functions": [],
      "imports": [
        "asyncio",
        "json",
        "logging",
        "abc.abstractmethod",
        "pathlib.Path",
        "typing.Any",
        "typing.Dict",
        "typing.List",
        "typing.Optional",
        "base_provider.ModelProvider",
        "base_provider.GenerationRequest",
        "base_provider.GenerationResponse"
      ],
      "exports": [],
      "lines": 402
    },
    {
      "name": "codex_provider",
      "file": "model_chorus/src/model_chorus/providers/codex_provider.py",
      "language": "python",
      "docstring": "Codex CLI provider for ModelChorus.\n\nThis module provides integration with OpenAI's Codex models via the `codex` CLI tool.",
      "classes": [
        "CodexProvider"
      ],
      "functions": [],
      "imports": [
        "json",
        "logging",
        "typing.Any",
        "typing.Dict",
        "typing.List",
        "typing.Optional",
        "cli_provider.CLIProvider",
        "base_provider.GenerationRequest",
        "base_provider.GenerationResponse",
        "base_provider.ModelConfig",
        "base_provider.ModelCapability",
        "base_provider.TokenUsage"
      ],
      "exports": [],
      "lines": 275
    },
    {
      "name": "cursor_agent_provider",
      "file": "model_chorus/src/model_chorus/providers/cursor_agent_provider.py",
      "language": "python",
      "docstring": "Cursor Agent CLI provider for ModelChorus.\n\nThis module provides integration with Cursor's AI agent via the `cursor-agent` CLI tool.",
      "classes": [
        "CursorAgentProvider"
      ],
      "functions": [],
      "imports": [
        "json",
        "logging",
        "typing.Any",
        "typing.Dict",
        "typing.List",
        "typing.Optional",
        "cli_provider.CLIProvider",
        "base_provider.GenerationRequest",
        "base_provider.GenerationResponse",
        "base_provider.ModelConfig",
        "base_provider.ModelCapability",
        "base_provider.TokenUsage"
      ],
      "exports": [],
      "lines": 273
    },
    {
      "name": "gemini_provider",
      "file": "model_chorus/src/model_chorus/providers/gemini_provider.py",
      "language": "python",
      "docstring": "Gemini CLI provider for ModelChorus.\n\nThis module provides integration with Google's Gemini models via the `gemini` CLI tool.",
      "classes": [
        "GeminiProvider"
      ],
      "functions": [],
      "imports": [
        "json",
        "logging",
        "typing.Any",
        "typing.Dict",
        "typing.List",
        "typing.Optional",
        "cli_provider.CLIProvider",
        "base_provider.GenerationRequest",
        "base_provider.GenerationResponse",
        "base_provider.ModelConfig",
        "base_provider.ModelCapability"
      ],
      "exports": [],
      "lines": 319
    },
    {
      "name": "__init__",
      "file": "model_chorus/src/model_chorus/utils/__init__.py",
      "language": "python",
      "docstring": "Utility functions and helpers for ModelChorus.\n\nThis module contains shared utilities, helpers, and common functions\nused across the ModelChorus package.",
      "classes": [],
      "functions": [],
      "imports": [
        "model_chorus.utils.citation_formatter.CitationStyle",
        "model_chorus.utils.citation_formatter.format_citation",
        "model_chorus.utils.citation_formatter.format_citation_map",
        "model_chorus.utils.citation_formatter.validate_citation",
        "model_chorus.utils.citation_formatter.calculate_citation_confidence",
        "model_chorus.utils.citation_formatter.calculate_citation_map_confidence"
      ],
      "exports": [],
      "lines": 24
    },
    {
      "name": "citation_formatter",
      "file": "model_chorus/src/model_chorus/utils/citation_formatter.py",
      "language": "python",
      "docstring": "Citation formatting utilities for ModelChorus ARGUMENT workflow.\n\nProvides formatting functions to convert Citation objects into standard\ncitation formats (APA, MLA, Chicago) for academic and professional use.\n\nAlso includes validation and confidence scoring utilities for citation quality\nassessment and verification.",
      "classes": [
        "CitationStyle"
      ],
      "functions": [
        "format_citation",
        "_format_apa",
        "_format_mla",
        "_format_chicago",
        "format_citation_map",
        "validate_citation",
        "calculate_citation_confidence",
        "calculate_citation_map_confidence"
      ],
      "imports": [
        "typing.Optional",
        "typing.List",
        "typing.Dict",
        "typing.Any",
        "typing.Tuple",
        "enum.Enum"
      ],
      "exports": [],
      "lines": 435
    },
    {
      "name": "__init__",
      "file": "model_chorus/src/model_chorus/workflows/__init__.py",
      "language": "python",
      "docstring": "Workflow implementations for ModelChorus.\n\nThis module contains specific workflow types such as thinkdeep, debug,\nconsensus, codereview, precommit, and planner.",
      "classes": [],
      "functions": [],
      "imports": [
        "argument.ArgumentWorkflow",
        "chat.ChatWorkflow",
        "consensus.ConsensusWorkflow",
        "consensus.ConsensusStrategy",
        "consensus.ConsensusResult",
        "consensus.ProviderConfig",
        "ideate.IdeateWorkflow",
        "study.StudyWorkflow",
        "thinkdeep.ThinkDeepWorkflow",
        "core.models.ConfidenceLevel",
        "core.models.Hypothesis",
        "core.models.InvestigationStep",
        "core.models.InvestigationPhase",
        "core.models.StudyState",
        "core.models.ThinkDeepState"
      ],
      "exports": [],
      "lines": 44
    },
    {
      "name": "__init__",
      "file": "model_chorus/src/model_chorus/workflows/argument/__init__.py",
      "language": "python",
      "docstring": "ARGUMENT workflow module for evidence-based argumentation.\n\nProvides semantic similarity computation, claim comparison, clustering,\nand citation analysis for research and argumentation workflows.",
      "classes": [],
      "functions": [],
      "imports": [
        "model_chorus.workflows.argument.argument_workflow.ArgumentWorkflow",
        "model_chorus.workflows.argument.semantic.compute_claim_similarity",
        "model_chorus.workflows.argument.semantic.find_similar_claims",
        "model_chorus.workflows.argument.semantic.compute_embedding",
        "model_chorus.workflows.argument.semantic.cosine_similarity",
        "model_chorus.workflows.argument.semantic.cluster_claims_kmeans",
        "model_chorus.workflows.argument.semantic.cluster_claims_hierarchical",
        "model_chorus.workflows.argument.semantic.get_cluster_representative",
        "model_chorus.workflows.argument.semantic.compute_cluster_statistics"
      ],
      "exports": [],
      "lines": 30
    },
    {
      "name": "argument_workflow",
      "file": "model_chorus/src/model_chorus/workflows/argument/argument_workflow.py",
      "language": "python",
      "docstring": "Argument workflow for structured reasoning and dialectical analysis.\n\nThis module implements the ArgumentWorkflow which provides systematic analysis\nof claims, arguments, and reasoning through a structured workflow that examines\nmultiple perspectives and assesses argument strength.",
      "classes": [
        "ArgumentWorkflow"
      ],
      "functions": [],
      "imports": [
        "logging",
        "uuid",
        "typing.Optional",
        "typing.Dict",
        "typing.Any",
        "typing.List",
        "core.base_workflow.BaseWorkflow",
        "core.base_workflow.WorkflowResult",
        "core.base_workflow.WorkflowStep",
        "core.conversation.ConversationMemory",
        "core.prompts.prepend_system_constraints",
        "core.registry.WorkflowRegistry",
        "core.role_orchestration.RoleOrchestrator",
        "core.role_orchestration.ModelRole",
        "core.role_orchestration.OrchestrationPattern",
        "core.role_orchestration.OrchestrationResult",
        "providers.ModelProvider",
        "providers.GenerationRequest",
        "providers.GenerationResponse",
        "core.models.ConversationMessage",
        "core.models.ArgumentMap",
        "core.models.ArgumentPerspective",
        "core.progress.emit_workflow_start",
        "core.progress.emit_stage",
        "core.progress.emit_workflow_complete"
      ],
      "exports": [],
      "lines": 732
    },
    {
      "name": "semantic",
      "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
      "language": "python",
      "docstring": "Semantic similarity computation for claim comparison in ARGUMENT workflow.\n\nProvides embedding-based similarity computation using sentence transformers\nto identify similar claims, detect redundancy, and enable semantic search\nacross citation maps.",
      "classes": [],
      "functions": [
        "_get_model",
        "_normalize_text",
        "_compute_embedding_cached",
        "compute_embedding",
        "cosine_similarity",
        "compute_claim_similarity",
        "find_similar_claims",
        "compute_claim_similarity_batch",
        "add_similarity_to_citation",
        "find_duplicate_claims",
        "cluster_claims_kmeans",
        "cluster_claims_hierarchical",
        "get_cluster_representative",
        "generate_cluster_name",
        "summarize_cluster",
        "compute_cluster_statistics",
        "score_cluster_coherence",
        "score_cluster_separation",
        "score_clustering_quality"
      ],
      "imports": [
        "hashlib",
        "typing.List",
        "typing.Dict",
        "typing.Tuple",
        "typing.Optional",
        "typing.Any",
        "functools.lru_cache",
        "numpy",
        "sentence_transformers.SentenceTransformer",
        "model_chorus.core.models.Citation",
        "model_chorus.core.models.CitationMap"
      ],
      "exports": [],
      "lines": 997
    },
    {
      "name": "chat",
      "file": "model_chorus/src/model_chorus/workflows/chat.py",
      "language": "python",
      "docstring": "Chat workflow for single-model peer consultation with conversation threading.\n\nThis module implements the ChatWorkflow which provides simple, straightforward\nconsultation with a single AI model while maintaining conversation continuity\nthrough threading.",
      "classes": [
        "ChatWorkflow"
      ],
      "functions": [],
      "imports": [
        "logging",
        "uuid",
        "typing.Optional",
        "typing.Dict",
        "typing.Any",
        "typing.List",
        "core.base_workflow.BaseWorkflow",
        "core.base_workflow.WorkflowResult",
        "core.base_workflow.WorkflowStep",
        "core.conversation.ConversationMemory",
        "core.prompts.prepend_system_constraints",
        "providers.ModelProvider",
        "providers.GenerationRequest",
        "providers.GenerationResponse",
        "core.models.ConversationMessage",
        "core.progress.emit_workflow_start",
        "core.progress.emit_workflow_complete"
      ],
      "exports": [],
      "lines": 459
    },
    {
      "name": "consensus",
      "file": "model_chorus/src/model_chorus/workflows/consensus.py",
      "language": "python",
      "docstring": "Consensus workflow for multi-model coordination.\n\nThis module implements the ConsensusWorkflow which enables querying multiple\nAI models simultaneously and synthesizing their responses for improved accuracy\nand reliability.",
      "classes": [
        "ConsensusStrategy",
        "ProviderConfig",
        "ConsensusResult",
        "ConsensusWorkflow"
      ],
      "functions": [],
      "imports": [
        "asyncio",
        "logging",
        "typing.List",
        "typing.Dict",
        "typing.Any",
        "typing.Optional",
        "dataclasses.dataclass",
        "dataclasses.field",
        "dataclasses.replace",
        "enum.Enum",
        "providers.ModelProvider",
        "providers.GenerationRequest",
        "providers.GenerationResponse",
        "core.progress.emit_workflow_start",
        "core.progress.emit_provider_start",
        "core.progress.emit_provider_complete",
        "core.progress.emit_workflow_complete"
      ],
      "exports": [],
      "lines": 372
    },
    {
      "name": "__init__",
      "file": "model_chorus/src/model_chorus/workflows/ideate/__init__.py",
      "language": "python",
      "docstring": "Ideate workflow for brainstorming and creative idea generation.",
      "classes": [],
      "functions": [],
      "imports": [
        "ideate_workflow.IdeateWorkflow"
      ],
      "exports": [],
      "lines": 7
    },
    {
      "name": "ideate_workflow",
      "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
      "language": "python",
      "docstring": "Ideate workflow for brainstorming and creative idea generation.\n\nThis module implements the IdeateWorkflow which provides systematic ideation\nthrough structured brainstorming sessions with creative prompting.",
      "classes": [
        "IdeateWorkflow"
      ],
      "functions": [],
      "imports": [
        "logging",
        "uuid",
        "datetime.datetime",
        "datetime.timezone",
        "typing.Optional",
        "typing.Dict",
        "typing.Any",
        "typing.List",
        "core.base_workflow.BaseWorkflow",
        "core.base_workflow.WorkflowResult",
        "core.base_workflow.WorkflowStep",
        "core.conversation.ConversationMemory",
        "core.registry.WorkflowRegistry",
        "core.role_orchestration.RoleOrchestrator",
        "core.role_orchestration.ModelRole",
        "core.role_orchestration.OrchestrationPattern",
        "core.role_orchestration.OrchestrationResult",
        "providers.ModelProvider",
        "providers.GenerationRequest",
        "providers.GenerationResponse",
        "core.models.ConversationMessage",
        "core.progress.emit_workflow_start",
        "core.progress.emit_workflow_complete"
      ],
      "exports": [],
      "lines": 2314
    },
    {
      "name": "__init__",
      "file": "model_chorus/src/model_chorus/workflows/study/__init__.py",
      "language": "python",
      "docstring": "STUDY workflow module for persona-based collaborative research.\n\nProvides multi-persona investigation workflows with role-based orchestration,\nconversation memory, and systematic hypothesis exploration.",
      "classes": [],
      "functions": [],
      "imports": [
        "study_workflow.StudyWorkflow"
      ],
      "exports": [],
      "lines": 10
    },
    {
      "name": "config",
      "file": "model_chorus/src/model_chorus/workflows/study/config.py",
      "language": "python",
      "docstring": "Configuration dataclasses for STUDY workflow.\n\nThis module defines configuration options and defaults for persona-based\ncollaborative research investigations.",
      "classes": [
        "PersonaConfig",
        "StudyConfig",
        "InvestigationResult"
      ],
      "functions": [],
      "imports": [
        "dataclasses.dataclass",
        "dataclasses.field",
        "typing.Dict",
        "typing.Any",
        "typing.List",
        "typing.Optional"
      ],
      "exports": [],
      "lines": 105
    },
    {
      "name": "context_analysis",
      "file": "model_chorus/src/model_chorus/workflows/study/context_analysis.py",
      "language": "python",
      "docstring": "Context analysis skill for Study workflow persona consultation.\n\nThis module provides context analysis before persona invocation, determining\nwhich persona to consult next based on current investigation state, findings,\nand unresolved questions.\n\nSkill Input Parameters:\n    current_phase: Current investigation phase (discovery/validation/planning/complete)\n    confidence: Current confidence level (0-100 or ConfidenceLevel enum value)\n    findings: List of findings/insights discovered so far\n    unresolved_questions: List of questions still needing investigation\n    prior_persona: Previously consulted persona name (optional)",
      "classes": [
        "ContextAnalysisInput",
        "ContextAnalysisResult"
      ],
      "functions": [
        "_select_persona_by_phase_and_state",
        "analyze_context"
      ],
      "imports": [
        "dataclasses.dataclass",
        "dataclasses.field",
        "dataclasses.asdict",
        "typing.Optional",
        "typing.List",
        "typing.Dict",
        "typing.Any",
        "json",
        "pydantic.BaseModel",
        "pydantic.Field",
        "pydantic.field_validator",
        "core.models.InvestigationPhase",
        "core.models.ConfidenceLevel"
      ],
      "exports": [],
      "lines": 383
    },
    {
      "name": "__init__",
      "file": "model_chorus/src/model_chorus/workflows/study/memory/__init__.py",
      "language": "python",
      "docstring": "Memory system for STUDY workflow persona-based investigations.\n\nThis package implements a two-tier memory architecture for persona-based collaborative\nresearch, enabling context retention and knowledge accumulation across investigation steps.\n\nArchitecture:\n-----------\n\nTwo-Tier Memory System:\n    1. Short-term Cache (In-Memory):\n       - Fast access for active investigation data\n       - Persona-specific context for current investigation\n       - Hypothesis tracking and intermediate findings\n       - Session-based lifecycle\n\n    2. Long-term Persistence (SQLite):\n       - Durable storage for completed investigations\n       - Cross-investigation knowledge retrieval\n       - Historical context and patterns\n       - Searchable investigation archives\n\nIntegration with Core:\n    - Complements core.conversation.ConversationMemory with persona-aware capabilities\n    - ConversationMemory: Message-level threading and turn management\n    - PersonaMemory: Investigation-level context and knowledge retention\n    - Both work together to provide complete memory coverage\n\nMemory Lifecycle:\n    1. Investigation Start: Create new memory context in cache\n    2. Active Investigation: Store findings, hypotheses, persona interactions in cache\n    3. Investigation Complete: Persist important findings to long-term storage\n    4. Future Investigations: Retrieve relevant historical context from persistence\n\nKey Features:\n    - Persona-specific memory contexts (what each persona knows/remembers)\n    - Automatic memory summarization and pruning\n    - Context-aware retrieval (find relevant past investigations)\n    - Memory consolidation (cache \u2192 persistence)\n    - Investigation threading (link related investigations)\n\nComponents:\n----------\n    models.py: Data models for memory entries and metadata\n    cache.py: In-memory short-term cache implementation\n    persistence.py: SQLite-based long-term persistence layer\n    controller.py: Memory controller coordinating cache and persistence\n\nUsage:\n-----\n    >>> from model_chorus.workflows.study.memory import MemoryController\n    >>>\n    >>> # Create memory system\n    >>> memory = MemoryController()\n    >>>\n    >>> # Store investigation finding\n    >>> memory.store(\n    ...     persona_id=\"researcher\",\n    ...     content=\"Found pattern X in dataset Y\",\n    ...     context_type=\"finding\",\n    ...     investigation_id=\"inv-123\"\n    ... )\n    >>>\n    >>> # Retrieve persona-specific context\n    >>> context = memory.get_context(\n    ...     persona_id=\"researcher\",\n    ...     investigation_id=\"inv-123\"\n    ... )\n\nFuture Extensions:\n    - Vector embeddings for semantic similarity search\n    - Cross-persona memory sharing and consensus\n    - Memory importance scoring and automatic summarization\n    - Investigation dependency tracking",
      "classes": [],
      "functions": [],
      "imports": [
        "models.MemoryEntry",
        "models.MemoryMetadata",
        "models.MemoryType",
        "models.MemoryQuery",
        "cache.ShortTermCache",
        "persistence.LongTermStorage",
        "controller.MemoryController"
      ],
      "exports": [],
      "lines": 97
    },
    {
      "name": "cache",
      "file": "model_chorus/src/model_chorus/workflows/study/memory/cache.py",
      "language": "python",
      "docstring": "In-memory short-term cache for STUDY workflow memory system.\n\nThis module implements a fast, LRU-based cache for active investigation memory entries.\nThe cache provides quick access to recent findings and context without persistence overhead.\n\nArchitecture:\n- LRU (Least Recently Used) eviction policy using OrderedDict\n- Configurable maximum size (default 100 entries)\n- Thread-safe operations for concurrent access\n- Statistics tracking (hits, misses, evictions)",
      "classes": [
        "ShortTermCache"
      ],
      "functions": [],
      "imports": [
        "logging",
        "threading",
        "collections.OrderedDict",
        "typing.Dict",
        "typing.List",
        "typing.Optional",
        "datetime.datetime",
        "datetime.timezone",
        "models.MemoryEntry",
        "models.MemoryMetadata",
        "models.MemoryQuery"
      ],
      "exports": [],
      "lines": 315
    },
    {
      "name": "controller",
      "file": "model_chorus/src/model_chorus/workflows/study/memory/controller.py",
      "language": "python",
      "docstring": "Memory controller coordinating short-term cache and long-term persistence.\n\nThis module provides a unified interface for memory operations that transparently\ncoordinates between the fast in-memory cache and durable SQLite persistence.\n\nArchitecture:\n- Write-through caching: Writes go to both cache and persistence\n- Cache-first reads: Check cache first, fall back to persistence\n- Automatic promotion: Persistence reads are cached for future access\n- Configurable persistence policy (write-through, write-back, manual)",
      "classes": [
        "MemoryController"
      ],
      "functions": [],
      "imports": [
        "logging",
        "uuid",
        "typing.List",
        "typing.Optional",
        "datetime.datetime",
        "datetime.timezone",
        "models.MemoryEntry",
        "models.MemoryMetadata",
        "models.MemoryQuery",
        "cache.ShortTermCache",
        "persistence.LongTermStorage"
      ],
      "exports": [],
      "lines": 383
    },
    {
      "name": "models",
      "file": "model_chorus/src/model_chorus/workflows/study/memory/models.py",
      "language": "python",
      "docstring": "Pydantic models for STUDY workflow memory system.\n\nThis module defines the data models used for memory entries, metadata,\nand memory operations in the persona-based investigation workflow.\n\nThe models support a two-tier memory architecture:\n- Short-term cache: MemoryEntry instances in memory\n- Long-term persistence: Serialized MemoryEntry stored in SQLite",
      "classes": [
        "MemoryType",
        "MemoryEntry",
        "MemoryMetadata",
        "MemoryQuery"
      ],
      "functions": [],
      "imports": [
        "datetime.datetime",
        "datetime.timezone",
        "typing.Any",
        "typing.Dict",
        "typing.List",
        "typing.Optional",
        "enum.Enum",
        "pydantic.BaseModel",
        "pydantic.Field",
        "pydantic.ConfigDict"
      ],
      "exports": [],
      "lines": 319
    },
    {
      "name": "persistence",
      "file": "model_chorus/src/model_chorus/workflows/study/memory/persistence.py",
      "language": "python",
      "docstring": "SQLite-based long-term persistence for STUDY workflow memory system.\n\nThis module implements durable storage for completed investigations and\nimportant findings using SQLite. Provides searchable archives of historical\ninvestigation data with support for complex queries and cross-investigation\nknowledge retrieval.\n\nArchitecture:\n- SQLite database with normalized schema\n- Three tables: investigations, memory_entries, memory_references\n- Connection pooling and transaction management\n- Full-text search support (future enhancement)",
      "classes": [
        "LongTermStorage"
      ],
      "functions": [],
      "imports": [
        "logging",
        "sqlite3",
        "json",
        "pathlib.Path",
        "typing.List",
        "typing.Optional",
        "typing.Dict",
        "typing.Any",
        "datetime.datetime",
        "datetime.timezone",
        "models.MemoryEntry",
        "models.MemoryMetadata",
        "models.MemoryQuery",
        "models.MemoryType"
      ],
      "exports": [],
      "lines": 532
    },
    {
      "name": "persona_base",
      "file": "model_chorus/src/model_chorus/workflows/study/persona_base.py",
      "language": "python",
      "docstring": "Persona implementations for STUDY workflow.\n\nThis module defines the Persona dataclass and related persona management\nfor persona-based collaborative research.",
      "classes": [
        "PersonaResponse",
        "Persona",
        "PersonaRegistry"
      ],
      "functions": [],
      "imports": [
        "dataclasses.dataclass",
        "dataclasses.field",
        "typing.Optional",
        "typing.Dict",
        "typing.List",
        "typing.Any"
      ],
      "exports": [],
      "lines": 122
    },
    {
      "name": "persona_router",
      "file": "model_chorus/src/model_chorus/workflows/study/persona_router.py",
      "language": "python",
      "docstring": "Persona router for Study workflow.\n\nThis module provides persona routing functionality, determining which persona\nto consult next based on current investigation state using the context analysis skill.",
      "classes": [
        "RoutingDecision",
        "RoutingHistoryEntry",
        "PersonaRouter"
      ],
      "functions": [],
      "imports": [
        "logging",
        "typing.Optional",
        "typing.List",
        "typing.Dict",
        "typing.Any",
        "typing.Tuple",
        "dataclasses.dataclass",
        "dataclasses.field",
        "datetime.datetime",
        "core.models.StudyState",
        "persona_base.Persona",
        "persona_base.PersonaRegistry",
        "context_analysis.ContextAnalysisInput",
        "context_analysis.ContextAnalysisResult",
        "context_analysis.analyze_context"
      ],
      "exports": [],
      "lines": 421
    },
    {
      "name": "__init__",
      "file": "model_chorus/src/model_chorus/workflows/study/personas/__init__.py",
      "language": "python",
      "docstring": "Persona implementations for STUDY workflow.\n\nThis package contains concrete persona implementations for the study workflow,\nincluding Researcher, Critic, Planner, and other specialized investigation personas.",
      "classes": [],
      "functions": [
        "create_default_personas",
        "get_default_registry"
      ],
      "imports": [
        "persona_base.PersonaRegistry",
        "researcher.ResearcherPersona",
        "researcher.create_researcher",
        "critic.CriticPersona",
        "critic.create_critic",
        "planner.PlannerPersona",
        "planner.create_planner"
      ],
      "exports": [],
      "lines": 49
    },
    {
      "name": "critic",
      "file": "model_chorus/src/model_chorus/workflows/study/personas/critic.py",
      "language": "python",
      "docstring": "Critic persona implementation for STUDY workflow.\n\nThe Critic persona focuses on challenging assumptions, identifying edge cases,\nand stress-testing conclusions through rigorous scrutiny.",
      "classes": [
        "CriticPersona"
      ],
      "functions": [
        "create_critic"
      ],
      "imports": [
        "typing.Dict",
        "typing.Any",
        "typing.List",
        "persona_base.Persona",
        "persona_base.PersonaResponse"
      ],
      "exports": [],
      "lines": 134
    },
    {
      "name": "planner",
      "file": "model_chorus/src/model_chorus/workflows/study/personas/planner.py",
      "language": "python",
      "docstring": "Planner persona implementation for STUDY workflow.\n\nThe Planner persona focuses on synthesizing findings into actionable roadmaps,\ncreating structured plans, and defining next steps.",
      "classes": [
        "PlannerPersona"
      ],
      "functions": [
        "create_planner"
      ],
      "imports": [
        "typing.Dict",
        "typing.Any",
        "typing.List",
        "persona_base.Persona",
        "persona_base.PersonaResponse"
      ],
      "exports": [],
      "lines": 135
    },
    {
      "name": "researcher",
      "file": "model_chorus/src/model_chorus/workflows/study/personas/researcher.py",
      "language": "python",
      "docstring": "Researcher persona implementation for STUDY workflow.\n\nThe Researcher persona focuses on systematic investigation, deep analysis,\nand comprehensive exploration of topics.",
      "classes": [
        "ResearcherPersona"
      ],
      "functions": [
        "create_researcher"
      ],
      "imports": [
        "typing.Dict",
        "typing.Any",
        "typing.List",
        "persona_base.Persona",
        "persona_base.PersonaResponse"
      ],
      "exports": [],
      "lines": 125
    },
    {
      "name": "state_machine",
      "file": "model_chorus/src/model_chorus/workflows/study/state_machine.py",
      "language": "python",
      "docstring": "State machine for Study workflow investigation phases.\n\nThis module implements phase transition logic for persona-based investigations,\nensuring systematic progression through DISCOVERY \u2192 VALIDATION \u2192 PLANNING \u2192 COMPLETE.",
      "classes": [
        "InvestigationStateMachine"
      ],
      "functions": [],
      "imports": [
        "logging",
        "typing.Optional",
        "typing.List",
        "typing.Dict",
        "typing.Any",
        "enum.Enum",
        "core.models.InvestigationPhase",
        "core.models.StudyState",
        "core.models.ConfidenceLevel"
      ],
      "exports": [],
      "lines": 284
    },
    {
      "name": "study_workflow",
      "file": "model_chorus/src/model_chorus/workflows/study/study_workflow.py",
      "language": "python",
      "docstring": "STUDY workflow for persona-based collaborative research.\n\nThis module implements the StudyWorkflow which provides multi-persona investigation\nwith role-based orchestration, conversation memory, and systematic exploration.",
      "classes": [
        "StudyWorkflow"
      ],
      "functions": [],
      "imports": [
        "logging",
        "uuid",
        "datetime.datetime",
        "datetime.timezone",
        "typing.Optional",
        "typing.Dict",
        "typing.Any",
        "typing.List",
        "core.base_workflow.BaseWorkflow",
        "core.base_workflow.WorkflowResult",
        "core.base_workflow.WorkflowStep",
        "core.conversation.ConversationMemory",
        "core.registry.WorkflowRegistry",
        "core.role_orchestration.RoleOrchestrator",
        "core.role_orchestration.ModelRole",
        "core.role_orchestration.OrchestrationPattern",
        "core.role_orchestration.OrchestrationResult",
        "providers.ModelProvider",
        "providers.GenerationRequest",
        "providers.GenerationResponse",
        "core.models.ConversationMessage",
        "core.progress.emit_workflow_start",
        "core.progress.emit_workflow_complete",
        "persona_router.PersonaRouter",
        "personas.get_default_registry"
      ],
      "exports": [],
      "lines": 451
    },
    {
      "name": "thinkdeep",
      "file": "model_chorus/src/model_chorus/workflows/thinkdeep.py",
      "language": "python",
      "docstring": "ThinkDeep workflow for extended reasoning and systematic investigation.\n\nThis module implements the ThinkDeepWorkflow which provides multi-step\ninvestigation with hypothesis tracking, evidence collection, and confidence\nprogression across conversation turns.",
      "classes": [
        "ThinkDeepWorkflow"
      ],
      "functions": [],
      "imports": [
        "logging",
        "uuid",
        "typing.Optional",
        "typing.Dict",
        "typing.Any",
        "typing.List",
        "core.base_workflow.BaseWorkflow",
        "core.base_workflow.WorkflowResult",
        "core.base_workflow.WorkflowStep",
        "core.conversation.ConversationMemory",
        "providers.ModelProvider",
        "providers.GenerationRequest",
        "providers.GenerationResponse",
        "core.models.ConversationMessage",
        "core.models.ThinkDeepState",
        "core.models.Hypothesis",
        "core.models.InvestigationStep",
        "core.models.ConfidenceLevel",
        "core.progress.emit_workflow_start",
        "core.progress.emit_workflow_complete",
        "core.progress.emit_progress"
      ],
      "exports": [],
      "lines": 1060
    },
    {
      "name": "__init__",
      "file": "model_chorus/tests/__init__.py",
      "language": "python",
      "docstring": "Tests for ModelChorus CLI-based multi-model workflow package.\n\nThis test suite covers:\n- CLI providers (ClaudeProvider, CodexProvider)\n- Consensus workflow\n- Integration tests",
      "classes": [],
      "functions": [],
      "imports": [],
      "exports": [],
      "lines": 8
    },
    {
      "name": "conftest",
      "file": "model_chorus/tests/conftest.py",
      "language": "python",
      "docstring": "Pytest configuration and fixtures for ModelChorus tests.",
      "classes": [],
      "functions": [
        "mock_claude_response",
        "mock_codex_response",
        "mock_subprocess_run",
        "sample_generation_request"
      ],
      "imports": [
        "pytest",
        "unittest.mock.AsyncMock",
        "unittest.mock.MagicMock"
      ],
      "exports": [],
      "lines": 65
    },
    {
      "name": "test_chat_integration",
      "file": "model_chorus/tests/test_chat_integration.py",
      "language": "python",
      "docstring": "Integration tests for ChatWorkflow with multiple providers.\n\nTests chat functionality with Claude, Gemini, and Codex providers to ensure\nmulti-provider compatibility and conversation continuity.",
      "classes": [
        "TestMultiProviderChat",
        "TestChatErrorHandling",
        "TestChatThreadManagement",
        "TestLongConversations"
      ],
      "functions": [
        "is_provider_available",
        "conversation_memory",
        "provider_name",
        "provider",
        "chat_workflow"
      ],
      "imports": [
        "pytest",
        "os",
        "pathlib.Path",
        "model_chorus.workflows.ChatWorkflow",
        "model_chorus.providers.ClaudeProvider",
        "model_chorus.providers.GeminiProvider",
        "model_chorus.providers.CodexProvider",
        "model_chorus.core.conversation.ConversationMemory"
      ],
      "exports": [],
      "lines": 489
    },
    {
      "name": "test_chat_workflow",
      "file": "model_chorus/tests/test_chat_workflow.py",
      "language": "python",
      "docstring": "Tests for ChatWorkflow functionality.\n\nTests conversation initiation, continuation, file context, and conversation tracking.",
      "classes": [
        "TestChatWorkflowInitialization",
        "TestConversationInitiation",
        "TestConversationContinuation",
        "TestFileContext",
        "TestConversationTracking",
        "TestErrorHandling"
      ],
      "functions": [
        "mock_provider",
        "conversation_memory",
        "chat_workflow"
      ],
      "imports": [
        "pytest",
        "uuid",
        "unittest.mock.AsyncMock",
        "unittest.mock.MagicMock",
        "unittest.mock.patch",
        "pathlib.Path",
        "model_chorus.workflows.ChatWorkflow",
        "model_chorus.providers.base_provider.GenerationRequest",
        "model_chorus.providers.base_provider.GenerationResponse",
        "model_chorus.core.conversation.ConversationMemory"
      ],
      "exports": [],
      "lines": 384
    },
    {
      "name": "test_citation",
      "file": "model_chorus/tests/test_citation.py",
      "language": "python",
      "docstring": "Unit tests for Citation and CitationMap models.\n\nTests verify citation tracking functionality including:\n- Citation model creation, validation, and field constraints\n- CitationMap model for claim-to-citation mapping\n- Model serialization and deserialization\n- Edge cases and validation errors\n- Integration scenarios for evidence tracking",
      "classes": [
        "TestCitation",
        "TestCitationMap",
        "TestCitationIntegration"
      ],
      "functions": [],
      "imports": [
        "json",
        "pytest",
        "pydantic.ValidationError",
        "model_chorus.core.models.Citation",
        "model_chorus.core.models.CitationMap"
      ],
      "exports": [],
      "lines": 724
    },
    {
      "name": "test_claude_provider",
      "file": "model_chorus/tests/test_claude_provider.py",
      "language": "python",
      "docstring": "Tests for ClaudeProvider CLI integration.",
      "classes": [
        "TestClaudeProvider"
      ],
      "functions": [],
      "imports": [
        "json",
        "pytest",
        "unittest.mock.AsyncMock",
        "unittest.mock.patch",
        "model_chorus.providers.claude_provider.ClaudeProvider",
        "model_chorus.providers.base_provider.GenerationRequest"
      ],
      "exports": [],
      "lines": 203
    },
    {
      "name": "test_codex_provider",
      "file": "model_chorus/tests/test_codex_provider.py",
      "language": "python",
      "docstring": "Tests for CodexProvider CLI integration.",
      "classes": [
        "TestCodexProvider"
      ],
      "functions": [],
      "imports": [
        "json",
        "pytest",
        "unittest.mock.AsyncMock",
        "unittest.mock.patch",
        "model_chorus.providers.codex_provider.CodexProvider",
        "model_chorus.providers.base_provider.GenerationRequest"
      ],
      "exports": [],
      "lines": 210
    },
    {
      "name": "test_config",
      "file": "model_chorus/tests/test_config.py",
      "language": "python",
      "docstring": "Unit tests for configuration module.\n\nTests verify configuration loading, validation, and default behavior including:\n- Config file discovery and loading (YAML and JSON)\n- Configuration validation with Pydantic models\n- Default value precedence (workflow-specific > global > fallback)\n- Provider configuration (single and multi-provider)\n- Config management CLI commands",
      "classes": [
        "TestConfigLoader",
        "TestWorkflowConfigValidation",
        "TestComplexConfigScenarios"
      ],
      "functions": [],
      "imports": [
        "json",
        "pytest",
        "pathlib.Path",
        "model_chorus.core.config.ConfigLoader",
        "model_chorus.core.config.GenerationDefaults",
        "model_chorus.core.config.WorkflowConfig",
        "model_chorus.core.config.ModelChorusConfig",
        "model_chorus.core.config.get_config_loader"
      ],
      "exports": [],
      "lines": 527
    },
    {
      "name": "test_consensus_workflow",
      "file": "model_chorus/tests/test_consensus_workflow.py",
      "language": "python",
      "docstring": "Tests for Consensus workflow.",
      "classes": [
        "TestConsensusWorkflow"
      ],
      "functions": [],
      "imports": [
        "pytest",
        "unittest.mock.AsyncMock",
        "model_chorus.workflows.consensus.ConsensusWorkflow",
        "model_chorus.workflows.consensus.ConsensusStrategy",
        "model_chorus.providers.base_provider.GenerationResponse",
        "model_chorus.providers.base_provider.GenerationRequest"
      ],
      "exports": [],
      "lines": 142
    },
    {
      "name": "test_conversation",
      "file": "model_chorus/tests/test_conversation.py",
      "language": "python",
      "docstring": "Unit tests for conversation infrastructure.\n\nTests verify ConversationMemory functionality including:\n- Thread creation with UUID generation\n- Continuation ID handling\n- Message persistence\n- Thread lifecycle management\n- File-based storage",
      "classes": [
        "TestConversationMemory"
      ],
      "functions": [],
      "imports": [
        "json",
        "pytest",
        "uuid",
        "pathlib.Path",
        "datetime.datetime",
        "datetime.timezone",
        "model_chorus.core.conversation.ConversationMemory",
        "model_chorus.core.models.ConversationMessage",
        "model_chorus.core.models.ConversationThread"
      ],
      "exports": [],
      "lines": 246
    },
    {
      "name": "test_gemini_integration",
      "file": "model_chorus/tests/test_gemini_integration.py",
      "language": "python",
      "docstring": "Integration tests for GeminiProvider.\n\nThese tests verify that the Gemini CLI integration works correctly with real CLI calls.",
      "classes": [
        "TestGeminiIntegration"
      ],
      "functions": [],
      "imports": [
        "pytest",
        "subprocess",
        "model_chorus.providers.gemini_provider.GeminiProvider",
        "model_chorus.providers.base_provider.GenerationRequest"
      ],
      "exports": [],
      "lines": 148
    },
    {
      "name": "test_ideate_workflow",
      "file": "model_chorus/tests/test_ideate_workflow.py",
      "language": "python",
      "docstring": "Tests for IdeateWorkflow functionality.\n\nTests divergent brainstorming, convergent analysis, and complete ideation workflow.",
      "classes": [
        "TestIdeateWorkflowInitialization",
        "TestConvergentAnalysis",
        "TestIdeaExtraction",
        "TestIdeaClustering",
        "TestIdeaScoring",
        "TestCompleteIdeation"
      ],
      "functions": [
        "mock_provider",
        "ideate_workflow",
        "mock_brainstorming_result"
      ],
      "imports": [
        "pytest",
        "unittest.mock.AsyncMock",
        "unittest.mock.MagicMock",
        "typing.Dict",
        "typing.Any",
        "model_chorus.workflows.ideate.ideate_workflow.IdeateWorkflow",
        "model_chorus.providers.base_provider.GenerationRequest",
        "model_chorus.providers.base_provider.GenerationResponse",
        "model_chorus.core.base_workflow.WorkflowResult",
        "model_chorus.core.base_workflow.WorkflowStep",
        "model_chorus.core.models.ConversationMessage"
      ],
      "exports": [],
      "lines": 414
    },
    {
      "name": "test_integration",
      "file": "model_chorus/tests/test_integration.py",
      "language": "python",
      "docstring": "Integration tests for ModelChorus.\n\nThese tests verify that components work together correctly.\nNote: These tests use mocks to avoid calling actual CLI tools.",
      "classes": [
        "TestIntegration"
      ],
      "functions": [],
      "imports": [
        "pytest",
        "unittest.mock.patch",
        "unittest.mock.AsyncMock",
        "model_chorus.workflows.consensus.ConsensusWorkflow",
        "model_chorus.workflows.consensus.ConsensusStrategy",
        "model_chorus.providers.base_provider.GenerationResponse",
        "model_chorus.providers.base_provider.GenerationRequest",
        "model_chorus.providers.claude_provider.ClaudeProvider",
        "model_chorus.providers.codex_provider.CodexProvider"
      ],
      "exports": [],
      "lines": 187
    },
    {
      "name": "test_review_response",
      "file": "model_chorus/tests/test_review_response.py",
      "language": "python",
      "docstring": "Tests for review response parsing and validation.",
      "classes": [],
      "functions": [
        "review_json_path",
        "review_json_data",
        "test_review_json_exists",
        "test_review_json_valid_json",
        "test_review_json_has_required_fields",
        "test_overall_score_valid",
        "test_recommendation_valid",
        "test_dimension_scores_structure",
        "test_issues_structure",
        "test_strengths_structure",
        "test_review_response_consistency",
        "test_issues_have_locations",
        "test_review_response_completeness"
      ],
      "imports": [
        "json",
        "pytest",
        "pathlib.Path"
      ],
      "exports": [],
      "lines": 143
    },
    {
      "name": "test_semantic_similarity",
      "file": "model_chorus/tests/test_semantic_similarity.py",
      "language": "python",
      "docstring": "Unit tests for semantic similarity computation in ARGUMENT workflow.\n\nTests embedding computation, similarity scoring, claim comparison,\nand integration with Citation/CitationMap models.",
      "classes": [
        "TestEmbeddingComputation",
        "TestCosineSimilarity",
        "TestClaimSimilarity",
        "TestFindSimilarClaims",
        "TestBatchSimilarity",
        "TestCitationIntegration",
        "TestDuplicateDetection",
        "TestEdgeCases",
        "TestKMeansClustering",
        "TestHierarchicalClustering",
        "TestClusterRepresentative",
        "TestClusterStatistics",
        "TestClusteringIntegration"
      ],
      "functions": [],
      "imports": [
        "pytest",
        "numpy",
        "model_chorus.core.models.Citation",
        "model_chorus.core.models.CitationMap",
        "model_chorus.workflows.argument.semantic.compute_embedding",
        "model_chorus.workflows.argument.semantic.cosine_similarity",
        "model_chorus.workflows.argument.semantic.compute_claim_similarity",
        "model_chorus.workflows.argument.semantic.find_similar_claims",
        "model_chorus.workflows.argument.semantic.compute_claim_similarity_batch",
        "model_chorus.workflows.argument.semantic.add_similarity_to_citation",
        "model_chorus.workflows.argument.semantic.find_duplicate_claims",
        "model_chorus.workflows.argument.semantic.cluster_claims_kmeans",
        "model_chorus.workflows.argument.semantic.cluster_claims_hierarchical",
        "model_chorus.workflows.argument.semantic.get_cluster_representative",
        "model_chorus.workflows.argument.semantic.compute_cluster_statistics"
      ],
      "exports": [],
      "lines": 804
    },
    {
      "name": "test_state",
      "file": "model_chorus/tests/test_state.py",
      "language": "python",
      "docstring": "Unit tests for state persistence layer.\n\nTests verify StateManager functionality including:\n- In-memory state storage and retrieval\n- Thread-safe concurrent operations\n- JSON serialization and deserialization\n- File-based persistence (when enabled)\n- Error handling and edge cases",
      "classes": [
        "TestStateManager",
        "TestStateManagerExportImportRoundtrip",
        "TestStateManagerFileRecovery"
      ],
      "functions": [],
      "imports": [
        "json",
        "pytest",
        "threading",
        "time",
        "pathlib.Path",
        "datetime.datetime",
        "datetime.timezone",
        "model_chorus.core.state.StateManager",
        "model_chorus.core.state.get_default_state_manager",
        "model_chorus.core.models.ConversationState"
      ],
      "exports": [],
      "lines": 682
    },
    {
      "name": "test_thinkdeep_models",
      "file": "model_chorus/tests/test_thinkdeep_models.py",
      "language": "python",
      "docstring": "Unit tests for ThinkDeep workflow models.\n\nTests verify ThinkDeep model functionality including:\n- ConfidenceLevel enum values and progression\n- Hypothesis model creation, validation, and evidence tracking\n- InvestigationStep model with findings and confidence\n- ThinkDeepState model with hypothesis and step management\n- Model serialization and deserialization\n- Edge cases and validation errors",
      "classes": [
        "TestConfidenceLevel",
        "TestHypothesis",
        "TestInvestigationStep",
        "TestThinkDeepState",
        "TestModelIntegration"
      ],
      "functions": [],
      "imports": [
        "json",
        "pytest",
        "pydantic.ValidationError",
        "model_chorus.core.models.ConfidenceLevel",
        "model_chorus.core.models.Hypothesis",
        "model_chorus.core.models.InvestigationStep",
        "model_chorus.core.models.ThinkDeepState"
      ],
      "exports": [],
      "lines": 687
    },
    {
      "name": "__init__",
      "file": "model_chorus/tests/workflows/study/memory/__init__.py",
      "language": "python",
      "docstring": "Tests for STUDY workflow memory system.",
      "classes": [],
      "functions": [],
      "imports": [],
      "exports": [],
      "lines": 1
    },
    {
      "name": "test_persistence",
      "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
      "language": "python",
      "docstring": "Tests for memory persistence layer (LongTermStorage).\n\nVerifies that memory entries are correctly persisted to SQLite,\nretrieved accurately, and survive across sessions.",
      "classes": [],
      "functions": [
        "temp_db",
        "storage",
        "test_save_and_retrieve",
        "test_persistence_across_sessions",
        "test_query_by_investigation",
        "test_query_by_persona",
        "test_delete",
        "test_memory_references",
        "test_get_metadata"
      ],
      "imports": [
        "pytest",
        "tempfile",
        "os",
        "pathlib.Path",
        "model_chorus.workflows.study.memory.MemoryEntry",
        "model_chorus.workflows.study.memory.MemoryQuery",
        "model_chorus.workflows.study.memory.MemoryType",
        "model_chorus.workflows.study.memory.LongTermStorage"
      ],
      "exports": [],
      "lines": 210
    },
    {
      "name": "test_personas",
      "file": "model_chorus/tests/workflows/study/test_personas.py",
      "language": "python",
      "docstring": "Tests for persona system in STUDY workflow.\n\nTests verify that:\n- Persona dataclasses work correctly (Persona, PersonaResponse)\n- PersonaRegistry manages personas properly\n- Individual persona implementations work as expected\n- Persona factory functions create correctly configured instances\n- Default registry is properly initialized",
      "classes": [
        "TestPersonaResponse",
        "TestPersona",
        "TestPersonaRegistry",
        "TestResearcherPersona",
        "TestCriticPersona",
        "TestPlannerPersona",
        "TestPersonaFactories",
        "TestPersonaIntegration"
      ],
      "functions": [],
      "imports": [
        "pytest",
        "model_chorus.workflows.study.persona_base.Persona",
        "model_chorus.workflows.study.persona_base.PersonaResponse",
        "model_chorus.workflows.study.persona_base.PersonaRegistry",
        "model_chorus.workflows.study.personas.ResearcherPersona",
        "model_chorus.workflows.study.personas.CriticPersona",
        "model_chorus.workflows.study.personas.PlannerPersona",
        "model_chorus.workflows.study.personas.create_researcher",
        "model_chorus.workflows.study.personas.create_critic",
        "model_chorus.workflows.study.personas.create_planner",
        "model_chorus.workflows.study.personas.get_default_registry",
        "model_chorus.workflows.study.personas.create_default_personas"
      ],
      "exports": [],
      "lines": 616
    },
    {
      "name": "test_routing",
      "file": "model_chorus/tests/workflows/study/test_routing.py",
      "language": "python",
      "docstring": "Tests for PersonaRouter and routing functionality in STUDY workflow.\n\nTests cover:\n- Routing skill invocation and JSON output\n- Fallback routing when context analysis fails\n- Routing decision structure and metadata\n- Integration with StudyWorkflow",
      "classes": [
        "TestRoutingSkillInvocation",
        "TestFallbackRouting",
        "TestRoutingHistory",
        "TestStudyWorkflowIntegration"
      ],
      "functions": [],
      "imports": [
        "pytest",
        "unittest.mock.Mock",
        "unittest.mock.patch",
        "model_chorus.workflows.study.persona_router.PersonaRouter",
        "model_chorus.workflows.study.persona_router.RoutingDecision",
        "model_chorus.workflows.study.persona_base.Persona",
        "model_chorus.workflows.study.persona_base.PersonaRegistry",
        "model_chorus.workflows.study.personas.get_default_registry",
        "model_chorus.core.models.StudyState"
      ],
      "exports": [],
      "lines": 374
    },
    {
      "name": "test_state_machine",
      "file": "model_chorus/tests/workflows/study/test_state_machine.py",
      "language": "python",
      "docstring": "Tests for Study workflow state machine.\n\nTests verify that the InvestigationStateMachine correctly implements\nvalid phase transitions and confidence escalation logic.",
      "classes": [
        "TestInvestigationStateMachineTransitions",
        "TestConfidenceLevelProgression",
        "TestStateTransitionIntegration"
      ],
      "functions": [],
      "imports": [
        "pytest",
        "model_chorus.core.models.InvestigationPhase",
        "model_chorus.core.models.StudyState",
        "model_chorus.core.models.ConfidenceLevel",
        "model_chorus.workflows.study.state_machine.InvestigationStateMachine"
      ],
      "exports": [],
      "lines": 457
    },
    {
      "name": "test_study_workflow",
      "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
      "language": "python",
      "docstring": "Tests for StudyWorkflow.\n\nTests verify that the StudyWorkflow correctly:\n- Initializes with providers and persona router\n- Executes investigation workflow with role-based personas\n- Manages conversation threading and history\n- Handles errors gracefully\n- Integrates with PersonaRouter for intelligent persona selection",
      "classes": [
        "TestStudyWorkflowInitialization",
        "TestStudyWorkflowRun",
        "TestStudyWorkflowPersonaSetup",
        "TestStudyWorkflowConversationHandling",
        "TestStudyWorkflowInvestigation",
        "TestStudyWorkflowSynthesis",
        "TestStudyWorkflowErrorHandling",
        "TestStudyWorkflowRoutingHistory",
        "TestStudyWorkflowIntegration"
      ],
      "functions": [],
      "imports": [
        "pytest",
        "unittest.mock.Mock",
        "unittest.mock.patch",
        "unittest.mock.AsyncMock",
        "unittest.mock.MagicMock",
        "datetime.datetime",
        "datetime.timezone",
        "model_chorus.workflows.study.study_workflow.StudyWorkflow",
        "model_chorus.core.base_workflow.WorkflowResult",
        "model_chorus.core.base_workflow.WorkflowStep",
        "model_chorus.core.conversation.ConversationMemory",
        "model_chorus.core.models.ConversationMessage"
      ],
      "exports": [],
      "lines": 674
    },
    {
      "name": "test_backward_compat",
      "file": "test_backward_compat.py",
      "language": "python",
      "docstring": "Test backward compatibility and different response formats",
      "classes": [],
      "functions": [],
      "imports": [
        "json",
        "sys"
      ],
      "exports": [],
      "lines": 104
    },
    {
      "name": "test_codex_parse",
      "file": "test_codex_parse.py",
      "language": "python",
      "docstring": "Test that code_blocks and language metadata are preserved in raw_response",
      "classes": [],
      "functions": [],
      "imports": [
        "json",
        "sys"
      ],
      "exports": [],
      "lines": 111
    },
    {
      "name": "test_parse_response",
      "file": "test_parse_response.py",
      "language": "python",
      "docstring": "Test script to verify CursorAgentProvider.parse_response() implementation",
      "classes": [],
      "functions": [],
      "imports": [
        "json",
        "sys"
      ],
      "exports": [],
      "lines": 87
    },
    {
      "name": "__init__",
      "file": "tests/__init__.py",
      "language": "python",
      "docstring": "Tests for ModelChorus package.",
      "classes": [],
      "functions": [],
      "imports": [],
      "exports": [],
      "lines": 1
    },
    {
      "name": "test_argument_workflow",
      "file": "tests/test_argument_workflow.py",
      "language": "python",
      "docstring": "Tests for ArgumentWorkflow functionality.\n\nTests the complete dialectical analysis workflow including Creator (thesis),\nSkeptic (rebuttal), and Moderator (synthesis) roles, ArgumentMap generation,\nand conversation threading.",
      "classes": [
        "TestArgumentWorkflowInitialization",
        "TestRoleCreation",
        "TestArgumentMapGeneration",
        "TestArgumentWorkflowExecution",
        "TestConversationThreading",
        "TestErrorHandling"
      ],
      "functions": [
        "mock_provider",
        "conversation_memory",
        "argument_workflow"
      ],
      "imports": [
        "pytest",
        "uuid",
        "unittest.mock.AsyncMock",
        "unittest.mock.MagicMock",
        "unittest.mock.patch",
        "pathlib.Path",
        "model_chorus.workflows.argument.ArgumentWorkflow",
        "model_chorus.providers.base_provider.GenerationRequest",
        "model_chorus.providers.base_provider.GenerationResponse",
        "model_chorus.core.conversation.ConversationMemory",
        "model_chorus.core.models.ArgumentMap",
        "model_chorus.core.models.ArgumentPerspective",
        "model_chorus.core.role_orchestration.OrchestrationResult",
        "model_chorus.core.role_orchestration.OrchestrationPattern"
      ],
      "exports": [],
      "lines": 503
    },
    {
      "name": "test_citation",
      "file": "tests/test_citation.py",
      "language": "python",
      "docstring": "Tests for citation formatting and validation utilities.\n\nVerifies that the citation engine validates and formats citations correctly\naccording to different academic styles (APA, MLA, Chicago).",
      "classes": [
        "TestCitationFormatting",
        "TestCitationMapFormatting",
        "TestCitationValidation",
        "TestCitationConfidenceScoring",
        "TestCitationMapConfidenceScoring",
        "TestCitationStyleEnum"
      ],
      "functions": [
        "complete_citation",
        "minimal_citation",
        "file_citation",
        "doi_citation",
        "citation_map_complete",
        "citation_map_empty"
      ],
      "imports": [
        "pytest",
        "model_chorus.core.models.Citation",
        "model_chorus.core.models.CitationMap",
        "model_chorus.utils.citation_formatter.CitationStyle",
        "model_chorus.utils.citation_formatter.format_citation",
        "model_chorus.utils.citation_formatter.format_citation_map",
        "model_chorus.utils.citation_formatter.validate_citation",
        "model_chorus.utils.citation_formatter.calculate_citation_confidence",
        "model_chorus.utils.citation_formatter.calculate_citation_map_confidence"
      ],
      "exports": [],
      "lines": 537
    },
    {
      "name": "test_cli_integration",
      "file": "tests/test_cli_integration.py",
      "language": "python",
      "docstring": "Integration tests for ModelChorus CLI commands.\n\nTests the complete CLI interface including argument and ideate commands\nwith various parameters, options, and error conditions.",
      "classes": [
        "TestArgumentCommand",
        "TestIdeateCommand",
        "TestThinkDeepCommand",
        "TestErrorHandling",
        "TestCommandIntegration"
      ],
      "functions": [
        "cli_runner",
        "mock_provider",
        "mock_workflow_result",
        "temp_test_file",
        "temp_output_file"
      ],
      "imports": [
        "json",
        "importlib",
        "sys",
        "pytest",
        "pathlib.Path",
        "typer.testing.CliRunner",
        "unittest.mock.AsyncMock",
        "unittest.mock.MagicMock",
        "unittest.mock.patch",
        "unittest.mock.mock_open",
        "model_chorus.cli.main.app",
        "model_chorus.providers.base_provider.GenerationResponse",
        "model_chorus.core.base_workflow.WorkflowResult",
        "model_chorus.core.base_workflow.WorkflowStep"
      ],
      "exports": [],
      "lines": 852
    },
    {
      "name": "test_clustering",
      "file": "tests/test_clustering.py",
      "language": "python",
      "docstring": "Unit tests for the semantic clustering algorithm.\n\nTests verify that:\n- Embeddings are computed correctly and cached properly\n- Similarity metrics work as expected\n- K-means clustering produces valid results\n- Hierarchical clustering produces valid results\n- Cluster naming and summarization work correctly\n- Cluster quality scoring is accurate\n- Edge cases are handled properly",
      "classes": [
        "TestClusterResult",
        "TestSemanticClustering",
        "TestClusteringIntegration"
      ],
      "functions": [
        "_check_sentence_transformers_available"
      ],
      "imports": [
        "pytest",
        "numpy",
        "unittest.mock.Mock",
        "unittest.mock.patch",
        "unittest.mock.MagicMock",
        "model_chorus.core.clustering.SemanticClustering",
        "model_chorus.core.clustering.ClusterResult"
      ],
      "exports": [],
      "lines": 432
    },
    {
      "name": "test_concurrent_conversations",
      "file": "tests/test_concurrent_conversations.py",
      "language": "python",
      "docstring": "Concurrency and performance tests for ConversationMemory.\n\nTests verify that ConversationMemory can handle:\n- 100+ concurrent conversation threads\n- Thread-safe operations under parallel access\n- Memory management under high load\n- Thread isolation (no cross-contamination between conversations)",
      "classes": [
        "TestConcurrentConversationHandling"
      ],
      "functions": [],
      "imports": [
        "pytest",
        "asyncio",
        "unittest.mock.AsyncMock",
        "uuid",
        "concurrent.futures.ThreadPoolExecutor",
        "time",
        "datetime.datetime",
        "datetime.timezone",
        "model_chorus.workflows.chat.ChatWorkflow",
        "model_chorus.workflows.thinkdeep.ThinkDeepWorkflow",
        "model_chorus.providers.base_provider.GenerationResponse",
        "model_chorus.core.conversation.ConversationMemory",
        "model_chorus.core.models.ConversationMessage"
      ],
      "exports": [],
      "lines": 372
    },
    {
      "name": "test_consensus_provider_models",
      "file": "tests/test_consensus_provider_models.py",
      "language": "python",
      "docstring": "Tests for provider-level metadata handling within the consensus workflow.",
      "classes": [],
      "functions": [
        "_make_provider",
        "test_consensus_applies_provider_model_override_without_mutation",
        "test_shared_request_model_overrides_provider_metadata"
      ],
      "imports": [
        "sys",
        "pathlib.Path",
        "unittest.mock.AsyncMock",
        "pytest",
        "model_chorus.providers.base_provider.GenerationRequest",
        "model_chorus.providers.base_provider.GenerationResponse",
        "model_chorus.workflows.consensus.ConsensusWorkflow"
      ],
      "exports": [],
      "lines": 90
    },
    {
      "name": "test_contradiction",
      "file": "tests/test_contradiction.py",
      "language": "python",
      "docstring": "Tests for contradiction detection module.\n\nVerifies that contradiction detection identifies conflicts accurately\nwith appropriate severity levels.",
      "classes": [
        "TestPolarityOpposition",
        "TestSeverityAssessment",
        "TestContradictionExplanation",
        "TestReconciliationSuggestions",
        "TestContradictionModel",
        "TestContradictionDetection",
        "TestBatchContradictionDetection",
        "TestRealisticScenarios"
      ],
      "functions": [],
      "imports": [
        "pytest",
        "model_chorus.core.contradiction.Contradiction",
        "model_chorus.core.contradiction.ContradictionSeverity",
        "model_chorus.core.contradiction.detect_contradiction",
        "model_chorus.core.contradiction.detect_contradictions_batch",
        "model_chorus.core.contradiction.detect_polarity_opposition",
        "model_chorus.core.contradiction.assess_contradiction_severity",
        "model_chorus.core.contradiction.generate_contradiction_explanation",
        "model_chorus.core.contradiction.generate_reconciliation_suggestion"
      ],
      "exports": [],
      "lines": 422
    },
    {
      "name": "test_gap_analysis",
      "file": "tests/test_gap_analysis.py",
      "language": "python",
      "docstring": "Tests for gap analysis module.\n\nVerifies that gap detection identifies missing evidence, logical gaps,\nand unsupported claims accurately with appropriate severity levels.",
      "classes": [
        "TestGapModel",
        "TestSeverityAssessment",
        "TestGapRecommendations",
        "TestMissingEvidenceDetection",
        "TestLogicalGapDetection",
        "TestUnsupportedClaimsDetection",
        "TestComprehensiveGapDetection",
        "TestRealisticScenarios"
      ],
      "functions": [],
      "imports": [
        "pytest",
        "model_chorus.core.gap_analysis.Gap",
        "model_chorus.core.gap_analysis.GapType",
        "model_chorus.core.gap_analysis.GapSeverity",
        "model_chorus.core.gap_analysis.detect_gaps",
        "model_chorus.core.gap_analysis.detect_missing_evidence",
        "model_chorus.core.gap_analysis.detect_logical_gaps",
        "model_chorus.core.gap_analysis.detect_unsupported_claims",
        "model_chorus.core.gap_analysis.assess_gap_severity",
        "model_chorus.core.gap_analysis.generate_gap_recommendation"
      ],
      "exports": [],
      "lines": 558
    },
    {
      "name": "test_ideate_workflow",
      "file": "tests/test_ideate_workflow.py",
      "language": "python",
      "docstring": "Tests for IdeateWorkflow functionality.\n\nTests the complete ideation workflow including parallel brainstorming,\nconvergent analysis (extraction, clustering, scoring), interactive selection,\nand elaboration into detailed outlines.",
      "classes": [
        "TestIdeateWorkflowInitialization",
        "TestBasicIdeation",
        "TestRoleCreation",
        "TestParallelBrainstorming",
        "TestConvergentAnalysis",
        "TestInteractiveSelection",
        "TestElaboration",
        "TestCompleteIdeation",
        "TestErrorHandling",
        "TestSystemPrompts",
        "TestPromptFraming"
      ],
      "functions": [
        "mock_provider",
        "conversation_memory",
        "ideate_workflow"
      ],
      "imports": [
        "pytest",
        "uuid",
        "unittest.mock.AsyncMock",
        "unittest.mock.MagicMock",
        "unittest.mock.patch",
        "pathlib.Path",
        "model_chorus.workflows.ideate.IdeateWorkflow",
        "model_chorus.providers.base_provider.GenerationRequest",
        "model_chorus.providers.base_provider.GenerationResponse",
        "model_chorus.core.conversation.ConversationMemory",
        "model_chorus.core.models.Idea",
        "model_chorus.core.models.IdeaCluster",
        "model_chorus.core.models.IdeationState",
        "model_chorus.core.role_orchestration.OrchestrationResult",
        "model_chorus.core.role_orchestration.OrchestrationPattern"
      ],
      "exports": [],
      "lines": 877
    },
    {
      "name": "test_memory_management",
      "file": "tests/test_memory_management.py",
      "language": "python",
      "docstring": "Memory management tests for ConversationMemory with long conversations.\n\nTests verify that:\n- Memory usage doesn't grow unbounded with long conversations\n- Context window limits are respected\n- Old conversation cleanup works properly\n- No memory leaks from conversation storage",
      "classes": [
        "TestMemoryManagement"
      ],
      "functions": [],
      "imports": [
        "pytest",
        "asyncio",
        "unittest.mock.AsyncMock",
        "uuid",
        "sys",
        "model_chorus.workflows.chat.ChatWorkflow",
        "model_chorus.workflows.thinkdeep.ThinkDeepWorkflow",
        "model_chorus.providers.base_provider.GenerationResponse",
        "model_chorus.core.conversation.ConversationMemory"
      ],
      "exports": [],
      "lines": 339
    },
    {
      "name": "__init__",
      "file": "tests/test_providers/__init__.py",
      "language": "python",
      "docstring": "Tests for provider implementations.",
      "classes": [],
      "functions": [],
      "imports": [],
      "exports": [],
      "lines": 1
    },
    {
      "name": "test_cli_interface",
      "file": "tests/test_providers/test_cli_interface.py",
      "language": "python",
      "docstring": "Test CLI providers implement the ModelProvider interface correctly.\n\nThis test suite verifies that all CLI-based providers (CLIProvider, ClaudeProvider,\nCodexProvider, GeminiProvider, CursorAgentProvider) properly implement the\nModelProvider abstract interface.",
      "classes": [
        "TestCLIProvidersImplementInterface"
      ],
      "functions": [],
      "imports": [
        "sys",
        "pathlib.Path",
        "pytest",
        "model_chorus.providers.ModelProvider",
        "model_chorus.providers.CLIProvider",
        "model_chorus.providers.ClaudeProvider",
        "model_chorus.providers.CodexProvider",
        "model_chorus.providers.GeminiProvider",
        "model_chorus.providers.CursorAgentProvider",
        "model_chorus.providers.GenerationRequest"
      ],
      "exports": [],
      "lines": 175
    },
    {
      "name": "test_role_orchestration",
      "file": "tests/test_role_orchestration.py",
      "language": "python",
      "docstring": "Unit tests for role-based orchestration framework.\n\nTests verify that:\n- ModelRole correctly validates input and constructs prompts\n- OrchestrationResult properly stores execution metadata\n- RoleOrchestrator handles initialization, provider resolution\n- Sequential execution pattern works correctly\n- Parallel execution pattern works correctly\n- Synthesis strategies combine outputs appropriately\n- Error handling and edge cases are managed properly",
      "classes": [
        "MockGenerationRequest",
        "MockGenerationResponse",
        "MockProvider",
        "TestModelRole",
        "TestOrchestrationResult",
        "TestRoleOrchestrator",
        "TestEnums"
      ],
      "functions": [],
      "imports": [
        "pytest",
        "asyncio",
        "unittest.mock.Mock",
        "unittest.mock.AsyncMock",
        "unittest.mock.patch",
        "dataclasses.dataclass",
        "typing.Optional",
        "typing.Dict",
        "typing.Any",
        "model_chorus.core.role_orchestration.ModelRole",
        "model_chorus.core.role_orchestration.OrchestrationPattern",
        "model_chorus.core.role_orchestration.OrchestrationResult",
        "model_chorus.core.role_orchestration.RoleOrchestrator",
        "model_chorus.core.role_orchestration.SynthesisStrategy"
      ],
      "exports": [],
      "lines": 730
    },
    {
      "name": "test_thinkdeep_complex",
      "file": "tests/test_thinkdeep_complex.py",
      "language": "python",
      "docstring": "Complex problem investigation tests for ThinkDeep workflow.\n\nTests verify ThinkDeepWorkflow handles complex scenarios including:\n- Architectural decision making with pros/cons analysis\n- Bug investigation with systematic debugging\n- Multi-step reasoning and hypothesis evolution\n- Long-form problem analysis",
      "classes": [
        "TestArchitecturalDecisionScenarios",
        "TestBugInvestigationScenarios",
        "TestComplexMultiStepReasoning"
      ],
      "functions": [],
      "imports": [
        "pytest",
        "unittest.mock.AsyncMock",
        "unittest.mock.MagicMock",
        "unittest.mock.patch",
        "uuid",
        "model_chorus.workflows.thinkdeep.ThinkDeepWorkflow",
        "model_chorus.providers.base_provider.GenerationResponse",
        "model_chorus.providers.base_provider.GenerationRequest",
        "model_chorus.core.conversation.ConversationMemory",
        "model_chorus.core.models.ConfidenceLevel",
        "model_chorus.core.models.Hypothesis",
        "model_chorus.core.models.InvestigationStep",
        "model_chorus.core.models.ThinkDeepState"
      ],
      "exports": [],
      "lines": 844
    },
    {
      "name": "test_thinkdeep_expert_validation",
      "file": "tests/test_thinkdeep_expert_validation.py",
      "language": "python",
      "docstring": "Expert validation flow tests for ThinkDeep workflow.\n\nTests verify expert validation functionality including:\n- Expert provider integration and triggering\n- Confidence-based validation triggering\n- Multiple expert models coordination\n- Expert validation result handling\n- Error handling when expert validation fails",
      "classes": [
        "TestExpertProviderIntegration",
        "TestExpertValidationTriggering",
        "TestExpertValidationResultHandling",
        "TestExpertValidationErrorHandling",
        "TestExpertValidationWithHypotheses"
      ],
      "functions": [],
      "imports": [
        "pytest",
        "unittest.mock.AsyncMock",
        "unittest.mock.MagicMock",
        "unittest.mock.patch",
        "uuid",
        "model_chorus.workflows.thinkdeep.ThinkDeepWorkflow",
        "model_chorus.providers.base_provider.GenerationResponse",
        "model_chorus.providers.base_provider.GenerationRequest",
        "model_chorus.core.conversation.ConversationMemory",
        "model_chorus.core.models.ConfidenceLevel",
        "model_chorus.core.models.Hypothesis",
        "model_chorus.core.models.InvestigationStep",
        "model_chorus.core.models.ThinkDeepState"
      ],
      "exports": [],
      "lines": 705
    },
    {
      "name": "test_thinkdeep_workflow",
      "file": "tests/test_thinkdeep_workflow.py",
      "language": "python",
      "docstring": "Integration tests for ThinkDeep workflow.\n\nTests verify ThinkDeepWorkflow functionality including:\n- Investigation step execution and tracking\n- Multi-step investigation with state management\n- Conversation threading and continuation\n- Hypothesis management through workflow\n- Confidence progression tracking\n- File examination tracking\n- Expert validation integration",
      "classes": [
        "TestInvestigationStepExecution",
        "TestHypothesisEvolution",
        "TestConfidenceProgression",
        "TestEndToEndIntegration"
      ],
      "functions": [],
      "imports": [
        "pytest",
        "unittest.mock.AsyncMock",
        "unittest.mock.MagicMock",
        "unittest.mock.patch",
        "uuid",
        "model_chorus.workflows.thinkdeep.ThinkDeepWorkflow",
        "model_chorus.providers.base_provider.GenerationResponse",
        "model_chorus.providers.base_provider.GenerationRequest",
        "model_chorus.core.conversation.ConversationMemory",
        "model_chorus.core.models.ConfidenceLevel",
        "model_chorus.core.models.Hypothesis",
        "model_chorus.core.models.InvestigationStep",
        "model_chorus.core.models.ThinkDeepState"
      ],
      "exports": [],
      "lines": 2007
    },
    {
      "name": "test_workflow_integration_chaining",
      "file": "tests/test_workflow_integration_chaining.py",
      "language": "python",
      "docstring": "Integration tests for workflow chaining patterns.\n\nTests verify that different workflows can be chained together effectively,\ndemonstrating ModelChorus's orchestration capabilities:\n- Consensus \u2192 ThinkDeep \u2192 Chat workflow integration\n- Context preservation across workflow boundaries\n- Continuation ID management across workflow types",
      "classes": [
        "TestConsensusThinkDeepChatChaining"
      ],
      "functions": [],
      "imports": [
        "sys",
        "uuid",
        "pathlib.Path",
        "unittest.mock.AsyncMock",
        "unittest.mock.patch",
        "pytest",
        "model_chorus.workflows.consensus.ConsensusWorkflow",
        "model_chorus.workflows.consensus.ConsensusStrategy",
        "model_chorus.workflows.thinkdeep.ThinkDeepWorkflow",
        "model_chorus.workflows.chat.ChatWorkflow",
        "model_chorus.providers.base_provider.GenerationResponse",
        "model_chorus.providers.base_provider.GenerationRequest",
        "model_chorus.core.conversation.ConversationMemory"
      ],
      "exports": [],
      "lines": 352
    },
    {
      "name": "test_cache",
      "file": "tests/workflows/study/memory/test_cache.py",
      "language": "python",
      "docstring": "Tests for memory cache layer (ShortTermCache).\n\nVerifies LRU eviction, cache promotion, metrics tracking,\nand overall cache behavior.",
      "classes": [],
      "functions": [
        "cache",
        "test_lru_eviction",
        "test_cache_metrics_hits_and_misses",
        "test_cache_eviction_metric",
        "test_cache_update_existing",
        "test_cache_delete",
        "test_cache_query",
        "test_cache_clear",
        "test_cache_metadata"
      ],
      "imports": [
        "pytest",
        "model_chorus.workflows.study.memory.MemoryEntry",
        "model_chorus.workflows.study.memory.MemoryQuery",
        "model_chorus.workflows.study.memory.MemoryType",
        "model_chorus.workflows.study.memory.ShortTermCache"
      ],
      "exports": [],
      "lines": 229
    }
  ],
  "classes": [
    {
      "name": "ExampleWorkflow",
      "file": "model_chorus/examples/basic_workflow.py",
      "line": 14,
      "language": "python",
      "docstring": "Example workflow that demonstrates basic workflow structure.\n\nThis is a placeholder implementation showing the minimal structure\nneeded to create a working workflow.",
      "bases": [
        "BaseWorkflow"
      ],
      "methods": [
        "run"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "ExampleProvider",
      "file": "model_chorus/examples/provider_integration.py",
      "line": 18,
      "language": "python",
      "docstring": "Example provider implementation.\n\nThis is a placeholder showing how to implement a custom provider\nfor ModelChorus. In a real implementation, this would integrate\nwith an actual AI provider's API.",
      "bases": [
        "ModelProvider"
      ],
      "methods": [
        "__init__",
        "generate",
        "supports_vision"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "main",
          "file": "model_chorus/examples/provider_integration.py",
          "line": 108,
          "context": [
            "main"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 1
    },
    {
      "name": "WorkflowStep",
      "file": "model_chorus/src/model_chorus/core/base_workflow.py",
      "line": 26,
      "language": "python",
      "docstring": "Represents a single step in a workflow execution.",
      "bases": [],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "add_step",
          "file": "model_chorus/src/model_chorus/core/base_workflow.py",
          "line": 49,
          "context": [
            "WorkflowResult",
            "add_step"
          ]
        },
        {
          "instantiator": "run",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 228,
          "context": [
            "IdeateWorkflow",
            "run"
          ]
        },
        {
          "instantiator": "run_parallel_brainstorming",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 451,
          "context": [
            "IdeateWorkflow",
            "run_parallel_brainstorming"
          ]
        },
        {
          "instantiator": "_extract_ideas",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 666,
          "context": [
            "IdeateWorkflow",
            "_extract_ideas"
          ]
        },
        {
          "instantiator": "_cluster_ideas",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 862,
          "context": [
            "IdeateWorkflow",
            "_cluster_ideas"
          ]
        },
        {
          "instantiator": "_score_ideas",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 1085,
          "context": [
            "IdeateWorkflow",
            "_score_ideas"
          ]
        },
        {
          "instantiator": "run_interactive_selection",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 1660,
          "context": [
            "IdeateWorkflow",
            "run_interactive_selection"
          ]
        },
        {
          "instantiator": "_elaborate_cluster",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 2065,
          "context": [
            "IdeateWorkflow",
            "_elaborate_cluster"
          ]
        },
        {
          "instantiator": "_conduct_investigation",
          "file": "model_chorus/src/model_chorus/workflows/study/study_workflow.py",
          "line": 378,
          "context": [
            "StudyWorkflow",
            "_conduct_investigation"
          ]
        },
        {
          "instantiator": "mock_brainstorming_result",
          "file": "model_chorus/tests/test_ideate_workflow.py",
          "line": 127,
          "context": [
            "mock_brainstorming_result"
          ]
        },
        {
          "instantiator": "mock_brainstorming_result",
          "file": "model_chorus/tests/test_ideate_workflow.py",
          "line": 137,
          "context": [
            "mock_brainstorming_result"
          ]
        },
        {
          "instantiator": "mock_brainstorming_result",
          "file": "model_chorus/tests/test_ideate_workflow.py",
          "line": 147,
          "context": [
            "mock_brainstorming_result"
          ]
        },
        {
          "instantiator": "test_synthesize_findings_returns_string",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 465,
          "context": [
            "TestStudyWorkflowSynthesis",
            "test_synthesize_findings_returns_string"
          ]
        },
        {
          "instantiator": "test_synthesize_findings_multiple_steps",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 487,
          "context": [
            "TestStudyWorkflowSynthesis",
            "test_synthesize_findings_multiple_steps"
          ]
        },
        {
          "instantiator": "test_synthesize_findings_multiple_steps",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 488,
          "context": [
            "TestStudyWorkflowSynthesis",
            "test_synthesize_findings_multiple_steps"
          ]
        },
        {
          "instantiator": "test_synthesize_findings_multiple_steps",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 489,
          "context": [
            "TestStudyWorkflowSynthesis",
            "test_synthesize_findings_multiple_steps"
          ]
        },
        {
          "instantiator": "test_synthesize_includes_step_count",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 501,
          "context": [
            "TestStudyWorkflowSynthesis",
            "test_synthesize_includes_step_count"
          ]
        },
        {
          "instantiator": "test_synthesize_includes_step_count",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 502,
          "context": [
            "TestStudyWorkflowSynthesis",
            "test_synthesize_includes_step_count"
          ]
        },
        {
          "instantiator": "mock_workflow_result",
          "file": "tests/test_cli_integration.py",
          "line": 66,
          "context": [
            "mock_workflow_result"
          ]
        },
        {
          "instantiator": "test_argument_with_continuation",
          "file": "tests/test_cli_integration.py",
          "line": 173,
          "context": [
            "TestArgumentCommand",
            "test_argument_with_continuation"
          ]
        },
        {
          "instantiator": "test_ideate_with_continuation",
          "file": "tests/test_cli_integration.py",
          "line": 441,
          "context": [
            "TestIdeateCommand",
            "test_ideate_with_continuation"
          ]
        },
        {
          "instantiator": "mock_brainstorming_result",
          "file": "tests/test_ideate_workflow.py",
          "line": 357,
          "context": [
            "TestConvergentAnalysis",
            "mock_brainstorming_result"
          ]
        },
        {
          "instantiator": "mock_brainstorming_result",
          "file": "tests/test_ideate_workflow.py",
          "line": 363,
          "context": [
            "TestConvergentAnalysis",
            "mock_brainstorming_result"
          ]
        },
        {
          "instantiator": "test_idea_clustering",
          "file": "tests/test_ideate_workflow.py",
          "line": 422,
          "context": [
            "TestConvergentAnalysis",
            "test_idea_clustering"
          ]
        },
        {
          "instantiator": "test_idea_scoring",
          "file": "tests/test_ideate_workflow.py",
          "line": 453,
          "context": [
            "TestConvergentAnalysis",
            "test_idea_scoring"
          ]
        },
        {
          "instantiator": "mock_convergent_result",
          "file": "tests/test_ideate_workflow.py",
          "line": 500,
          "context": [
            "TestInteractiveSelection",
            "mock_convergent_result"
          ]
        },
        {
          "instantiator": "mock_convergent_result",
          "file": "tests/test_ideate_workflow.py",
          "line": 517,
          "context": [
            "TestInteractiveSelection",
            "mock_convergent_result"
          ]
        },
        {
          "instantiator": "mock_selection_result",
          "file": "tests/test_ideate_workflow.py",
          "line": 588,
          "context": [
            "TestElaboration",
            "mock_selection_result"
          ]
        },
        {
          "instantiator": "test_clustering_with_no_extracted_ideas",
          "file": "tests/test_ideate_workflow.py",
          "line": 785,
          "context": [
            "TestErrorHandling",
            "test_clustering_with_no_extracted_ideas"
          ]
        },
        {
          "instantiator": "test_scoring_with_no_clusters",
          "file": "tests/test_ideate_workflow.py",
          "line": 800,
          "context": [
            "TestErrorHandling",
            "test_scoring_with_no_clusters"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 30
    },
    {
      "name": "WorkflowResult",
      "file": "model_chorus/src/model_chorus/core/base_workflow.py",
      "line": 37,
      "language": "python",
      "docstring": "Result of a workflow execution.",
      "bases": [],
      "methods": [
        "add_step"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "run",
          "file": "model_chorus/examples/basic_workflow.py",
          "line": 34,
          "context": [
            "ExampleWorkflow",
            "run"
          ]
        },
        {
          "instantiator": "run",
          "file": "model_chorus/src/model_chorus/workflows/argument/argument_workflow.py",
          "line": 450,
          "context": [
            "ArgumentWorkflow",
            "run"
          ]
        },
        {
          "instantiator": "run",
          "file": "model_chorus/src/model_chorus/workflows/chat.py",
          "line": 201,
          "context": [
            "ChatWorkflow",
            "run"
          ]
        },
        {
          "instantiator": "run",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 255,
          "context": [
            "IdeateWorkflow",
            "run"
          ]
        },
        {
          "instantiator": "run_parallel_brainstorming",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 468,
          "context": [
            "IdeateWorkflow",
            "run_parallel_brainstorming"
          ]
        },
        {
          "instantiator": "run_convergent_analysis",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 595,
          "context": [
            "IdeateWorkflow",
            "run_convergent_analysis"
          ]
        },
        {
          "instantiator": "run_complete_ideation",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 1551,
          "context": [
            "IdeateWorkflow",
            "run_complete_ideation"
          ]
        },
        {
          "instantiator": "run_interactive_selection",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 1673,
          "context": [
            "IdeateWorkflow",
            "run_interactive_selection"
          ]
        },
        {
          "instantiator": "run_elaboration",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 2006,
          "context": [
            "IdeateWorkflow",
            "run_elaboration"
          ]
        },
        {
          "instantiator": "run",
          "file": "model_chorus/src/model_chorus/workflows/study/study_workflow.py",
          "line": 219,
          "context": [
            "StudyWorkflow",
            "run"
          ]
        },
        {
          "instantiator": "run",
          "file": "model_chorus/src/model_chorus/workflows/thinkdeep.py",
          "line": 251,
          "context": [
            "ThinkDeepWorkflow",
            "run"
          ]
        },
        {
          "instantiator": "mock_brainstorming_result",
          "file": "model_chorus/tests/test_ideate_workflow.py",
          "line": 159,
          "context": [
            "mock_brainstorming_result"
          ]
        },
        {
          "instantiator": "test_convergent_analysis_raises_error_on_empty_result",
          "file": "model_chorus/tests/test_ideate_workflow.py",
          "line": 237,
          "context": [
            "TestConvergentAnalysis",
            "test_convergent_analysis_raises_error_on_empty_result"
          ]
        },
        {
          "instantiator": "mock_workflow_result",
          "file": "tests/test_cli_integration.py",
          "line": 62,
          "context": [
            "mock_workflow_result"
          ]
        },
        {
          "instantiator": "test_argument_with_continuation",
          "file": "tests/test_cli_integration.py",
          "line": 169,
          "context": [
            "TestArgumentCommand",
            "test_argument_with_continuation"
          ]
        },
        {
          "instantiator": "test_ideate_with_continuation",
          "file": "tests/test_cli_integration.py",
          "line": 437,
          "context": [
            "TestIdeateCommand",
            "test_ideate_with_continuation"
          ]
        },
        {
          "instantiator": "mock_brainstorming_result",
          "file": "tests/test_ideate_workflow.py",
          "line": 371,
          "context": [
            "TestConvergentAnalysis",
            "mock_brainstorming_result"
          ]
        },
        {
          "instantiator": "mock_convergent_result",
          "file": "tests/test_ideate_workflow.py",
          "line": 538,
          "context": [
            "TestInteractiveSelection",
            "mock_convergent_result"
          ]
        },
        {
          "instantiator": "mock_selection_result",
          "file": "tests/test_ideate_workflow.py",
          "line": 610,
          "context": [
            "TestElaboration",
            "mock_selection_result"
          ]
        },
        {
          "instantiator": "test_extraction_with_no_brainstorming_steps",
          "file": "tests/test_ideate_workflow.py",
          "line": 765,
          "context": [
            "TestErrorHandling",
            "test_extraction_with_no_brainstorming_steps"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 20
    },
    {
      "name": "BaseWorkflow",
      "file": "model_chorus/src/model_chorus/core/base_workflow.py",
      "line": 58,
      "language": "python",
      "docstring": "Abstract base class for all ModelChorus workflows.\n\nAll workflow implementations (thinkdeep, debug, consensus, etc.) must inherit\nfrom this class and implement the run() method.\n\nAttributes:\n    name: Human-readable name of the workflow\n    description: Brief description of what this workflow does\n    config: Configuration dictionary for the workflow\n    conversation_memory: Optional ConversationMemory instance for multi-turn conversations",
      "bases": [
        "ABC"
      ],
      "methods": [
        "__init__",
        "run",
        "synthesize",
        "get_result",
        "validate_config",
        "_execute_with_fallback",
        "check_provider_availability",
        "get_thread",
        "add_message",
        "resume_conversation",
        "__repr__"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "ClusterResult",
      "file": "model_chorus/src/model_chorus/core/clustering.py",
      "line": 21,
      "language": "python",
      "docstring": "Result of a clustering operation.\n\nAttributes:\n    cluster_id: Unique identifier for this cluster\n    items: List of item indices belonging to this cluster\n    centroid: Cluster centroid in embedding space\n    name: Human-readable cluster name/label\n    summary: Brief summary of cluster theme\n    quality_score: Quality/coherence score (0.0 = poor, 1.0 = excellent)\n    metadata: Additional cluster metadata",
      "bases": [],
      "methods": [
        "__repr__"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "cluster",
          "file": "model_chorus/src/model_chorus/core/clustering.py",
          "line": 451,
          "context": [
            "SemanticClustering",
            "cluster"
          ]
        },
        {
          "instantiator": "test_cluster_result_creation",
          "file": "tests/test_clustering.py",
          "line": 39,
          "context": [
            "TestClusterResult",
            "test_cluster_result_creation"
          ]
        },
        {
          "instantiator": "test_cluster_result_repr",
          "file": "tests/test_clustering.py",
          "line": 58,
          "context": [
            "TestClusterResult",
            "test_cluster_result_repr"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 3
    },
    {
      "name": "SemanticClustering",
      "file": "model_chorus/src/model_chorus/core/clustering.py",
      "line": 52,
      "language": "python",
      "docstring": "Semantic clustering engine for grouping textual content by theme.\n\nThis class provides methods for:\n1. Computing semantic similarity between texts using embeddings\n2. Clustering texts using K-means or hierarchical methods\n3. Naming and summarizing clusters\n4. Scoring cluster quality\n\nExample:\n    >>> clustering = SemanticClustering(model_name=\"all-MiniLM-L6-v2\")\n    >>> texts = [\"Python is great\", \"I love Python\", \"Java is verbose\"]\n    >>> clusters = clustering.cluster(texts, n_clusters=2)\n    >>> for cluster in clusters:\n    ...     print(f\"{cluster.name}: {cluster.items}\")",
      "bases": [],
      "methods": [
        "__init__",
        "_load_model",
        "compute_embeddings",
        "compute_similarity",
        "cluster_kmeans",
        "cluster_hierarchical",
        "name_cluster",
        "summarize_cluster",
        "score_cluster",
        "cluster"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "clustering",
          "file": "tests/test_clustering.py",
          "line": 79,
          "context": [
            "TestSemanticClustering",
            "clustering"
          ]
        },
        {
          "instantiator": "test_compute_embeddings_no_cache",
          "file": "tests/test_clustering.py",
          "line": 133,
          "context": [
            "TestSemanticClustering",
            "test_compute_embeddings_no_cache"
          ]
        },
        {
          "instantiator": "test_real_clustering_with_semantics",
          "file": "tests/test_clustering.py",
          "line": 416,
          "context": [
            "TestClusteringIntegration",
            "test_real_clustering_with_semantics"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 3
    },
    {
      "name": "GenerationDefaults",
      "file": "model_chorus/src/model_chorus/core/config.py",
      "line": 21,
      "language": "python",
      "docstring": "Default generation parameters.",
      "bases": [
        "BaseModel"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "test_generation_defaults_validation",
          "file": "model_chorus/tests/test_config.py",
          "line": 320,
          "context": [
            "TestConfigLoader",
            "test_generation_defaults_validation"
          ]
        },
        {
          "instantiator": "test_model_chorus_config_complete",
          "file": "model_chorus/tests/test_config.py",
          "line": 351,
          "context": [
            "TestConfigLoader",
            "test_model_chorus_config_complete"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 2
    },
    {
      "name": "ProviderConfig",
      "file": "model_chorus/src/model_chorus/core/config.py",
      "line": 30,
      "language": "python",
      "docstring": "Configuration for a specific provider.",
      "bases": [
        "BaseModel"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "__init__",
          "file": "model_chorus/src/model_chorus/workflows/consensus.py",
          "line": 110,
          "context": [
            "ConsensusWorkflow",
            "__init__"
          ]
        },
        {
          "instantiator": "add_provider",
          "file": "model_chorus/src/model_chorus/workflows/consensus.py",
          "line": 130,
          "context": [
            "ConsensusWorkflow",
            "add_provider"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 2
    },
    {
      "name": "WorkflowConfig",
      "file": "model_chorus/src/model_chorus/core/config.py",
      "line": 36,
      "language": "python",
      "docstring": "Configuration for a specific workflow.",
      "bases": [
        "BaseModel"
      ],
      "methods": [
        "validate_provider",
        "validate_providers"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "test_workflow_config_validation",
          "file": "model_chorus/tests/test_config.py",
          "line": 332,
          "context": [
            "TestConfigLoader",
            "test_workflow_config_validation"
          ]
        },
        {
          "instantiator": "test_workflow_config_provider_normalization",
          "file": "model_chorus/tests/test_config.py",
          "line": 344,
          "context": [
            "TestConfigLoader",
            "test_workflow_config_provider_normalization"
          ]
        },
        {
          "instantiator": "test_model_chorus_config_complete",
          "file": "model_chorus/tests/test_config.py",
          "line": 353,
          "context": [
            "TestConfigLoader",
            "test_model_chorus_config_complete"
          ]
        },
        {
          "instantiator": "test_model_chorus_config_complete",
          "file": "model_chorus/tests/test_config.py",
          "line": 354,
          "context": [
            "TestConfigLoader",
            "test_model_chorus_config_complete"
          ]
        },
        {
          "instantiator": "test_thinkdeep_thinking_mode_validation",
          "file": "model_chorus/tests/test_config.py",
          "line": 414,
          "context": [
            "TestWorkflowConfigValidation",
            "test_thinkdeep_thinking_mode_validation"
          ]
        },
        {
          "instantiator": "test_thinkdeep_thinking_mode_validation",
          "file": "model_chorus/tests/test_config.py",
          "line": 419,
          "context": [
            "TestWorkflowConfigValidation",
            "test_thinkdeep_thinking_mode_validation"
          ]
        },
        {
          "instantiator": "test_research_citation_style_validation",
          "file": "model_chorus/tests/test_config.py",
          "line": 425,
          "context": [
            "TestWorkflowConfigValidation",
            "test_research_citation_style_validation"
          ]
        },
        {
          "instantiator": "test_research_citation_style_validation",
          "file": "model_chorus/tests/test_config.py",
          "line": 430,
          "context": [
            "TestWorkflowConfigValidation",
            "test_research_citation_style_validation"
          ]
        },
        {
          "instantiator": "test_research_depth_validation",
          "file": "model_chorus/tests/test_config.py",
          "line": 436,
          "context": [
            "TestWorkflowConfigValidation",
            "test_research_depth_validation"
          ]
        },
        {
          "instantiator": "test_research_depth_validation",
          "file": "model_chorus/tests/test_config.py",
          "line": 441,
          "context": [
            "TestWorkflowConfigValidation",
            "test_research_depth_validation"
          ]
        },
        {
          "instantiator": "test_consensus_strategy_validation",
          "file": "model_chorus/tests/test_config.py",
          "line": 447,
          "context": [
            "TestWorkflowConfigValidation",
            "test_consensus_strategy_validation"
          ]
        },
        {
          "instantiator": "test_consensus_strategy_validation",
          "file": "model_chorus/tests/test_config.py",
          "line": 452,
          "context": [
            "TestWorkflowConfigValidation",
            "test_consensus_strategy_validation"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 12
    },
    {
      "name": "ModelChorusConfig",
      "file": "model_chorus/src/model_chorus/core/config.py",
      "line": 76,
      "language": "python",
      "docstring": "Root configuration model for ModelChorus.",
      "bases": [
        "BaseModel"
      ],
      "methods": [
        "validate_default_provider",
        "validate_provider_names",
        "validate_workflow_names"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "load_config",
          "file": "model_chorus/src/model_chorus/core/config.py",
          "line": 158,
          "context": [
            "ConfigLoader",
            "load_config"
          ]
        },
        {
          "instantiator": "load_config",
          "file": "model_chorus/src/model_chorus/core/config.py",
          "line": 174,
          "context": [
            "ConfigLoader",
            "load_config"
          ]
        },
        {
          "instantiator": "get_config",
          "file": "model_chorus/src/model_chorus/core/config.py",
          "line": 225,
          "context": [
            "ConfigLoader",
            "get_config"
          ]
        },
        {
          "instantiator": "test_model_chorus_config_complete",
          "file": "model_chorus/tests/test_config.py",
          "line": 349,
          "context": [
            "TestConfigLoader",
            "test_model_chorus_config_complete"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 4
    },
    {
      "name": "ConfigLoader",
      "file": "model_chorus/src/model_chorus/core/config.py",
      "line": 112,
      "language": "python",
      "docstring": "Loads and manages ModelChorus configuration.",
      "bases": [],
      "methods": [
        "__init__",
        "find_config_file",
        "load_config",
        "_parse_config_content",
        "get_config",
        "get_workflow_default",
        "get_default_provider",
        "get_default_providers",
        "get_fallback_providers",
        "get_fallback_providers_excluding",
        "get_provider_model"
      ],
      "properties": [
        "config_path"
      ],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "validate_config",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 613,
          "context": [
            "validate_config"
          ]
        },
        {
          "instantiator": "get_config_loader",
          "file": "model_chorus/src/model_chorus/core/config.py",
          "line": 389,
          "context": [
            "get_config_loader"
          ]
        },
        {
          "instantiator": "test_find_config_file_in_current_dir",
          "file": "model_chorus/tests/test_config.py",
          "line": 37,
          "context": [
            "TestConfigLoader",
            "test_find_config_file_in_current_dir"
          ]
        },
        {
          "instantiator": "test_find_config_file_in_parent_dir",
          "file": "model_chorus/tests/test_config.py",
          "line": 51,
          "context": [
            "TestConfigLoader",
            "test_find_config_file_in_parent_dir"
          ]
        },
        {
          "instantiator": "test_find_config_file_yaml_extension",
          "file": "model_chorus/tests/test_config.py",
          "line": 61,
          "context": [
            "TestConfigLoader",
            "test_find_config_file_yaml_extension"
          ]
        },
        {
          "instantiator": "test_find_config_file_json_extension",
          "file": "model_chorus/tests/test_config.py",
          "line": 71,
          "context": [
            "TestConfigLoader",
            "test_find_config_file_json_extension"
          ]
        },
        {
          "instantiator": "test_find_config_file_not_found",
          "file": "model_chorus/tests/test_config.py",
          "line": 78,
          "context": [
            "TestConfigLoader",
            "test_find_config_file_not_found"
          ]
        },
        {
          "instantiator": "test_load_yaml_config_global_defaults",
          "file": "model_chorus/tests/test_config.py",
          "line": 99,
          "context": [
            "TestConfigLoader",
            "test_load_yaml_config_global_defaults"
          ]
        },
        {
          "instantiator": "test_load_yaml_config_workflow_specific",
          "file": "model_chorus/tests/test_config.py",
          "line": 123,
          "context": [
            "TestConfigLoader",
            "test_load_yaml_config_workflow_specific"
          ]
        },
        {
          "instantiator": "test_load_json_config",
          "file": "model_chorus/tests/test_config.py",
          "line": 150,
          "context": [
            "TestConfigLoader",
            "test_load_json_config"
          ]
        },
        {
          "instantiator": "test_invalid_provider_raises_error",
          "file": "model_chorus/tests/test_config.py",
          "line": 166,
          "context": [
            "TestConfigLoader",
            "test_invalid_provider_raises_error"
          ]
        },
        {
          "instantiator": "test_invalid_temperature_raises_error",
          "file": "model_chorus/tests/test_config.py",
          "line": 180,
          "context": [
            "TestConfigLoader",
            "test_invalid_temperature_raises_error"
          ]
        },
        {
          "instantiator": "test_invalid_workflow_name_raises_error",
          "file": "model_chorus/tests/test_config.py",
          "line": 195,
          "context": [
            "TestConfigLoader",
            "test_invalid_workflow_name_raises_error"
          ]
        },
        {
          "instantiator": "test_invalid_consensus_strategy_raises_error",
          "file": "model_chorus/tests/test_config.py",
          "line": 210,
          "context": [
            "TestConfigLoader",
            "test_invalid_consensus_strategy_raises_error"
          ]
        },
        {
          "instantiator": "test_get_default_provider_workflow_specific",
          "file": "model_chorus/tests/test_config.py",
          "line": 230,
          "context": [
            "TestConfigLoader",
            "test_get_default_provider_workflow_specific"
          ]
        },
        {
          "instantiator": "test_get_default_provider_fallback",
          "file": "model_chorus/tests/test_config.py",
          "line": 241,
          "context": [
            "TestConfigLoader",
            "test_get_default_provider_fallback"
          ]
        },
        {
          "instantiator": "test_get_workflow_default_temperature",
          "file": "model_chorus/tests/test_config.py",
          "line": 258,
          "context": [
            "TestConfigLoader",
            "test_get_workflow_default_temperature"
          ]
        },
        {
          "instantiator": "test_get_default_providers_multi",
          "file": "model_chorus/tests/test_config.py",
          "line": 280,
          "context": [
            "TestConfigLoader",
            "test_get_default_providers_multi"
          ]
        },
        {
          "instantiator": "test_load_empty_config",
          "file": "model_chorus/tests/test_config.py",
          "line": 295,
          "context": [
            "TestConfigLoader",
            "test_load_empty_config"
          ]
        },
        {
          "instantiator": "test_load_minimal_config",
          "file": "model_chorus/tests/test_config.py",
          "line": 307,
          "context": [
            "TestConfigLoader",
            "test_load_minimal_config"
          ]
        },
        {
          "instantiator": "test_load_nonexistent_file_raises_error",
          "file": "model_chorus/tests/test_config.py",
          "line": 382,
          "context": [
            "TestConfigLoader",
            "test_load_nonexistent_file_raises_error"
          ]
        },
        {
          "instantiator": "test_load_invalid_yaml_raises_error",
          "file": "model_chorus/tests/test_config.py",
          "line": 392,
          "context": [
            "TestConfigLoader",
            "test_load_invalid_yaml_raises_error"
          ]
        },
        {
          "instantiator": "test_load_invalid_json_raises_error",
          "file": "model_chorus/tests/test_config.py",
          "line": 402,
          "context": [
            "TestConfigLoader",
            "test_load_invalid_json_raises_error"
          ]
        },
        {
          "instantiator": "test_full_config_all_workflows",
          "file": "model_chorus/tests/test_config.py",
          "line": 490,
          "context": [
            "TestComplexConfigScenarios",
            "test_full_config_all_workflows"
          ]
        },
        {
          "instantiator": "test_precedence_workflow_overrides_global",
          "file": "model_chorus/tests/test_config.py",
          "line": 517,
          "context": [
            "TestComplexConfigScenarios",
            "test_precedence_workflow_overrides_global"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 25
    },
    {
      "name": "ContradictionSeverity",
      "file": "model_chorus/src/model_chorus/core/contradiction.py",
      "line": 27,
      "language": "python",
      "docstring": "Severity levels for contradictions between claims.\n\nClassifies contradictions by their importance and impact on\nargument validity. Higher severity indicates more significant\nconflicts requiring immediate attention.\n\nValues:\n    MINOR: Slight inconsistency, may be due to different perspectives\n           or temporal differences. Low impact on argument validity.\n    MODERATE: Notable contradiction that should be investigated.\n             May indicate measurement differences or scope variations.\n    MAJOR: Significant contradiction that undermines argument coherence.\n          Requires careful analysis and resolution.\n    CRITICAL: Direct, irreconcilable contradiction that invalidates\n             one or both claims. Immediate attention required.",
      "bases": [
        "str",
        "Enum"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "Contradiction",
      "file": "model_chorus/src/model_chorus/core/contradiction.py",
      "line": 52,
      "language": "python",
      "docstring": "Model for tracking contradictions between claims in ARGUMENT workflow.\n\nRepresents a detected contradiction between two claims, including\nseverity assessment, confidence in detection, and resolution suggestions.\nUsed to identify conflicts in evidence and maintain argument coherence.\n\nAttributes:\n    contradiction_id: Unique identifier for this contradiction\n    claim_1_id: Identifier of the first conflicting claim\n    claim_2_id: Identifier of the second conflicting claim\n    claim_1_text: Full text of the first claim\n    claim_2_text: Full text of the second claim\n    severity: Severity level of the contradiction\n    confidence: Confidence in contradiction detection (0.0-1.0)\n    explanation: Detailed explanation of why claims contradict\n    resolution_suggestion: Optional suggestion for resolving the contradiction\n    metadata: Additional metadata (detection_method, timestamp, etc.)",
      "bases": [
        "BaseModel"
      ],
      "methods": [
        "validate_confidence",
        "validate_different_claims"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "detect_contradiction",
          "file": "model_chorus/src/model_chorus/core/contradiction.py",
          "line": 555,
          "context": [
            "detect_contradiction"
          ]
        },
        {
          "instantiator": "test_valid_contradiction_creation",
          "file": "tests/test_contradiction.py",
          "line": 206,
          "context": [
            "TestContradictionModel",
            "test_valid_contradiction_creation"
          ]
        },
        {
          "instantiator": "test_confidence_validation_in_range",
          "file": "tests/test_contradiction.py",
          "line": 226,
          "context": [
            "TestContradictionModel",
            "test_confidence_validation_in_range"
          ]
        },
        {
          "instantiator": "test_confidence_validation_too_high",
          "file": "tests/test_contradiction.py",
          "line": 243,
          "context": [
            "TestContradictionModel",
            "test_confidence_validation_too_high"
          ]
        },
        {
          "instantiator": "test_confidence_validation_too_low",
          "file": "tests/test_contradiction.py",
          "line": 259,
          "context": [
            "TestContradictionModel",
            "test_confidence_validation_too_low"
          ]
        },
        {
          "instantiator": "test_different_claim_ids_validation",
          "file": "tests/test_contradiction.py",
          "line": 273,
          "context": [
            "TestContradictionModel",
            "test_different_claim_ids_validation"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 6
    },
    {
      "name": "ConversationMemory",
      "file": "model_chorus/src/model_chorus/core/conversation.py",
      "line": 36,
      "language": "python",
      "docstring": "Manages conversation threads with file-based persistence.\n\nProvides thread-safe storage and retrieval of conversation history,\nenabling multi-turn conversations across workflow executions.\n\nArchitecture:\n    - Each thread stored as JSON file: ~/.model-chorus/conversations/{thread_id}.json\n    - File locking prevents concurrent access corruption\n    - TTL-based cleanup removes expired threads\n    - Supports conversation chains via parent_thread_id\n\nAttributes:\n    conversations_dir: Directory where conversation files are stored\n    ttl_hours: Time-to-live for conversation threads in hours\n    max_messages: Maximum messages per thread before truncation",
      "bases": [],
      "methods": [
        "__init__",
        "create_thread",
        "get_thread",
        "get_thread_chain",
        "add_message",
        "get_messages",
        "build_conversation_history",
        "get_context_summary",
        "complete_thread",
        "archive_thread",
        "cleanup_expired_threads",
        "cleanup_archived_threads",
        "_save_thread",
        "_delete_thread"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "example_argument_basic",
          "file": "examples/workflow_examples.py",
          "line": 50,
          "context": [
            "example_argument_basic"
          ]
        },
        {
          "instantiator": "example_argument_with_files",
          "file": "examples/workflow_examples.py",
          "line": 118,
          "context": [
            "example_argument_with_files"
          ]
        },
        {
          "instantiator": "example_argument_continuation",
          "file": "examples/workflow_examples.py",
          "line": 152,
          "context": [
            "example_argument_continuation"
          ]
        },
        {
          "instantiator": "example_argument_custom_config",
          "file": "examples/workflow_examples.py",
          "line": 193,
          "context": [
            "example_argument_custom_config"
          ]
        },
        {
          "instantiator": "example_ideate_basic",
          "file": "examples/workflow_examples.py",
          "line": 227,
          "context": [
            "example_ideate_basic"
          ]
        },
        {
          "instantiator": "example_ideate_high_creativity",
          "file": "examples/workflow_examples.py",
          "line": 267,
          "context": [
            "example_ideate_high_creativity"
          ]
        },
        {
          "instantiator": "example_ideate_with_constraints",
          "file": "examples/workflow_examples.py",
          "line": 298,
          "context": [
            "example_ideate_with_constraints"
          ]
        },
        {
          "instantiator": "example_ideate_refine",
          "file": "examples/workflow_examples.py",
          "line": 338,
          "context": [
            "example_ideate_refine"
          ]
        },
        {
          "instantiator": "example_error_handling",
          "file": "examples/workflow_examples.py",
          "line": 384,
          "context": [
            "example_error_handling"
          ]
        },
        {
          "instantiator": "example_output_management",
          "file": "examples/workflow_examples.py",
          "line": 426,
          "context": [
            "example_output_management"
          ]
        },
        {
          "instantiator": "example_provider_comparison",
          "file": "examples/workflow_examples.py",
          "line": 483,
          "context": [
            "example_provider_comparison"
          ]
        },
        {
          "instantiator": "basic_chat_example",
          "file": "model_chorus/examples/chat_example.py",
          "line": 27,
          "context": [
            "basic_chat_example"
          ]
        },
        {
          "instantiator": "multi_turn_conversation_example",
          "file": "model_chorus/examples/chat_example.py",
          "line": 56,
          "context": [
            "multi_turn_conversation_example"
          ]
        },
        {
          "instantiator": "chat_with_file_context_example",
          "file": "model_chorus/examples/chat_example.py",
          "line": 127,
          "context": [
            "chat_with_file_context_example"
          ]
        },
        {
          "instantiator": "conversation_tracking_example",
          "file": "model_chorus/examples/chat_example.py",
          "line": 160,
          "context": [
            "conversation_tracking_example"
          ]
        },
        {
          "instantiator": "basic_investigation_example",
          "file": "model_chorus/examples/thinkdeep_example.py",
          "line": 35,
          "context": [
            "basic_investigation_example"
          ]
        },
        {
          "instantiator": "multi_step_investigation_example",
          "file": "model_chorus/examples/thinkdeep_example.py",
          "line": 115,
          "context": [
            "multi_step_investigation_example"
          ]
        },
        {
          "instantiator": "investigation_with_expert_validation",
          "file": "model_chorus/examples/thinkdeep_example.py",
          "line": 234,
          "context": [
            "investigation_with_expert_validation"
          ]
        },
        {
          "instantiator": "hypothesis_management_example",
          "file": "model_chorus/examples/thinkdeep_example.py",
          "line": 288,
          "context": [
            "hypothesis_management_example"
          ]
        },
        {
          "instantiator": "confidence_progression_example",
          "file": "model_chorus/examples/thinkdeep_example.py",
          "line": 377,
          "context": [
            "confidence_progression_example"
          ]
        },
        {
          "instantiator": "chat",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 311,
          "context": [
            "chat"
          ]
        },
        {
          "instantiator": "argument",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 516,
          "context": [
            "argument"
          ]
        },
        {
          "instantiator": "ideate",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 719,
          "context": [
            "ideate"
          ]
        },
        {
          "instantiator": "thinkdeep",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1180,
          "context": [
            "thinkdeep"
          ]
        },
        {
          "instantiator": "thinkdeep_status",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1381,
          "context": [
            "thinkdeep_status"
          ]
        },
        {
          "instantiator": "start",
          "file": "model_chorus/src/model_chorus/cli/study_commands.py",
          "line": 236,
          "context": [
            "start"
          ]
        },
        {
          "instantiator": "study_next",
          "file": "model_chorus/src/model_chorus/cli/study_commands.py",
          "line": 484,
          "context": [
            "study_next"
          ]
        },
        {
          "instantiator": "study_view",
          "file": "model_chorus/src/model_chorus/cli/study_commands.py",
          "line": 659,
          "context": [
            "study_view"
          ]
        },
        {
          "instantiator": "conversation_memory",
          "file": "model_chorus/tests/test_chat_integration.py",
          "line": 37,
          "context": [
            "conversation_memory"
          ]
        },
        {
          "instantiator": "conversation_memory",
          "file": "model_chorus/tests/test_chat_workflow.py",
          "line": 40,
          "context": [
            "conversation_memory"
          ]
        },
        {
          "instantiator": "test_create_thread_generates_valid_uuid",
          "file": "model_chorus/tests/test_conversation.py",
          "line": 31,
          "context": [
            "TestConversationMemory",
            "test_create_thread_generates_valid_uuid"
          ]
        },
        {
          "instantiator": "test_create_thread_unique_ids",
          "file": "model_chorus/tests/test_conversation.py",
          "line": 45,
          "context": [
            "TestConversationMemory",
            "test_create_thread_unique_ids"
          ]
        },
        {
          "instantiator": "test_create_thread_with_initial_context",
          "file": "model_chorus/tests/test_conversation.py",
          "line": 58,
          "context": [
            "TestConversationMemory",
            "test_create_thread_with_initial_context"
          ]
        },
        {
          "instantiator": "test_create_thread_persists_to_file",
          "file": "model_chorus/tests/test_conversation.py",
          "line": 78,
          "context": [
            "TestConversationMemory",
            "test_create_thread_persists_to_file"
          ]
        },
        {
          "instantiator": "test_create_thread_with_parent",
          "file": "model_chorus/tests/test_conversation.py",
          "line": 94,
          "context": [
            "TestConversationMemory",
            "test_create_thread_with_parent"
          ]
        },
        {
          "instantiator": "test_add_message_to_thread",
          "file": "model_chorus/tests/test_conversation.py",
          "line": 116,
          "context": [
            "TestConversationMemory",
            "test_add_message_to_thread"
          ]
        },
        {
          "instantiator": "test_add_multiple_messages",
          "file": "model_chorus/tests/test_conversation.py",
          "line": 134,
          "context": [
            "TestConversationMemory",
            "test_add_multiple_messages"
          ]
        },
        {
          "instantiator": "test_add_message_with_metadata",
          "file": "model_chorus/tests/test_conversation.py",
          "line": 153,
          "context": [
            "TestConversationMemory",
            "test_add_message_with_metadata"
          ]
        },
        {
          "instantiator": "test_get_messages_returns_chronological_order",
          "file": "model_chorus/tests/test_conversation.py",
          "line": 177,
          "context": [
            "TestConversationMemory",
            "test_get_messages_returns_chronological_order"
          ]
        },
        {
          "instantiator": "test_message_persistence_across_instances",
          "file": "model_chorus/tests/test_conversation.py",
          "line": 197,
          "context": [
            "TestConversationMemory",
            "test_message_persistence_across_instances"
          ]
        },
        {
          "instantiator": "test_message_persistence_across_instances",
          "file": "model_chorus/tests/test_conversation.py",
          "line": 202,
          "context": [
            "TestConversationMemory",
            "test_message_persistence_across_instances"
          ]
        },
        {
          "instantiator": "test_thread_context_window_management",
          "file": "model_chorus/tests/test_conversation.py",
          "line": 213,
          "context": [
            "TestConversationMemory",
            "test_thread_context_window_management"
          ]
        },
        {
          "instantiator": "test_get_thread_context_includes_state",
          "file": "model_chorus/tests/test_conversation.py",
          "line": 229,
          "context": [
            "TestConversationMemory",
            "test_get_thread_context_includes_state"
          ]
        },
        {
          "instantiator": "test_init_with_conversation_memory",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 62,
          "context": [
            "TestStudyWorkflowInitialization",
            "test_init_with_conversation_memory"
          ]
        },
        {
          "instantiator": "workflow_with_memory",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 304,
          "context": [
            "TestStudyWorkflowConversationHandling",
            "workflow_with_memory"
          ]
        },
        {
          "instantiator": "workflow_with_memory",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 599,
          "context": [
            "TestStudyWorkflowIntegration",
            "workflow_with_memory"
          ]
        },
        {
          "instantiator": "conversation_memory",
          "file": "tests/test_argument_workflow.py",
          "line": 44,
          "context": [
            "conversation_memory"
          ]
        },
        {
          "instantiator": "conversation_memory",
          "file": "tests/test_concurrent_conversations.py",
          "line": 45,
          "context": [
            "TestConcurrentConversationHandling",
            "conversation_memory"
          ]
        },
        {
          "instantiator": "conversation_memory",
          "file": "tests/test_ideate_workflow.py",
          "line": 137,
          "context": [
            "conversation_memory"
          ]
        },
        {
          "instantiator": "conversation_memory",
          "file": "tests/test_memory_management.py",
          "line": 42,
          "context": [
            "TestMemoryManagement",
            "conversation_memory"
          ]
        },
        {
          "instantiator": "conversation_memory",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 40,
          "context": [
            "TestArchitecturalDecisionScenarios",
            "conversation_memory"
          ]
        },
        {
          "instantiator": "conversation_memory",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 264,
          "context": [
            "TestBugInvestigationScenarios",
            "conversation_memory"
          ]
        },
        {
          "instantiator": "conversation_memory",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 611,
          "context": [
            "TestComplexMultiStepReasoning",
            "conversation_memory"
          ]
        },
        {
          "instantiator": "conversation_memory",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 49,
          "context": [
            "TestExpertProviderIntegration",
            "conversation_memory"
          ]
        },
        {
          "instantiator": "conversation_memory",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 138,
          "context": [
            "TestExpertValidationTriggering",
            "conversation_memory"
          ]
        },
        {
          "instantiator": "conversation_memory",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 336,
          "context": [
            "TestExpertValidationResultHandling",
            "conversation_memory"
          ]
        },
        {
          "instantiator": "conversation_memory",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 450,
          "context": [
            "TestExpertValidationErrorHandling",
            "conversation_memory"
          ]
        },
        {
          "instantiator": "conversation_memory",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 601,
          "context": [
            "TestExpertValidationWithHypotheses",
            "conversation_memory"
          ]
        },
        {
          "instantiator": "conversation_memory",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 53,
          "context": [
            "TestInvestigationStepExecution",
            "conversation_memory"
          ]
        },
        {
          "instantiator": "conversation_memory",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 728,
          "context": [
            "TestHypothesisEvolution",
            "conversation_memory"
          ]
        },
        {
          "instantiator": "conversation_memory",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1265,
          "context": [
            "TestConfidenceProgression",
            "conversation_memory"
          ]
        },
        {
          "instantiator": "conversation_memory",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1743,
          "context": [
            "TestEndToEndIntegration",
            "conversation_memory"
          ]
        },
        {
          "instantiator": "conversation_memory",
          "file": "tests/test_workflow_integration_chaining.py",
          "line": 62,
          "context": [
            "TestConsensusThinkDeepChatChaining",
            "conversation_memory"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 63
    },
    {
      "name": "GapType",
      "file": "model_chorus/src/model_chorus/core/gap_analysis.py",
      "line": 27,
      "language": "python",
      "docstring": "Types of gaps that can be detected in arguments.\n\nClassifies gaps by their nature to help prioritize remediation\nand guide improvement strategies.\n\nValues:\n    EVIDENCE: Claim lacks supporting evidence or citations\n    LOGICAL: Missing logical steps or reasoning gaps\n    SUPPORT: Insufficient supporting arguments for main claim\n    ASSUMPTION: Unstated or unjustified assumptions",
      "bases": [
        "str",
        "Enum"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "GapSeverity",
      "file": "model_chorus/src/model_chorus/core/gap_analysis.py",
      "line": 47,
      "language": "python",
      "docstring": "Severity levels for gaps in arguments.\n\nClassifies gaps by their impact on argument validity and persuasiveness.\nHigher severity indicates more critical gaps requiring immediate attention.\n\nValues:\n    MINOR: Small gap with minimal impact on argument strength.\n           May improve clarity but not essential.\n    MODERATE: Notable gap that weakens the argument.\n             Should be addressed to improve persuasiveness.\n    MAJOR: Significant gap that undermines argument validity.\n          Must be addressed for credible argumentation.\n    CRITICAL: Fundamental gap that invalidates the argument.\n             Immediate attention required.",
      "bases": [
        "str",
        "Enum"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "Gap",
      "file": "model_chorus/src/model_chorus/core/gap_analysis.py",
      "line": 71,
      "language": "python",
      "docstring": "Model for tracking gaps in arguments.\n\nRepresents a detected gap in reasoning, evidence, or support,\nincluding severity assessment, confidence in detection, and\nrecommendations for improvement.\n\nAttributes:\n    gap_id: Unique identifier for this gap\n    gap_type: Type of gap (evidence/logical/support/assumption)\n    severity: Severity level of the gap\n    claim_id: Identifier of the claim with the gap\n    claim_text: Full text of the claim\n    description: Detailed description of what's missing\n    recommendation: Suggestion for addressing the gap\n    confidence: Confidence in gap detection (0.0-1.0)\n    metadata: Additional metadata (detection_method, context, etc.)",
      "bases": [
        "BaseModel"
      ],
      "methods": [
        "validate_confidence"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "detect_missing_evidence",
          "file": "model_chorus/src/model_chorus/core/gap_analysis.py",
          "line": 387,
          "context": [
            "detect_missing_evidence"
          ]
        },
        {
          "instantiator": "detect_logical_gaps",
          "file": "model_chorus/src/model_chorus/core/gap_analysis.py",
          "line": 463,
          "context": [
            "detect_logical_gaps"
          ]
        },
        {
          "instantiator": "test_valid_gap_creation",
          "file": "tests/test_gap_analysis.py",
          "line": 27,
          "context": [
            "TestGapModel",
            "test_valid_gap_creation"
          ]
        },
        {
          "instantiator": "test_confidence_validation_in_range",
          "file": "tests/test_gap_analysis.py",
          "line": 46,
          "context": [
            "TestGapModel",
            "test_confidence_validation_in_range"
          ]
        },
        {
          "instantiator": "test_confidence_validation_too_high",
          "file": "tests/test_gap_analysis.py",
          "line": 63,
          "context": [
            "TestGapModel",
            "test_confidence_validation_too_high"
          ]
        },
        {
          "instantiator": "test_confidence_validation_too_low",
          "file": "tests/test_gap_analysis.py",
          "line": 79,
          "context": [
            "TestGapModel",
            "test_confidence_validation_too_low"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 6
    },
    {
      "name": "ConfidenceLevel",
      "file": "model_chorus/src/model_chorus/core/models.py",
      "line": 16,
      "language": "python",
      "docstring": "Confidence level enum for investigation workflows.\n\nUsed in Thinkdeep workflow to track the investigator's confidence\nin their hypothesis as evidence accumulates. Levels progress from\ninitial exploration through to complete certainty.\n\nValues:\n    EXPLORING: Just starting investigation, no clear hypothesis yet\n    LOW: Early investigation with initial hypothesis forming\n    MEDIUM: Some supporting evidence found\n    HIGH: Strong evidence supporting hypothesis\n    VERY_HIGH: Very strong evidence, high confidence\n    ALMOST_CERTAIN: Near complete confidence, comprehensive evidence\n    CERTAIN: 100% confidence, hypothesis validated beyond reasonable doubt",
      "bases": [
        "str",
        "Enum"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "update_confidence",
          "file": "model_chorus/src/model_chorus/workflows/study/state_machine.py",
          "line": 202,
          "context": [
            "InvestigationStateMachine",
            "update_confidence"
          ]
        },
        {
          "instantiator": "should_escalate_phase",
          "file": "model_chorus/src/model_chorus/workflows/study/state_machine.py",
          "line": 220,
          "context": [
            "InvestigationStateMachine",
            "should_escalate_phase"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 2
    },
    {
      "name": "InvestigationPhase",
      "file": "model_chorus/src/model_chorus/core/models.py",
      "line": 43,
      "language": "python",
      "docstring": "Investigation phase enum for persona-based research workflows.\n\nUsed in Study workflow to track the current phase of collaborative\ninvestigation. Phases progress from initial discovery through to\ncompletion with systematic exploration and validation.\n\nValues:\n    DISCOVERY: Initial exploration phase where personas gather information\n    VALIDATION: Critical examination phase where findings are validated\n    PLANNING: Synthesis phase where insights are organized into actionable plans\n    COMPLETE: Investigation concluded with comprehensive findings",
      "bases": [
        "str",
        "Enum"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "__init__",
          "file": "model_chorus/src/model_chorus/workflows/study/state_machine.py",
          "line": 57,
          "context": [
            "InvestigationStateMachine",
            "__init__"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 1
    },
    {
      "name": "WorkflowRequest",
      "file": "model_chorus/src/model_chorus/core/models.py",
      "line": 64,
      "language": "python",
      "docstring": "Request model for workflow execution.\n\nEncapsulates all the information needed to execute a workflow,\nincluding the prompt, model specifications, and configuration.\n\nAttributes:\n    prompt: The main input prompt/task for the workflow\n    models: List of model identifiers to use (e.g., [\"gpt-4\", \"claude-3\"])\n    config: Optional workflow-specific configuration dictionary\n    system_prompt: Optional system prompt for model context\n    temperature: Optional temperature setting (0.0-1.0)\n    max_tokens: Optional maximum tokens for generation\n    images: Optional list of image paths or URLs for vision-capable models\n    metadata: Additional metadata for the workflow execution",
      "bases": [
        "BaseModel"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "main",
          "file": "model_chorus/examples/basic_workflow.py",
          "line": 60,
          "context": [
            "main"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 1
    },
    {
      "name": "WorkflowResponse",
      "file": "model_chorus/src/model_chorus/core/models.py",
      "line": 138,
      "language": "python",
      "docstring": "Response model for workflow execution.\n\nContains the results of a workflow execution along with metadata\nabout the execution process.\n\nAttributes:\n    result: The main result/output from the workflow\n    success: Whether the workflow executed successfully\n    workflow_name: Name of the workflow that was executed\n    steps: Number of steps executed in the workflow\n    models_used: List of models that were used\n    error: Error message if the workflow failed\n    metadata: Additional metadata about the execution",
      "bases": [
        "BaseModel"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "ModelSelection",
      "file": "model_chorus/src/model_chorus/core/models.py",
      "line": 205,
      "language": "python",
      "docstring": "Model for specifying model selection criteria.\n\nUsed to configure which models should be used for specific\nworkflow steps or roles.\n\nAttributes:\n    model_id: The model identifier (e.g., \"gpt-4\", \"claude-3-opus\")\n    role: Optional role for this model (e.g., \"analyzer\", \"synthesizer\")\n    config: Optional model-specific configuration",
      "bases": [
        "BaseModel"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "WorkflowStep",
      "file": "model_chorus/src/model_chorus/core/models.py",
      "line": 245,
      "language": "python",
      "docstring": "Model for a single workflow execution step.\n\nRepresents one step in a multi-step workflow, capturing what\nwas done, which model was used, and the results.\n\nAttributes:\n    step_number: Sequential step number (1-indexed)\n    description: Human-readable description of this step\n    model: Model that executed this step\n    prompt: The prompt used for this step\n    response: The response from this step\n    metadata: Additional step metadata",
      "bases": [
        "BaseModel"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "add_step",
          "file": "model_chorus/src/model_chorus/core/base_workflow.py",
          "line": 49,
          "context": [
            "WorkflowResult",
            "add_step"
          ]
        },
        {
          "instantiator": "run",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 228,
          "context": [
            "IdeateWorkflow",
            "run"
          ]
        },
        {
          "instantiator": "run_parallel_brainstorming",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 451,
          "context": [
            "IdeateWorkflow",
            "run_parallel_brainstorming"
          ]
        },
        {
          "instantiator": "_extract_ideas",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 666,
          "context": [
            "IdeateWorkflow",
            "_extract_ideas"
          ]
        },
        {
          "instantiator": "_cluster_ideas",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 862,
          "context": [
            "IdeateWorkflow",
            "_cluster_ideas"
          ]
        },
        {
          "instantiator": "_score_ideas",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 1085,
          "context": [
            "IdeateWorkflow",
            "_score_ideas"
          ]
        },
        {
          "instantiator": "run_interactive_selection",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 1660,
          "context": [
            "IdeateWorkflow",
            "run_interactive_selection"
          ]
        },
        {
          "instantiator": "_elaborate_cluster",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 2065,
          "context": [
            "IdeateWorkflow",
            "_elaborate_cluster"
          ]
        },
        {
          "instantiator": "_conduct_investigation",
          "file": "model_chorus/src/model_chorus/workflows/study/study_workflow.py",
          "line": 378,
          "context": [
            "StudyWorkflow",
            "_conduct_investigation"
          ]
        },
        {
          "instantiator": "mock_brainstorming_result",
          "file": "model_chorus/tests/test_ideate_workflow.py",
          "line": 127,
          "context": [
            "mock_brainstorming_result"
          ]
        },
        {
          "instantiator": "mock_brainstorming_result",
          "file": "model_chorus/tests/test_ideate_workflow.py",
          "line": 137,
          "context": [
            "mock_brainstorming_result"
          ]
        },
        {
          "instantiator": "mock_brainstorming_result",
          "file": "model_chorus/tests/test_ideate_workflow.py",
          "line": 147,
          "context": [
            "mock_brainstorming_result"
          ]
        },
        {
          "instantiator": "test_synthesize_findings_returns_string",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 465,
          "context": [
            "TestStudyWorkflowSynthesis",
            "test_synthesize_findings_returns_string"
          ]
        },
        {
          "instantiator": "test_synthesize_findings_multiple_steps",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 487,
          "context": [
            "TestStudyWorkflowSynthesis",
            "test_synthesize_findings_multiple_steps"
          ]
        },
        {
          "instantiator": "test_synthesize_findings_multiple_steps",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 488,
          "context": [
            "TestStudyWorkflowSynthesis",
            "test_synthesize_findings_multiple_steps"
          ]
        },
        {
          "instantiator": "test_synthesize_findings_multiple_steps",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 489,
          "context": [
            "TestStudyWorkflowSynthesis",
            "test_synthesize_findings_multiple_steps"
          ]
        },
        {
          "instantiator": "test_synthesize_includes_step_count",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 501,
          "context": [
            "TestStudyWorkflowSynthesis",
            "test_synthesize_includes_step_count"
          ]
        },
        {
          "instantiator": "test_synthesize_includes_step_count",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 502,
          "context": [
            "TestStudyWorkflowSynthesis",
            "test_synthesize_includes_step_count"
          ]
        },
        {
          "instantiator": "mock_workflow_result",
          "file": "tests/test_cli_integration.py",
          "line": 66,
          "context": [
            "mock_workflow_result"
          ]
        },
        {
          "instantiator": "test_argument_with_continuation",
          "file": "tests/test_cli_integration.py",
          "line": 173,
          "context": [
            "TestArgumentCommand",
            "test_argument_with_continuation"
          ]
        },
        {
          "instantiator": "test_ideate_with_continuation",
          "file": "tests/test_cli_integration.py",
          "line": 441,
          "context": [
            "TestIdeateCommand",
            "test_ideate_with_continuation"
          ]
        },
        {
          "instantiator": "mock_brainstorming_result",
          "file": "tests/test_ideate_workflow.py",
          "line": 357,
          "context": [
            "TestConvergentAnalysis",
            "mock_brainstorming_result"
          ]
        },
        {
          "instantiator": "mock_brainstorming_result",
          "file": "tests/test_ideate_workflow.py",
          "line": 363,
          "context": [
            "TestConvergentAnalysis",
            "mock_brainstorming_result"
          ]
        },
        {
          "instantiator": "test_idea_clustering",
          "file": "tests/test_ideate_workflow.py",
          "line": 422,
          "context": [
            "TestConvergentAnalysis",
            "test_idea_clustering"
          ]
        },
        {
          "instantiator": "test_idea_scoring",
          "file": "tests/test_ideate_workflow.py",
          "line": 453,
          "context": [
            "TestConvergentAnalysis",
            "test_idea_scoring"
          ]
        },
        {
          "instantiator": "mock_convergent_result",
          "file": "tests/test_ideate_workflow.py",
          "line": 500,
          "context": [
            "TestInteractiveSelection",
            "mock_convergent_result"
          ]
        },
        {
          "instantiator": "mock_convergent_result",
          "file": "tests/test_ideate_workflow.py",
          "line": 517,
          "context": [
            "TestInteractiveSelection",
            "mock_convergent_result"
          ]
        },
        {
          "instantiator": "mock_selection_result",
          "file": "tests/test_ideate_workflow.py",
          "line": 588,
          "context": [
            "TestElaboration",
            "mock_selection_result"
          ]
        },
        {
          "instantiator": "test_clustering_with_no_extracted_ideas",
          "file": "tests/test_ideate_workflow.py",
          "line": 785,
          "context": [
            "TestErrorHandling",
            "test_clustering_with_no_extracted_ideas"
          ]
        },
        {
          "instantiator": "test_scoring_with_no_clusters",
          "file": "tests/test_ideate_workflow.py",
          "line": 800,
          "context": [
            "TestErrorHandling",
            "test_scoring_with_no_clusters"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 30
    },
    {
      "name": "ModelResponse",
      "file": "model_chorus/src/model_chorus/core/models.py",
      "line": 307,
      "language": "python",
      "docstring": "Model for a response from a single model.\n\nRepresents the output from querying a specific model, used in\nmulti-model workflows to track individual model contributions.\n\nAttributes:\n    model: Identifier of the model that generated this response\n    content: The response content/text\n    role: Optional role this model played (e.g., \"for\", \"against\", \"neutral\")\n    metadata: Additional response metadata (tokens, latency, etc.)",
      "bases": [
        "BaseModel"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "ConsensusConfig",
      "file": "model_chorus/src/model_chorus/core/models.py",
      "line": 355,
      "language": "python",
      "docstring": "Configuration for consensus-building workflows.\n\nSpecifies how multiple models should be consulted and how their\nresponses should be synthesized into a consensus.\n\nAttributes:\n    mode: Consensus mode (\"debate\", \"vote\", \"synthesis\")\n    stances: Optional list of stances to assign to models (e.g., [\"for\", \"against\", \"neutral\"])\n    temperature: Temperature for model responses\n    min_agreement: Minimum agreement threshold (0.0-1.0) for consensus\n    synthesis_model: Optional model to use for final synthesis\n    max_rounds: Maximum number of consensus rounds",
      "bases": [
        "BaseModel"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "ConversationMessage",
      "file": "model_chorus/src/model_chorus/core/models.py",
      "line": 428,
      "language": "python",
      "docstring": "Single message in a conversation thread.\n\nBased on Zen MCP's ConversationTurn but adapted for CLI-based architecture.\nTracks who said what, when, and with what context (files, models, workflow).\n\nAttributes:\n    role: Message role - 'user' or 'assistant'\n    content: The actual message text/content\n    timestamp: ISO format timestamp of when message was created\n    files: Optional list of file paths referenced in this message\n    workflow_name: Optional workflow that generated this message (for assistant messages)\n    model_provider: Optional provider type used (cli, api, mcp)\n    model_name: Optional specific model identifier (e.g., claude-3-opus, gpt-5)\n    metadata: Additional message metadata (tokens, latency, cost, etc.)",
      "bases": [
        "BaseModel"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "add_message",
          "file": "model_chorus/src/model_chorus/core/conversation.py",
          "line": 283,
          "context": [
            "ConversationMemory",
            "add_message"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 1
    },
    {
      "name": "ConversationThread",
      "file": "model_chorus/src/model_chorus/core/models.py",
      "line": 500,
      "language": "python",
      "docstring": "Complete conversation context for a thread.\n\nAdapted from Zen MCP's ThreadContext with enhancements for CLI orchestration:\n- Provider-agnostic design supporting multiple CLI providers\n- Explicit lifecycle management (status field)\n- Support for conversation branching (future enhancement)\n- Workflow-specific state persistence\n\nAttributes:\n    thread_id: UUID identifying this conversation thread\n    parent_thread_id: Optional parent thread ID for conversation chains\n    created_at: ISO timestamp of thread creation\n    last_updated_at: ISO timestamp of last update\n    workflow_name: Workflow that created this thread\n    messages: All messages in chronological order\n    state: Workflow-specific state data (persisted across turns)\n    initial_context: Original request parameters\n    status: Thread lifecycle status (active, completed, archived)\n    branch_point: Optional message ID where branch occurred\n    sibling_threads: Other thread IDs branched from same point",
      "bases": [
        "BaseModel"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "create_thread",
          "file": "model_chorus/src/model_chorus/core/conversation.py",
          "line": 116,
          "context": [
            "ConversationMemory",
            "create_thread"
          ]
        },
        {
          "instantiator": "get_thread",
          "file": "model_chorus/src/model_chorus/core/conversation.py",
          "line": 173,
          "context": [
            "ConversationMemory",
            "get_thread"
          ]
        },
        {
          "instantiator": "add_message",
          "file": "model_chorus/src/model_chorus/core/conversation.py",
          "line": 270,
          "context": [
            "ConversationMemory",
            "add_message"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 3
    },
    {
      "name": "Hypothesis",
      "file": "model_chorus/src/model_chorus/core/models.py",
      "line": 610,
      "language": "python",
      "docstring": "Model for tracking hypotheses in investigation workflows.\n\nUsed in Thinkdeep workflow to track hypothesis evolution during\nsystematic investigation, including the hypothesis text, supporting\nevidence, and current validation status.\n\nAttributes:\n    hypothesis: The hypothesis text/statement being investigated\n    evidence: List of evidence items supporting or refuting this hypothesis\n    status: Current validation status (active, disproven, validated)",
      "bases": [
        "BaseModel"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "run",
          "file": "model_chorus/src/model_chorus/workflows/thinkdeep.py",
          "line": 349,
          "context": [
            "ThinkDeepWorkflow",
            "run"
          ]
        },
        {
          "instantiator": "add_hypothesis",
          "file": "model_chorus/src/model_chorus/workflows/thinkdeep.py",
          "line": 792,
          "context": [
            "ThinkDeepWorkflow",
            "add_hypothesis"
          ]
        },
        {
          "instantiator": "test_hypothesis_creation",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 74,
          "context": [
            "TestHypothesis",
            "test_hypothesis_creation"
          ]
        },
        {
          "instantiator": "test_hypothesis_default_values",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 87,
          "context": [
            "TestHypothesis",
            "test_hypothesis_default_values"
          ]
        },
        {
          "instantiator": "test_hypothesis_all_statuses",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 98,
          "context": [
            "TestHypothesis",
            "test_hypothesis_all_statuses"
          ]
        },
        {
          "instantiator": "test_hypothesis_invalid_status",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 107,
          "context": [
            "TestHypothesis",
            "test_hypothesis_invalid_status"
          ]
        },
        {
          "instantiator": "test_hypothesis_empty_hypothesis_text",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 115,
          "context": [
            "TestHypothesis",
            "test_hypothesis_empty_hypothesis_text"
          ]
        },
        {
          "instantiator": "test_hypothesis_with_multiple_evidence",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 126,
          "context": [
            "TestHypothesis",
            "test_hypothesis_with_multiple_evidence"
          ]
        },
        {
          "instantiator": "test_hypothesis_serialization",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 137,
          "context": [
            "TestHypothesis",
            "test_hypothesis_serialization"
          ]
        },
        {
          "instantiator": "test_hypothesis_json_serialization",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 151,
          "context": [
            "TestHypothesis",
            "test_hypothesis_json_serialization"
          ]
        },
        {
          "instantiator": "test_hypothesis_from_dict",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 173,
          "context": [
            "TestHypothesis",
            "test_hypothesis_from_dict"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_creation",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 319,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_creation"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_multiple_hypotheses",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 355,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_multiple_hypotheses"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_multiple_hypotheses",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 356,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_multiple_hypotheses"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_multiple_hypotheses",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 357,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_multiple_hypotheses"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_multiple_hypotheses",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 358,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_multiple_hypotheses"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_complex_scenario",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 422,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_complex_scenario"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_complex_scenario",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 431,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_complex_scenario"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_serialization",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 494,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_serialization"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_json_roundtrip",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 520,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_json_roundtrip"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_json_roundtrip",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 525,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_json_roundtrip"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_nested_validation",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 574,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_nested_validation"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_nested_validation",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 575,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_nested_validation"
          ]
        },
        {
          "instantiator": "test_hypothesis_lifecycle",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 598,
          "context": [
            "TestModelIntegration",
            "test_hypothesis_lifecycle"
          ]
        },
        {
          "instantiator": "test_investigation_progression",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 624,
          "context": [
            "TestModelIntegration",
            "test_investigation_progression"
          ]
        },
        {
          "instantiator": "test_multiple_hypothesis_tracking",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 668,
          "context": [
            "TestModelIntegration",
            "test_multiple_hypothesis_tracking"
          ]
        },
        {
          "instantiator": "test_multiple_hypothesis_tracking",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 669,
          "context": [
            "TestModelIntegration",
            "test_multiple_hypothesis_tracking"
          ]
        },
        {
          "instantiator": "test_multiple_hypothesis_tracking",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 670,
          "context": [
            "TestModelIntegration",
            "test_multiple_hypothesis_tracking"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 28
    },
    {
      "name": "InvestigationStep",
      "file": "model_chorus/src/model_chorus/core/models.py",
      "line": 655,
      "language": "python",
      "docstring": "Model for a single investigation step in Thinkdeep workflow.\n\nCaptures the details of one step in a systematic investigation,\nincluding what was found, which files were examined, and the\ncurrent confidence level in the hypothesis.\n\nAttributes:\n    step_number: Sequential step number (1-indexed)\n    findings: Key findings and insights discovered in this step\n    files_checked: List of files examined during this step\n    confidence: Current confidence level after this step",
      "bases": [
        "BaseModel"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "run",
          "file": "model_chorus/src/model_chorus/workflows/thinkdeep.py",
          "line": 326,
          "context": [
            "ThinkDeepWorkflow",
            "run"
          ]
        },
        {
          "instantiator": "test_investigation_step_creation",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 185,
          "context": [
            "TestInvestigationStep",
            "test_investigation_step_creation"
          ]
        },
        {
          "instantiator": "test_investigation_step_default_files",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 199,
          "context": [
            "TestInvestigationStep",
            "test_investigation_step_default_files"
          ]
        },
        {
          "instantiator": "test_investigation_step_multiple_files",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 216,
          "context": [
            "TestInvestigationStep",
            "test_investigation_step_multiple_files"
          ]
        },
        {
          "instantiator": "test_investigation_step_number_validation",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 229,
          "context": [
            "TestInvestigationStep",
            "test_investigation_step_number_validation"
          ]
        },
        {
          "instantiator": "test_investigation_step_number_validation",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 236,
          "context": [
            "TestInvestigationStep",
            "test_investigation_step_number_validation"
          ]
        },
        {
          "instantiator": "test_investigation_step_number_validation",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 245,
          "context": [
            "TestInvestigationStep",
            "test_investigation_step_number_validation"
          ]
        },
        {
          "instantiator": "test_investigation_step_number_validation",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 252,
          "context": [
            "TestInvestigationStep",
            "test_investigation_step_number_validation"
          ]
        },
        {
          "instantiator": "test_investigation_step_empty_findings",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 261,
          "context": [
            "TestInvestigationStep",
            "test_investigation_step_empty_findings"
          ]
        },
        {
          "instantiator": "test_investigation_step_empty_confidence",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 270,
          "context": [
            "TestInvestigationStep",
            "test_investigation_step_empty_confidence"
          ]
        },
        {
          "instantiator": "test_investigation_step_serialization",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 278,
          "context": [
            "TestInvestigationStep",
            "test_investigation_step_serialization"
          ]
        },
        {
          "instantiator": "test_investigation_step_json_roundtrip",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 294,
          "context": [
            "TestInvestigationStep",
            "test_investigation_step_json_roundtrip"
          ]
        },
        {
          "instantiator": "test_investigation_step_json_roundtrip",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 306,
          "context": [
            "TestInvestigationStep",
            "test_investigation_step_json_roundtrip"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_creation",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 325,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_creation"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_multiple_steps",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 370,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_multiple_steps"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_multiple_steps",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 375,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_multiple_steps"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_multiple_steps",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 380,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_multiple_steps"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_multiple_steps",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 385,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_multiple_steps"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_complex_scenario",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 443,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_complex_scenario"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_complex_scenario",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 449,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_complex_scenario"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_complex_scenario",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 455,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_complex_scenario"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_serialization",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 495,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_serialization"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_json_roundtrip",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 528,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_json_roundtrip"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_json_roundtrip",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 534,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_json_roundtrip"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_nested_validation",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 583,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_nested_validation"
          ]
        },
        {
          "instantiator": "test_investigation_progression",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 629,
          "context": [
            "TestModelIntegration",
            "test_investigation_progression"
          ]
        },
        {
          "instantiator": "test_investigation_progression",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 639,
          "context": [
            "TestModelIntegration",
            "test_investigation_progression"
          ]
        },
        {
          "instantiator": "test_investigation_progression",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 648,
          "context": [
            "TestModelIntegration",
            "test_investigation_progression"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 28
    },
    {
      "name": "ThinkDeepState",
      "file": "model_chorus/src/model_chorus/core/models.py",
      "line": 709,
      "language": "python",
      "docstring": "State model for Thinkdeep workflow multi-turn conversations.\n\nMaintains the complete investigation state across conversation turns,\ntracking hypothesis evolution, investigation steps, confidence progression,\nand files examined.\n\nAttributes:\n    hypotheses: List of all hypotheses tracked during investigation\n    steps: List of all investigation steps completed\n    current_confidence: Current overall confidence level\n    relevant_files: All files identified as relevant to the investigation",
      "bases": [
        "BaseModel"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "_get_or_create_state",
          "file": "model_chorus/src/model_chorus/workflows/thinkdeep.py",
          "line": 437,
          "context": [
            "ThinkDeepWorkflow",
            "_get_or_create_state"
          ]
        },
        {
          "instantiator": "_get_or_create_state",
          "file": "model_chorus/src/model_chorus/workflows/thinkdeep.py",
          "line": 441,
          "context": [
            "ThinkDeepWorkflow",
            "_get_or_create_state"
          ]
        },
        {
          "instantiator": "_get_or_create_state",
          "file": "model_chorus/src/model_chorus/workflows/thinkdeep.py",
          "line": 446,
          "context": [
            "ThinkDeepWorkflow",
            "_get_or_create_state"
          ]
        },
        {
          "instantiator": "_get_or_create_state",
          "file": "model_chorus/src/model_chorus/workflows/thinkdeep.py",
          "line": 449,
          "context": [
            "ThinkDeepWorkflow",
            "_get_or_create_state"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_creation",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 331,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_creation"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_default_values",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 345,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_default_values"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_multiple_hypotheses",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 361,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_multiple_hypotheses"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_multiple_steps",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 392,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_multiple_steps"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_file_accumulation",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 412,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_file_accumulation"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_complex_scenario",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 464,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_complex_scenario"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_serialization",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 501,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_serialization"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_json_roundtrip",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 518,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_json_roundtrip"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_json_roundtrip",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 550,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_json_roundtrip"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_nested_validation",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 572,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_nested_validation"
          ]
        },
        {
          "instantiator": "test_thinkdeep_state_nested_validation",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 581,
          "context": [
            "TestThinkDeepState",
            "test_thinkdeep_state_nested_validation"
          ]
        },
        {
          "instantiator": "test_investigation_progression",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 616,
          "context": [
            "TestModelIntegration",
            "test_investigation_progression"
          ]
        },
        {
          "instantiator": "test_multiple_hypothesis_tracking",
          "file": "model_chorus/tests/test_thinkdeep_models.py",
          "line": 664,
          "context": [
            "TestModelIntegration",
            "test_multiple_hypothesis_tracking"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 17
    },
    {
      "name": "StudyState",
      "file": "model_chorus/src/model_chorus/core/models.py",
      "line": 784,
      "language": "python",
      "docstring": "State model for Study workflow multi-persona investigations.\n\nMaintains the complete investigation state across conversation turns,\ntracking investigation phase, persona findings, confidence levels,\nand collaborative exploration progress.\n\nAttributes:\n    investigation_id: Unique identifier for this investigation session\n    session_id: Session/thread identifier for conversation continuity\n    current_phase: Current phase of investigation (InvestigationPhase)\n    confidence: Overall confidence level in findings (ConfidenceLevel)\n    iteration_count: Number of investigation iterations completed\n    findings: List of all findings from persona investigations\n    personas_active: List of personas currently participating\n    relevant_files: Files examined during investigation",
      "bases": [
        "BaseModel"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "test_routing_skill_invocation",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 29,
          "context": [
            "TestRoutingSkillInvocation",
            "test_routing_skill_invocation"
          ]
        },
        {
          "instantiator": "test_routing_different_phases",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 84,
          "context": [
            "TestRoutingSkillInvocation",
            "test_routing_different_phases"
          ]
        },
        {
          "instantiator": "test_routing_with_findings",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 105,
          "context": [
            "TestRoutingSkillInvocation",
            "test_routing_with_findings"
          ]
        },
        {
          "instantiator": "test_routing_complete_phase",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 134,
          "context": [
            "TestRoutingSkillInvocation",
            "test_routing_complete_phase"
          ]
        },
        {
          "instantiator": "test_fallback_routing_on_exception",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 159,
          "context": [
            "TestFallbackRouting",
            "test_fallback_routing_on_exception"
          ]
        },
        {
          "instantiator": "test_fallback_for_all_phases",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 204,
          "context": [
            "TestFallbackRouting",
            "test_fallback_for_all_phases"
          ]
        },
        {
          "instantiator": "test_fallback_provides_valid_guidance",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 226,
          "context": [
            "TestFallbackRouting",
            "test_fallback_provides_valid_guidance"
          ]
        },
        {
          "instantiator": "test_routing_history_recorded",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 257,
          "context": [
            "TestRoutingHistory",
            "test_routing_history_recorded"
          ]
        },
        {
          "instantiator": "test_routing_history_filtering",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 285,
          "context": [
            "TestRoutingHistory",
            "test_routing_history_filtering"
          ]
        },
        {
          "instantiator": "test_routing_history_limit",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 308,
          "context": [
            "TestRoutingHistory",
            "test_routing_history_limit"
          ]
        },
        {
          "instantiator": "initial_state",
          "file": "model_chorus/tests/workflows/study/test_state_machine.py",
          "line": 23,
          "context": [
            "TestInvestigationStateMachineTransitions",
            "initial_state"
          ]
        },
        {
          "instantiator": "state_machine",
          "file": "model_chorus/tests/workflows/study/test_state_machine.py",
          "line": 272,
          "context": [
            "TestConfidenceLevelProgression",
            "state_machine"
          ]
        },
        {
          "instantiator": "state_machine",
          "file": "model_chorus/tests/workflows/study/test_state_machine.py",
          "line": 382,
          "context": [
            "TestStateTransitionIntegration",
            "state_machine"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 13
    },
    {
      "name": "ConversationState",
      "file": "model_chorus/src/model_chorus/core/models.py",
      "line": 872,
      "language": "python",
      "docstring": "Generic state container for workflow-specific conversation data.\n\nProvides type-safe structure for storing arbitrary workflow state\nwhile maintaining serializability for file-based persistence.\nIncludes versioning to support schema evolution.\n\nAttributes:\n    workflow_name: Workflow this state belongs to\n    data: Arbitrary workflow-specific state data\n    schema_version: State schema version for compatibility\n    created_at: ISO timestamp of state creation\n    updated_at: ISO timestamp of last state update",
      "bases": [
        "BaseModel"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "set_state",
          "file": "model_chorus/src/model_chorus/core/state.py",
          "line": 114,
          "context": [
            "StateManager",
            "set_state"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 1
    },
    {
      "name": "Citation",
      "file": "model_chorus/src/model_chorus/core/models.py",
      "line": 932,
      "language": "python",
      "docstring": "Citation model for tracking sources in ARGUMENT workflow.\n\nTracks the source of information, its location, and confidence level\nfor evidence-based argumentation and research workflows.\n\nAttributes:\n    source: The source identifier (URL, file path, document ID, etc.)\n    location: Specific location within source (page, line, section, timestamp)\n    confidence: Confidence level in the citation accuracy (0.0-1.0)\n    snippet: Optional text snippet from the source\n    metadata: Additional citation metadata (author, date, context, etc.)",
      "bases": [
        "BaseModel"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "test_citation_creation",
          "file": "model_chorus/tests/test_citation.py",
          "line": 24,
          "context": [
            "TestCitation",
            "test_citation_creation"
          ]
        },
        {
          "instantiator": "test_citation_minimal_creation",
          "file": "model_chorus/tests/test_citation.py",
          "line": 46,
          "context": [
            "TestCitation",
            "test_citation_minimal_creation"
          ]
        },
        {
          "instantiator": "test_citation_empty_source",
          "file": "model_chorus/tests/test_citation.py",
          "line": 60,
          "context": [
            "TestCitation",
            "test_citation_empty_source"
          ]
        },
        {
          "instantiator": "test_citation_confidence_bounds",
          "file": "model_chorus/tests/test_citation.py",
          "line": 68,
          "context": [
            "TestCitation",
            "test_citation_confidence_bounds"
          ]
        },
        {
          "instantiator": "test_citation_confidence_bounds",
          "file": "model_chorus/tests/test_citation.py",
          "line": 71,
          "context": [
            "TestCitation",
            "test_citation_confidence_bounds"
          ]
        },
        {
          "instantiator": "test_citation_confidence_bounds",
          "file": "model_chorus/tests/test_citation.py",
          "line": 74,
          "context": [
            "TestCitation",
            "test_citation_confidence_bounds"
          ]
        },
        {
          "instantiator": "test_citation_confidence_bounds",
          "file": "model_chorus/tests/test_citation.py",
          "line": 79,
          "context": [
            "TestCitation",
            "test_citation_confidence_bounds"
          ]
        },
        {
          "instantiator": "test_citation_confidence_bounds",
          "file": "model_chorus/tests/test_citation.py",
          "line": 83,
          "context": [
            "TestCitation",
            "test_citation_confidence_bounds"
          ]
        },
        {
          "instantiator": "test_citation_various_source_types",
          "file": "model_chorus/tests/test_citation.py",
          "line": 96,
          "context": [
            "TestCitation",
            "test_citation_various_source_types"
          ]
        },
        {
          "instantiator": "test_citation_location_formats",
          "file": "model_chorus/tests/test_citation.py",
          "line": 113,
          "context": [
            "TestCitation",
            "test_citation_location_formats"
          ]
        },
        {
          "instantiator": "test_citation_metadata_flexibility",
          "file": "model_chorus/tests/test_citation.py",
          "line": 122,
          "context": [
            "TestCitation",
            "test_citation_metadata_flexibility"
          ]
        },
        {
          "instantiator": "test_citation_serialization",
          "file": "model_chorus/tests/test_citation.py",
          "line": 148,
          "context": [
            "TestCitation",
            "test_citation_serialization"
          ]
        },
        {
          "instantiator": "test_citation_json_serialization",
          "file": "model_chorus/tests/test_citation.py",
          "line": 166,
          "context": [
            "TestCitation",
            "test_citation_json_serialization"
          ]
        },
        {
          "instantiator": "test_citation_from_dict",
          "file": "model_chorus/tests/test_citation.py",
          "line": 191,
          "context": [
            "TestCitation",
            "test_citation_from_dict"
          ]
        },
        {
          "instantiator": "test_citation_json_roundtrip",
          "file": "model_chorus/tests/test_citation.py",
          "line": 201,
          "context": [
            "TestCitation",
            "test_citation_json_roundtrip"
          ]
        },
        {
          "instantiator": "test_citation_json_roundtrip",
          "file": "model_chorus/tests/test_citation.py",
          "line": 218,
          "context": [
            "TestCitation",
            "test_citation_json_roundtrip"
          ]
        },
        {
          "instantiator": "test_citation_map_creation",
          "file": "model_chorus/tests/test_citation.py",
          "line": 233,
          "context": [
            "TestCitationMap",
            "test_citation_map_creation"
          ]
        },
        {
          "instantiator": "test_citation_map_creation",
          "file": "model_chorus/tests/test_citation.py",
          "line": 239,
          "context": [
            "TestCitationMap",
            "test_citation_map_creation"
          ]
        },
        {
          "instantiator": "test_citation_map_single_citation",
          "file": "model_chorus/tests/test_citation.py",
          "line": 334,
          "context": [
            "TestCitationMap",
            "test_citation_map_single_citation"
          ]
        },
        {
          "instantiator": "test_citation_map_multiple_citations",
          "file": "model_chorus/tests/test_citation.py",
          "line": 352,
          "context": [
            "TestCitationMap",
            "test_citation_map_multiple_citations"
          ]
        },
        {
          "instantiator": "test_citation_map_multiple_citations",
          "file": "model_chorus/tests/test_citation.py",
          "line": 353,
          "context": [
            "TestCitationMap",
            "test_citation_map_multiple_citations"
          ]
        },
        {
          "instantiator": "test_citation_map_multiple_citations",
          "file": "model_chorus/tests/test_citation.py",
          "line": 354,
          "context": [
            "TestCitationMap",
            "test_citation_map_multiple_citations"
          ]
        },
        {
          "instantiator": "test_citation_map_multiple_citations",
          "file": "model_chorus/tests/test_citation.py",
          "line": 355,
          "context": [
            "TestCitationMap",
            "test_citation_map_multiple_citations"
          ]
        },
        {
          "instantiator": "test_citation_map_multiple_citations",
          "file": "model_chorus/tests/test_citation.py",
          "line": 356,
          "context": [
            "TestCitationMap",
            "test_citation_map_multiple_citations"
          ]
        },
        {
          "instantiator": "test_citation_map_serialization",
          "file": "model_chorus/tests/test_citation.py",
          "line": 398,
          "context": [
            "TestCitationMap",
            "test_citation_map_serialization"
          ]
        },
        {
          "instantiator": "test_citation_map_json_roundtrip",
          "file": "model_chorus/tests/test_citation.py",
          "line": 439,
          "context": [
            "TestCitationMap",
            "test_citation_map_json_roundtrip"
          ]
        },
        {
          "instantiator": "test_citation_map_json_roundtrip",
          "file": "model_chorus/tests/test_citation.py",
          "line": 445,
          "context": [
            "TestCitationMap",
            "test_citation_map_json_roundtrip"
          ]
        },
        {
          "instantiator": "test_citation_map_nested_validation",
          "file": "model_chorus/tests/test_citation.py",
          "line": 489,
          "context": [
            "TestCitationMap",
            "test_citation_map_nested_validation"
          ]
        },
        {
          "instantiator": "test_citation_map_nested_validation",
          "file": "model_chorus/tests/test_citation.py",
          "line": 490,
          "context": [
            "TestCitationMap",
            "test_citation_map_nested_validation"
          ]
        },
        {
          "instantiator": "test_citation_map_nested_validation",
          "file": "model_chorus/tests/test_citation.py",
          "line": 501,
          "context": [
            "TestCitationMap",
            "test_citation_map_nested_validation"
          ]
        },
        {
          "instantiator": "test_claim_evidence_mapping",
          "file": "model_chorus/tests/test_citation.py",
          "line": 513,
          "context": [
            "TestCitationIntegration",
            "test_claim_evidence_mapping"
          ]
        },
        {
          "instantiator": "test_claim_evidence_mapping",
          "file": "model_chorus/tests/test_citation.py",
          "line": 521,
          "context": [
            "TestCitationIntegration",
            "test_claim_evidence_mapping"
          ]
        },
        {
          "instantiator": "test_claim_evidence_mapping",
          "file": "model_chorus/tests/test_citation.py",
          "line": 529,
          "context": [
            "TestCitationIntegration",
            "test_claim_evidence_mapping"
          ]
        },
        {
          "instantiator": "test_multiple_claims_same_source",
          "file": "model_chorus/tests/test_citation.py",
          "line": 570,
          "context": [
            "TestCitationIntegration",
            "test_multiple_claims_same_source"
          ]
        },
        {
          "instantiator": "test_multiple_claims_same_source",
          "file": "model_chorus/tests/test_citation.py",
          "line": 577,
          "context": [
            "TestCitationIntegration",
            "test_multiple_claims_same_source"
          ]
        },
        {
          "instantiator": "test_multiple_claims_same_source",
          "file": "model_chorus/tests/test_citation.py",
          "line": 584,
          "context": [
            "TestCitationIntegration",
            "test_multiple_claims_same_source"
          ]
        },
        {
          "instantiator": "test_citation_strength_calculation",
          "file": "model_chorus/tests/test_citation.py",
          "line": 624,
          "context": [
            "TestCitationIntegration",
            "test_citation_strength_calculation"
          ]
        },
        {
          "instantiator": "test_citation_strength_calculation",
          "file": "model_chorus/tests/test_citation.py",
          "line": 625,
          "context": [
            "TestCitationIntegration",
            "test_citation_strength_calculation"
          ]
        },
        {
          "instantiator": "test_citation_strength_calculation",
          "file": "model_chorus/tests/test_citation.py",
          "line": 626,
          "context": [
            "TestCitationIntegration",
            "test_citation_strength_calculation"
          ]
        },
        {
          "instantiator": "test_citation_strength_calculation",
          "file": "model_chorus/tests/test_citation.py",
          "line": 627,
          "context": [
            "TestCitationIntegration",
            "test_citation_strength_calculation"
          ]
        },
        {
          "instantiator": "test_citation_filtering_by_confidence",
          "file": "model_chorus/tests/test_citation.py",
          "line": 646,
          "context": [
            "TestCitationIntegration",
            "test_citation_filtering_by_confidence"
          ]
        },
        {
          "instantiator": "test_citation_filtering_by_confidence",
          "file": "model_chorus/tests/test_citation.py",
          "line": 647,
          "context": [
            "TestCitationIntegration",
            "test_citation_filtering_by_confidence"
          ]
        },
        {
          "instantiator": "test_citation_filtering_by_confidence",
          "file": "model_chorus/tests/test_citation.py",
          "line": 648,
          "context": [
            "TestCitationIntegration",
            "test_citation_filtering_by_confidence"
          ]
        },
        {
          "instantiator": "test_citation_filtering_by_confidence",
          "file": "model_chorus/tests/test_citation.py",
          "line": 649,
          "context": [
            "TestCitationIntegration",
            "test_citation_filtering_by_confidence"
          ]
        },
        {
          "instantiator": "test_citation_filtering_by_confidence",
          "file": "model_chorus/tests/test_citation.py",
          "line": 650,
          "context": [
            "TestCitationIntegration",
            "test_citation_filtering_by_confidence"
          ]
        },
        {
          "instantiator": "test_argument_workflow_citation_tracking",
          "file": "model_chorus/tests/test_citation.py",
          "line": 676,
          "context": [
            "TestCitationIntegration",
            "test_argument_workflow_citation_tracking"
          ]
        },
        {
          "instantiator": "test_argument_workflow_citation_tracking",
          "file": "model_chorus/tests/test_citation.py",
          "line": 684,
          "context": [
            "TestCitationIntegration",
            "test_argument_workflow_citation_tracking"
          ]
        },
        {
          "instantiator": "test_add_similarity_to_citation_with_snippet",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 313,
          "context": [
            "TestCitationIntegration",
            "test_add_similarity_to_citation_with_snippet"
          ]
        },
        {
          "instantiator": "test_add_similarity_to_citation_without_snippet",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 329,
          "context": [
            "TestCitationIntegration",
            "test_add_similarity_to_citation_without_snippet"
          ]
        },
        {
          "instantiator": "test_add_similarity_preserves_existing_metadata",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 344,
          "context": [
            "TestCitationIntegration",
            "test_add_similarity_preserves_existing_metadata"
          ]
        },
        {
          "instantiator": "complete_citation",
          "file": "tests/test_citation.py",
          "line": 28,
          "context": [
            "complete_citation"
          ]
        },
        {
          "instantiator": "minimal_citation",
          "file": "tests/test_citation.py",
          "line": 44,
          "context": [
            "minimal_citation"
          ]
        },
        {
          "instantiator": "file_citation",
          "file": "tests/test_citation.py",
          "line": 53,
          "context": [
            "file_citation"
          ]
        },
        {
          "instantiator": "doi_citation",
          "file": "tests/test_citation.py",
          "line": 68,
          "context": [
            "doi_citation"
          ]
        },
        {
          "instantiator": "test_year_extraction_from_full_date",
          "file": "tests/test_citation.py",
          "line": 186,
          "context": [
            "TestCitationFormatting",
            "test_year_extraction_from_full_date"
          ]
        },
        {
          "instantiator": "test_validate_empty_source_fails",
          "file": "tests/test_citation.py",
          "line": 272,
          "context": [
            "TestCitationValidation",
            "test_validate_empty_source_fails"
          ]
        },
        {
          "instantiator": "test_validate_whitespace_source_fails",
          "file": "tests/test_citation.py",
          "line": 276,
          "context": [
            "TestCitationValidation",
            "test_validate_whitespace_source_fails"
          ]
        },
        {
          "instantiator": "test_validate_confidence_out_of_range_low",
          "file": "tests/test_citation.py",
          "line": 285,
          "context": [
            "TestCitationValidation",
            "test_validate_confidence_out_of_range_low"
          ]
        },
        {
          "instantiator": "test_validate_confidence_out_of_range_high",
          "file": "tests/test_citation.py",
          "line": 296,
          "context": [
            "TestCitationValidation",
            "test_validate_confidence_out_of_range_high"
          ]
        },
        {
          "instantiator": "test_validate_recognized_source_formats",
          "file": "tests/test_citation.py",
          "line": 317,
          "context": [
            "TestCitationValidation",
            "test_validate_recognized_source_formats"
          ]
        },
        {
          "instantiator": "test_validate_unrecognized_source_format",
          "file": "tests/test_citation.py",
          "line": 329,
          "context": [
            "TestCitationValidation",
            "test_validate_unrecognized_source_format"
          ]
        },
        {
          "instantiator": "test_confidence_academic_source_bonus",
          "file": "tests/test_citation.py",
          "line": 376,
          "context": [
            "TestCitationConfidenceScoring",
            "test_confidence_academic_source_bonus"
          ]
        },
        {
          "instantiator": "test_confidence_doi_source_bonus",
          "file": "tests/test_citation.py",
          "line": 388,
          "context": [
            "TestCitationConfidenceScoring",
            "test_confidence_doi_source_bonus"
          ]
        },
        {
          "instantiator": "test_confidence_https_vs_http",
          "file": "tests/test_citation.py",
          "line": 400,
          "context": [
            "TestCitationConfidenceScoring",
            "test_confidence_https_vs_http"
          ]
        },
        {
          "instantiator": "test_confidence_https_vs_http",
          "file": "tests/test_citation.py",
          "line": 405,
          "context": [
            "TestCitationConfidenceScoring",
            "test_confidence_https_vs_http"
          ]
        },
        {
          "instantiator": "test_confidence_location_specificity_bonus",
          "file": "tests/test_citation.py",
          "line": 419,
          "context": [
            "TestCitationConfidenceScoring",
            "test_confidence_location_specificity_bonus"
          ]
        },
        {
          "instantiator": "test_confidence_location_specificity_bonus",
          "file": "tests/test_citation.py",
          "line": 424,
          "context": [
            "TestCitationConfidenceScoring",
            "test_confidence_location_specificity_bonus"
          ]
        },
        {
          "instantiator": "test_confidence_location_specificity_bonus",
          "file": "tests/test_citation.py",
          "line": 433,
          "context": [
            "TestCitationConfidenceScoring",
            "test_confidence_location_specificity_bonus"
          ]
        },
        {
          "instantiator": "test_calculate_map_confidence_count_plateau",
          "file": "tests/test_citation.py",
          "line": 501,
          "context": [
            "TestCitationMapConfidenceScoring",
            "test_calculate_map_confidence_count_plateau"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 69
    },
    {
      "name": "CitationMap",
      "file": "model_chorus/src/model_chorus/core/models.py",
      "line": 992,
      "language": "python",
      "docstring": "Maps claims to their supporting citations for evidence tracking.\n\nUsed in ARGUMENT workflow to maintain bidirectional mapping between\nclaims/arguments and their source citations, enabling verification\nand citation analysis.\n\nAttributes:\n    claim_id: Unique identifier for the claim being supported\n    claim_text: The actual claim or argument text\n    citations: List of Citation objects supporting this claim\n    strength: Overall strength of citation support (0.0-1.0)\n    metadata: Additional mapping metadata (argument_type, verification_status, etc.)",
      "bases": [
        "BaseModel"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "test_citation_map_creation",
          "file": "model_chorus/tests/test_citation.py",
          "line": 247,
          "context": [
            "TestCitationMap",
            "test_citation_map_creation"
          ]
        },
        {
          "instantiator": "test_citation_map_minimal_creation",
          "file": "model_chorus/tests/test_citation.py",
          "line": 269,
          "context": [
            "TestCitationMap",
            "test_citation_map_minimal_creation"
          ]
        },
        {
          "instantiator": "test_citation_map_empty_claim_id",
          "file": "model_chorus/tests/test_citation.py",
          "line": 284,
          "context": [
            "TestCitationMap",
            "test_citation_map_empty_claim_id"
          ]
        },
        {
          "instantiator": "test_citation_map_empty_claim_text",
          "file": "model_chorus/tests/test_citation.py",
          "line": 293,
          "context": [
            "TestCitationMap",
            "test_citation_map_empty_claim_text"
          ]
        },
        {
          "instantiator": "test_citation_map_strength_bounds",
          "file": "model_chorus/tests/test_citation.py",
          "line": 302,
          "context": [
            "TestCitationMap",
            "test_citation_map_strength_bounds"
          ]
        },
        {
          "instantiator": "test_citation_map_strength_bounds",
          "file": "model_chorus/tests/test_citation.py",
          "line": 309,
          "context": [
            "TestCitationMap",
            "test_citation_map_strength_bounds"
          ]
        },
        {
          "instantiator": "test_citation_map_strength_bounds",
          "file": "model_chorus/tests/test_citation.py",
          "line": 318,
          "context": [
            "TestCitationMap",
            "test_citation_map_strength_bounds"
          ]
        },
        {
          "instantiator": "test_citation_map_strength_bounds",
          "file": "model_chorus/tests/test_citation.py",
          "line": 326,
          "context": [
            "TestCitationMap",
            "test_citation_map_strength_bounds"
          ]
        },
        {
          "instantiator": "test_citation_map_single_citation",
          "file": "model_chorus/tests/test_citation.py",
          "line": 339,
          "context": [
            "TestCitationMap",
            "test_citation_map_single_citation"
          ]
        },
        {
          "instantiator": "test_citation_map_multiple_citations",
          "file": "model_chorus/tests/test_citation.py",
          "line": 359,
          "context": [
            "TestCitationMap",
            "test_citation_map_multiple_citations"
          ]
        },
        {
          "instantiator": "test_citation_map_metadata_flexibility",
          "file": "model_chorus/tests/test_citation.py",
          "line": 375,
          "context": [
            "TestCitationMap",
            "test_citation_map_metadata_flexibility"
          ]
        },
        {
          "instantiator": "test_citation_map_serialization",
          "file": "model_chorus/tests/test_citation.py",
          "line": 400,
          "context": [
            "TestCitationMap",
            "test_citation_map_serialization"
          ]
        },
        {
          "instantiator": "test_citation_map_json_serialization",
          "file": "model_chorus/tests/test_citation.py",
          "line": 418,
          "context": [
            "TestCitationMap",
            "test_citation_map_json_serialization"
          ]
        },
        {
          "instantiator": "test_citation_map_json_roundtrip",
          "file": "model_chorus/tests/test_citation.py",
          "line": 435,
          "context": [
            "TestCitationMap",
            "test_citation_map_json_roundtrip"
          ]
        },
        {
          "instantiator": "test_citation_map_json_roundtrip",
          "file": "model_chorus/tests/test_citation.py",
          "line": 463,
          "context": [
            "TestCitationMap",
            "test_citation_map_json_roundtrip"
          ]
        },
        {
          "instantiator": "test_citation_map_nested_validation",
          "file": "model_chorus/tests/test_citation.py",
          "line": 485,
          "context": [
            "TestCitationMap",
            "test_citation_map_nested_validation"
          ]
        },
        {
          "instantiator": "test_citation_map_nested_validation",
          "file": "model_chorus/tests/test_citation.py",
          "line": 497,
          "context": [
            "TestCitationMap",
            "test_citation_map_nested_validation"
          ]
        },
        {
          "instantiator": "test_claim_evidence_mapping",
          "file": "model_chorus/tests/test_citation.py",
          "line": 537,
          "context": [
            "TestCitationIntegration",
            "test_claim_evidence_mapping"
          ]
        },
        {
          "instantiator": "test_multiple_claims_same_source",
          "file": "model_chorus/tests/test_citation.py",
          "line": 592,
          "context": [
            "TestCitationIntegration",
            "test_multiple_claims_same_source"
          ]
        },
        {
          "instantiator": "test_multiple_claims_same_source",
          "file": "model_chorus/tests/test_citation.py",
          "line": 599,
          "context": [
            "TestCitationIntegration",
            "test_multiple_claims_same_source"
          ]
        },
        {
          "instantiator": "test_multiple_claims_same_source",
          "file": "model_chorus/tests/test_citation.py",
          "line": 606,
          "context": [
            "TestCitationIntegration",
            "test_multiple_claims_same_source"
          ]
        },
        {
          "instantiator": "test_citation_strength_calculation",
          "file": "model_chorus/tests/test_citation.py",
          "line": 633,
          "context": [
            "TestCitationIntegration",
            "test_citation_strength_calculation"
          ]
        },
        {
          "instantiator": "test_citation_filtering_by_confidence",
          "file": "model_chorus/tests/test_citation.py",
          "line": 656,
          "context": [
            "TestCitationIntegration",
            "test_citation_filtering_by_confidence"
          ]
        },
        {
          "instantiator": "test_argument_workflow_citation_tracking",
          "file": "model_chorus/tests/test_citation.py",
          "line": 693,
          "context": [
            "TestCitationIntegration",
            "test_argument_workflow_citation_tracking"
          ]
        },
        {
          "instantiator": "test_argument_workflow_citation_tracking",
          "file": "model_chorus/tests/test_citation.py",
          "line": 706,
          "context": [
            "TestCitationIntegration",
            "test_argument_workflow_citation_tracking"
          ]
        },
        {
          "instantiator": "sample_citation_maps",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 170,
          "context": [
            "TestFindSimilarClaims",
            "sample_citation_maps"
          ]
        },
        {
          "instantiator": "sample_citation_maps",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 176,
          "context": [
            "TestFindSimilarClaims",
            "sample_citation_maps"
          ]
        },
        {
          "instantiator": "sample_citation_maps",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 182,
          "context": [
            "TestFindSimilarClaims",
            "sample_citation_maps"
          ]
        },
        {
          "instantiator": "sample_citation_maps",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 188,
          "context": [
            "TestFindSimilarClaims",
            "sample_citation_maps"
          ]
        },
        {
          "instantiator": "test_find_duplicate_claims_basic",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 364,
          "context": [
            "TestDuplicateDetection",
            "test_find_duplicate_claims_basic"
          ]
        },
        {
          "instantiator": "test_find_duplicate_claims_basic",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 370,
          "context": [
            "TestDuplicateDetection",
            "test_find_duplicate_claims_basic"
          ]
        },
        {
          "instantiator": "test_find_duplicate_claims_basic",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 376,
          "context": [
            "TestDuplicateDetection",
            "test_find_duplicate_claims_basic"
          ]
        },
        {
          "instantiator": "test_find_duplicate_claims_high_threshold",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 394,
          "context": [
            "TestDuplicateDetection",
            "test_find_duplicate_claims_high_threshold"
          ]
        },
        {
          "instantiator": "test_find_duplicate_claims_high_threshold",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 400,
          "context": [
            "TestDuplicateDetection",
            "test_find_duplicate_claims_high_threshold"
          ]
        },
        {
          "instantiator": "test_find_duplicate_claims_high_threshold",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 406,
          "context": [
            "TestDuplicateDetection",
            "test_find_duplicate_claims_high_threshold"
          ]
        },
        {
          "instantiator": "test_find_duplicate_claims_no_duplicates",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 422,
          "context": [
            "TestDuplicateDetection",
            "test_find_duplicate_claims_no_duplicates"
          ]
        },
        {
          "instantiator": "test_find_duplicate_claims_no_duplicates",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 428,
          "context": [
            "TestDuplicateDetection",
            "test_find_duplicate_claims_no_duplicates"
          ]
        },
        {
          "instantiator": "test_find_duplicate_claims_no_duplicates",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 434,
          "context": [
            "TestDuplicateDetection",
            "test_find_duplicate_claims_no_duplicates"
          ]
        },
        {
          "instantiator": "test_find_duplicate_claims_single_item",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 456,
          "context": [
            "TestDuplicateDetection",
            "test_find_duplicate_claims_single_item"
          ]
        },
        {
          "instantiator": "diverse_citation_maps",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 508,
          "context": [
            "TestKMeansClustering",
            "diverse_citation_maps"
          ]
        },
        {
          "instantiator": "diverse_citation_maps",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 514,
          "context": [
            "TestKMeansClustering",
            "diverse_citation_maps"
          ]
        },
        {
          "instantiator": "diverse_citation_maps",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 520,
          "context": [
            "TestKMeansClustering",
            "diverse_citation_maps"
          ]
        },
        {
          "instantiator": "diverse_citation_maps",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 527,
          "context": [
            "TestKMeansClustering",
            "diverse_citation_maps"
          ]
        },
        {
          "instantiator": "diverse_citation_maps",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 533,
          "context": [
            "TestKMeansClustering",
            "diverse_citation_maps"
          ]
        },
        {
          "instantiator": "diverse_citation_maps",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 540,
          "context": [
            "TestKMeansClustering",
            "diverse_citation_maps"
          ]
        },
        {
          "instantiator": "diverse_citation_maps",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 546,
          "context": [
            "TestKMeansClustering",
            "diverse_citation_maps"
          ]
        },
        {
          "instantiator": "test_cluster_claims_kmeans_too_many_clusters",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 580,
          "context": [
            "TestKMeansClustering",
            "test_cluster_claims_kmeans_too_many_clusters"
          ]
        },
        {
          "instantiator": "test_cluster_claims_kmeans_too_many_clusters",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 581,
          "context": [
            "TestKMeansClustering",
            "test_cluster_claims_kmeans_too_many_clusters"
          ]
        },
        {
          "instantiator": "sample_maps",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 604,
          "context": [
            "TestHierarchicalClustering",
            "sample_maps"
          ]
        },
        {
          "instantiator": "sample_maps",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 610,
          "context": [
            "TestHierarchicalClustering",
            "sample_maps"
          ]
        },
        {
          "instantiator": "sample_maps",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 616,
          "context": [
            "TestHierarchicalClustering",
            "sample_maps"
          ]
        },
        {
          "instantiator": "sample_maps",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 622,
          "context": [
            "TestHierarchicalClustering",
            "sample_maps"
          ]
        },
        {
          "instantiator": "test_cluster_claims_hierarchical_too_many_clusters",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 658,
          "context": [
            "TestHierarchicalClustering",
            "test_cluster_claims_hierarchical_too_many_clusters"
          ]
        },
        {
          "instantiator": "test_get_cluster_representative_basic",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 671,
          "context": [
            "TestClusterRepresentative",
            "test_get_cluster_representative_basic"
          ]
        },
        {
          "instantiator": "test_get_cluster_representative_basic",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 677,
          "context": [
            "TestClusterRepresentative",
            "test_get_cluster_representative_basic"
          ]
        },
        {
          "instantiator": "test_get_cluster_representative_basic",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 683,
          "context": [
            "TestClusterRepresentative",
            "test_get_cluster_representative_basic"
          ]
        },
        {
          "instantiator": "test_get_cluster_representative_single_item",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 699,
          "context": [
            "TestClusterRepresentative",
            "test_get_cluster_representative_single_item"
          ]
        },
        {
          "instantiator": "test_compute_cluster_statistics_basic",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 725,
          "context": [
            "TestClusterStatistics",
            "test_compute_cluster_statistics_basic"
          ]
        },
        {
          "instantiator": "test_compute_cluster_statistics_basic",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 726,
          "context": [
            "TestClusterStatistics",
            "test_compute_cluster_statistics_basic"
          ]
        },
        {
          "instantiator": "test_compute_cluster_statistics_basic",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 727,
          "context": [
            "TestClusterStatistics",
            "test_compute_cluster_statistics_basic"
          ]
        },
        {
          "instantiator": "test_compute_cluster_statistics_basic",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 731,
          "context": [
            "TestClusterStatistics",
            "test_compute_cluster_statistics_basic"
          ]
        },
        {
          "instantiator": "test_compute_cluster_statistics_basic",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 732,
          "context": [
            "TestClusterStatistics",
            "test_compute_cluster_statistics_basic"
          ]
        },
        {
          "instantiator": "test_compute_cluster_statistics_single_item_clusters",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 758,
          "context": [
            "TestClusterStatistics",
            "test_compute_cluster_statistics_single_item_clusters"
          ]
        },
        {
          "instantiator": "test_compute_cluster_statistics_single_item_clusters",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 759,
          "context": [
            "TestClusterStatistics",
            "test_compute_cluster_statistics_single_item_clusters"
          ]
        },
        {
          "instantiator": "test_kmeans_to_statistics_pipeline",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 774,
          "context": [
            "TestClusteringIntegration",
            "test_kmeans_to_statistics_pipeline"
          ]
        },
        {
          "instantiator": "test_hierarchical_to_statistics_pipeline",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 791,
          "context": [
            "TestClusteringIntegration",
            "test_hierarchical_to_statistics_pipeline"
          ]
        },
        {
          "instantiator": "test_hierarchical_to_statistics_pipeline",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 792,
          "context": [
            "TestClusteringIntegration",
            "test_hierarchical_to_statistics_pipeline"
          ]
        },
        {
          "instantiator": "test_hierarchical_to_statistics_pipeline",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 793,
          "context": [
            "TestClusteringIntegration",
            "test_hierarchical_to_statistics_pipeline"
          ]
        },
        {
          "instantiator": "test_hierarchical_to_statistics_pipeline",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 794,
          "context": [
            "TestClusteringIntegration",
            "test_hierarchical_to_statistics_pipeline"
          ]
        },
        {
          "instantiator": "citation_map_complete",
          "file": "tests/test_citation.py",
          "line": 83,
          "context": [
            "citation_map_complete"
          ]
        },
        {
          "instantiator": "citation_map_empty",
          "file": "tests/test_citation.py",
          "line": 95,
          "context": [
            "citation_map_empty"
          ]
        },
        {
          "instantiator": "test_calculate_map_confidence_count_plateau",
          "file": "tests/test_citation.py",
          "line": 505,
          "context": [
            "TestCitationMapConfidenceScoring",
            "test_calculate_map_confidence_count_plateau"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 72
    },
    {
      "name": "Claim",
      "file": "model_chorus/src/model_chorus/core/models.py",
      "line": 1067,
      "language": "python",
      "docstring": "Represents a factual or arguable statement extracted from model output.\n\nClaims are fundamental units in argument analysis and research workflows.\nEach claim captures a specific assertion along with metadata about its source,\nlocation, and confidence level.\n\nUsed in workflows like:\n- ARGUMENT: Extracting claims from debate responses for contradiction detection\n- RESEARCH: Identifying factual claims across multiple sources\n- IDEATE: Capturing key assertions from diverse perspectives\n\nAttributes:\n    content: The actual claim text (the statement being made)\n    source_id: Identifier for the source (role name, document ID, model ID, etc.)\n    location: Optional location within source (line number, section, paragraph, etc.)\n    confidence: Confidence score for this claim (0.0 = low, 1.0 = high)\n\nExample:\n    >>> claim = Claim(\n    ...     content=\"TypeScript reduces runtime errors by 15%\",\n    ...     source_id=\"proponent\",\n    ...     location=\"paragraph 2\",\n    ...     confidence=0.8\n    ... )\n    >>> print(claim)\n    [proponent@paragraph 2] (0.80): TypeScript reduces runtime errors by 15%",
      "bases": [
        "BaseModel"
      ],
      "methods": [
        "__str__",
        "to_dict",
        "from_dict"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "Evidence",
      "file": "model_chorus/src/model_chorus/core/models.py",
      "line": 1189,
      "language": "python",
      "docstring": "Represents supporting or refuting evidence for claims and hypotheses.\n\nEvidence is a fundamental building block in investigation, research, and\nargument workflows. Each piece of evidence captures specific information\nfrom a source along with its type, strength, and relevance.\n\nUsed in workflows like:\n- THINKDEEP: Tracking evidence that supports or refutes hypotheses\n- ARGUMENT: Recording factual evidence for debate claims\n- RESEARCH: Documenting findings from multiple sources\n\nAttributes:\n    content: The actual evidence text (the observation or fact)\n    source_id: Identifier for the source (file path, model ID, document ID, etc.)\n    location: Optional location within source (line number, section, page, etc.)\n    evidence_type: Type of evidence (supporting, refuting, neutral, contextual)\n    strength: Strength/weight of this evidence (0.0 = weak, 1.0 = strong)\n    timestamp: Optional ISO timestamp when evidence was collected\n    metadata: Additional evidence metadata (tags, categories, analysis, etc.)\n\nExample:\n    >>> evidence = Evidence(\n    ...     content=\"Found async def pattern in auth.py line 45\",\n    ...     source_id=\"src/services/auth.py\",\n    ...     location=\"line 45\",\n    ...     evidence_type=\"supporting\",\n    ...     strength=0.9\n    ... )\n    >>> print(evidence)\n    [src/services/auth.py@line 45] (supporting, 0.90): Found async def pattern in auth.py line 45",
      "bases": [
        "BaseModel"
      ],
      "methods": [
        "__str__",
        "to_dict",
        "from_dict"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "ArgumentPerspective",
      "file": "model_chorus/src/model_chorus/core/models.py",
      "line": 1363,
      "language": "python",
      "docstring": "Represents a single perspective in an argument analysis.\n\nEach perspective captures one role's analysis (Creator, Skeptic, or Moderator)\nwith their stance, reasoning, and key points.\n\nAttributes:\n    role: The role name (creator, skeptic, moderator)\n    stance: The perspective's stance (for, against, neutral)\n    content: Full response content from this perspective\n    key_points: List of key points or arguments\n    model: Model used for this perspective\n    metadata: Additional perspective metadata\n\nExample:\n    >>> perspective = ArgumentPerspective(\n    ...     role=\"creator\",\n    ...     stance=\"for\",\n    ...     content=\"Universal basic income would reduce poverty...\",\n    ...     key_points=[\"Ensures basic needs\", \"Reduces wealth gap\"],\n    ...     model=\"claude-sonnet-4\"\n    ... )",
      "bases": [
        "BaseModel"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "from_dict",
          "file": "model_chorus/src/model_chorus/core/models.py",
          "line": 1568,
          "context": [
            "ArgumentMap",
            "from_dict"
          ]
        },
        {
          "instantiator": "_generate_argument_map",
          "file": "model_chorus/src/model_chorus/workflows/argument/argument_workflow.py",
          "line": 309,
          "context": [
            "ArgumentWorkflow",
            "_generate_argument_map"
          ]
        },
        {
          "instantiator": "_generate_argument_map",
          "file": "model_chorus/src/model_chorus/workflows/argument/argument_workflow.py",
          "line": 319,
          "context": [
            "ArgumentWorkflow",
            "_generate_argument_map"
          ]
        },
        {
          "instantiator": "_generate_argument_map",
          "file": "model_chorus/src/model_chorus/workflows/argument/argument_workflow.py",
          "line": 329,
          "context": [
            "ArgumentWorkflow",
            "_generate_argument_map"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 4
    },
    {
      "name": "ArgumentMap",
      "file": "model_chorus/src/model_chorus/core/models.py",
      "line": 1434,
      "language": "python",
      "docstring": "Structured output from ARGUMENT workflow containing all perspectives.\n\nArgumentMap provides a comprehensive view of the dialectical analysis,\nincluding the thesis (Creator), rebuttal (Skeptic), and synthesis (Moderator).\nThis structured format enables programmatic access to different perspectives\nand supports downstream analysis, visualization, and decision-making.\n\nAttributes:\n    topic: The argument topic or claim being analyzed\n    perspectives: List of perspectives (Creator, Skeptic, Moderator)\n    synthesis: Final balanced synthesis from Moderator\n    metadata: Additional workflow metadata (thread_id, model, timestamps, etc.)\n\nExample:\n    >>> arg_map = ArgumentMap(\n    ...     topic=\"Universal basic income would reduce poverty\",\n    ...     perspectives=[creator_perspective, skeptic_perspective, moderator_perspective],\n    ...     synthesis=\"After examining both perspectives...\",\n    ...     metadata={\"thread_id\": \"abc123\", \"model\": \"claude-sonnet-4\"}\n    ... )\n    >>> print(arg_map.perspectives[0].role)  # 'creator'\n    >>> print(arg_map.perspectives[1].role)  # 'skeptic'\n    >>> print(arg_map.perspectives[2].role)  # 'moderator'",
      "bases": [
        "BaseModel"
      ],
      "methods": [
        "get_perspective",
        "to_dict",
        "from_dict"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "_generate_argument_map",
          "file": "model_chorus/src/model_chorus/workflows/argument/argument_workflow.py",
          "line": 339,
          "context": [
            "ArgumentWorkflow",
            "_generate_argument_map"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 1
    },
    {
      "name": "Idea",
      "file": "model_chorus/src/model_chorus/core/models.py",
      "line": 1584,
      "language": "python",
      "docstring": "Represents a single idea extracted from brainstorming.\n\nUsed in the IDEATE workflow to track individual creative ideas\nthat are extracted from multiple perspective-based brainstorming sessions.\n\nAttributes:\n    id: Unique identifier for the idea (e.g., \"idea-1\")\n    label: Brief descriptive label for the idea (1-2 words)\n    description: Full description of the idea (1-2 sentences)\n    perspective: The perspective this idea originated from (practical, innovative, etc.)\n    source_model: Model that generated this idea\n    metadata: Additional metadata about the idea\n\nExample:\n    >>> idea = Idea(\n    ...     id=\"idea-1\",\n    ...     label=\"Gamification System\",\n    ...     description=\"Add game mechanics like points and badges to improve engagement\",\n    ...     perspective=\"innovative\",\n    ...     source_model=\"claude\"\n    ... )",
      "bases": [
        "BaseModel"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "from_dict",
          "file": "model_chorus/src/model_chorus/core/models.py",
          "line": 2016,
          "context": [
            "IdeationState",
            "from_dict"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 1
    },
    {
      "name": "IdeaCluster",
      "file": "model_chorus/src/model_chorus/core/models.py",
      "line": 1657,
      "language": "python",
      "docstring": "Represents a themed cluster of related ideas.\n\nUsed in the IDEATE workflow to group similar ideas into coherent\nthemes after convergent analysis. Each cluster represents a distinct\napproach or solution category.\n\nAttributes:\n    id: Unique identifier for the cluster (e.g., \"cluster-1\")\n    theme: Theme name that describes this cluster\n    description: Detailed description of the cluster theme\n    idea_ids: List of idea IDs belonging to this cluster\n    ideas: Optional list of full Idea objects in this cluster\n    scores: Evaluation scores for this cluster (feasibility, impact, etc.)\n    overall_score: Average score across all criteria (0.0-5.0)\n    recommendation: Priority recommendation (High/Medium/Low Priority)\n    metadata: Additional metadata about the cluster\n\nExample:\n    >>> cluster = IdeaCluster(\n    ...     id=\"cluster-1\",\n    ...     theme=\"User Experience Improvements\",\n    ...     description=\"Ideas focused on enhancing user interface and usability\",\n    ...     idea_ids=[\"idea-1\", \"idea-3\", \"idea-5\"],\n    ...     scores={\"feasibility\": 4.5, \"impact\": 4.0, \"novelty\": 3.5},\n    ...     overall_score=4.0,\n    ...     recommendation=\"High Priority\"\n    ... )",
      "bases": [
        "BaseModel"
      ],
      "methods": [
        "add_idea",
        "get_idea_count"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "from_dict",
          "file": "model_chorus/src/model_chorus/core/models.py",
          "line": 2022,
          "context": [
            "IdeationState",
            "from_dict"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 1
    },
    {
      "name": "IdeationState",
      "file": "model_chorus/src/model_chorus/core/models.py",
      "line": 1785,
      "language": "python",
      "docstring": "Represents the complete state of an ideation workflow session.\n\nTracks the full lifecycle of an IDEATE workflow execution, from initial\nbrainstorming through convergent analysis, selection, and elaboration.\n\nAttributes:\n    session_id: Unique identifier for this ideation session\n    topic: The topic or problem being ideated on\n    perspectives: List of perspectives used in brainstorming\n    ideas: All extracted ideas from brainstorming\n    clusters: Thematic clusters of related ideas\n    selected_cluster_ids: IDs of clusters selected for elaboration\n    elaborations: Detailed outlines for selected clusters\n    scoring_criteria: Criteria used for evaluation (feasibility, impact, etc.)\n    workflow_metadata: Metadata about workflow execution\n    created_at: Timestamp when ideation session started\n    updated_at: Timestamp of last update\n\nExample:\n    >>> state = IdeationState(\n    ...     session_id=\"ideation-2024-01-15-001\",\n    ...     topic=\"How can we improve our API documentation?\",\n    ...     perspectives=[\"practical\", \"innovative\", \"user-focused\"],\n    ...     ideas=[idea1, idea2, idea3],\n    ...     clusters=[cluster1, cluster2],\n    ...     selected_cluster_ids=[\"cluster-1\"],\n    ...     scoring_criteria=[\"feasibility\", \"impact\", \"user_value\"]\n    ... )",
      "bases": [
        "BaseModel"
      ],
      "methods": [
        "add_idea",
        "add_cluster",
        "get_cluster_by_id",
        "get_selected_clusters",
        "get_idea_count",
        "get_cluster_count",
        "to_dict",
        "from_dict"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "Source",
      "file": "model_chorus/src/model_chorus/core/models.py",
      "line": 2046,
      "language": "python",
      "docstring": "Represents a research source with metadata and validation.\n\nUsed in the RESEARCH workflow to track sources that provide evidence\nfor research findings. Each source includes credibility assessment,\ntype classification, and validation status.\n\nAttributes:\n    source_id: Unique identifier for this source\n    title: Title or description of the source\n    url: Optional URL or reference to the source\n    source_type: Type of source (article, paper, book, website, etc.)\n    credibility: Credibility assessment (high, medium, low, unassessed)\n    tags: Optional list of tags for categorization\n    validated: Whether source has been validated\n    validation_score: Numeric validation score if validated\n    validation_notes: List of validation findings\n    ingested_at: ISO timestamp when source was added\n    metadata: Additional source metadata\n\nExample:\n    >>> source = Source(\n    ...     source_id=\"src-001\",\n    ...     title=\"Machine Learning Best Practices\",\n    ...     url=\"https://example.com/ml-practices\",\n    ...     source_type=\"article\",\n    ...     credibility=\"high\",\n    ...     tags=[\"machine-learning\", \"best-practices\"]\n    ... )",
      "bases": [
        "BaseModel"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "WorkflowRegistry",
      "file": "model_chorus/src/model_chorus/core/registry.py",
      "line": 13,
      "language": "python",
      "docstring": "Registry for workflow implementations.\n\nProvides a plugin system for registering and retrieving workflow classes\ndynamically. Workflows can be registered using the @register decorator or\nprogrammatically via register_workflow().\n\nExample:\n    ```python\n    @WorkflowRegistry.register(\"thinkdeep\")\n    class ThinkDeepWorkflow(BaseWorkflow):\n        async def run(self, prompt: str, **kwargs):\n            # Implementation\n            pass\n\n    # Later, retrieve the workflow\n    workflow_class = WorkflowRegistry.get(\"thinkdeep\")\n    workflow = workflow_class(\"My Workflow\", \"Description\")\n    ```",
      "bases": [],
      "methods": [
        "register",
        "register_workflow",
        "get",
        "list_workflows",
        "is_registered",
        "unregister",
        "clear"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "OrchestrationPattern",
      "file": "model_chorus/src/model_chorus/core/role_orchestration.py",
      "line": 29,
      "language": "python",
      "docstring": "Execution patterns for multi-model orchestration.\n\nDefines how multiple models with assigned roles are coordinated\nduring workflow execution. Different patterns enable different\ncollaboration strategies.\n\nValues:\n    SEQUENTIAL: Execute models one at a time in defined order\n               (e.g., analyst \u2192 critic \u2192 synthesizer)\n    PARALLEL: Execute all models concurrently, then aggregate\n             (e.g., multiple experts providing simultaneous input)\n    HYBRID: Mix of sequential and parallel phases\n           (e.g., parallel research \u2192 sequential debate \u2192 parallel voting)",
      "bases": [
        "str",
        "Enum"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "SynthesisStrategy",
      "file": "model_chorus/src/model_chorus/core/role_orchestration.py",
      "line": 51,
      "language": "python",
      "docstring": "Strategies for combining multiple role outputs into a unified result.\n\nAfter roles execute (sequentially or in parallel), their outputs can be\nsynthesized using different strategies depending on workflow needs.\n\nValues:\n    NONE: No synthesis - return raw responses as-is\n         Use when: You want to process each response individually\n\n    CONCATENATE: Simple concatenation with role labels\n                Use when: You want a readable combined text with clear attribution\n\n    AI_SYNTHESIZE: Use AI model to intelligently combine responses\n                  Use when: You want a coherent synthesis that resolves conflicts\n                           and integrates multiple perspectives\n\n    STRUCTURED: Combine into structured format (dict with role keys)\n               Use when: You need programmatic access to individual responses\n                        while keeping them organized\n\nExample:\n    >>> # Get raw responses\n    >>> result = await orchestrator.execute(prompt, synthesis=SynthesisStrategy.NONE)\n    >>>\n    >>> # Get simple concatenation\n    >>> result = await orchestrator.execute(prompt, synthesis=SynthesisStrategy.CONCATENATE)\n    >>>\n    >>> # Get AI-synthesized output\n    >>> result = await orchestrator.execute(\n    ...     prompt,\n    ...     synthesis=SynthesisStrategy.AI_SYNTHESIZE,\n    ...     synthesis_provider=synthesis_model\n    ... )",
      "bases": [
        "str",
        "Enum"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "ModelRole",
      "file": "model_chorus/src/model_chorus/core/role_orchestration.py",
      "line": 94,
      "language": "python",
      "docstring": "Data class defining a model's role, stance, and prompt customization.\n\nRepresents a specific role assignment for an AI model in a multi-model\nworkflow. Includes the role name, optional stance (for/against/neutral),\nand prompt customization to guide the model's behavior.\n\nUsed in workflows like ARGUMENT (models with different stances),\nIDEATE (models with different creative perspectives), and RESEARCH\n(models focusing on different aspects of investigation).\n\nAttributes:\n    role: Descriptive name for this role (e.g., \"proponent\", \"critic\", \"synthesizer\")\n    model: Model identifier to assign to this role (e.g., \"gpt-5\", \"gemini-2.5-pro\")\n    stance: Optional stance for debate-style workflows (\"for\", \"against\", \"neutral\")\n    stance_prompt: Optional additional prompt text to reinforce the stance\n    system_prompt: Optional system-level prompt for this role\n    temperature: Optional temperature override for this role (0.0-1.0)\n    max_tokens: Optional max tokens override for this role\n    metadata: Additional metadata for this role (tags, priority, etc.)\n\nExample:\n    >>> proponent = ModelRole(\n    ...     role=\"proponent\",\n    ...     model=\"gpt-5\",\n    ...     stance=\"for\",\n    ...     stance_prompt=\"You are advocating FOR the proposal. Present strong supporting arguments.\"\n    ... )\n    >>> critic = ModelRole(\n    ...     role=\"critic\",\n    ...     model=\"gemini-2.5-pro\",\n    ...     stance=\"against\",\n    ...     stance_prompt=\"You are critically analyzing AGAINST the proposal. Identify weaknesses and risks.\"\n    ... )",
      "bases": [
        "BaseModel"
      ],
      "methods": [
        "validate_stance",
        "validate_temperature",
        "get_full_prompt"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "_create_creator_role",
          "file": "model_chorus/src/model_chorus/workflows/argument/argument_workflow.py",
          "line": 151,
          "context": [
            "ArgumentWorkflow",
            "_create_creator_role"
          ]
        },
        {
          "instantiator": "_create_skeptic_role",
          "file": "model_chorus/src/model_chorus/workflows/argument/argument_workflow.py",
          "line": 196,
          "context": [
            "ArgumentWorkflow",
            "_create_skeptic_role"
          ]
        },
        {
          "instantiator": "_create_moderator_role",
          "file": "model_chorus/src/model_chorus/workflows/argument/argument_workflow.py",
          "line": 242,
          "context": [
            "ArgumentWorkflow",
            "_create_moderator_role"
          ]
        },
        {
          "instantiator": "_create_brainstormer_role",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 364,
          "context": [
            "IdeateWorkflow",
            "_create_brainstormer_role"
          ]
        },
        {
          "instantiator": "test_model_role_creation_minimal",
          "file": "tests/test_role_orchestration.py",
          "line": 99,
          "context": [
            "TestModelRole",
            "test_model_role_creation_minimal"
          ]
        },
        {
          "instantiator": "test_model_role_creation_full",
          "file": "tests/test_role_orchestration.py",
          "line": 113,
          "context": [
            "TestModelRole",
            "test_model_role_creation_full"
          ]
        },
        {
          "instantiator": "test_stance_validation_valid",
          "file": "tests/test_role_orchestration.py",
          "line": 136,
          "context": [
            "TestModelRole",
            "test_stance_validation_valid"
          ]
        },
        {
          "instantiator": "test_stance_validation_invalid",
          "file": "tests/test_role_orchestration.py",
          "line": 142,
          "context": [
            "TestModelRole",
            "test_stance_validation_invalid"
          ]
        },
        {
          "instantiator": "test_temperature_validation_valid",
          "file": "tests/test_role_orchestration.py",
          "line": 147,
          "context": [
            "TestModelRole",
            "test_temperature_validation_valid"
          ]
        },
        {
          "instantiator": "test_temperature_validation_invalid",
          "file": "tests/test_role_orchestration.py",
          "line": 153,
          "context": [
            "TestModelRole",
            "test_temperature_validation_invalid"
          ]
        },
        {
          "instantiator": "test_temperature_validation_invalid",
          "file": "tests/test_role_orchestration.py",
          "line": 156,
          "context": [
            "TestModelRole",
            "test_temperature_validation_invalid"
          ]
        },
        {
          "instantiator": "test_max_tokens_validation_valid",
          "file": "tests/test_role_orchestration.py",
          "line": 160,
          "context": [
            "TestModelRole",
            "test_max_tokens_validation_valid"
          ]
        },
        {
          "instantiator": "test_max_tokens_validation_invalid",
          "file": "tests/test_role_orchestration.py",
          "line": 166,
          "context": [
            "TestModelRole",
            "test_max_tokens_validation_invalid"
          ]
        },
        {
          "instantiator": "test_max_tokens_validation_invalid",
          "file": "tests/test_role_orchestration.py",
          "line": 169,
          "context": [
            "TestModelRole",
            "test_max_tokens_validation_invalid"
          ]
        },
        {
          "instantiator": "test_get_full_prompt_base_only",
          "file": "tests/test_role_orchestration.py",
          "line": 173,
          "context": [
            "TestModelRole",
            "test_get_full_prompt_base_only"
          ]
        },
        {
          "instantiator": "test_get_full_prompt_with_system",
          "file": "tests/test_role_orchestration.py",
          "line": 180,
          "context": [
            "TestModelRole",
            "test_get_full_prompt_with_system"
          ]
        },
        {
          "instantiator": "test_get_full_prompt_with_stance",
          "file": "tests/test_role_orchestration.py",
          "line": 191,
          "context": [
            "TestModelRole",
            "test_get_full_prompt_with_stance"
          ]
        },
        {
          "instantiator": "test_get_full_prompt_with_all",
          "file": "tests/test_role_orchestration.py",
          "line": 203,
          "context": [
            "TestModelRole",
            "test_get_full_prompt_with_all"
          ]
        },
        {
          "instantiator": "test_role_length_validation",
          "file": "tests/test_role_orchestration.py",
          "line": 218,
          "context": [
            "TestModelRole",
            "test_role_length_validation"
          ]
        },
        {
          "instantiator": "test_role_length_validation",
          "file": "tests/test_role_orchestration.py",
          "line": 219,
          "context": [
            "TestModelRole",
            "test_role_length_validation"
          ]
        },
        {
          "instantiator": "test_role_length_validation",
          "file": "tests/test_role_orchestration.py",
          "line": 223,
          "context": [
            "TestModelRole",
            "test_role_length_validation"
          ]
        },
        {
          "instantiator": "test_role_length_validation",
          "file": "tests/test_role_orchestration.py",
          "line": 227,
          "context": [
            "TestModelRole",
            "test_role_length_validation"
          ]
        },
        {
          "instantiator": "test_model_name_validation",
          "file": "tests/test_role_orchestration.py",
          "line": 232,
          "context": [
            "TestModelRole",
            "test_model_name_validation"
          ]
        },
        {
          "instantiator": "test_model_name_validation",
          "file": "tests/test_role_orchestration.py",
          "line": 236,
          "context": [
            "TestModelRole",
            "test_model_name_validation"
          ]
        },
        {
          "instantiator": "simple_roles",
          "file": "tests/test_role_orchestration.py",
          "line": 287,
          "context": [
            "TestRoleOrchestrator",
            "simple_roles"
          ]
        },
        {
          "instantiator": "simple_roles",
          "file": "tests/test_role_orchestration.py",
          "line": 288,
          "context": [
            "TestRoleOrchestrator",
            "simple_roles"
          ]
        },
        {
          "instantiator": "test_execute_parallel_maintains_order",
          "file": "tests/test_role_orchestration.py",
          "line": 487,
          "context": [
            "TestRoleOrchestrator",
            "test_execute_parallel_maintains_order"
          ]
        },
        {
          "instantiator": "test_execute_parallel_maintains_order",
          "file": "tests/test_role_orchestration.py",
          "line": 488,
          "context": [
            "TestRoleOrchestrator",
            "test_execute_parallel_maintains_order"
          ]
        },
        {
          "instantiator": "test_execute_parallel_maintains_order",
          "file": "tests/test_role_orchestration.py",
          "line": 489,
          "context": [
            "TestRoleOrchestrator",
            "test_execute_parallel_maintains_order"
          ]
        },
        {
          "instantiator": "test_role_prompt_customization",
          "file": "tests/test_role_orchestration.py",
          "line": 653,
          "context": [
            "TestRoleOrchestrator",
            "test_role_prompt_customization"
          ]
        },
        {
          "instantiator": "test_role_prompt_customization",
          "file": "tests/test_role_orchestration.py",
          "line": 662,
          "context": [
            "TestRoleOrchestrator",
            "test_role_prompt_customization"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 31
    },
    {
      "name": "OrchestrationResult",
      "file": "model_chorus/src/model_chorus/core/role_orchestration.py",
      "line": 299,
      "language": "python",
      "docstring": "Result from orchestrating multiple models with assigned roles.\n\nContains responses from all models, execution metadata, synthesis output,\nand error information. Used by RoleOrchestrator to return structured results\nafter executing a multi-model workflow.\n\nAttributes:\n    role_responses: List of (role_name, response) tuples in execution order\n    all_responses: List of all GenerationResponse objects\n    failed_roles: List of role names that failed to execute\n    pattern_used: Orchestration pattern that was executed\n    execution_order: List of role names in the order they were executed\n    synthesized_output: Optional synthesized/combined output (if synthesis enabled)\n    synthesis_strategy: Strategy used for synthesis (if any)\n    metadata: Additional execution metadata (timing, context, synthesis_metadata, etc.)\n\nExample:\n    >>> result = OrchestrationResult(\n    ...     role_responses=[\n    ...         (\"proponent\", GenerationResponse(content=\"Argument FOR...\", model=\"gpt-5\")),\n    ...         (\"critic\", GenerationResponse(content=\"Argument AGAINST...\", model=\"gemini-2.5-pro\")),\n    ...     ],\n    ...     pattern_used=OrchestrationPattern.SEQUENTIAL,\n    ...     execution_order=[\"proponent\", \"critic\"],\n    ...     synthesized_output=\"After considering both perspectives...\",\n    ...     synthesis_strategy=SynthesisStrategy.AI_SYNTHESIZE\n    ... )",
      "bases": [],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "_execute_sequential",
          "file": "model_chorus/src/model_chorus/core/role_orchestration.py",
          "line": 590,
          "context": [
            "RoleOrchestrator",
            "_execute_sequential"
          ]
        },
        {
          "instantiator": "_execute_parallel",
          "file": "model_chorus/src/model_chorus/core/role_orchestration.py",
          "line": 706,
          "context": [
            "RoleOrchestrator",
            "_execute_parallel"
          ]
        },
        {
          "instantiator": "test_workflow_execution_with_mocked_orchestrator",
          "file": "tests/test_argument_workflow.py",
          "line": 282,
          "context": [
            "TestArgumentWorkflowExecution",
            "test_workflow_execution_with_mocked_orchestrator"
          ]
        },
        {
          "instantiator": "test_workflow_metadata",
          "file": "tests/test_argument_workflow.py",
          "line": 357,
          "context": [
            "TestArgumentWorkflowExecution",
            "test_workflow_metadata"
          ]
        },
        {
          "instantiator": "test_new_conversation_creates_thread",
          "file": "tests/test_argument_workflow.py",
          "line": 397,
          "context": [
            "TestConversationThreading",
            "test_new_conversation_creates_thread"
          ]
        },
        {
          "instantiator": "test_continuation_uses_existing_thread",
          "file": "tests/test_argument_workflow.py",
          "line": 430,
          "context": [
            "TestConversationThreading",
            "test_continuation_uses_existing_thread"
          ]
        },
        {
          "instantiator": "test_workflow_handles_insufficient_responses",
          "file": "tests/test_argument_workflow.py",
          "line": 487,
          "context": [
            "TestErrorHandling",
            "test_workflow_handles_insufficient_responses"
          ]
        },
        {
          "instantiator": "test_orchestration_result_creation_minimal",
          "file": "tests/test_role_orchestration.py",
          "line": 244,
          "context": [
            "TestOrchestrationResult",
            "test_orchestration_result_creation_minimal"
          ]
        },
        {
          "instantiator": "test_orchestration_result_creation_full",
          "file": "tests/test_role_orchestration.py",
          "line": 258,
          "context": [
            "TestOrchestrationResult",
            "test_orchestration_result_creation_full"
          ]
        },
        {
          "instantiator": "test_synthesize_ai_strategy_no_responses",
          "file": "tests/test_role_orchestration.py",
          "line": 633,
          "context": [
            "TestRoleOrchestrator",
            "test_synthesize_ai_strategy_no_responses"
          ]
        },
        {
          "instantiator": "test_build_synthesis_prompt",
          "file": "tests/test_role_orchestration.py",
          "line": 698,
          "context": [
            "TestRoleOrchestrator",
            "test_build_synthesis_prompt"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 11
    },
    {
      "name": "RoleOrchestrator",
      "file": "model_chorus/src/model_chorus/core/role_orchestration.py",
      "line": 340,
      "language": "python",
      "docstring": "Coordinator for executing multiple models with assigned roles.\n\nManages the execution of multi-model workflows where each model has a specific\nrole (e.g., proponent, critic, synthesizer). Supports both sequential and parallel\nexecution patterns. Handles provider resolution, prompt customization, and result\naggregation.\n\nExecution Patterns:\n    SEQUENTIAL: Roles execute one at a time in defined order\n               (e.g., analyst \u2192 critic \u2192 synthesizer)\n    PARALLEL: All roles execute concurrently for independent perspectives\n             (e.g., multiple experts providing simultaneous input)\n    HYBRID: Not yet implemented (future work)\n\nThis orchestrator enables workflows like:\n- ARGUMENT: Sequential debate (roles take turns) or parallel perspectives\n- IDEATE: Multiple creative perspectives (parallel for diversity)\n- RESEARCH: Multi-angle investigation (parallel for breadth)\n\nAttributes:\n    roles: List of ModelRole instances defining the workflow\n    provider_map: Mapping from model identifiers to provider instances\n    pattern: Orchestration pattern (SEQUENTIAL or PARALLEL)\n    default_timeout: Default timeout for each model execution (seconds)\n\nExample:\n    >>> from model_chorus.core.role_orchestration import ModelRole, RoleOrchestrator\n    >>> from model_chorus.providers import ClaudeProvider, GeminiProvider\n    >>>\n    >>> # Define roles\n    >>> roles = [\n    ...     ModelRole(role=\"proponent\", model=\"claude\", stance=\"for\"),\n    ...     ModelRole(role=\"critic\", model=\"gemini\", stance=\"against\"),\n    ... ]\n    >>>\n    >>> # Create provider map\n    >>> providers = {\n    ...     \"claude\": ClaudeProvider(),\n    ...     \"gemini\": GeminiProvider(),\n    ... }\n    >>>\n    >>> # Create orchestrator\n    >>> orchestrator = RoleOrchestrator(roles, providers)\n    >>>\n    >>> # Execute workflow\n    >>> result = await orchestrator.execute(\"Should we adopt this proposal?\")\n    >>> for role_name, response in result.role_responses:\n    ...     print(f\"{role_name}: {response.content}\")",
      "bases": [],
      "methods": [
        "__init__",
        "_resolve_provider",
        "execute",
        "_execute_sequential",
        "_execute_parallel",
        "synthesize",
        "_build_synthesis_prompt"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "run",
          "file": "model_chorus/src/model_chorus/workflows/argument/argument_workflow.py",
          "line": 472,
          "context": [
            "ArgumentWorkflow",
            "run"
          ]
        },
        {
          "instantiator": "run_parallel_brainstorming",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 435,
          "context": [
            "IdeateWorkflow",
            "run_parallel_brainstorming"
          ]
        },
        {
          "instantiator": "test_orchestrator_initialization_minimal",
          "file": "tests/test_role_orchestration.py",
          "line": 301,
          "context": [
            "TestRoleOrchestrator",
            "test_orchestrator_initialization_minimal"
          ]
        },
        {
          "instantiator": "test_orchestrator_initialization_custom",
          "file": "tests/test_role_orchestration.py",
          "line": 310,
          "context": [
            "TestRoleOrchestrator",
            "test_orchestrator_initialization_custom"
          ]
        },
        {
          "instantiator": "test_orchestrator_initialization_empty_roles",
          "file": "tests/test_role_orchestration.py",
          "line": 323,
          "context": [
            "TestRoleOrchestrator",
            "test_orchestrator_initialization_empty_roles"
          ]
        },
        {
          "instantiator": "test_orchestrator_initialization_unsupported_pattern",
          "file": "tests/test_role_orchestration.py",
          "line": 328,
          "context": [
            "TestRoleOrchestrator",
            "test_orchestrator_initialization_unsupported_pattern"
          ]
        },
        {
          "instantiator": "test_resolve_provider_exact_match",
          "file": "tests/test_role_orchestration.py",
          "line": 336,
          "context": [
            "TestRoleOrchestrator",
            "test_resolve_provider_exact_match"
          ]
        },
        {
          "instantiator": "test_resolve_provider_case_variation",
          "file": "tests/test_role_orchestration.py",
          "line": 344,
          "context": [
            "TestRoleOrchestrator",
            "test_resolve_provider_case_variation"
          ]
        },
        {
          "instantiator": "test_resolve_provider_hyphen_variation",
          "file": "tests/test_role_orchestration.py",
          "line": 353,
          "context": [
            "TestRoleOrchestrator",
            "test_resolve_provider_hyphen_variation"
          ]
        },
        {
          "instantiator": "test_resolve_provider_not_found",
          "file": "tests/test_role_orchestration.py",
          "line": 361,
          "context": [
            "TestRoleOrchestrator",
            "test_resolve_provider_not_found"
          ]
        },
        {
          "instantiator": "test_execute_sequential_success",
          "file": "tests/test_role_orchestration.py",
          "line": 371,
          "context": [
            "TestRoleOrchestrator",
            "test_execute_sequential_success"
          ]
        },
        {
          "instantiator": "test_execute_sequential_with_context",
          "file": "tests/test_role_orchestration.py",
          "line": 399,
          "context": [
            "TestRoleOrchestrator",
            "test_execute_sequential_with_context"
          ]
        },
        {
          "instantiator": "test_execute_sequential_partial_failure",
          "file": "tests/test_role_orchestration.py",
          "line": 420,
          "context": [
            "TestRoleOrchestrator",
            "test_execute_sequential_partial_failure"
          ]
        },
        {
          "instantiator": "test_execute_parallel_success",
          "file": "tests/test_role_orchestration.py",
          "line": 437,
          "context": [
            "TestRoleOrchestrator",
            "test_execute_parallel_success"
          ]
        },
        {
          "instantiator": "test_execute_parallel_partial_failure",
          "file": "tests/test_role_orchestration.py",
          "line": 468,
          "context": [
            "TestRoleOrchestrator",
            "test_execute_parallel_partial_failure"
          ]
        },
        {
          "instantiator": "test_execute_parallel_maintains_order",
          "file": "tests/test_role_orchestration.py",
          "line": 493,
          "context": [
            "TestRoleOrchestrator",
            "test_execute_parallel_maintains_order"
          ]
        },
        {
          "instantiator": "test_synthesize_none_strategy",
          "file": "tests/test_role_orchestration.py",
          "line": 511,
          "context": [
            "TestRoleOrchestrator",
            "test_synthesize_none_strategy"
          ]
        },
        {
          "instantiator": "test_synthesize_concatenate_strategy",
          "file": "tests/test_role_orchestration.py",
          "line": 523,
          "context": [
            "TestRoleOrchestrator",
            "test_synthesize_concatenate_strategy"
          ]
        },
        {
          "instantiator": "test_synthesize_structured_strategy",
          "file": "tests/test_role_orchestration.py",
          "line": 539,
          "context": [
            "TestRoleOrchestrator",
            "test_synthesize_structured_strategy"
          ]
        },
        {
          "instantiator": "test_synthesize_ai_strategy_default_provider",
          "file": "tests/test_role_orchestration.py",
          "line": 556,
          "context": [
            "TestRoleOrchestrator",
            "test_synthesize_ai_strategy_default_provider"
          ]
        },
        {
          "instantiator": "test_synthesize_ai_strategy_custom_provider",
          "file": "tests/test_role_orchestration.py",
          "line": 572,
          "context": [
            "TestRoleOrchestrator",
            "test_synthesize_ai_strategy_custom_provider"
          ]
        },
        {
          "instantiator": "test_synthesize_ai_strategy_custom_prompt",
          "file": "tests/test_role_orchestration.py",
          "line": 588,
          "context": [
            "TestRoleOrchestrator",
            "test_synthesize_ai_strategy_custom_prompt"
          ]
        },
        {
          "instantiator": "test_synthesize_ai_strategy_fallback_on_failure",
          "file": "tests/test_role_orchestration.py",
          "line": 613,
          "context": [
            "TestRoleOrchestrator",
            "test_synthesize_ai_strategy_fallback_on_failure"
          ]
        },
        {
          "instantiator": "test_synthesize_ai_strategy_no_responses",
          "file": "tests/test_role_orchestration.py",
          "line": 630,
          "context": [
            "TestRoleOrchestrator",
            "test_synthesize_ai_strategy_no_responses"
          ]
        },
        {
          "instantiator": "test_synthesize_unknown_strategy",
          "file": "tests/test_role_orchestration.py",
          "line": 642,
          "context": [
            "TestRoleOrchestrator",
            "test_synthesize_unknown_strategy"
          ]
        },
        {
          "instantiator": "test_role_prompt_customization",
          "file": "tests/test_role_orchestration.py",
          "line": 674,
          "context": [
            "TestRoleOrchestrator",
            "test_role_prompt_customization"
          ]
        },
        {
          "instantiator": "test_build_synthesis_prompt",
          "file": "tests/test_role_orchestration.py",
          "line": 695,
          "context": [
            "TestRoleOrchestrator",
            "test_build_synthesis_prompt"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 27
    },
    {
      "name": "StateManager",
      "file": "model_chorus/src/model_chorus/core/state.py",
      "line": 32,
      "language": "python",
      "docstring": "Thread-safe state persistence manager for workflows.\n\nManages workflow execution state separately from conversation history.\nProvides in-memory storage with optional file-based persistence.\n\nWorkflow state typically includes:\n- Current step/phase information\n- Intermediate results\n- Configuration and settings\n- Workflow-specific metadata\n\nAttributes:\n    state_dir: Directory for file-based state persistence\n    enable_file_persistence: Whether to persist state to disk\n    _state_store: Thread-safe in-memory state storage\n    _lock: Lock for thread-safe operations",
      "bases": [],
      "methods": [
        "__init__",
        "set_state",
        "get_state",
        "get_state_object",
        "update_state",
        "delete_state",
        "list_workflows",
        "clear_all",
        "serialize_state",
        "deserialize_state",
        "export_state",
        "import_state",
        "_save_to_file",
        "_delete_file",
        "load_from_disk",
        "load_all_from_disk",
        "sync_to_disk"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "get_default_state_manager",
          "file": "model_chorus/src/model_chorus/core/state.py",
          "line": 531,
          "context": [
            "get_default_state_manager"
          ]
        },
        {
          "instantiator": "test_set_and_get_state",
          "file": "model_chorus/tests/test_state.py",
          "line": 32,
          "context": [
            "TestStateManager",
            "test_set_and_get_state"
          ]
        },
        {
          "instantiator": "test_get_state_object_with_metadata",
          "file": "model_chorus/tests/test_state.py",
          "line": 50,
          "context": [
            "TestStateManager",
            "test_get_state_object_with_metadata"
          ]
        },
        {
          "instantiator": "test_update_state_existing",
          "file": "model_chorus/tests/test_state.py",
          "line": 66,
          "context": [
            "TestStateManager",
            "test_update_state_existing"
          ]
        },
        {
          "instantiator": "test_update_state_nonexistent",
          "file": "model_chorus/tests/test_state.py",
          "line": 91,
          "context": [
            "TestStateManager",
            "test_update_state_nonexistent"
          ]
        },
        {
          "instantiator": "test_delete_state",
          "file": "model_chorus/tests/test_state.py",
          "line": 104,
          "context": [
            "TestStateManager",
            "test_delete_state"
          ]
        },
        {
          "instantiator": "test_list_workflows",
          "file": "model_chorus/tests/test_state.py",
          "line": 120,
          "context": [
            "TestStateManager",
            "test_list_workflows"
          ]
        },
        {
          "instantiator": "test_clear_all",
          "file": "model_chorus/tests/test_state.py",
          "line": 138,
          "context": [
            "TestStateManager",
            "test_clear_all"
          ]
        },
        {
          "instantiator": "test_concurrent_set_state",
          "file": "model_chorus/tests/test_state.py",
          "line": 159,
          "context": [
            "TestStateManager",
            "test_concurrent_set_state"
          ]
        },
        {
          "instantiator": "test_concurrent_read_write",
          "file": "model_chorus/tests/test_state.py",
          "line": 191,
          "context": [
            "TestStateManager",
            "test_concurrent_read_write"
          ]
        },
        {
          "instantiator": "test_state_isolation",
          "file": "model_chorus/tests/test_state.py",
          "line": 240,
          "context": [
            "TestStateManager",
            "test_state_isolation"
          ]
        },
        {
          "instantiator": "test_serialize_state",
          "file": "model_chorus/tests/test_state.py",
          "line": 265,
          "context": [
            "TestStateManager",
            "test_serialize_state"
          ]
        },
        {
          "instantiator": "test_deserialize_state",
          "file": "model_chorus/tests/test_state.py",
          "line": 287,
          "context": [
            "TestStateManager",
            "test_deserialize_state"
          ]
        },
        {
          "instantiator": "test_roundtrip_serialization",
          "file": "model_chorus/tests/test_state.py",
          "line": 308,
          "context": [
            "TestStateManager",
            "test_roundtrip_serialization"
          ]
        },
        {
          "instantiator": "test_export_state",
          "file": "model_chorus/tests/test_state.py",
          "line": 334,
          "context": [
            "TestStateManager",
            "test_export_state"
          ]
        },
        {
          "instantiator": "test_import_state",
          "file": "model_chorus/tests/test_state.py",
          "line": 353,
          "context": [
            "TestStateManager",
            "test_import_state"
          ]
        },
        {
          "instantiator": "test_deserialize_invalid_json",
          "file": "model_chorus/tests/test_state.py",
          "line": 380,
          "context": [
            "TestStateManager",
            "test_deserialize_invalid_json"
          ]
        },
        {
          "instantiator": "test_file_persistence_on_set",
          "file": "model_chorus/tests/test_state.py",
          "line": 394,
          "context": [
            "TestStateManager",
            "test_file_persistence_on_set"
          ]
        },
        {
          "instantiator": "test_load_from_disk",
          "file": "model_chorus/tests/test_state.py",
          "line": 426,
          "context": [
            "TestStateManager",
            "test_load_from_disk"
          ]
        },
        {
          "instantiator": "test_load_all_from_disk",
          "file": "model_chorus/tests/test_state.py",
          "line": 455,
          "context": [
            "TestStateManager",
            "test_load_all_from_disk"
          ]
        },
        {
          "instantiator": "test_sync_to_disk",
          "file": "model_chorus/tests/test_state.py",
          "line": 470,
          "context": [
            "TestStateManager",
            "test_sync_to_disk"
          ]
        },
        {
          "instantiator": "test_delete_removes_file",
          "file": "model_chorus/tests/test_state.py",
          "line": 492,
          "context": [
            "TestStateManager",
            "test_delete_removes_file"
          ]
        },
        {
          "instantiator": "test_persistence_disabled_no_files",
          "file": "model_chorus/tests/test_state.py",
          "line": 508,
          "context": [
            "TestStateManager",
            "test_persistence_disabled_no_files"
          ]
        },
        {
          "instantiator": "test_get_nonexistent_workflow",
          "file": "model_chorus/tests/test_state.py",
          "line": 526,
          "context": [
            "TestStateManager",
            "test_get_nonexistent_workflow"
          ]
        },
        {
          "instantiator": "test_delete_nonexistent_workflow",
          "file": "model_chorus/tests/test_state.py",
          "line": 533,
          "context": [
            "TestStateManager",
            "test_delete_nonexistent_workflow"
          ]
        },
        {
          "instantiator": "test_serialize_nonexistent",
          "file": "model_chorus/tests/test_state.py",
          "line": 540,
          "context": [
            "TestStateManager",
            "test_serialize_nonexistent"
          ]
        },
        {
          "instantiator": "test_import_malformed_json",
          "file": "model_chorus/tests/test_state.py",
          "line": 547,
          "context": [
            "TestStateManager",
            "test_import_malformed_json"
          ]
        },
        {
          "instantiator": "test_state_timestamps_update",
          "file": "model_chorus/tests/test_state.py",
          "line": 557,
          "context": [
            "TestStateManager",
            "test_state_timestamps_update"
          ]
        },
        {
          "instantiator": "test_schema_version_preservation",
          "file": "model_chorus/tests/test_state.py",
          "line": 579,
          "context": [
            "TestStateManager",
            "test_schema_version_preservation"
          ]
        },
        {
          "instantiator": "test_export_import_roundtrip",
          "file": "model_chorus/tests/test_state.py",
          "line": 615,
          "context": [
            "TestStateManagerExportImportRoundtrip",
            "test_export_import_roundtrip"
          ]
        },
        {
          "instantiator": "test_export_import_roundtrip",
          "file": "model_chorus/tests/test_state.py",
          "line": 633,
          "context": [
            "TestStateManagerExportImportRoundtrip",
            "test_export_import_roundtrip"
          ]
        },
        {
          "instantiator": "test_process_restart_recovery",
          "file": "model_chorus/tests/test_state.py",
          "line": 655,
          "context": [
            "TestStateManagerFileRecovery",
            "test_process_restart_recovery"
          ]
        },
        {
          "instantiator": "test_process_restart_recovery",
          "file": "model_chorus/tests/test_state.py",
          "line": 665,
          "context": [
            "TestStateManagerFileRecovery",
            "test_process_restart_recovery"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 33
    },
    {
      "name": "ModelCapability",
      "file": "model_chorus/src/model_chorus/providers/base_provider.py",
      "line": 15,
      "language": "python",
      "docstring": "Enumeration of model capabilities.",
      "bases": [
        "Enum"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "ModelConfig",
      "file": "model_chorus/src/model_chorus/providers/base_provider.py",
      "line": 26,
      "language": "python",
      "docstring": "Configuration for a model.",
      "bases": [],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "__init__",
          "file": "model_chorus/examples/provider_integration.py",
          "line": 36,
          "context": [
            "ExampleProvider",
            "__init__"
          ]
        },
        {
          "instantiator": "__init__",
          "file": "model_chorus/examples/provider_integration.py",
          "line": 45,
          "context": [
            "ExampleProvider",
            "__init__"
          ]
        },
        {
          "instantiator": "_initialize_models",
          "file": "model_chorus/src/model_chorus/providers/claude_provider.py",
          "line": 83,
          "context": [
            "ClaudeProvider",
            "_initialize_models"
          ]
        },
        {
          "instantiator": "_initialize_models",
          "file": "model_chorus/src/model_chorus/providers/claude_provider.py",
          "line": 94,
          "context": [
            "ClaudeProvider",
            "_initialize_models"
          ]
        },
        {
          "instantiator": "_initialize_models",
          "file": "model_chorus/src/model_chorus/providers/codex_provider.py",
          "line": 82,
          "context": [
            "CodexProvider",
            "_initialize_models"
          ]
        },
        {
          "instantiator": "_initialize_models",
          "file": "model_chorus/src/model_chorus/providers/codex_provider.py",
          "line": 92,
          "context": [
            "CodexProvider",
            "_initialize_models"
          ]
        },
        {
          "instantiator": "_initialize_models",
          "file": "model_chorus/src/model_chorus/providers/codex_provider.py",
          "line": 102,
          "context": [
            "CodexProvider",
            "_initialize_models"
          ]
        },
        {
          "instantiator": "_initialize_models",
          "file": "model_chorus/src/model_chorus/providers/cursor_agent_provider.py",
          "line": 85,
          "context": [
            "CursorAgentProvider",
            "_initialize_models"
          ]
        },
        {
          "instantiator": "_initialize_models",
          "file": "model_chorus/src/model_chorus/providers/cursor_agent_provider.py",
          "line": 95,
          "context": [
            "CursorAgentProvider",
            "_initialize_models"
          ]
        },
        {
          "instantiator": "_initialize_models",
          "file": "model_chorus/src/model_chorus/providers/gemini_provider.py",
          "line": 83,
          "context": [
            "GeminiProvider",
            "_initialize_models"
          ]
        },
        {
          "instantiator": "_initialize_models",
          "file": "model_chorus/src/model_chorus/providers/gemini_provider.py",
          "line": 94,
          "context": [
            "GeminiProvider",
            "_initialize_models"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 11
    },
    {
      "name": "GenerationRequest",
      "file": "model_chorus/src/model_chorus/providers/base_provider.py",
      "line": 37,
      "language": "python",
      "docstring": "Request for text generation.",
      "bases": [],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "main",
          "file": "model_chorus/examples/provider_integration.py",
          "line": 127,
          "context": [
            "main"
          ]
        },
        {
          "instantiator": "consensus",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 936,
          "context": [
            "consensus"
          ]
        },
        {
          "instantiator": "_execute_sequential",
          "file": "model_chorus/src/model_chorus/core/role_orchestration.py",
          "line": 563,
          "context": [
            "RoleOrchestrator",
            "_execute_sequential"
          ]
        },
        {
          "instantiator": "execute_role",
          "file": "model_chorus/src/model_chorus/core/role_orchestration.py",
          "line": 662,
          "context": [
            "RoleOrchestrator",
            "_execute_parallel",
            "execute_role"
          ]
        },
        {
          "instantiator": "synthesize",
          "file": "model_chorus/src/model_chorus/core/role_orchestration.py",
          "line": 817,
          "context": [
            "RoleOrchestrator",
            "synthesize"
          ]
        },
        {
          "instantiator": "run",
          "file": "model_chorus/src/model_chorus/workflows/chat.py",
          "line": 213,
          "context": [
            "ChatWorkflow",
            "run"
          ]
        },
        {
          "instantiator": "run",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 209,
          "context": [
            "IdeateWorkflow",
            "run"
          ]
        },
        {
          "instantiator": "_extract_ideas",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 647,
          "context": [
            "IdeateWorkflow",
            "_extract_ideas"
          ]
        },
        {
          "instantiator": "_cluster_ideas",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 843,
          "context": [
            "IdeateWorkflow",
            "_cluster_ideas"
          ]
        },
        {
          "instantiator": "_score_ideas",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 1066,
          "context": [
            "IdeateWorkflow",
            "_score_ideas"
          ]
        },
        {
          "instantiator": "_elaborate_cluster",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 2046,
          "context": [
            "IdeateWorkflow",
            "_elaborate_cluster"
          ]
        },
        {
          "instantiator": "run",
          "file": "model_chorus/src/model_chorus/workflows/thinkdeep.py",
          "line": 273,
          "context": [
            "ThinkDeepWorkflow",
            "run"
          ]
        },
        {
          "instantiator": "_perform_expert_validation",
          "file": "model_chorus/src/model_chorus/workflows/thinkdeep.py",
          "line": 672,
          "context": [
            "ThinkDeepWorkflow",
            "_perform_expert_validation"
          ]
        },
        {
          "instantiator": "sample_generation_request",
          "file": "model_chorus/tests/conftest.py",
          "line": 59,
          "context": [
            "sample_generation_request"
          ]
        },
        {
          "instantiator": "test_build_command_with_model",
          "file": "model_chorus/tests/test_claude_provider.py",
          "line": 39,
          "context": [
            "TestClaudeProvider",
            "test_build_command_with_model"
          ]
        },
        {
          "instantiator": "test_build_command_without_system_prompt",
          "file": "model_chorus/tests/test_claude_provider.py",
          "line": 51,
          "context": [
            "TestClaudeProvider",
            "test_build_command_without_system_prompt"
          ]
        },
        {
          "instantiator": "test_generate_success",
          "file": "model_chorus/tests/test_claude_provider.py",
          "line": 104,
          "context": [
            "TestClaudeProvider",
            "test_generate_success"
          ]
        },
        {
          "instantiator": "test_generate_with_retry",
          "file": "model_chorus/tests/test_claude_provider.py",
          "line": 122,
          "context": [
            "TestClaudeProvider",
            "test_generate_with_retry"
          ]
        },
        {
          "instantiator": "test_generate_all_retries_fail",
          "file": "model_chorus/tests/test_claude_provider.py",
          "line": 141,
          "context": [
            "TestClaudeProvider",
            "test_generate_all_retries_fail"
          ]
        },
        {
          "instantiator": "test_build_command_with_model",
          "file": "model_chorus/tests/test_codex_provider.py",
          "line": 37,
          "context": [
            "TestCodexProvider",
            "test_build_command_with_model"
          ]
        },
        {
          "instantiator": "test_build_command_with_images",
          "file": "model_chorus/tests/test_codex_provider.py",
          "line": 49,
          "context": [
            "TestCodexProvider",
            "test_build_command_with_images"
          ]
        },
        {
          "instantiator": "test_generate_success",
          "file": "model_chorus/tests/test_codex_provider.py",
          "line": 118,
          "context": [
            "TestCodexProvider",
            "test_generate_success"
          ]
        },
        {
          "instantiator": "test_generate_with_retry",
          "file": "model_chorus/tests/test_codex_provider.py",
          "line": 136,
          "context": [
            "TestCodexProvider",
            "test_generate_with_retry"
          ]
        },
        {
          "instantiator": "test_generate_all_retries_fail",
          "file": "model_chorus/tests/test_codex_provider.py",
          "line": 155,
          "context": [
            "TestCodexProvider",
            "test_generate_all_retries_fail"
          ]
        },
        {
          "instantiator": "test_execute_all_responses_strategy",
          "file": "model_chorus/tests/test_consensus_workflow.py",
          "line": 65,
          "context": [
            "TestConsensusWorkflow",
            "test_execute_all_responses_strategy"
          ]
        },
        {
          "instantiator": "test_execute_first_valid_strategy",
          "file": "model_chorus/tests/test_consensus_workflow.py",
          "line": 91,
          "context": [
            "TestConsensusWorkflow",
            "test_execute_first_valid_strategy"
          ]
        },
        {
          "instantiator": "test_execute_with_parameters",
          "file": "model_chorus/tests/test_consensus_workflow.py",
          "line": 111,
          "context": [
            "TestConsensusWorkflow",
            "test_execute_with_parameters"
          ]
        },
        {
          "instantiator": "test_execute_all_providers_fail",
          "file": "model_chorus/tests/test_consensus_workflow.py",
          "line": 137,
          "context": [
            "TestConsensusWorkflow",
            "test_execute_all_providers_fail"
          ]
        },
        {
          "instantiator": "simple_request",
          "file": "model_chorus/tests/test_gemini_integration.py",
          "line": 24,
          "context": [
            "TestGeminiIntegration",
            "simple_request"
          ]
        },
        {
          "instantiator": "test_build_command_with_model",
          "file": "model_chorus/tests/test_gemini_integration.py",
          "line": 65,
          "context": [
            "TestGeminiIntegration",
            "test_build_command_with_model"
          ]
        },
        {
          "instantiator": "test_end_to_end_consensus",
          "file": "model_chorus/tests/test_integration.py",
          "line": 51,
          "context": [
            "TestIntegration",
            "test_end_to_end_consensus"
          ]
        },
        {
          "instantiator": "test_provider_initialization_and_generation",
          "file": "model_chorus/tests/test_integration.py",
          "line": 76,
          "context": [
            "TestIntegration",
            "test_provider_initialization_and_generation"
          ]
        },
        {
          "instantiator": "test_error_handling_across_workflow",
          "file": "model_chorus/tests/test_integration.py",
          "line": 95,
          "context": [
            "TestIntegration",
            "test_error_handling_across_workflow"
          ]
        },
        {
          "instantiator": "test_multiple_strategy_comparison",
          "file": "model_chorus/tests/test_integration.py",
          "line": 130,
          "context": [
            "TestIntegration",
            "test_multiple_strategy_comparison"
          ]
        },
        {
          "instantiator": "test_concurrent_provider_execution",
          "file": "model_chorus/tests/test_integration.py",
          "line": 179,
          "context": [
            "TestIntegration",
            "test_concurrent_provider_execution"
          ]
        },
        {
          "instantiator": "test_consensus_applies_provider_model_override_without_mutation",
          "file": "tests/test_consensus_provider_models.py",
          "line": 47,
          "context": [
            "test_consensus_applies_provider_model_override_without_mutation"
          ]
        },
        {
          "instantiator": "test_shared_request_model_overrides_provider_metadata",
          "file": "tests/test_consensus_provider_models.py",
          "line": 79,
          "context": [
            "test_shared_request_model_overrides_provider_metadata"
          ]
        },
        {
          "instantiator": "test_build_command_returns_list",
          "file": "tests/test_providers/test_cli_interface.py",
          "line": 143,
          "context": [
            "TestCLIProvidersImplementInterface",
            "test_build_command_returns_list"
          ]
        },
        {
          "instantiator": "test_build_command_includes_cli_command",
          "file": "tests/test_providers/test_cli_interface.py",
          "line": 159,
          "context": [
            "TestCLIProvidersImplementInterface",
            "test_build_command_includes_cli_command"
          ]
        },
        {
          "instantiator": "test_consensus_to_thinkdeep_to_chat_workflow",
          "file": "tests/test_workflow_integration_chaining.py",
          "line": 109,
          "context": [
            "TestConsensusThinkDeepChatChaining",
            "test_consensus_to_thinkdeep_to_chat_workflow"
          ]
        },
        {
          "instantiator": "test_consensus_without_continuation_support",
          "file": "tests/test_workflow_integration_chaining.py",
          "line": 336,
          "context": [
            "TestConsensusThinkDeepChatChaining",
            "test_consensus_without_continuation_support"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 41
    },
    {
      "name": "TokenUsage",
      "file": "model_chorus/src/model_chorus/providers/base_provider.py",
      "line": 51,
      "language": "python",
      "docstring": "Token usage information with explicit fields for type safety.\n\nThis dataclass provides a standardized way to track token consumption\nacross different AI providers, with support for caching and provider-\nspecific metadata.\n\nSupports both attribute access (usage.input_tokens) and dict-like access\n(usage['input_tokens']) for backward compatibility.\n\nAttributes:\n    input_tokens: Number of tokens in the input prompt/context.\n    output_tokens: Number of tokens in the generated response.\n    cached_input_tokens: Number of input tokens retrieved from cache\n        (provider-dependent, e.g., OpenAI prompt caching).\n    total_tokens: Total token count, typically input + output tokens.\n        May or may not include cached tokens depending on provider.\n    metadata: Provider-specific additional usage information (e.g.,\n        cost, rate limits, model-specific metrics).",
      "bases": [],
      "methods": [
        "__getitem__",
        "__setitem__",
        "get",
        "keys",
        "values",
        "items"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "parse_response",
          "file": "model_chorus/src/model_chorus/providers/claude_provider.py",
          "line": 218,
          "context": [
            "ClaudeProvider",
            "parse_response"
          ]
        },
        {
          "instantiator": "parse_response",
          "file": "model_chorus/src/model_chorus/providers/codex_provider.py",
          "line": 223,
          "context": [
            "CodexProvider",
            "parse_response"
          ]
        },
        {
          "instantiator": "parse_response",
          "file": "model_chorus/src/model_chorus/providers/cursor_agent_provider.py",
          "line": 214,
          "context": [
            "CursorAgentProvider",
            "parse_response"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 3
    },
    {
      "name": "GenerationResponse",
      "file": "model_chorus/src/model_chorus/providers/base_provider.py",
      "line": 149,
      "language": "python",
      "docstring": "Response from text generation with standardized structure across providers.\n\nThis dataclass provides a unified response format for all AI providers (Claude,\nGemini, OpenAI Codex, etc.), supporting conversation continuation via thread_id,\ntoken usage tracking, and debugging capabilities.\n\nAttributes:\n    content: The generated text content from the model.\n    model: Model identifier that generated this response (e.g., \"claude-3-opus\",\n        \"gemini-pro\", \"gpt-4\").\n    usage: Token usage information as a TokenUsage dataclass. Supports both\n        attribute access (usage.input_tokens) and dict-like access\n        (usage['input_tokens']) for backward compatibility.\n    stop_reason: Reason generation stopped (e.g., \"end_turn\", \"max_tokens\",\n        \"stop_sequence\"). Provider-specific values, may be None.\n    metadata: Provider-specific additional metadata (e.g., safety ratings,\n        citations, model version details).\n    thread_id: Conversation continuation identifier for multi-turn interactions.\n        Provider-specific mapping:\n        - Claude: Maps from CLI response 'session_id' field\n        - Cursor: Maps from CLI response 'session_id' field\n        - Codex (OpenAI): Maps from CLI response 'thread_id' field\n        - Gemini: Always None (does not support conversation continuation)\n        Used to maintain context across multiple generation requests.\n    provider: Name of the provider that generated this response. Valid values:\n        \"claude\", \"gemini\", \"codex\", \"cursor\". Useful for multi-provider\n        workflows and debugging.\n    stderr: Standard error output captured from CLI-based providers. Contains\n        warning messages, debug output, or error details. Empty string if no\n        errors, None if not captured. Only populated for CLI providers (Claude,\n        Gemini, Codex).\n    duration_ms: Request duration in milliseconds, measured from request start\n        to response completion. Useful for performance monitoring, latency\n        analysis, and cost optimization. None if not measured.\n    raw_response: Complete raw response from the provider as returned by the\n        CLI or API. Useful for debugging, testing provider-specific features,\n        and understanding response structure. May contain sensitive data.\n        None if not captured.\n\nExample:\n    Basic usage::\n\n        response = GenerationResponse(\n            content=\"Hello, world!\",\n            model=\"claude-3-opus-20240229\",\n            provider=\"claude\"\n        )\n        response.usage['input_tokens'] = 10\n        response.usage['output_tokens'] = 5\n\n    With conversation continuation::\n\n        # First turn\n        resp1 = GenerationResponse(\n            content=\"Initial response\",\n            model=\"gpt-4\",\n            thread_id=\"thread_abc123\",\n            provider=\"codex\"\n        )\n\n        # Follow-up turn using same thread_id\n        resp2 = GenerationResponse(\n            content=\"Follow-up response\",\n            model=\"gpt-4\",\n            thread_id=\"thread_abc123\",  # Same ID for continuation\n            provider=\"codex\"\n        )",
      "bases": [],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "generate",
          "file": "model_chorus/examples/provider_integration.py",
          "line": 81,
          "context": [
            "ExampleProvider",
            "generate"
          ]
        },
        {
          "instantiator": "parse_response",
          "file": "model_chorus/src/model_chorus/providers/claude_provider.py",
          "line": 230,
          "context": [
            "ClaudeProvider",
            "parse_response"
          ]
        },
        {
          "instantiator": "parse_response",
          "file": "model_chorus/src/model_chorus/providers/codex_provider.py",
          "line": 231,
          "context": [
            "CodexProvider",
            "parse_response"
          ]
        },
        {
          "instantiator": "parse_response",
          "file": "model_chorus/src/model_chorus/providers/cursor_agent_provider.py",
          "line": 222,
          "context": [
            "CursorAgentProvider",
            "parse_response"
          ]
        },
        {
          "instantiator": "parse_response",
          "file": "model_chorus/src/model_chorus/providers/gemini_provider.py",
          "line": 275,
          "context": [
            "GeminiProvider",
            "parse_response"
          ]
        },
        {
          "instantiator": "mock_generate",
          "file": "model_chorus/tests/test_chat_workflow.py",
          "line": 26,
          "context": [
            "mock_provider",
            "mock_generate"
          ]
        },
        {
          "instantiator": "test_execute_all_responses_strategy",
          "file": "model_chorus/tests/test_consensus_workflow.py",
          "line": 49,
          "context": [
            "TestConsensusWorkflow",
            "test_execute_all_responses_strategy"
          ]
        },
        {
          "instantiator": "test_execute_all_responses_strategy",
          "file": "model_chorus/tests/test_consensus_workflow.py",
          "line": 57,
          "context": [
            "TestConsensusWorkflow",
            "test_execute_all_responses_strategy"
          ]
        },
        {
          "instantiator": "test_execute_first_valid_strategy",
          "file": "model_chorus/tests/test_consensus_workflow.py",
          "line": 83,
          "context": [
            "TestConsensusWorkflow",
            "test_execute_first_valid_strategy"
          ]
        },
        {
          "instantiator": "test_execute_with_parameters",
          "file": "model_chorus/tests/test_consensus_workflow.py",
          "line": 103,
          "context": [
            "TestConsensusWorkflow",
            "test_execute_with_parameters"
          ]
        },
        {
          "instantiator": "mock_generate",
          "file": "model_chorus/tests/test_ideate_workflow.py",
          "line": 106,
          "context": [
            "mock_provider",
            "mock_generate"
          ]
        },
        {
          "instantiator": "mock_generate",
          "file": "tests/test_argument_workflow.py",
          "line": 30,
          "context": [
            "mock_provider",
            "mock_generate"
          ]
        },
        {
          "instantiator": "test_workflow_execution_with_mocked_orchestrator",
          "file": "tests/test_argument_workflow.py",
          "line": 259,
          "context": [
            "TestArgumentWorkflowExecution",
            "test_workflow_execution_with_mocked_orchestrator"
          ]
        },
        {
          "instantiator": "test_workflow_execution_with_mocked_orchestrator",
          "file": "tests/test_argument_workflow.py",
          "line": 266,
          "context": [
            "TestArgumentWorkflowExecution",
            "test_workflow_execution_with_mocked_orchestrator"
          ]
        },
        {
          "instantiator": "test_workflow_execution_with_mocked_orchestrator",
          "file": "tests/test_argument_workflow.py",
          "line": 273,
          "context": [
            "TestArgumentWorkflowExecution",
            "test_workflow_execution_with_mocked_orchestrator"
          ]
        },
        {
          "instantiator": "test_workflow_metadata",
          "file": "tests/test_argument_workflow.py",
          "line": 336,
          "context": [
            "TestArgumentWorkflowExecution",
            "test_workflow_metadata"
          ]
        },
        {
          "instantiator": "test_workflow_metadata",
          "file": "tests/test_argument_workflow.py",
          "line": 343,
          "context": [
            "TestArgumentWorkflowExecution",
            "test_workflow_metadata"
          ]
        },
        {
          "instantiator": "test_workflow_metadata",
          "file": "tests/test_argument_workflow.py",
          "line": 350,
          "context": [
            "TestArgumentWorkflowExecution",
            "test_workflow_metadata"
          ]
        },
        {
          "instantiator": "test_new_conversation_creates_thread",
          "file": "tests/test_argument_workflow.py",
          "line": 387,
          "context": [
            "TestConversationThreading",
            "test_new_conversation_creates_thread"
          ]
        },
        {
          "instantiator": "test_new_conversation_creates_thread",
          "file": "tests/test_argument_workflow.py",
          "line": 390,
          "context": [
            "TestConversationThreading",
            "test_new_conversation_creates_thread"
          ]
        },
        {
          "instantiator": "test_new_conversation_creates_thread",
          "file": "tests/test_argument_workflow.py",
          "line": 393,
          "context": [
            "TestConversationThreading",
            "test_new_conversation_creates_thread"
          ]
        },
        {
          "instantiator": "test_continuation_uses_existing_thread",
          "file": "tests/test_argument_workflow.py",
          "line": 420,
          "context": [
            "TestConversationThreading",
            "test_continuation_uses_existing_thread"
          ]
        },
        {
          "instantiator": "test_continuation_uses_existing_thread",
          "file": "tests/test_argument_workflow.py",
          "line": 423,
          "context": [
            "TestConversationThreading",
            "test_continuation_uses_existing_thread"
          ]
        },
        {
          "instantiator": "test_continuation_uses_existing_thread",
          "file": "tests/test_argument_workflow.py",
          "line": 426,
          "context": [
            "TestConversationThreading",
            "test_continuation_uses_existing_thread"
          ]
        },
        {
          "instantiator": "test_workflow_handles_insufficient_responses",
          "file": "tests/test_argument_workflow.py",
          "line": 480,
          "context": [
            "TestErrorHandling",
            "test_workflow_handles_insufficient_responses"
          ]
        },
        {
          "instantiator": "test_workflow_handles_insufficient_responses",
          "file": "tests/test_argument_workflow.py",
          "line": 483,
          "context": [
            "TestErrorHandling",
            "test_workflow_handles_insufficient_responses"
          ]
        },
        {
          "instantiator": "mock_generate",
          "file": "tests/test_cli_integration.py",
          "line": 48,
          "context": [
            "mock_provider",
            "mock_generate"
          ]
        },
        {
          "instantiator": "generate_response",
          "file": "tests/test_concurrent_conversations.py",
          "line": 64,
          "context": [
            "TestConcurrentConversationHandling",
            "test_100_concurrent_chat_conversations",
            "generate_response"
          ]
        },
        {
          "instantiator": "generate_response",
          "file": "tests/test_concurrent_conversations.py",
          "line": 168,
          "context": [
            "TestConcurrentConversationHandling",
            "test_concurrent_multi_turn_conversations",
            "generate_response"
          ]
        },
        {
          "instantiator": "test_mixed_workflow_concurrent_execution",
          "file": "tests/test_concurrent_conversations.py",
          "line": 252,
          "context": [
            "TestConcurrentConversationHandling",
            "test_mixed_workflow_concurrent_execution"
          ]
        },
        {
          "instantiator": "test_performance_scalability",
          "file": "tests/test_concurrent_conversations.py",
          "line": 331,
          "context": [
            "TestConcurrentConversationHandling",
            "test_performance_scalability"
          ]
        },
        {
          "instantiator": "_generate",
          "file": "tests/test_consensus_provider_models.py",
          "line": 26,
          "context": [
            "_make_provider",
            "_generate"
          ]
        },
        {
          "instantiator": "mock_generate",
          "file": "tests/test_ideate_workflow.py",
          "line": 123,
          "context": [
            "mock_provider",
            "mock_generate"
          ]
        },
        {
          "instantiator": "test_run_parallel_brainstorming",
          "file": "tests/test_ideate_workflow.py",
          "line": 298,
          "context": [
            "TestParallelBrainstorming",
            "test_run_parallel_brainstorming"
          ]
        },
        {
          "instantiator": "test_run_parallel_brainstorming",
          "file": "tests/test_ideate_workflow.py",
          "line": 303,
          "context": [
            "TestParallelBrainstorming",
            "test_run_parallel_brainstorming"
          ]
        },
        {
          "instantiator": "test_run_complete_ideation",
          "file": "tests/test_ideate_workflow.py",
          "line": 694,
          "context": [
            "TestCompleteIdeation",
            "test_run_complete_ideation"
          ]
        },
        {
          "instantiator": "test_run_complete_ideation",
          "file": "tests/test_ideate_workflow.py",
          "line": 699,
          "context": [
            "TestCompleteIdeation",
            "test_run_complete_ideation"
          ]
        },
        {
          "instantiator": "generate_response",
          "file": "tests/test_memory_management.py",
          "line": 67,
          "context": [
            "TestMemoryManagement",
            "test_long_conversation_memory_stability",
            "generate_response"
          ]
        },
        {
          "instantiator": "test_multiple_long_conversations_memory_isolation",
          "file": "tests/test_memory_management.py",
          "line": 158,
          "context": [
            "TestMemoryManagement",
            "test_multiple_long_conversations_memory_isolation"
          ]
        },
        {
          "instantiator": "generate_large_response",
          "file": "tests/test_memory_management.py",
          "line": 225,
          "context": [
            "TestMemoryManagement",
            "test_memory_efficiency_with_large_messages",
            "generate_large_response"
          ]
        },
        {
          "instantiator": "test_concurrent_long_conversations_memory",
          "file": "tests/test_memory_management.py",
          "line": 283,
          "context": [
            "TestMemoryManagement",
            "test_concurrent_long_conversations_memory"
          ]
        },
        {
          "instantiator": "test_architectural_decision_rest_vs_graphql",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 62,
          "context": [
            "TestArchitecturalDecisionScenarios",
            "test_architectural_decision_rest_vs_graphql"
          ]
        },
        {
          "instantiator": "test_architectural_decision_rest_vs_graphql",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 91,
          "context": [
            "TestArchitecturalDecisionScenarios",
            "test_architectural_decision_rest_vs_graphql"
          ]
        },
        {
          "instantiator": "test_architectural_decision_rest_vs_graphql",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 118,
          "context": [
            "TestArchitecturalDecisionScenarios",
            "test_architectural_decision_rest_vs_graphql"
          ]
        },
        {
          "instantiator": "test_architectural_decision_rest_vs_graphql",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 147,
          "context": [
            "TestArchitecturalDecisionScenarios",
            "test_architectural_decision_rest_vs_graphql"
          ]
        },
        {
          "instantiator": "test_architectural_decision_database_selection",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 204,
          "context": [
            "TestArchitecturalDecisionScenarios",
            "test_architectural_decision_database_selection"
          ]
        },
        {
          "instantiator": "test_architectural_decision_database_selection",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 225,
          "context": [
            "TestArchitecturalDecisionScenarios",
            "test_architectural_decision_database_selection"
          ]
        },
        {
          "instantiator": "test_bug_investigation_api_slowness",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 286,
          "context": [
            "TestBugInvestigationScenarios",
            "test_bug_investigation_api_slowness"
          ]
        },
        {
          "instantiator": "test_bug_investigation_api_slowness",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 327,
          "context": [
            "TestBugInvestigationScenarios",
            "test_bug_investigation_api_slowness"
          ]
        },
        {
          "instantiator": "test_bug_investigation_api_slowness",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 354,
          "context": [
            "TestBugInvestigationScenarios",
            "test_bug_investigation_api_slowness"
          ]
        },
        {
          "instantiator": "test_bug_investigation_api_slowness",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 376,
          "context": [
            "TestBugInvestigationScenarios",
            "test_bug_investigation_api_slowness"
          ]
        },
        {
          "instantiator": "test_bug_investigation_api_slowness",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 394,
          "context": [
            "TestBugInvestigationScenarios",
            "test_bug_investigation_api_slowness"
          ]
        },
        {
          "instantiator": "test_bug_investigation_api_slowness",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 411,
          "context": [
            "TestBugInvestigationScenarios",
            "test_bug_investigation_api_slowness"
          ]
        },
        {
          "instantiator": "test_bug_investigation_intermittent_crash",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 472,
          "context": [
            "TestBugInvestigationScenarios",
            "test_bug_investigation_intermittent_crash"
          ]
        },
        {
          "instantiator": "test_bug_investigation_intermittent_crash",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 506,
          "context": [
            "TestBugInvestigationScenarios",
            "test_bug_investigation_intermittent_crash"
          ]
        },
        {
          "instantiator": "test_bug_investigation_intermittent_crash",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 527,
          "context": [
            "TestBugInvestigationScenarios",
            "test_bug_investigation_intermittent_crash"
          ]
        },
        {
          "instantiator": "test_bug_investigation_intermittent_crash",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 554,
          "context": [
            "TestBugInvestigationScenarios",
            "test_bug_investigation_intermittent_crash"
          ]
        },
        {
          "instantiator": "test_bug_investigation_intermittent_crash",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 569,
          "context": [
            "TestBugInvestigationScenarios",
            "test_bug_investigation_intermittent_crash"
          ]
        },
        {
          "instantiator": "test_long_investigation_with_hypothesis_pivots",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 632,
          "context": [
            "TestComplexMultiStepReasoning",
            "test_long_investigation_with_hypothesis_pivots"
          ]
        },
        {
          "instantiator": "test_long_investigation_with_hypothesis_pivots",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 654,
          "context": [
            "TestComplexMultiStepReasoning",
            "test_long_investigation_with_hypothesis_pivots"
          ]
        },
        {
          "instantiator": "test_investigation_with_multiple_evidence_types",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 739,
          "context": [
            "TestComplexMultiStepReasoning",
            "test_investigation_with_multiple_evidence_types"
          ]
        },
        {
          "instantiator": "test_investigation_with_multiple_evidence_types",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 760,
          "context": [
            "TestComplexMultiStepReasoning",
            "test_investigation_with_multiple_evidence_types"
          ]
        },
        {
          "instantiator": "test_investigation_with_multiple_evidence_types",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 780,
          "context": [
            "TestComplexMultiStepReasoning",
            "test_investigation_with_multiple_evidence_types"
          ]
        },
        {
          "instantiator": "test_investigation_with_multiple_evidence_types",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 804,
          "context": [
            "TestComplexMultiStepReasoning",
            "test_investigation_with_multiple_evidence_types"
          ]
        },
        {
          "instantiator": "test_expert_validation_triggered_at_medium_confidence",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 146,
          "context": [
            "TestExpertValidationTriggering",
            "test_expert_validation_triggered_at_medium_confidence"
          ]
        },
        {
          "instantiator": "test_expert_validation_triggered_at_medium_confidence",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 153,
          "context": [
            "TestExpertValidationTriggering",
            "test_expert_validation_triggered_at_medium_confidence"
          ]
        },
        {
          "instantiator": "test_expert_validation_not_triggered_at_exploring_confidence",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 194,
          "context": [
            "TestExpertValidationTriggering",
            "test_expert_validation_not_triggered_at_exploring_confidence"
          ]
        },
        {
          "instantiator": "test_expert_validation_triggered_at_high_confidence",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 233,
          "context": [
            "TestExpertValidationTriggering",
            "test_expert_validation_triggered_at_high_confidence"
          ]
        },
        {
          "instantiator": "test_expert_validation_triggered_at_high_confidence",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 240,
          "context": [
            "TestExpertValidationTriggering",
            "test_expert_validation_triggered_at_high_confidence"
          ]
        },
        {
          "instantiator": "test_expert_validation_not_triggered_when_disabled",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 281,
          "context": [
            "TestExpertValidationTriggering",
            "test_expert_validation_not_triggered_when_disabled"
          ]
        },
        {
          "instantiator": "test_expert_validation_result_included_in_metadata",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 344,
          "context": [
            "TestExpertValidationResultHandling",
            "test_expert_validation_result_included_in_metadata"
          ]
        },
        {
          "instantiator": "test_expert_validation_result_included_in_metadata",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 351,
          "context": [
            "TestExpertValidationResultHandling",
            "test_expert_validation_result_included_in_metadata"
          ]
        },
        {
          "instantiator": "test_expert_validation_conversation_history_updated",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 387,
          "context": [
            "TestExpertValidationResultHandling",
            "test_expert_validation_conversation_history_updated"
          ]
        },
        {
          "instantiator": "test_expert_validation_conversation_history_updated",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 395,
          "context": [
            "TestExpertValidationResultHandling",
            "test_expert_validation_conversation_history_updated"
          ]
        },
        {
          "instantiator": "test_expert_validation_failure_does_not_crash_investigation",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 458,
          "context": [
            "TestExpertValidationErrorHandling",
            "test_expert_validation_failure_does_not_crash_investigation"
          ]
        },
        {
          "instantiator": "test_expert_validation_timeout_handling",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 500,
          "context": [
            "TestExpertValidationErrorHandling",
            "test_expert_validation_timeout_handling"
          ]
        },
        {
          "instantiator": "test_expert_validation_with_empty_response",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 541,
          "context": [
            "TestExpertValidationErrorHandling",
            "test_expert_validation_with_empty_response"
          ]
        },
        {
          "instantiator": "test_expert_validation_with_empty_response",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 549,
          "context": [
            "TestExpertValidationErrorHandling",
            "test_expert_validation_with_empty_response"
          ]
        },
        {
          "instantiator": "test_expert_validation_validates_hypothesis",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 609,
          "context": [
            "TestExpertValidationWithHypotheses",
            "test_expert_validation_validates_hypothesis"
          ]
        },
        {
          "instantiator": "test_expert_validation_validates_hypothesis",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 616,
          "context": [
            "TestExpertValidationWithHypotheses",
            "test_expert_validation_validates_hypothesis"
          ]
        },
        {
          "instantiator": "test_expert_validation_with_multiple_hypotheses",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 663,
          "context": [
            "TestExpertValidationWithHypotheses",
            "test_expert_validation_with_multiple_hypotheses"
          ]
        },
        {
          "instantiator": "test_expert_validation_with_multiple_hypotheses",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 670,
          "context": [
            "TestExpertValidationWithHypotheses",
            "test_expert_validation_with_multiple_hypotheses"
          ]
        },
        {
          "instantiator": "test_single_investigation_step_execution",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 61,
          "context": [
            "TestInvestigationStepExecution",
            "test_single_investigation_step_execution"
          ]
        },
        {
          "instantiator": "test_investigation_step_creates_investigation_step_object",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 105,
          "context": [
            "TestInvestigationStepExecution",
            "test_investigation_step_creates_investigation_step_object"
          ]
        },
        {
          "instantiator": "test_multi_step_investigation_progression",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 151,
          "context": [
            "TestInvestigationStepExecution",
            "test_multi_step_investigation_progression"
          ]
        },
        {
          "instantiator": "test_multi_step_investigation_progression",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 170,
          "context": [
            "TestInvestigationStepExecution",
            "test_multi_step_investigation_progression"
          ]
        },
        {
          "instantiator": "test_multi_step_investigation_progression",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 190,
          "context": [
            "TestInvestigationStepExecution",
            "test_multi_step_investigation_progression"
          ]
        },
        {
          "instantiator": "test_investigation_step_tracks_files_checked",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 218,
          "context": [
            "TestInvestigationStepExecution",
            "test_investigation_step_tracks_files_checked"
          ]
        },
        {
          "instantiator": "test_relevant_files_merge_into_state_and_metadata",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 265,
          "context": [
            "TestInvestigationStepExecution",
            "test_relevant_files_merge_into_state_and_metadata"
          ]
        },
        {
          "instantiator": "test_relevant_files_merge_into_state_and_metadata",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 271,
          "context": [
            "TestInvestigationStepExecution",
            "test_relevant_files_merge_into_state_and_metadata"
          ]
        },
        {
          "instantiator": "test_investigation_step_with_no_files",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 343,
          "context": [
            "TestInvestigationStepExecution",
            "test_investigation_step_with_no_files"
          ]
        },
        {
          "instantiator": "test_investigation_step_confidence_tracking",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 384,
          "context": [
            "TestInvestigationStepExecution",
            "test_investigation_step_confidence_tracking"
          ]
        },
        {
          "instantiator": "test_investigation_step_confidence_tracking",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 403,
          "context": [
            "TestInvestigationStepExecution",
            "test_investigation_step_confidence_tracking"
          ]
        },
        {
          "instantiator": "test_investigation_step_with_hypothesis_integration",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 429,
          "context": [
            "TestInvestigationStepExecution",
            "test_investigation_step_with_hypothesis_integration"
          ]
        },
        {
          "instantiator": "test_investigation_step_with_hypothesis_integration",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 459,
          "context": [
            "TestInvestigationStepExecution",
            "test_investigation_step_with_hypothesis_integration"
          ]
        },
        {
          "instantiator": "test_investigation_step_findings_extraction",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 494,
          "context": [
            "TestInvestigationStepExecution",
            "test_investigation_step_findings_extraction"
          ]
        },
        {
          "instantiator": "test_investigation_step_with_expert_validation",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 530,
          "context": [
            "TestInvestigationStepExecution",
            "test_investigation_step_with_expert_validation"
          ]
        },
        {
          "instantiator": "test_investigation_step_with_expert_validation",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 538,
          "context": [
            "TestInvestigationStepExecution",
            "test_investigation_step_with_expert_validation"
          ]
        },
        {
          "instantiator": "test_investigation_step_metadata_completeness",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 583,
          "context": [
            "TestInvestigationStepExecution",
            "test_investigation_step_metadata_completeness"
          ]
        },
        {
          "instantiator": "test_empty_provider_response_reports_error",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 654,
          "context": [
            "TestInvestigationStepExecution",
            "test_empty_provider_response_reports_error"
          ]
        },
        {
          "instantiator": "test_investigation_without_conversation_memory",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 691,
          "context": [
            "TestInvestigationStepExecution",
            "test_investigation_without_conversation_memory"
          ]
        },
        {
          "instantiator": "test_add_hypothesis_to_investigation",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 736,
          "context": [
            "TestHypothesisEvolution",
            "test_add_hypothesis_to_investigation"
          ]
        },
        {
          "instantiator": "test_update_hypothesis_with_evidence",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 776,
          "context": [
            "TestHypothesisEvolution",
            "test_update_hypothesis_with_evidence"
          ]
        },
        {
          "instantiator": "test_validate_hypothesis",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 821,
          "context": [
            "TestHypothesisEvolution",
            "test_validate_hypothesis"
          ]
        },
        {
          "instantiator": "test_disprove_hypothesis",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 862,
          "context": [
            "TestHypothesisEvolution",
            "test_disprove_hypothesis"
          ]
        },
        {
          "instantiator": "test_multiple_hypothesis_evolution",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 903,
          "context": [
            "TestHypothesisEvolution",
            "test_multiple_hypothesis_evolution"
          ]
        },
        {
          "instantiator": "test_get_active_hypotheses",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 974,
          "context": [
            "TestHypothesisEvolution",
            "test_get_active_hypotheses"
          ]
        },
        {
          "instantiator": "test_get_all_hypotheses",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1013,
          "context": [
            "TestHypothesisEvolution",
            "test_get_all_hypotheses"
          ]
        },
        {
          "instantiator": "test_hypothesis_persistence_across_turns",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1058,
          "context": [
            "TestHypothesisEvolution",
            "test_hypothesis_persistence_across_turns"
          ]
        },
        {
          "instantiator": "test_hypothesis_persistence_across_turns",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1075,
          "context": [
            "TestHypothesisEvolution",
            "test_hypothesis_persistence_across_turns"
          ]
        },
        {
          "instantiator": "test_hypothesis_persistence_across_turns",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1095,
          "context": [
            "TestHypothesisEvolution",
            "test_hypothesis_persistence_across_turns"
          ]
        },
        {
          "instantiator": "test_hypothesis_update_with_status_change",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1130,
          "context": [
            "TestHypothesisEvolution",
            "test_hypothesis_update_with_status_change"
          ]
        },
        {
          "instantiator": "test_hypothesis_not_found_handling",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1174,
          "context": [
            "TestHypothesisEvolution",
            "test_hypothesis_not_found_handling"
          ]
        },
        {
          "instantiator": "test_hypothesis_metadata_tracking",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1220,
          "context": [
            "TestHypothesisEvolution",
            "test_hypothesis_metadata_tracking"
          ]
        },
        {
          "instantiator": "test_initial_confidence_level",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1273,
          "context": [
            "TestConfidenceProgression",
            "test_initial_confidence_level"
          ]
        },
        {
          "instantiator": "test_update_confidence_level",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1303,
          "context": [
            "TestConfidenceProgression",
            "test_update_confidence_level"
          ]
        },
        {
          "instantiator": "test_get_confidence_level",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1341,
          "context": [
            "TestConfidenceProgression",
            "test_get_confidence_level"
          ]
        },
        {
          "instantiator": "test_confidence_progression_across_steps",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1377,
          "context": [
            "TestConfidenceProgression",
            "test_confidence_progression_across_steps"
          ]
        },
        {
          "instantiator": "test_confidence_progression_across_steps",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1394,
          "context": [
            "TestConfidenceProgression",
            "test_confidence_progression_across_steps"
          ]
        },
        {
          "instantiator": "test_confidence_progression_across_steps",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1412,
          "context": [
            "TestConfidenceProgression",
            "test_confidence_progression_across_steps"
          ]
        },
        {
          "instantiator": "test_confidence_progression_across_steps",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1430,
          "context": [
            "TestConfidenceProgression",
            "test_confidence_progression_across_steps"
          ]
        },
        {
          "instantiator": "test_confidence_tracked_in_metadata",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1458,
          "context": [
            "TestConfidenceProgression",
            "test_confidence_tracked_in_metadata"
          ]
        },
        {
          "instantiator": "test_invalid_confidence_level_rejected",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1489,
          "context": [
            "TestConfidenceProgression",
            "test_invalid_confidence_level_rejected"
          ]
        },
        {
          "instantiator": "test_confidence_complete_progression",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1518,
          "context": [
            "TestConfidenceProgression",
            "test_confidence_complete_progression"
          ]
        },
        {
          "instantiator": "test_investigation_completion_criteria",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1566,
          "context": [
            "TestConfidenceProgression",
            "test_investigation_completion_criteria"
          ]
        },
        {
          "instantiator": "test_investigation_summary_includes_confidence",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1610,
          "context": [
            "TestConfidenceProgression",
            "test_investigation_summary_includes_confidence"
          ]
        },
        {
          "instantiator": "test_confidence_cannot_decrease",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1646,
          "context": [
            "TestConfidenceProgression",
            "test_confidence_cannot_decrease"
          ]
        },
        {
          "instantiator": "test_confidence_persistence_across_turns",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1685,
          "context": [
            "TestConfidenceProgression",
            "test_confidence_persistence_across_turns"
          ]
        },
        {
          "instantiator": "test_confidence_persistence_across_turns",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1698,
          "context": [
            "TestConfidenceProgression",
            "test_confidence_persistence_across_turns"
          ]
        },
        {
          "instantiator": "test_confidence_persistence_across_turns",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1710,
          "context": [
            "TestConfidenceProgression",
            "test_confidence_persistence_across_turns"
          ]
        },
        {
          "instantiator": "test_five_step_investigation_with_hypothesis_evolution",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1766,
          "context": [
            "TestEndToEndIntegration",
            "test_five_step_investigation_with_hypothesis_evolution"
          ]
        },
        {
          "instantiator": "test_five_step_investigation_with_hypothesis_evolution",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1790,
          "context": [
            "TestEndToEndIntegration",
            "test_five_step_investigation_with_hypothesis_evolution"
          ]
        },
        {
          "instantiator": "test_five_step_investigation_with_hypothesis_evolution",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1821,
          "context": [
            "TestEndToEndIntegration",
            "test_five_step_investigation_with_hypothesis_evolution"
          ]
        },
        {
          "instantiator": "test_five_step_investigation_with_hypothesis_evolution",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1845,
          "context": [
            "TestEndToEndIntegration",
            "test_five_step_investigation_with_hypothesis_evolution"
          ]
        },
        {
          "instantiator": "test_five_step_investigation_with_hypothesis_evolution",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1870,
          "context": [
            "TestEndToEndIntegration",
            "test_five_step_investigation_with_hypothesis_evolution"
          ]
        },
        {
          "instantiator": "test_five_step_investigation_with_hypothesis_evolution",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1887,
          "context": [
            "TestEndToEndIntegration",
            "test_five_step_investigation_with_hypothesis_evolution"
          ]
        },
        {
          "instantiator": "test_complete_investigation_workflow",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1966,
          "context": [
            "TestEndToEndIntegration",
            "test_complete_investigation_workflow"
          ]
        },
        {
          "instantiator": "test_complete_investigation_workflow",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1981,
          "context": [
            "TestEndToEndIntegration",
            "test_complete_investigation_workflow"
          ]
        },
        {
          "instantiator": "test_consensus_to_thinkdeep_to_chat_workflow",
          "file": "tests/test_workflow_integration_chaining.py",
          "line": 83,
          "context": [
            "TestConsensusThinkDeepChatChaining",
            "test_consensus_to_thinkdeep_to_chat_workflow"
          ]
        },
        {
          "instantiator": "test_consensus_to_thinkdeep_to_chat_workflow",
          "file": "tests/test_workflow_integration_chaining.py",
          "line": 93,
          "context": [
            "TestConsensusThinkDeepChatChaining",
            "test_consensus_to_thinkdeep_to_chat_workflow"
          ]
        },
        {
          "instantiator": "test_consensus_to_thinkdeep_to_chat_workflow",
          "file": "tests/test_workflow_integration_chaining.py",
          "line": 129,
          "context": [
            "TestConsensusThinkDeepChatChaining",
            "test_consensus_to_thinkdeep_to_chat_workflow"
          ]
        },
        {
          "instantiator": "test_consensus_to_thinkdeep_to_chat_workflow",
          "file": "tests/test_workflow_integration_chaining.py",
          "line": 168,
          "context": [
            "TestConsensusThinkDeepChatChaining",
            "test_consensus_to_thinkdeep_to_chat_workflow"
          ]
        },
        {
          "instantiator": "test_workflow_chain_context_isolation",
          "file": "tests/test_workflow_integration_chaining.py",
          "line": 237,
          "context": [
            "TestConsensusThinkDeepChatChaining",
            "test_workflow_chain_context_isolation"
          ]
        },
        {
          "instantiator": "test_consensus_without_continuation_support",
          "file": "tests/test_workflow_integration_chaining.py",
          "line": 314,
          "context": [
            "TestConsensusThinkDeepChatChaining",
            "test_consensus_without_continuation_support"
          ]
        },
        {
          "instantiator": "test_consensus_without_continuation_support",
          "file": "tests/test_workflow_integration_chaining.py",
          "line": 321,
          "context": [
            "TestConsensusThinkDeepChatChaining",
            "test_consensus_without_continuation_support"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 145
    },
    {
      "name": "ModelProvider",
      "file": "model_chorus/src/model_chorus/providers/base_provider.py",
      "line": 231,
      "language": "python",
      "docstring": "Abstract base class for all model providers.\n\nAll provider implementations (Anthropic, OpenAI, Google, etc.) must inherit\nfrom this class and implement the required methods.\n\nAttributes:\n    provider_name: Name of the provider (e.g., \"anthropic\", \"openai\")\n    api_key: API key for authentication\n    config: Provider-specific configuration",
      "bases": [
        "ABC"
      ],
      "methods": [
        "__init__",
        "generate",
        "supports_vision",
        "get_available_models",
        "supports_capability",
        "validate_api_key",
        "set_model_list",
        "__repr__"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "ClaudeProvider",
      "file": "model_chorus/src/model_chorus/providers/claude_provider.py",
      "line": 23,
      "language": "python",
      "docstring": "Provider for Anthropic's Claude models via the `claude` CLI tool.\n\nThis provider wraps the `claude` command-line interface to enable\ntext generation with Claude models (Opus, Sonnet, Haiku).\n\nSupported features:\n- Text generation with customizable prompts\n- System prompts\n- Temperature and token control\n- Vision capabilities (model-dependent)\n- Thinking mode (extended reasoning)\n\nExample:\n    >>> provider = ClaudeProvider()\n    >>> request = GenerationRequest(\n    ...     prompt=\"Explain quantum computing\",\n    ...     temperature=0.7,\n    ...     max_tokens=1000\n    ... )\n    >>> response = await provider.generate(request)\n    >>> print(response.content)",
      "bases": [
        "CLIProvider"
      ],
      "methods": [
        "__init__",
        "_initialize_models",
        "build_command",
        "parse_response",
        "supports_vision",
        "supports_thinking"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "example_argument_basic",
          "file": "examples/workflow_examples.py",
          "line": 49,
          "context": [
            "example_argument_basic"
          ]
        },
        {
          "instantiator": "example_argument_with_files",
          "file": "examples/workflow_examples.py",
          "line": 117,
          "context": [
            "example_argument_with_files"
          ]
        },
        {
          "instantiator": "example_argument_continuation",
          "file": "examples/workflow_examples.py",
          "line": 151,
          "context": [
            "example_argument_continuation"
          ]
        },
        {
          "instantiator": "example_argument_custom_config",
          "file": "examples/workflow_examples.py",
          "line": 192,
          "context": [
            "example_argument_custom_config"
          ]
        },
        {
          "instantiator": "example_ideate_basic",
          "file": "examples/workflow_examples.py",
          "line": 226,
          "context": [
            "example_ideate_basic"
          ]
        },
        {
          "instantiator": "example_ideate_high_creativity",
          "file": "examples/workflow_examples.py",
          "line": 266,
          "context": [
            "example_ideate_high_creativity"
          ]
        },
        {
          "instantiator": "example_ideate_with_constraints",
          "file": "examples/workflow_examples.py",
          "line": 297,
          "context": [
            "example_ideate_with_constraints"
          ]
        },
        {
          "instantiator": "example_ideate_refine",
          "file": "examples/workflow_examples.py",
          "line": 337,
          "context": [
            "example_ideate_refine"
          ]
        },
        {
          "instantiator": "example_error_handling",
          "file": "examples/workflow_examples.py",
          "line": 383,
          "context": [
            "example_error_handling"
          ]
        },
        {
          "instantiator": "example_output_management",
          "file": "examples/workflow_examples.py",
          "line": 425,
          "context": [
            "example_output_management"
          ]
        },
        {
          "instantiator": "example_provider_comparison",
          "file": "examples/workflow_examples.py",
          "line": 479,
          "context": [
            "example_provider_comparison"
          ]
        },
        {
          "instantiator": "basic_chat_example",
          "file": "model_chorus/examples/chat_example.py",
          "line": 26,
          "context": [
            "basic_chat_example"
          ]
        },
        {
          "instantiator": "multi_turn_conversation_example",
          "file": "model_chorus/examples/chat_example.py",
          "line": 55,
          "context": [
            "multi_turn_conversation_example"
          ]
        },
        {
          "instantiator": "chat_with_file_context_example",
          "file": "model_chorus/examples/chat_example.py",
          "line": 126,
          "context": [
            "chat_with_file_context_example"
          ]
        },
        {
          "instantiator": "conversation_tracking_example",
          "file": "model_chorus/examples/chat_example.py",
          "line": 159,
          "context": [
            "conversation_tracking_example"
          ]
        },
        {
          "instantiator": "basic_investigation_example",
          "file": "model_chorus/examples/thinkdeep_example.py",
          "line": 34,
          "context": [
            "basic_investigation_example"
          ]
        },
        {
          "instantiator": "multi_step_investigation_example",
          "file": "model_chorus/examples/thinkdeep_example.py",
          "line": 114,
          "context": [
            "multi_step_investigation_example"
          ]
        },
        {
          "instantiator": "investigation_with_expert_validation",
          "file": "model_chorus/examples/thinkdeep_example.py",
          "line": 232,
          "context": [
            "investigation_with_expert_validation"
          ]
        },
        {
          "instantiator": "hypothesis_management_example",
          "file": "model_chorus/examples/thinkdeep_example.py",
          "line": 287,
          "context": [
            "hypothesis_management_example"
          ]
        },
        {
          "instantiator": "confidence_progression_example",
          "file": "model_chorus/examples/thinkdeep_example.py",
          "line": 376,
          "context": [
            "confidence_progression_example"
          ]
        },
        {
          "instantiator": "thinkdeep_status",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1385,
          "context": [
            "thinkdeep_status"
          ]
        },
        {
          "instantiator": "list_providers",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1685,
          "context": [
            "list_providers"
          ]
        },
        {
          "instantiator": "check_available_providers",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 209,
          "context": [
            "check_available_providers"
          ]
        },
        {
          "instantiator": "test_initialization",
          "file": "model_chorus/tests/test_claude_provider.py",
          "line": 18,
          "context": [
            "TestClaudeProvider",
            "test_initialization"
          ]
        },
        {
          "instantiator": "test_build_command_basic",
          "file": "model_chorus/tests/test_claude_provider.py",
          "line": 26,
          "context": [
            "TestClaudeProvider",
            "test_build_command_basic"
          ]
        },
        {
          "instantiator": "test_build_command_with_model",
          "file": "model_chorus/tests/test_claude_provider.py",
          "line": 38,
          "context": [
            "TestClaudeProvider",
            "test_build_command_with_model"
          ]
        },
        {
          "instantiator": "test_build_command_without_system_prompt",
          "file": "model_chorus/tests/test_claude_provider.py",
          "line": 50,
          "context": [
            "TestClaudeProvider",
            "test_build_command_without_system_prompt"
          ]
        },
        {
          "instantiator": "test_parse_response_success",
          "file": "model_chorus/tests/test_claude_provider.py",
          "line": 61,
          "context": [
            "TestClaudeProvider",
            "test_parse_response_success"
          ]
        },
        {
          "instantiator": "test_parse_response_failure",
          "file": "model_chorus/tests/test_claude_provider.py",
          "line": 77,
          "context": [
            "TestClaudeProvider",
            "test_parse_response_failure"
          ]
        },
        {
          "instantiator": "test_parse_response_invalid_json",
          "file": "model_chorus/tests/test_claude_provider.py",
          "line": 90,
          "context": [
            "TestClaudeProvider",
            "test_parse_response_invalid_json"
          ]
        },
        {
          "instantiator": "test_generate_success",
          "file": "model_chorus/tests/test_claude_provider.py",
          "line": 103,
          "context": [
            "TestClaudeProvider",
            "test_generate_success"
          ]
        },
        {
          "instantiator": "test_generate_with_retry",
          "file": "model_chorus/tests/test_claude_provider.py",
          "line": 121,
          "context": [
            "TestClaudeProvider",
            "test_generate_with_retry"
          ]
        },
        {
          "instantiator": "test_generate_all_retries_fail",
          "file": "model_chorus/tests/test_claude_provider.py",
          "line": 140,
          "context": [
            "TestClaudeProvider",
            "test_generate_all_retries_fail"
          ]
        },
        {
          "instantiator": "test_supports_vision",
          "file": "model_chorus/tests/test_claude_provider.py",
          "line": 154,
          "context": [
            "TestClaudeProvider",
            "test_supports_vision"
          ]
        },
        {
          "instantiator": "test_supports_thinking",
          "file": "model_chorus/tests/test_claude_provider.py",
          "line": 162,
          "context": [
            "TestClaudeProvider",
            "test_supports_thinking"
          ]
        },
        {
          "instantiator": "test_read_only_mode_allowed_tools",
          "file": "model_chorus/tests/test_claude_provider.py",
          "line": 170,
          "context": [
            "TestClaudeProvider",
            "test_read_only_mode_allowed_tools"
          ]
        },
        {
          "instantiator": "test_read_only_mode_disallowed_tools",
          "file": "model_chorus/tests/test_claude_provider.py",
          "line": 190,
          "context": [
            "TestClaudeProvider",
            "test_read_only_mode_disallowed_tools"
          ]
        },
        {
          "instantiator": "test_end_to_end_consensus",
          "file": "model_chorus/tests/test_integration.py",
          "line": 24,
          "context": [
            "TestIntegration",
            "test_end_to_end_consensus"
          ]
        },
        {
          "instantiator": "test_provider_initialization_and_generation",
          "file": "model_chorus/tests/test_integration.py",
          "line": 63,
          "context": [
            "TestIntegration",
            "test_provider_initialization_and_generation"
          ]
        },
        {
          "instantiator": "test_error_handling_across_workflow",
          "file": "model_chorus/tests/test_integration.py",
          "line": 85,
          "context": [
            "TestIntegration",
            "test_error_handling_across_workflow"
          ]
        },
        {
          "instantiator": "test_multiple_strategy_comparison",
          "file": "model_chorus/tests/test_integration.py",
          "line": 127,
          "context": [
            "TestIntegration",
            "test_multiple_strategy_comparison"
          ]
        },
        {
          "instantiator": "test_multiple_strategy_comparison",
          "file": "model_chorus/tests/test_integration.py",
          "line": 136,
          "context": [
            "TestIntegration",
            "test_multiple_strategy_comparison"
          ]
        },
        {
          "instantiator": "test_concurrent_provider_execution",
          "file": "model_chorus/tests/test_integration.py",
          "line": 150,
          "context": [
            "TestIntegration",
            "test_concurrent_provider_execution"
          ]
        },
        {
          "instantiator": "test_workflow_has_router",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 335,
          "context": [
            "TestStudyWorkflowIntegration",
            "test_workflow_has_router"
          ]
        },
        {
          "instantiator": "test_workflow_routing_history_access",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 362,
          "context": [
            "TestStudyWorkflowIntegration",
            "test_workflow_routing_history_access"
          ]
        },
        {
          "instantiator": "providers",
          "file": "tests/test_providers/test_cli_interface.py",
          "line": 34,
          "context": [
            "TestCLIProvidersImplementInterface",
            "providers"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 46
    },
    {
      "name": "ProviderUnavailableError",
      "file": "model_chorus/src/model_chorus/providers/cli_provider.py",
      "line": 24,
      "language": "python",
      "docstring": "Provider CLI is not available or cannot be used.",
      "bases": [
        "Exception"
      ],
      "methods": [
        "__init__"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "execute_command",
          "file": "model_chorus/src/model_chorus/providers/cli_provider.py",
          "line": 253,
          "context": [
            "CLIProvider",
            "execute_command"
          ]
        },
        {
          "instantiator": "execute_command",
          "file": "model_chorus/src/model_chorus/providers/cli_provider.py",
          "line": 266,
          "context": [
            "CLIProvider",
            "execute_command"
          ]
        },
        {
          "instantiator": "run",
          "file": "model_chorus/src/model_chorus/workflows/argument/argument_workflow.py",
          "line": 424,
          "context": [
            "ArgumentWorkflow",
            "run"
          ]
        },
        {
          "instantiator": "run",
          "file": "model_chorus/src/model_chorus/workflows/chat.py",
          "line": 175,
          "context": [
            "ChatWorkflow",
            "run"
          ]
        },
        {
          "instantiator": "run",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 168,
          "context": [
            "IdeateWorkflow",
            "run"
          ]
        },
        {
          "instantiator": "run",
          "file": "model_chorus/src/model_chorus/workflows/study/study_workflow.py",
          "line": 182,
          "context": [
            "StudyWorkflow",
            "run"
          ]
        },
        {
          "instantiator": "run",
          "file": "model_chorus/src/model_chorus/workflows/thinkdeep.py",
          "line": 225,
          "context": [
            "ThinkDeepWorkflow",
            "run"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 7
    },
    {
      "name": "CLIProvider",
      "file": "model_chorus/src/model_chorus/providers/cli_provider.py",
      "line": 42,
      "language": "python",
      "docstring": "Base class for CLI-based model providers.\n\nThis class extends ModelProvider to handle interactions with AI models\nvia CLI tools, providing common functionality for:\n- Building CLI commands\n- Executing commands asynchronously via subprocess\n- Parsing CLI output\n- Error handling and retries\n\nSubclasses must implement:\n- build_command(): Construct the CLI command for a request\n- parse_response(): Parse CLI output into GenerationResponse\n\nAttributes:\n    cli_command: Base CLI command (e.g., \"claude\", \"gemini\")\n    timeout: Command timeout in seconds\n    retry_limit: Maximum number of retry attempts",
      "bases": [
        "ModelProvider"
      ],
      "methods": [
        "__init__",
        "check_availability",
        "_load_conversation_context",
        "build_command",
        "parse_response",
        "execute_command",
        "_is_retryable_error",
        "generate",
        "supports_vision",
        "__repr__"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "CodexProvider",
      "file": "model_chorus/src/model_chorus/providers/codex_provider.py",
      "line": 23,
      "language": "python",
      "docstring": "Provider for OpenAI's Codex models via the `codex` CLI tool.\n\nThis provider wraps the `codex` command-line interface to enable\ncode generation and completion with Codex models (GPT-4, GPT-3.5, etc.).\n\nSupported features:\n- Text and code generation\n- System prompts\n- Temperature and token control\n- Function calling capabilities\n- Vision support (model-dependent)\n\nExample:\n    >>> provider = CodexProvider()\n    >>> request = GenerationRequest(\n    ...     prompt=\"Write a Python function to sort a list\",\n    ...     temperature=0.5,\n    ...     max_tokens=500\n    ... )\n    >>> response = await provider.generate(request)\n    >>> print(response.content)",
      "bases": [
        "CLIProvider"
      ],
      "methods": [
        "__init__",
        "_initialize_models",
        "build_command",
        "parse_response",
        "supports_vision",
        "supports_function_calling"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "list_providers",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1686,
          "context": [
            "list_providers"
          ]
        },
        {
          "instantiator": "check_available_providers",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 211,
          "context": [
            "check_available_providers"
          ]
        },
        {
          "instantiator": "test_initialization",
          "file": "model_chorus/tests/test_codex_provider.py",
          "line": 18,
          "context": [
            "TestCodexProvider",
            "test_initialization"
          ]
        },
        {
          "instantiator": "test_build_command_basic",
          "file": "model_chorus/tests/test_codex_provider.py",
          "line": 26,
          "context": [
            "TestCodexProvider",
            "test_build_command_basic"
          ]
        },
        {
          "instantiator": "test_build_command_with_model",
          "file": "model_chorus/tests/test_codex_provider.py",
          "line": 36,
          "context": [
            "TestCodexProvider",
            "test_build_command_with_model"
          ]
        },
        {
          "instantiator": "test_build_command_with_images",
          "file": "model_chorus/tests/test_codex_provider.py",
          "line": 48,
          "context": [
            "TestCodexProvider",
            "test_build_command_with_images"
          ]
        },
        {
          "instantiator": "test_parse_response_success",
          "file": "model_chorus/tests/test_codex_provider.py",
          "line": 60,
          "context": [
            "TestCodexProvider",
            "test_parse_response_success"
          ]
        },
        {
          "instantiator": "test_parse_response_failure",
          "file": "model_chorus/tests/test_codex_provider.py",
          "line": 77,
          "context": [
            "TestCodexProvider",
            "test_parse_response_failure"
          ]
        },
        {
          "instantiator": "test_parse_response_invalid_jsonl",
          "file": "model_chorus/tests/test_codex_provider.py",
          "line": 90,
          "context": [
            "TestCodexProvider",
            "test_parse_response_invalid_jsonl"
          ]
        },
        {
          "instantiator": "test_parse_response_missing_agent_message",
          "file": "model_chorus/tests/test_codex_provider.py",
          "line": 102,
          "context": [
            "TestCodexProvider",
            "test_parse_response_missing_agent_message"
          ]
        },
        {
          "instantiator": "test_generate_success",
          "file": "model_chorus/tests/test_codex_provider.py",
          "line": 117,
          "context": [
            "TestCodexProvider",
            "test_generate_success"
          ]
        },
        {
          "instantiator": "test_generate_with_retry",
          "file": "model_chorus/tests/test_codex_provider.py",
          "line": 135,
          "context": [
            "TestCodexProvider",
            "test_generate_with_retry"
          ]
        },
        {
          "instantiator": "test_generate_all_retries_fail",
          "file": "model_chorus/tests/test_codex_provider.py",
          "line": 154,
          "context": [
            "TestCodexProvider",
            "test_generate_all_retries_fail"
          ]
        },
        {
          "instantiator": "test_supports_vision",
          "file": "model_chorus/tests/test_codex_provider.py",
          "line": 168,
          "context": [
            "TestCodexProvider",
            "test_supports_vision"
          ]
        },
        {
          "instantiator": "test_supports_function_calling",
          "file": "model_chorus/tests/test_codex_provider.py",
          "line": 176,
          "context": [
            "TestCodexProvider",
            "test_supports_function_calling"
          ]
        },
        {
          "instantiator": "test_read_only_sandbox_mode",
          "file": "model_chorus/tests/test_codex_provider.py",
          "line": 184,
          "context": [
            "TestCodexProvider",
            "test_read_only_sandbox_mode"
          ]
        },
        {
          "instantiator": "test_non_interactive_approval_mode",
          "file": "model_chorus/tests/test_codex_provider.py",
          "line": 199,
          "context": [
            "TestCodexProvider",
            "test_non_interactive_approval_mode"
          ]
        },
        {
          "instantiator": "test_end_to_end_consensus",
          "file": "model_chorus/tests/test_integration.py",
          "line": 25,
          "context": [
            "TestIntegration",
            "test_end_to_end_consensus"
          ]
        },
        {
          "instantiator": "test_multiple_strategy_comparison",
          "file": "model_chorus/tests/test_integration.py",
          "line": 128,
          "context": [
            "TestIntegration",
            "test_multiple_strategy_comparison"
          ]
        },
        {
          "instantiator": "test_multiple_strategy_comparison",
          "file": "model_chorus/tests/test_integration.py",
          "line": 137,
          "context": [
            "TestIntegration",
            "test_multiple_strategy_comparison"
          ]
        },
        {
          "instantiator": "test_concurrent_provider_execution",
          "file": "model_chorus/tests/test_integration.py",
          "line": 151,
          "context": [
            "TestIntegration",
            "test_concurrent_provider_execution"
          ]
        },
        {
          "instantiator": "providers",
          "file": "tests/test_providers/test_cli_interface.py",
          "line": 35,
          "context": [
            "TestCLIProvidersImplementInterface",
            "providers"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 22
    },
    {
      "name": "CursorAgentProvider",
      "file": "model_chorus/src/model_chorus/providers/cursor_agent_provider.py",
      "line": 23,
      "language": "python",
      "docstring": "Provider for Cursor's AI agent via the `cursor-agent` CLI tool.\n\nThis provider wraps the `cursor-agent` command-line interface to enable\ncode-focused AI interactions with Cursor's agent models.\n\nSupported features:\n- Code generation and completion\n- Natural language to code conversion\n- Code explanation and documentation\n- System prompts for context\n- Temperature control\n- Working directory support for context-aware code generation\n\nExample:\n    >>> provider = CursorAgentProvider()\n    >>> request = GenerationRequest(\n    ...     prompt=\"Write a function to validate email addresses\",\n    ...     temperature=0.3,\n    ...     max_tokens=500,\n    ...     metadata={\"working_directory\": \"/path/to/project\"}\n    ... )\n    >>> response = await provider.generate(request)\n    >>> print(response.content)",
      "bases": [
        "CLIProvider"
      ],
      "methods": [
        "__init__",
        "_initialize_models",
        "build_command",
        "parse_response",
        "supports_vision",
        "supports_code_generation"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "list_providers",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1688,
          "context": [
            "list_providers"
          ]
        },
        {
          "instantiator": "check_available_providers",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 212,
          "context": [
            "check_available_providers"
          ]
        },
        {
          "instantiator": "<module>",
          "file": "test_backward_compat.py",
          "line": 41,
          "context": []
        },
        {
          "instantiator": "<module>",
          "file": "test_codex_parse.py",
          "line": 39,
          "context": []
        },
        {
          "instantiator": "<module>",
          "file": "test_parse_response.py",
          "line": 17,
          "context": []
        },
        {
          "instantiator": "providers",
          "file": "tests/test_providers/test_cli_interface.py",
          "line": 37,
          "context": [
            "TestCLIProvidersImplementInterface",
            "providers"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 6
    },
    {
      "name": "GeminiProvider",
      "file": "model_chorus/src/model_chorus/providers/gemini_provider.py",
      "line": 22,
      "language": "python",
      "docstring": "Provider for Google's Gemini models via the `gemini` CLI tool.\n\nThis provider wraps the `gemini` command-line interface to enable\ntext generation with Gemini models (Pro, Flash, Ultra).\n\nSupported features:\n- Text generation with customizable prompts\n- System instructions\n- Temperature and token control\n- Vision capabilities (multimodal support)\n- Function calling\n- Thinking/reasoning mode\n\nExample:\n    >>> provider = GeminiProvider()\n    >>> request = GenerationRequest(\n    ...     prompt=\"Explain machine learning\",\n    ...     temperature=0.7,\n    ...     max_tokens=1000\n    ... )\n    >>> response = await provider.generate(request)\n    >>> print(response.content)",
      "bases": [
        "CLIProvider"
      ],
      "methods": [
        "__init__",
        "_initialize_models",
        "check_availability",
        "build_command",
        "parse_response",
        "supports_vision",
        "supports_thinking"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "example_provider_comparison",
          "file": "examples/workflow_examples.py",
          "line": 480,
          "context": [
            "example_provider_comparison"
          ]
        },
        {
          "instantiator": "investigation_with_expert_validation",
          "file": "model_chorus/examples/thinkdeep_example.py",
          "line": 233,
          "context": [
            "investigation_with_expert_validation"
          ]
        },
        {
          "instantiator": "list_providers",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1687,
          "context": [
            "list_providers"
          ]
        },
        {
          "instantiator": "check_available_providers",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 210,
          "context": [
            "check_available_providers"
          ]
        },
        {
          "instantiator": "provider",
          "file": "model_chorus/tests/test_gemini_integration.py",
          "line": 19,
          "context": [
            "TestGeminiIntegration",
            "provider"
          ]
        },
        {
          "instantiator": "providers",
          "file": "tests/test_providers/test_cli_interface.py",
          "line": 36,
          "context": [
            "TestCLIProvidersImplementInterface",
            "providers"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 6
    },
    {
      "name": "CitationStyle",
      "file": "model_chorus/src/model_chorus/utils/citation_formatter.py",
      "line": 15,
      "language": "python",
      "docstring": "Supported citation formatting styles.",
      "bases": [
        "str",
        "Enum"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "ArgumentWorkflow",
      "file": "model_chorus/src/model_chorus/workflows/argument/argument_workflow.py",
      "line": 31,
      "language": "python",
      "docstring": "Role-based dialectical reasoning workflow using RoleOrchestrator.\n\nThis workflow implements structured argument analysis through role-based\norchestration, where different AI roles (Creator, Skeptic, Moderator) examine\nan argument from multiple perspectives to produce balanced dialectical analysis.\n\nArchitecture:\n- Uses RoleOrchestrator for sequential role execution\n- Creator role: Generates strong thesis advocating FOR the position (Step 1)\n- Skeptic role: Provides critical rebuttal AGAINST the position (Step 2)\n- Moderator role: Synthesizes perspectives into balanced analysis (Step 3)\n\nCurrent Implementation Status:\n- Step 1 (Creator): \u2713 Implemented - Generates thesis with supporting arguments\n- Step 2 (Skeptic): \u2713 Implemented - Provides critical rebuttal and counter-arguments\n- Step 3 (Moderator): \u2713 Implemented - Synthesizes both perspectives into balanced analysis\n\nKey Features:\n- Role-based orchestration using RoleOrchestrator\n- Sequential execution pattern (roles build on each other's outputs)\n- Stance-driven prompts (for/against/neutral)\n- Conversation threading via continuation_id\n- Inherits conversation support from BaseWorkflow\n- Structured dialectical reasoning\n\nThe ArgumentWorkflow is ideal for:\n- Analyzing the strength of arguments and claims\n- Debate preparation and research\n- Critical thinking and decision-making support\n- Examining multiple perspectives systematically\n- Identifying both strengths and weaknesses in reasoning\n\nWorkflow Steps (when complete):\n1. **Creator Role (Thesis Generation)**: Build strong case FOR the position\n2. **Skeptic Role (Critical Rebuttal)**: Challenge with counter-arguments\n3. **Moderator Role (Synthesis)**: Integrate perspectives into balanced assessment\n\nExample:\n    >>> from model_chorus.providers import ClaudeProvider\n    >>> from model_chorus.workflows import ArgumentWorkflow\n    >>> from model_chorus.core.conversation import ConversationMemory\n    >>>\n    >>> # Create provider and conversation memory\n    >>> provider = ClaudeProvider()\n    >>> memory = ConversationMemory()\n    >>>\n    >>> # Create workflow\n    >>> workflow = ArgumentWorkflow(provider, conversation_memory=memory)\n    >>>\n    >>> # Analyze an argument (all three roles execute)\n    >>> result = await workflow.run(\n    ...     \"Universal basic income would reduce poverty\"\n    ... )\n    >>> print(result.steps[0].content)  # Creator's thesis\n    >>> print(result.steps[1].content)  # Skeptic's rebuttal\n    >>> print(result.steps[2].content)  # Moderator's synthesis\n    >>> print(result.metadata['roles_executed'])  # ['creator', 'skeptic', 'moderator']\n    >>>\n    >>> # Continue analysis with follow-up\n    >>> result2 = await workflow.run(\n    ...     \"What about the impact on work incentives?\",\n    ...     continuation_id=result.metadata.get('thread_id')\n    ... )\n    >>> print(result2.synthesis)",
      "bases": [
        "BaseWorkflow"
      ],
      "methods": [
        "__init__",
        "_create_creator_role",
        "_create_skeptic_role",
        "_create_moderator_role",
        "_generate_argument_map",
        "run",
        "_build_prompt_with_history",
        "_get_conversation_length",
        "get_provider",
        "validate_config",
        "__repr__"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "example_argument_basic",
          "file": "examples/workflow_examples.py",
          "line": 53,
          "context": [
            "example_argument_basic"
          ]
        },
        {
          "instantiator": "example_argument_with_files",
          "file": "examples/workflow_examples.py",
          "line": 119,
          "context": [
            "example_argument_with_files"
          ]
        },
        {
          "instantiator": "example_argument_continuation",
          "file": "examples/workflow_examples.py",
          "line": 153,
          "context": [
            "example_argument_continuation"
          ]
        },
        {
          "instantiator": "example_argument_custom_config",
          "file": "examples/workflow_examples.py",
          "line": 194,
          "context": [
            "example_argument_custom_config"
          ]
        },
        {
          "instantiator": "example_error_handling",
          "file": "examples/workflow_examples.py",
          "line": 385,
          "context": [
            "example_error_handling"
          ]
        },
        {
          "instantiator": "example_provider_comparison",
          "file": "examples/workflow_examples.py",
          "line": 489,
          "context": [
            "example_provider_comparison"
          ]
        },
        {
          "instantiator": "argument",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 519,
          "context": [
            "argument"
          ]
        },
        {
          "instantiator": "argument_workflow",
          "file": "tests/test_argument_workflow.py",
          "line": 50,
          "context": [
            "argument_workflow"
          ]
        },
        {
          "instantiator": "test_initialization_with_provider",
          "file": "tests/test_argument_workflow.py",
          "line": 61,
          "context": [
            "TestArgumentWorkflowInitialization",
            "test_initialization_with_provider"
          ]
        },
        {
          "instantiator": "test_initialization_without_memory",
          "file": "tests/test_argument_workflow.py",
          "line": 73,
          "context": [
            "TestArgumentWorkflowInitialization",
            "test_initialization_without_memory"
          ]
        },
        {
          "instantiator": "test_initialization_without_provider_raises_error",
          "file": "tests/test_argument_workflow.py",
          "line": 81,
          "context": [
            "TestArgumentWorkflowInitialization",
            "test_initialization_without_provider_raises_error"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 11
    },
    {
      "name": "ChatWorkflow",
      "file": "model_chorus/src/model_chorus/workflows/chat.py",
      "line": 23,
      "language": "python",
      "docstring": "Simple single-model chat workflow with conversation continuity.\n\nThis workflow provides straightforward peer consultation with a single AI model,\nsupporting conversation threading for multi-turn interactions. Unlike multi-model\nworkflows like Consensus, Chat focuses on simplicity and conversational flow.\n\nKey features:\n- Single provider (not multi-model)\n- Conversation threading via continuation_id\n- Inherits conversation support from BaseWorkflow\n- Automatic conversation history management\n- Simple request/response pattern\n\nThe ChatWorkflow is ideal for:\n- Quick second opinions from an AI model\n- Iterative conversations and refinement\n- Simple consultations without orchestration overhead\n- Building conversational applications\n\nExample:\n    >>> from model_chorus.providers import ClaudeProvider\n    >>> from model_chorus.workflows import ChatWorkflow\n    >>> from model_chorus.core.conversation import ConversationMemory\n    >>>\n    >>> # Create provider and conversation memory\n    >>> provider = ClaudeProvider()\n    >>> memory = ConversationMemory()\n    >>>\n    >>> # Create workflow\n    >>> workflow = ChatWorkflow(provider, conversation_memory=memory)\n    >>>\n    >>> # First message (creates new conversation)\n    >>> result1 = await workflow.run(\"What is quantum computing?\")\n    >>> thread_id = result1.metadata.get('thread_id')\n    >>> print(result1.synthesis)\n    >>>\n    >>> # Follow-up message (continues conversation)\n    >>> result2 = await workflow.run(\n    ...     \"How does it differ from classical computing?\",\n    ...     continuation_id=thread_id\n    ... )\n    >>> print(result2.synthesis)\n    >>>\n    >>> # Check conversation history\n    >>> thread = workflow.get_thread(thread_id)\n    >>> print(f\"Total messages: {len(thread.messages)}\")",
      "bases": [
        "BaseWorkflow"
      ],
      "methods": [
        "__init__",
        "run",
        "_build_prompt_with_history",
        "_get_conversation_length",
        "get_provider",
        "clear_conversation",
        "get_message_count",
        "validate_config",
        "__repr__"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "basic_chat_example",
          "file": "model_chorus/examples/chat_example.py",
          "line": 30,
          "context": [
            "basic_chat_example"
          ]
        },
        {
          "instantiator": "multi_turn_conversation_example",
          "file": "model_chorus/examples/chat_example.py",
          "line": 59,
          "context": [
            "multi_turn_conversation_example"
          ]
        },
        {
          "instantiator": "chat_with_file_context_example",
          "file": "model_chorus/examples/chat_example.py",
          "line": 130,
          "context": [
            "chat_with_file_context_example"
          ]
        },
        {
          "instantiator": "conversation_tracking_example",
          "file": "model_chorus/examples/chat_example.py",
          "line": 163,
          "context": [
            "conversation_tracking_example"
          ]
        },
        {
          "instantiator": "chat",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 314,
          "context": [
            "chat"
          ]
        },
        {
          "instantiator": "chat_workflow",
          "file": "model_chorus/tests/test_chat_integration.py",
          "line": 64,
          "context": [
            "chat_workflow"
          ]
        },
        {
          "instantiator": "test_multiple_concurrent_threads",
          "file": "model_chorus/tests/test_chat_integration.py",
          "line": 240,
          "context": [
            "TestChatThreadManagement",
            "test_multiple_concurrent_threads"
          ]
        },
        {
          "instantiator": "chat_workflow",
          "file": "model_chorus/tests/test_chat_workflow.py",
          "line": 46,
          "context": [
            "chat_workflow"
          ]
        },
        {
          "instantiator": "test_initialization_with_provider",
          "file": "model_chorus/tests/test_chat_workflow.py",
          "line": 57,
          "context": [
            "TestChatWorkflowInitialization",
            "test_initialization_with_provider"
          ]
        },
        {
          "instantiator": "test_initialization_without_memory",
          "file": "model_chorus/tests/test_chat_workflow.py",
          "line": 69,
          "context": [
            "TestChatWorkflowInitialization",
            "test_initialization_without_memory"
          ]
        },
        {
          "instantiator": "test_initialization_without_provider_raises_error",
          "file": "model_chorus/tests/test_chat_workflow.py",
          "line": 77,
          "context": [
            "TestChatWorkflowInitialization",
            "test_initialization_without_provider_raises_error"
          ]
        },
        {
          "instantiator": "test_new_conversation_without_memory",
          "file": "model_chorus/tests/test_chat_workflow.py",
          "line": 114,
          "context": [
            "TestConversationInitiation",
            "test_new_conversation_without_memory"
          ]
        },
        {
          "instantiator": "test_get_thread_without_memory_returns_none",
          "file": "model_chorus/tests/test_chat_workflow.py",
          "line": 327,
          "context": [
            "TestConversationTracking",
            "test_get_thread_without_memory_returns_none"
          ]
        },
        {
          "instantiator": "test_provider_error_handled",
          "file": "model_chorus/tests/test_chat_workflow.py",
          "line": 364,
          "context": [
            "TestErrorHandling",
            "test_provider_error_handled"
          ]
        },
        {
          "instantiator": "test_100_concurrent_chat_conversations",
          "file": "tests/test_concurrent_conversations.py",
          "line": 74,
          "context": [
            "TestConcurrentConversationHandling",
            "test_100_concurrent_chat_conversations"
          ]
        },
        {
          "instantiator": "test_concurrent_multi_turn_conversations",
          "file": "tests/test_concurrent_conversations.py",
          "line": 178,
          "context": [
            "TestConcurrentConversationHandling",
            "test_concurrent_multi_turn_conversations"
          ]
        },
        {
          "instantiator": "test_mixed_workflow_concurrent_execution",
          "file": "tests/test_concurrent_conversations.py",
          "line": 260,
          "context": [
            "TestConcurrentConversationHandling",
            "test_mixed_workflow_concurrent_execution"
          ]
        },
        {
          "instantiator": "test_performance_scalability",
          "file": "tests/test_concurrent_conversations.py",
          "line": 338,
          "context": [
            "TestConcurrentConversationHandling",
            "test_performance_scalability"
          ]
        },
        {
          "instantiator": "test_long_conversation_memory_stability",
          "file": "tests/test_memory_management.py",
          "line": 77,
          "context": [
            "TestMemoryManagement",
            "test_long_conversation_memory_stability"
          ]
        },
        {
          "instantiator": "test_multiple_long_conversations_memory_isolation",
          "file": "tests/test_memory_management.py",
          "line": 166,
          "context": [
            "TestMemoryManagement",
            "test_multiple_long_conversations_memory_isolation"
          ]
        },
        {
          "instantiator": "test_memory_efficiency_with_large_messages",
          "file": "tests/test_memory_management.py",
          "line": 235,
          "context": [
            "TestMemoryManagement",
            "test_memory_efficiency_with_large_messages"
          ]
        },
        {
          "instantiator": "test_concurrent_long_conversations_memory",
          "file": "tests/test_memory_management.py",
          "line": 291,
          "context": [
            "TestMemoryManagement",
            "test_concurrent_long_conversations_memory"
          ]
        },
        {
          "instantiator": "test_consensus_to_thinkdeep_to_chat_workflow",
          "file": "tests/test_workflow_integration_chaining.py",
          "line": 180,
          "context": [
            "TestConsensusThinkDeepChatChaining",
            "test_consensus_to_thinkdeep_to_chat_workflow"
          ]
        },
        {
          "instantiator": "test_workflow_chain_context_isolation",
          "file": "tests/test_workflow_integration_chaining.py",
          "line": 280,
          "context": [
            "TestConsensusThinkDeepChatChaining",
            "test_workflow_chain_context_isolation"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 24
    },
    {
      "name": "ConsensusStrategy",
      "file": "model_chorus/src/model_chorus/workflows/consensus.py",
      "line": 25,
      "language": "python",
      "docstring": "Strategy for reaching consensus among multiple model responses.",
      "bases": [
        "Enum"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "ProviderConfig",
      "file": "model_chorus/src/model_chorus/workflows/consensus.py",
      "line": 36,
      "language": "python",
      "docstring": "Configuration for a provider in the consensus workflow.",
      "bases": [],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "__init__",
          "file": "model_chorus/src/model_chorus/workflows/consensus.py",
          "line": 110,
          "context": [
            "ConsensusWorkflow",
            "__init__"
          ]
        },
        {
          "instantiator": "add_provider",
          "file": "model_chorus/src/model_chorus/workflows/consensus.py",
          "line": 130,
          "context": [
            "ConsensusWorkflow",
            "add_provider"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 2
    },
    {
      "name": "ConsensusResult",
      "file": "model_chorus/src/model_chorus/workflows/consensus.py",
      "line": 46,
      "language": "python",
      "docstring": "Result from a consensus workflow execution.",
      "bases": [],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "execute",
          "file": "model_chorus/src/model_chorus/workflows/consensus.py",
          "line": 251,
          "context": [
            "ConsensusWorkflow",
            "execute"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 1
    },
    {
      "name": "ConsensusWorkflow",
      "file": "model_chorus/src/model_chorus/workflows/consensus.py",
      "line": 57,
      "language": "python",
      "docstring": "Workflow for coordinating multiple AI models to reach consensus.\n\nThis workflow allows querying multiple models simultaneously and applying\nvarious strategies to synthesize or select from their responses.\n\nKey features:\n- Parallel execution across multiple providers\n- Configurable consensus strategies\n- Error handling and fallback mechanisms\n- Response weighting and prioritization\n- Timeout management per provider\n\nExample:\n    >>> from model_chorus.providers import ClaudeProvider, GeminiProvider\n    >>> from model_chorus.workflows import ConsensusWorkflow\n    >>>\n    >>> # Create providers\n    >>> claude = ClaudeProvider()\n    >>> gemini = GeminiProvider()\n    >>>\n    >>> # Create workflow with providers\n    >>> workflow = ConsensusWorkflow([claude, gemini])\n    >>>\n    >>> # Execute consensus query\n    >>> request = GenerationRequest(prompt=\"Explain quantum computing\")\n    >>> result = await workflow.execute(request)\n    >>>\n    >>> # Access consensus or individual responses\n    >>> print(result.consensus_response)\n    >>> for provider, response in result.provider_results.items():\n    ...     print(f\"{provider}: {response.content}\")",
      "bases": [],
      "methods": [
        "__init__",
        "add_provider",
        "_execute_provider",
        "execute",
        "_apply_strategy",
        "get_provider_count",
        "get_providers",
        "set_strategy",
        "__repr__"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "consensus",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 912,
          "context": [
            "consensus"
          ]
        },
        {
          "instantiator": "test_initialization",
          "file": "model_chorus/tests/test_consensus_workflow.py",
          "line": 20,
          "context": [
            "TestConsensusWorkflow",
            "test_initialization"
          ]
        },
        {
          "instantiator": "test_initialization_multiple_providers",
          "file": "model_chorus/tests/test_consensus_workflow.py",
          "line": 32,
          "context": [
            "TestConsensusWorkflow",
            "test_initialization_multiple_providers"
          ]
        },
        {
          "instantiator": "test_initialization_with_strategy",
          "file": "model_chorus/tests/test_consensus_workflow.py",
          "line": 40,
          "context": [
            "TestConsensusWorkflow",
            "test_initialization_with_strategy"
          ]
        },
        {
          "instantiator": "test_execute_all_responses_strategy",
          "file": "model_chorus/tests/test_consensus_workflow.py",
          "line": 63,
          "context": [
            "TestConsensusWorkflow",
            "test_execute_all_responses_strategy"
          ]
        },
        {
          "instantiator": "test_execute_first_valid_strategy",
          "file": "model_chorus/tests/test_consensus_workflow.py",
          "line": 89,
          "context": [
            "TestConsensusWorkflow",
            "test_execute_first_valid_strategy"
          ]
        },
        {
          "instantiator": "test_execute_with_parameters",
          "file": "model_chorus/tests/test_consensus_workflow.py",
          "line": 109,
          "context": [
            "TestConsensusWorkflow",
            "test_execute_with_parameters"
          ]
        },
        {
          "instantiator": "test_execute_all_providers_fail",
          "file": "model_chorus/tests/test_consensus_workflow.py",
          "line": 135,
          "context": [
            "TestConsensusWorkflow",
            "test_execute_all_providers_fail"
          ]
        },
        {
          "instantiator": "test_end_to_end_consensus",
          "file": "model_chorus/tests/test_integration.py",
          "line": 27,
          "context": [
            "TestIntegration",
            "test_end_to_end_consensus"
          ]
        },
        {
          "instantiator": "test_error_handling_across_workflow",
          "file": "model_chorus/tests/test_integration.py",
          "line": 86,
          "context": [
            "TestIntegration",
            "test_error_handling_across_workflow"
          ]
        },
        {
          "instantiator": "test_multiple_strategy_comparison",
          "file": "model_chorus/tests/test_integration.py",
          "line": 129,
          "context": [
            "TestIntegration",
            "test_multiple_strategy_comparison"
          ]
        },
        {
          "instantiator": "test_multiple_strategy_comparison",
          "file": "model_chorus/tests/test_integration.py",
          "line": 138,
          "context": [
            "TestIntegration",
            "test_multiple_strategy_comparison"
          ]
        },
        {
          "instantiator": "test_concurrent_provider_execution",
          "file": "model_chorus/tests/test_integration.py",
          "line": 152,
          "context": [
            "TestIntegration",
            "test_concurrent_provider_execution"
          ]
        },
        {
          "instantiator": "test_consensus_applies_provider_model_override_without_mutation",
          "file": "tests/test_consensus_provider_models.py",
          "line": 42,
          "context": [
            "test_consensus_applies_provider_model_override_without_mutation"
          ]
        },
        {
          "instantiator": "test_shared_request_model_overrides_provider_metadata",
          "file": "tests/test_consensus_provider_models.py",
          "line": 76,
          "context": [
            "test_shared_request_model_overrides_provider_metadata"
          ]
        },
        {
          "instantiator": "test_consensus_to_thinkdeep_to_chat_workflow",
          "file": "tests/test_workflow_integration_chaining.py",
          "line": 104,
          "context": [
            "TestConsensusThinkDeepChatChaining",
            "test_consensus_to_thinkdeep_to_chat_workflow"
          ]
        },
        {
          "instantiator": "test_consensus_without_continuation_support",
          "file": "tests/test_workflow_integration_chaining.py",
          "line": 329,
          "context": [
            "TestConsensusThinkDeepChatChaining",
            "test_consensus_without_continuation_support"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 17
    },
    {
      "name": "IdeateWorkflow",
      "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
      "line": 30,
      "language": "python",
      "docstring": "Creative ideation workflow for brainstorming and idea generation.\n\nThis workflow implements structured brainstorming through multiple rounds\nof creative idea generation, helping users explore diverse solutions and\ninnovative approaches to problems or challenges.\n\nArchitecture:\n- Single-model creative generation with high temperature\n- Multiple ideation rounds for diverse perspectives\n- Conversation threading for iterative refinement\n- Focus on quantity and creativity over evaluation\n\nKey Features:\n- Multi-round idea generation\n- Creative prompting strategies\n- Conversation threading via continuation_id\n- Inherits conversation support from BaseWorkflow\n- Structured brainstorming approach\n\nThe IdeateWorkflow is ideal for:\n- Brainstorming new features or solutions\n- Creative problem-solving\n- Exploring innovative approaches\n- Generating diverse perspectives on challenges\n- Early-stage product ideation\n\nWorkflow Pattern:\n1. **Initial Ideation**: Generate diverse initial ideas\n2. **Expansion**: Explore variations and combinations\n3. **Refinement**: Develop promising concepts further\n\nExample:\n    >>> from model_chorus.providers import ClaudeProvider\n    >>> from model_chorus.workflows import IdeateWorkflow\n    >>> from model_chorus.core.conversation import ConversationMemory\n    >>>\n    >>> # Create provider and conversation memory\n    >>> provider = ClaudeProvider()\n    >>> memory = ConversationMemory()\n    >>>\n    >>> # Create workflow\n    >>> workflow = IdeateWorkflow(provider, conversation_memory=memory)\n    >>>\n    >>> # Generate ideas\n    >>> result = await workflow.run(\n    ...     \"How can we improve user onboarding?\"\n    ... )\n    >>> print(result.synthesis)\n    >>>\n    >>> # Refine specific ideas\n    >>> result2 = await workflow.run(\n    ...     \"Expand on the gamification idea\",\n    ...     continuation_id=result.metadata.get('thread_id')\n    ... )",
      "bases": [
        "BaseWorkflow"
      ],
      "methods": [
        "__init__",
        "run",
        "_get_ideation_system_prompt",
        "_frame_ideation_prompt",
        "_create_brainstormer_role",
        "run_parallel_brainstorming",
        "_synthesize_brainstorming_results",
        "run_convergent_analysis",
        "_extract_ideas",
        "_create_extraction_prompt",
        "_get_extraction_system_prompt",
        "_parse_extracted_ideas",
        "_cluster_ideas",
        "_create_clustering_prompt",
        "_get_clustering_system_prompt",
        "_parse_clusters",
        "_score_ideas",
        "_create_scoring_prompt",
        "_get_scoring_system_prompt",
        "_parse_scores",
        "_synthesize_convergent_analysis",
        "_format_scored_cluster",
        "run_complete_ideation",
        "run_interactive_selection",
        "_display_and_select_clusters",
        "_parse_selection_input",
        "_synthesize_selection",
        "run_elaboration",
        "_elaborate_cluster",
        "_create_elaboration_prompt",
        "_get_elaboration_system_prompt",
        "_parse_outline_sections",
        "_synthesize_elaborations",
        "validate_config",
        "get_provider"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "example_ideate_basic",
          "file": "examples/workflow_examples.py",
          "line": 228,
          "context": [
            "example_ideate_basic"
          ]
        },
        {
          "instantiator": "example_ideate_high_creativity",
          "file": "examples/workflow_examples.py",
          "line": 268,
          "context": [
            "example_ideate_high_creativity"
          ]
        },
        {
          "instantiator": "example_ideate_with_constraints",
          "file": "examples/workflow_examples.py",
          "line": 299,
          "context": [
            "example_ideate_with_constraints"
          ]
        },
        {
          "instantiator": "example_ideate_refine",
          "file": "examples/workflow_examples.py",
          "line": 339,
          "context": [
            "example_ideate_refine"
          ]
        },
        {
          "instantiator": "example_output_management",
          "file": "examples/workflow_examples.py",
          "line": 427,
          "context": [
            "example_output_management"
          ]
        },
        {
          "instantiator": "ideate",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 722,
          "context": [
            "ideate"
          ]
        },
        {
          "instantiator": "ideate_workflow",
          "file": "model_chorus/tests/test_ideate_workflow.py",
          "line": 120,
          "context": [
            "ideate_workflow"
          ]
        },
        {
          "instantiator": "test_initialization_with_provider",
          "file": "model_chorus/tests/test_ideate_workflow.py",
          "line": 177,
          "context": [
            "TestIdeateWorkflowInitialization",
            "test_initialization_with_provider"
          ]
        },
        {
          "instantiator": "test_initialization_without_provider_raises_error",
          "file": "model_chorus/tests/test_ideate_workflow.py",
          "line": 186,
          "context": [
            "TestIdeateWorkflowInitialization",
            "test_initialization_without_provider_raises_error"
          ]
        },
        {
          "instantiator": "test_run_complete_ideation",
          "file": "model_chorus/tests/test_ideate_workflow.py",
          "line": 367,
          "context": [
            "TestCompleteIdeation",
            "test_run_complete_ideation"
          ]
        },
        {
          "instantiator": "test_complete_ideation_with_custom_parameters",
          "file": "model_chorus/tests/test_ideate_workflow.py",
          "line": 395,
          "context": [
            "TestCompleteIdeation",
            "test_complete_ideation_with_custom_parameters"
          ]
        },
        {
          "instantiator": "ideate_workflow",
          "file": "tests/test_ideate_workflow.py",
          "line": 143,
          "context": [
            "ideate_workflow"
          ]
        },
        {
          "instantiator": "test_initialization_with_provider",
          "file": "tests/test_ideate_workflow.py",
          "line": 154,
          "context": [
            "TestIdeateWorkflowInitialization",
            "test_initialization_with_provider"
          ]
        },
        {
          "instantiator": "test_initialization_without_memory",
          "file": "tests/test_ideate_workflow.py",
          "line": 166,
          "context": [
            "TestIdeateWorkflowInitialization",
            "test_initialization_without_memory"
          ]
        },
        {
          "instantiator": "test_initialization_without_provider_raises_error",
          "file": "tests/test_ideate_workflow.py",
          "line": 174,
          "context": [
            "TestIdeateWorkflowInitialization",
            "test_initialization_without_provider_raises_error"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 15
    },
    {
      "name": "PersonaConfig",
      "file": "model_chorus/src/model_chorus/workflows/study/config.py",
      "line": 13,
      "language": "python",
      "docstring": "Configuration for a single persona in the study workflow.\n\nAttributes:\n    name: Persona name (e.g., \"Researcher\", \"Critic\")\n    expertise: Domain expertise description\n    role: Role in investigation (e.g., \"primary investigator\", \"critical reviewer\")\n    system_prompt: Optional custom system prompt for this persona\n    temperature: Optional temperature override for this persona\n    metadata: Additional persona-specific metadata",
      "bases": [],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "<module>",
          "file": "model_chorus/src/model_chorus/workflows/study/config.py",
          "line": 55,
          "context": [
            "StudyConfig"
          ]
        },
        {
          "instantiator": "<module>",
          "file": "model_chorus/src/model_chorus/workflows/study/config.py",
          "line": 61,
          "context": [
            "StudyConfig"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 2
    },
    {
      "name": "StudyConfig",
      "file": "model_chorus/src/model_chorus/workflows/study/config.py",
      "line": 35,
      "language": "python",
      "docstring": "Configuration for STUDY workflow execution.\n\nDefines default settings and behavior for persona-based investigations,\nincluding persona configurations, iteration limits, and confidence thresholds.\n\nAttributes:\n    personas: List of persona configurations to use\n    max_iterations: Maximum number of investigation iterations\n    min_confidence_for_completion: Minimum confidence level to complete investigation\n    enable_cross_persona_dialogue: Whether personas should interact with each other\n    temperature: Default temperature for generation (can be overridden per persona)\n    max_tokens: Maximum tokens per persona response\n    enable_file_analysis: Whether to enable file examination capabilities\n    collaboration_rounds: Number of rounds of cross-persona collaboration\n    metadata: Additional workflow-specific metadata",
      "bases": [],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "InvestigationResult",
      "file": "model_chorus/src/model_chorus/workflows/study/config.py",
      "line": 80,
      "language": "python",
      "docstring": "Result from a study workflow investigation.\n\nContains all findings, persona contributions, and investigation metadata\nfrom a completed investigation session.\n\nAttributes:\n    investigation_id: Unique identifier for this investigation\n    final_phase: Final investigation phase reached\n    final_confidence: Final confidence level achieved\n    iteration_count: Number of iterations completed\n    persona_findings: Dict mapping persona names to their findings\n    synthesis: Final synthesis of all findings\n    relevant_files: Files examined during investigation\n    metadata: Additional result metadata",
      "bases": [],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "ContextAnalysisInput",
      "file": "model_chorus/src/model_chorus/workflows/study/context_analysis.py",
      "line": 24,
      "language": "python",
      "docstring": "Input model for context analysis skill.\n\nDefines the investigation context needed to determine which persona\nto consult next based on current phase, confidence, and findings.\n\nAttributes:\n    current_phase: Current investigation phase (discovery/validation/planning)\n    confidence: Current confidence level (0-100 or ConfidenceLevel enum value)\n    findings: List of findings/insights discovered so far in the investigation\n    unresolved_questions: List of questions that still need investigation\n    prior_persona: Name of the previously consulted persona (optional)",
      "bases": [
        "BaseModel"
      ],
      "methods": [
        "validate_phase",
        "validate_confidence"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "route_next_persona",
          "file": "model_chorus/src/model_chorus/workflows/study/persona_router.py",
          "line": 239,
          "context": [
            "PersonaRouter",
            "route_next_persona"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 1
    },
    {
      "name": "ContextAnalysisResult",
      "file": "model_chorus/src/model_chorus/workflows/study/context_analysis.py",
      "line": 139,
      "language": "python",
      "docstring": "Result of context analysis determining next persona to consult.\n\nContains the recommended persona, reasoning for the selection,\nand any context-specific guidance for the persona invocation.\n\nAttributes:\n    recommended_persona: Name of the persona to consult next\n    reasoning: Explanation for why this persona was selected\n    context_summary: Summary of current investigation context\n    confidence: Current confidence level from context\n    guidance: Specific guidance or focus areas for the persona\n    metadata: Additional analysis metadata",
      "bases": [],
      "methods": [
        "to_dict",
        "to_json"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "analyze_context",
          "file": "model_chorus/src/model_chorus/workflows/study/context_analysis.py",
          "line": 370,
          "context": [
            "analyze_context"
          ]
        },
        {
          "instantiator": "route_next_persona",
          "file": "model_chorus/src/model_chorus/workflows/study/persona_router.py",
          "line": 269,
          "context": [
            "PersonaRouter",
            "route_next_persona"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 2
    },
    {
      "name": "ShortTermCache",
      "file": "model_chorus/src/model_chorus/workflows/study/memory/cache.py",
      "line": 25,
      "language": "python",
      "docstring": "LRU-based in-memory cache for memory entries.\n\nProvides fast access to recent memory entries with automatic eviction\nof least recently used entries when the cache reaches capacity.\n\nThe cache uses OrderedDict to maintain insertion/access order and\nimplements LRU eviction by moving accessed items to the end and\nremoving items from the beginning when full.\n\nThread Safety:\n    All operations are protected by a threading lock to ensure\n    safe concurrent access from multiple personas/threads.\n\nAttributes:\n    max_size: Maximum number of entries to cache (default 100)\n    cache: OrderedDict storing entry_id -> MemoryEntry mappings\n    stats: Statistics tracking cache performance\n    lock: Threading lock for thread-safe operations\n\nExample:\n    >>> cache = ShortTermCache(max_size=50)\n    >>> cache.put(entry_id, memory_entry)\n    >>> entry = cache.get(entry_id)\n    >>> results = cache.query(MemoryQuery(persona=\"researcher\"))",
      "bases": [],
      "methods": [
        "__init__",
        "get",
        "put",
        "delete",
        "query",
        "_matches_query",
        "clear",
        "size",
        "get_metadata",
        "get_stats"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "__init__",
          "file": "model_chorus/src/model_chorus/workflows/study/memory/controller.py",
          "line": 88,
          "context": [
            "MemoryController",
            "__init__"
          ]
        },
        {
          "instantiator": "cache",
          "file": "tests/workflows/study/memory/test_cache.py",
          "line": 21,
          "context": [
            "cache"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 2
    },
    {
      "name": "MemoryController",
      "file": "model_chorus/src/model_chorus/workflows/study/memory/controller.py",
      "line": 26,
      "language": "python",
      "docstring": "Unified controller for memory system operations.\n\nCoordinates between ShortTermCache (fast, volatile) and LongTermStorage\n(durable, persistent) to provide optimal performance with durability.\n\nThe controller implements a write-through caching strategy:\n- Writes: Stored in both cache and persistence\n- Reads: Check cache first, fall back to persistence\n- Cache misses: Automatically promote to cache for future reads\n\nThis ensures:\n- Fast access to recent/active investigation data (cache)\n- Durable storage of all findings (persistence)\n- Automatic recovery after cache eviction (promotion)\n\nAttributes:\n    cache: ShortTermCache instance for fast access\n    storage: LongTermStorage instance for durability\n    write_through: If True, writes go to both cache and storage (default)\n\nExample:\n    >>> controller = MemoryController(\n    ...     cache_size=100,\n    ...     db_path=\"investigations.db\"\n    ... )\n    >>> controller.initialize()\n    >>>\n    >>> # Store memory entry (goes to cache + persistence)\n    >>> entry_id = controller.store(\n    ...     investigation_id=\"inv-123\",\n    ...     persona=\"researcher\",\n    ...     findings=\"Found important pattern\",\n    ...     evidence=\"Analysis of dataset X\"\n    ... )\n    >>>\n    >>> # Retrieve entry (cache-first)\n    >>> entry = controller.get(entry_id)\n    >>>\n    >>> # Query entries (searches both cache and persistence)\n    >>> results = controller.query(\n    ...     MemoryQuery(investigation_id=\"inv-123\", persona=\"researcher\")\n    ... )\n    >>>\n    >>> controller.close()",
      "bases": [],
      "methods": [
        "__init__",
        "initialize",
        "store",
        "get",
        "query",
        "delete",
        "flush_cache_to_storage",
        "clear_cache",
        "get_metadata",
        "close"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "MemoryType",
      "file": "model_chorus/src/model_chorus/workflows/study/memory/models.py",
      "line": 18,
      "language": "python",
      "docstring": "Type of memory entry for categorization and retrieval.\n\nValues:\n    FINDING: Research findings or discovered facts\n    HYPOTHESIS: Proposed hypotheses or theories\n    EVIDENCE: Supporting evidence for hypotheses\n    CONCLUSION: Final conclusions from investigation\n    QUESTION: Open questions requiring investigation\n    REFERENCE: References to external sources or context\n    PERSONA_NOTE: Persona-specific observations or notes",
      "bases": [
        "str",
        "Enum"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "get",
          "file": "model_chorus/src/model_chorus/workflows/study/memory/persistence.py",
          "line": 313,
          "context": [
            "LongTermStorage",
            "get"
          ]
        },
        {
          "instantiator": "query",
          "file": "model_chorus/src/model_chorus/workflows/study/memory/persistence.py",
          "line": 418,
          "context": [
            "LongTermStorage",
            "query"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 2
    },
    {
      "name": "MemoryEntry",
      "file": "model_chorus/src/model_chorus/workflows/study/memory/models.py",
      "line": 41,
      "language": "python",
      "docstring": "Single memory entry in the investigation memory system.\n\nA memory entry captures a discrete piece of information from the investigation,\nincluding what was learned, who learned it (persona), when it was learned,\nand how confident they are in the finding.\n\nMemory entries are created during investigation steps and can reference other\nmemory entries to build a knowledge graph of the investigation.\n\nAttributes:\n    investigation_id: Unique identifier for the investigation\n    session_id: Unique identifier for the current investigation session\n    timestamp: ISO format timestamp of when entry was created\n    persona: Persona identifier (e.g., 'researcher', 'critic', 'planner')\n    findings: The main content/finding of this memory entry\n    evidence: Supporting evidence or context for the finding\n    confidence_before: Confidence level before this investigation step\n    confidence_after: Confidence level after this investigation step\n    memory_references: List of memory entry IDs referenced/related to this one\n    memory_type: Type of memory entry for categorization\n    metadata: Additional metadata (sources, tags, importance score, etc.)",
      "bases": [
        "BaseModel"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "store",
          "file": "model_chorus/src/model_chorus/workflows/study/memory/controller.py",
          "line": 153,
          "context": [
            "MemoryController",
            "store"
          ]
        },
        {
          "instantiator": "get",
          "file": "model_chorus/src/model_chorus/workflows/study/memory/persistence.py",
          "line": 304,
          "context": [
            "LongTermStorage",
            "get"
          ]
        },
        {
          "instantiator": "query",
          "file": "model_chorus/src/model_chorus/workflows/study/memory/persistence.py",
          "line": 409,
          "context": [
            "LongTermStorage",
            "query"
          ]
        },
        {
          "instantiator": "test_save_and_retrieve",
          "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
          "line": 44,
          "context": [
            "test_save_and_retrieve"
          ]
        },
        {
          "instantiator": "test_persistence_across_sessions",
          "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
          "line": 73,
          "context": [
            "test_persistence_across_sessions"
          ]
        },
        {
          "instantiator": "test_query_by_investigation",
          "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
          "line": 102,
          "context": [
            "test_query_by_investigation"
          ]
        },
        {
          "instantiator": "test_query_by_persona",
          "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
          "line": 124,
          "context": [
            "test_query_by_persona"
          ]
        },
        {
          "instantiator": "test_delete",
          "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
          "line": 142,
          "context": [
            "test_delete"
          ]
        },
        {
          "instantiator": "test_memory_references",
          "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
          "line": 169,
          "context": [
            "test_memory_references"
          ]
        },
        {
          "instantiator": "test_get_metadata",
          "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
          "line": 192,
          "context": [
            "test_get_metadata"
          ]
        },
        {
          "instantiator": "test_lru_eviction",
          "file": "tests/workflows/study/memory/test_cache.py",
          "line": 28,
          "context": [
            "test_lru_eviction"
          ]
        },
        {
          "instantiator": "test_lru_eviction",
          "file": "tests/workflows/study/memory/test_cache.py",
          "line": 42,
          "context": [
            "test_lru_eviction"
          ]
        },
        {
          "instantiator": "test_cache_metrics_hits_and_misses",
          "file": "tests/workflows/study/memory/test_cache.py",
          "line": 64,
          "context": [
            "test_cache_metrics_hits_and_misses"
          ]
        },
        {
          "instantiator": "test_cache_eviction_metric",
          "file": "tests/workflows/study/memory/test_cache.py",
          "line": 89,
          "context": [
            "test_cache_eviction_metric"
          ]
        },
        {
          "instantiator": "test_cache_update_existing",
          "file": "tests/workflows/study/memory/test_cache.py",
          "line": 105,
          "context": [
            "test_cache_update_existing"
          ]
        },
        {
          "instantiator": "test_cache_update_existing",
          "file": "tests/workflows/study/memory/test_cache.py",
          "line": 114,
          "context": [
            "test_cache_update_existing"
          ]
        },
        {
          "instantiator": "test_cache_delete",
          "file": "tests/workflows/study/memory/test_cache.py",
          "line": 132,
          "context": [
            "test_cache_delete"
          ]
        },
        {
          "instantiator": "test_cache_query",
          "file": "tests/workflows/study/memory/test_cache.py",
          "line": 162,
          "context": [
            "test_cache_query"
          ]
        },
        {
          "instantiator": "test_cache_clear",
          "file": "tests/workflows/study/memory/test_cache.py",
          "line": 190,
          "context": [
            "test_cache_clear"
          ]
        },
        {
          "instantiator": "test_cache_metadata",
          "file": "tests/workflows/study/memory/test_cache.py",
          "line": 210,
          "context": [
            "test_cache_metadata"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 20
    },
    {
      "name": "MemoryMetadata",
      "file": "model_chorus/src/model_chorus/workflows/study/memory/models.py",
      "line": 148,
      "language": "python",
      "docstring": "Metadata for memory operations and statistics.\n\nTracks information about memory system usage, performance,\nand health metrics for monitoring and optimization.\n\nAttributes:\n    total_entries: Total number of memory entries stored\n    cache_entries: Number of entries currently in cache\n    persisted_entries: Number of entries persisted to long-term storage\n    investigation_count: Number of distinct investigations tracked\n    last_cleanup: ISO timestamp of last cleanup/pruning operation\n    cache_hit_rate: Percentage of cache hits vs misses\n    avg_retrieval_time_ms: Average retrieval time in milliseconds\n    storage_size_bytes: Total storage size in bytes (for persistence layer)",
      "bases": [
        "BaseModel"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "get_metadata",
          "file": "model_chorus/src/model_chorus/workflows/study/memory/cache.py",
          "line": 297,
          "context": [
            "ShortTermCache",
            "get_metadata"
          ]
        },
        {
          "instantiator": "get_metadata",
          "file": "model_chorus/src/model_chorus/workflows/study/memory/controller.py",
          "line": 366,
          "context": [
            "MemoryController",
            "get_metadata"
          ]
        },
        {
          "instantiator": "get_metadata",
          "file": "model_chorus/src/model_chorus/workflows/study/memory/persistence.py",
          "line": 496,
          "context": [
            "LongTermStorage",
            "get_metadata"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 3
    },
    {
      "name": "MemoryQuery",
      "file": "model_chorus/src/model_chorus/workflows/study/memory/models.py",
      "line": 230,
      "language": "python",
      "docstring": "Query model for searching and filtering memory entries.\n\nSupports flexible filtering across multiple dimensions to retrieve\nrelevant memory entries from cache or persistence storage.\n\nAttributes:\n    investigation_id: Filter by specific investigation ID\n    persona: Filter by persona identifier\n    confidence_level: Filter by minimum confidence level\n    time_range_start: Filter by start time (ISO format)\n    time_range_end: Filter by end time (ISO format)\n    memory_type: Filter by memory entry type\n    limit: Maximum number of results to return\n    offset: Number of results to skip (for pagination)\n    sort_by: Field to sort by (timestamp, confidence_after, etc.)\n    sort_order: Sort order (asc or desc)",
      "bases": [
        "BaseModel"
      ],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "query",
          "file": "model_chorus/src/model_chorus/workflows/study/memory/controller.py",
          "line": 234,
          "context": [
            "MemoryController",
            "query"
          ]
        },
        {
          "instantiator": "test_query_by_investigation",
          "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
          "line": 111,
          "context": [
            "test_query_by_investigation"
          ]
        },
        {
          "instantiator": "test_query_by_persona",
          "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
          "line": 133,
          "context": [
            "test_query_by_persona"
          ]
        },
        {
          "instantiator": "test_cache_query",
          "file": "tests/workflows/study/memory/test_cache.py",
          "line": 171,
          "context": [
            "test_cache_query"
          ]
        },
        {
          "instantiator": "test_cache_query",
          "file": "tests/workflows/study/memory/test_cache.py",
          "line": 175,
          "context": [
            "test_cache_query"
          ]
        },
        {
          "instantiator": "test_cache_query",
          "file": "tests/workflows/study/memory/test_cache.py",
          "line": 180,
          "context": [
            "test_cache_query"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 6
    },
    {
      "name": "LongTermStorage",
      "file": "model_chorus/src/model_chorus/workflows/study/memory/persistence.py",
      "line": 28,
      "language": "python",
      "docstring": "SQLite-based persistent storage for memory entries.\n\nProvides durable storage for investigation memory entries with support\nfor complex queries, historical analysis, and cross-investigation retrieval.\n\nDatabase Schema:\n    investigations: Track investigation metadata\n        - investigation_id (PK): Unique investigation identifier\n        - created_at: Investigation start timestamp\n        - completed_at: Investigation completion timestamp\n        - persona_count: Number of personas involved\n        - entry_count: Number of memory entries\n        - metadata_json: Additional investigation metadata\n\n    memory_entries: Store individual memory entries\n        - id (PK): Auto-incrementing entry ID\n        - entry_id: Unique entry identifier (for external reference)\n        - investigation_id (FK): Link to investigations table\n        - session_id: Session identifier\n        - timestamp: Entry creation timestamp\n        - persona: Persona identifier\n        - findings: Main content/findings\n        - evidence: Supporting evidence\n        - confidence_before: Confidence before this step\n        - confidence_after: Confidence after this step\n        - memory_type: Type of memory entry\n        - metadata_json: Additional entry metadata\n\n    memory_references: Track relationships between entries\n        - id (PK): Auto-incrementing reference ID\n        - source_entry_id: Entry making the reference\n        - target_entry_id: Entry being referenced\n        - created_at: Reference creation timestamp\n\nThread Safety:\n    SQLite connections are not shared across threads. Each operation\n    creates a new connection which is automatically closed.\n\nExample:\n    >>> storage = LongTermStorage(\"investigations.db\")\n    >>> storage.initialize()\n    >>> storage.save(entry_id, memory_entry)\n    >>> results = storage.query(MemoryQuery(persona=\"researcher\"))\n    >>> storage.close()",
      "bases": [],
      "methods": [
        "__init__",
        "initialize",
        "save",
        "get",
        "query",
        "delete",
        "get_metadata",
        "close",
        "_get_connection"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "__init__",
          "file": "model_chorus/src/model_chorus/workflows/study/memory/controller.py",
          "line": 89,
          "context": [
            "MemoryController",
            "__init__"
          ]
        },
        {
          "instantiator": "storage",
          "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
          "line": 35,
          "context": [
            "storage"
          ]
        },
        {
          "instantiator": "test_persistence_across_sessions",
          "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
          "line": 81,
          "context": [
            "test_persistence_across_sessions"
          ]
        },
        {
          "instantiator": "test_persistence_across_sessions",
          "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
          "line": 87,
          "context": [
            "test_persistence_across_sessions"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 4
    },
    {
      "name": "PersonaResponse",
      "file": "model_chorus/src/model_chorus/workflows/study/persona_base.py",
      "line": 13,
      "language": "python",
      "docstring": "Response from a persona invocation.\n\nContains the persona's findings and any confidence level updates\nbased on the investigation.\n\nAttributes:\n    findings: List of findings or insights from the persona\n    confidence_update: Optional confidence level change based on findings\n    metadata: Additional response metadata",
      "bases": [],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "invoke",
          "file": "model_chorus/src/model_chorus/workflows/study/persona_base.py",
          "line": 70,
          "context": [
            "Persona",
            "invoke"
          ]
        },
        {
          "instantiator": "invoke",
          "file": "model_chorus/src/model_chorus/workflows/study/personas/critic.py",
          "line": 110,
          "context": [
            "CriticPersona",
            "invoke"
          ]
        },
        {
          "instantiator": "invoke",
          "file": "model_chorus/src/model_chorus/workflows/study/personas/planner.py",
          "line": 111,
          "context": [
            "PlannerPersona",
            "invoke"
          ]
        },
        {
          "instantiator": "invoke",
          "file": "model_chorus/src/model_chorus/workflows/study/personas/researcher.py",
          "line": 102,
          "context": [
            "ResearcherPersona",
            "invoke"
          ]
        },
        {
          "instantiator": "test_persona_response_init",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 35,
          "context": [
            "TestPersonaResponse",
            "test_persona_response_init"
          ]
        },
        {
          "instantiator": "test_persona_response_with_findings",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 44,
          "context": [
            "TestPersonaResponse",
            "test_persona_response_with_findings"
          ]
        },
        {
          "instantiator": "test_persona_response_with_confidence_update",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 51,
          "context": [
            "TestPersonaResponse",
            "test_persona_response_with_confidence_update"
          ]
        },
        {
          "instantiator": "test_persona_response_with_metadata",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 58,
          "context": [
            "TestPersonaResponse",
            "test_persona_response_with_metadata"
          ]
        },
        {
          "instantiator": "test_persona_response_full_initialization",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 69,
          "context": [
            "TestPersonaResponse",
            "test_persona_response_full_initialization"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 9
    },
    {
      "name": "Persona",
      "file": "model_chorus/src/model_chorus/workflows/study/persona_base.py",
      "line": 32,
      "language": "python",
      "docstring": "Represents a persona in the STUDY workflow.\n\nA persona is a specialized investigator with specific expertise and\ncharacteristics that guide its contributions to the research process.\n\nAttributes:\n    name: The persona's name (e.g., \"Researcher\", \"Critic\")\n    prompt_template: Template for prompting this persona\n    temperature: Temperature setting for generation (controls randomness)\n    max_tokens: Maximum tokens in persona's responses",
      "bases": [],
      "methods": [
        "invoke"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "test_persona_init",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 85,
          "context": [
            "TestPersona",
            "test_persona_init"
          ]
        },
        {
          "instantiator": "test_persona_init_custom_temperature",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 97,
          "context": [
            "TestPersona",
            "test_persona_init_custom_temperature"
          ]
        },
        {
          "instantiator": "test_persona_init_custom_max_tokens",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 107,
          "context": [
            "TestPersona",
            "test_persona_init_custom_max_tokens"
          ]
        },
        {
          "instantiator": "test_persona_invoke_returns_response",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 117,
          "context": [
            "TestPersona",
            "test_persona_invoke_returns_response"
          ]
        },
        {
          "instantiator": "test_persona_invoke_with_context",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 128,
          "context": [
            "TestPersona",
            "test_persona_invoke_with_context"
          ]
        },
        {
          "instantiator": "test_persona_invoke_includes_metadata",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 141,
          "context": [
            "TestPersona",
            "test_persona_invoke_includes_metadata"
          ]
        },
        {
          "instantiator": "test_registry_register_persona",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 164,
          "context": [
            "TestPersonaRegistry",
            "test_registry_register_persona"
          ]
        },
        {
          "instantiator": "test_registry_register_multiple_personas",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 177,
          "context": [
            "TestPersonaRegistry",
            "test_registry_register_multiple_personas"
          ]
        },
        {
          "instantiator": "test_registry_register_multiple_personas",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 178,
          "context": [
            "TestPersonaRegistry",
            "test_registry_register_multiple_personas"
          ]
        },
        {
          "instantiator": "test_registry_register_multiple_personas",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 179,
          "context": [
            "TestPersonaRegistry",
            "test_registry_register_multiple_personas"
          ]
        },
        {
          "instantiator": "test_registry_register_duplicate_raises_error",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 190,
          "context": [
            "TestPersonaRegistry",
            "test_registry_register_duplicate_raises_error"
          ]
        },
        {
          "instantiator": "test_registry_register_duplicate_raises_error",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 191,
          "context": [
            "TestPersonaRegistry",
            "test_registry_register_duplicate_raises_error"
          ]
        },
        {
          "instantiator": "test_registry_get_persona",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 201,
          "context": [
            "TestPersonaRegistry",
            "test_registry_get_persona"
          ]
        },
        {
          "instantiator": "test_registry_list_all",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 222,
          "context": [
            "TestPersonaRegistry",
            "test_registry_list_all"
          ]
        },
        {
          "instantiator": "test_registry_list_all",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 223,
          "context": [
            "TestPersonaRegistry",
            "test_registry_list_all"
          ]
        },
        {
          "instantiator": "test_persona_max_tokens_configuration",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 604,
          "context": [
            "TestPersonaIntegration",
            "test_persona_max_tokens_configuration"
          ]
        },
        {
          "instantiator": "test_persona_max_tokens_configuration",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 609,
          "context": [
            "TestPersonaIntegration",
            "test_persona_max_tokens_configuration"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 17
    },
    {
      "name": "PersonaRegistry",
      "file": "model_chorus/src/model_chorus/workflows/study/persona_base.py",
      "line": 77,
      "language": "python",
      "docstring": "Registry for managing available personas in the STUDY workflow.\n\nProvides centralized management of persona definitions, allowing\nregistration, retrieval, and listing of available personas.",
      "bases": [],
      "methods": [
        "__init__",
        "register",
        "get",
        "list_all"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "get_default_registry",
          "file": "model_chorus/src/model_chorus/workflows/study/personas/__init__.py",
          "line": 46,
          "context": [
            "get_default_registry"
          ]
        },
        {
          "instantiator": "test_registry_init",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 157,
          "context": [
            "TestPersonaRegistry",
            "test_registry_init"
          ]
        },
        {
          "instantiator": "test_registry_register_persona",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 163,
          "context": [
            "TestPersonaRegistry",
            "test_registry_register_persona"
          ]
        },
        {
          "instantiator": "test_registry_register_multiple_personas",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 175,
          "context": [
            "TestPersonaRegistry",
            "test_registry_register_multiple_personas"
          ]
        },
        {
          "instantiator": "test_registry_register_duplicate_raises_error",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 189,
          "context": [
            "TestPersonaRegistry",
            "test_registry_register_duplicate_raises_error"
          ]
        },
        {
          "instantiator": "test_registry_get_persona",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 200,
          "context": [
            "TestPersonaRegistry",
            "test_registry_get_persona"
          ]
        },
        {
          "instantiator": "test_registry_get_nonexistent_persona",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 212,
          "context": [
            "TestPersonaRegistry",
            "test_registry_get_nonexistent_persona"
          ]
        },
        {
          "instantiator": "test_registry_list_all",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 220,
          "context": [
            "TestPersonaRegistry",
            "test_registry_list_all"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 8
    },
    {
      "name": "RoutingDecision",
      "file": "model_chorus/src/model_chorus/workflows/study/persona_router.py",
      "line": 21,
      "language": "python",
      "docstring": "Result of persona routing decision.\n\nContains the selected persona instance, reasoning for selection,\nand guidance for the persona invocation.\n\nAttributes:\n    persona: The Persona instance to consult next (None if investigation complete)\n    persona_name: Name of the selected persona\n    reasoning: Explanation for why this persona was selected\n    confidence: Current confidence level from investigation state\n    guidance: Specific guidance or focus areas for the persona\n    context_summary: Summary of the investigation context\n    metadata: Additional routing metadata\n    timestamp: When this routing decision was made (ISO format)",
      "bases": [],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "route_next_persona",
          "file": "model_chorus/src/model_chorus/workflows/study/persona_router.py",
          "line": 302,
          "context": [
            "PersonaRouter",
            "route_next_persona"
          ]
        },
        {
          "instantiator": "route_next_persona",
          "file": "model_chorus/src/model_chorus/workflows/study/persona_router.py",
          "line": 326,
          "context": [
            "PersonaRouter",
            "route_next_persona"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 2
    },
    {
      "name": "RoutingHistoryEntry",
      "file": "model_chorus/src/model_chorus/workflows/study/persona_router.py",
      "line": 50,
      "language": "python",
      "docstring": "Historical record of a routing decision.\n\nTracks routing decisions over time for analysis and debugging.\n\nAttributes:\n    timestamp: When the routing decision was made (ISO format)\n    investigation_id: Investigation this routing was for\n    phase: Investigation phase at time of routing\n    confidence: Confidence level at time of routing\n    findings_count: Number of findings at time of routing\n    questions_count: Number of unresolved questions\n    prior_persona: Previously consulted persona (if any)\n    selected_persona: Persona selected by routing decision\n    reasoning: Reasoning for the selection\n    context_summary: Summary of investigation context",
      "bases": [],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "route_next_persona",
          "file": "model_chorus/src/model_chorus/workflows/study/persona_router.py",
          "line": 337,
          "context": [
            "PersonaRouter",
            "route_next_persona"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 1
    },
    {
      "name": "PersonaRouter",
      "file": "model_chorus/src/model_chorus/workflows/study/persona_router.py",
      "line": 81,
      "language": "python",
      "docstring": "Router for determining which persona to consult next in Study workflow.\n\nUses context analysis skill to intelligently route to appropriate personas\nbased on investigation phase, confidence level, findings, and prior consultations.\n\nThe router integrates the context analysis logic with the persona registry,\nproviding a complete routing solution from state analysis to persona retrieval.\n\nAttributes:\n    registry: PersonaRegistry containing available personas\n    routing_history: List of historical routing decisions for analysis",
      "bases": [],
      "methods": [
        "__init__",
        "_get_fallback_persona",
        "route_next_persona",
        "get_available_personas",
        "get_routing_history",
        "clear_routing_history"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "__init__",
          "file": "model_chorus/src/model_chorus/workflows/study/study_workflow.py",
          "line": 131,
          "context": [
            "StudyWorkflow",
            "__init__"
          ]
        },
        {
          "instantiator": "test_routing_skill_invocation",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 26,
          "context": [
            "TestRoutingSkillInvocation",
            "test_routing_skill_invocation"
          ]
        },
        {
          "instantiator": "test_routing_different_phases",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 74,
          "context": [
            "TestRoutingSkillInvocation",
            "test_routing_different_phases"
          ]
        },
        {
          "instantiator": "test_routing_with_findings",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 102,
          "context": [
            "TestRoutingSkillInvocation",
            "test_routing_with_findings"
          ]
        },
        {
          "instantiator": "test_routing_complete_phase",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 131,
          "context": [
            "TestRoutingSkillInvocation",
            "test_routing_complete_phase"
          ]
        },
        {
          "instantiator": "test_fallback_routing_on_exception",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 157,
          "context": [
            "TestFallbackRouting",
            "test_fallback_routing_on_exception"
          ]
        },
        {
          "instantiator": "test_fallback_for_all_phases",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 192,
          "context": [
            "TestFallbackRouting",
            "test_fallback_for_all_phases"
          ]
        },
        {
          "instantiator": "test_fallback_provides_valid_guidance",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 224,
          "context": [
            "TestFallbackRouting",
            "test_fallback_provides_valid_guidance"
          ]
        },
        {
          "instantiator": "test_routing_history_recorded",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 255,
          "context": [
            "TestRoutingHistory",
            "test_routing_history_recorded"
          ]
        },
        {
          "instantiator": "test_routing_history_filtering",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 281,
          "context": [
            "TestRoutingHistory",
            "test_routing_history_filtering"
          ]
        },
        {
          "instantiator": "test_routing_history_limit",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 304,
          "context": [
            "TestRoutingHistory",
            "test_routing_history_limit"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 11
    },
    {
      "name": "CriticPersona",
      "file": "model_chorus/src/model_chorus/workflows/study/personas/critic.py",
      "line": 12,
      "language": "python",
      "docstring": "Critic persona with challenge and stress-test focus.\n\nThis persona specializes in:\n- Challenging assumptions and identifying biases\n- Finding edge cases and potential problems\n- Stress-testing conclusions and hypotheses\n- Identifying gaps in reasoning\n- Providing constructive skepticism\n\nThe Critic persona approaches investigations with healthy skepticism,\nseeking to strengthen findings by identifying weaknesses and alternatives.",
      "bases": [
        "Persona"
      ],
      "methods": [
        "__init__",
        "invoke"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "create_critic",
          "file": "model_chorus/src/model_chorus/workflows/study/personas/critic.py",
          "line": 134,
          "context": [
            "create_critic"
          ]
        },
        {
          "instantiator": "test_critic_init",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 342,
          "context": [
            "TestCriticPersona",
            "test_critic_init"
          ]
        },
        {
          "instantiator": "test_critic_init_custom_temperature",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 350,
          "context": [
            "TestCriticPersona",
            "test_critic_init_custom_temperature"
          ]
        },
        {
          "instantiator": "test_critic_prompt_template",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 356,
          "context": [
            "TestCriticPersona",
            "test_critic_prompt_template"
          ]
        },
        {
          "instantiator": "test_critic_invoke_returns_response",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 364,
          "context": [
            "TestCriticPersona",
            "test_critic_invoke_returns_response"
          ]
        },
        {
          "instantiator": "test_critic_invoke_includes_findings",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 373,
          "context": [
            "TestCriticPersona",
            "test_critic_invoke_includes_findings"
          ]
        },
        {
          "instantiator": "test_critic_invoke_metadata",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 384,
          "context": [
            "TestCriticPersona",
            "test_critic_invoke_metadata"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 7
    },
    {
      "name": "PlannerPersona",
      "file": "model_chorus/src/model_chorus/workflows/study/personas/planner.py",
      "line": 12,
      "language": "python",
      "docstring": "Planner persona with actionable roadmap focus.\n\nThis persona specializes in:\n- Synthesizing findings into coherent plans\n- Defining actionable next steps\n- Creating structured roadmaps\n- Prioritizing actions and recommendations\n- Translating insights into practical outcomes\n\nThe Planner persona approaches investigations with a solution-oriented mindset,\nfocusing on turning knowledge into actionable strategies.",
      "bases": [
        "Persona"
      ],
      "methods": [
        "__init__",
        "invoke"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "create_planner",
          "file": "model_chorus/src/model_chorus/workflows/study/personas/planner.py",
          "line": 135,
          "context": [
            "create_planner"
          ]
        },
        {
          "instantiator": "test_planner_init",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 412,
          "context": [
            "TestPlannerPersona",
            "test_planner_init"
          ]
        },
        {
          "instantiator": "test_planner_init_custom_temperature",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 420,
          "context": [
            "TestPlannerPersona",
            "test_planner_init_custom_temperature"
          ]
        },
        {
          "instantiator": "test_planner_prompt_template",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 426,
          "context": [
            "TestPlannerPersona",
            "test_planner_prompt_template"
          ]
        },
        {
          "instantiator": "test_planner_invoke_returns_response",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 433,
          "context": [
            "TestPlannerPersona",
            "test_planner_invoke_returns_response"
          ]
        },
        {
          "instantiator": "test_planner_invoke_includes_findings",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 442,
          "context": [
            "TestPlannerPersona",
            "test_planner_invoke_includes_findings"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 6
    },
    {
      "name": "ResearcherPersona",
      "file": "model_chorus/src/model_chorus/workflows/study/personas/researcher.py",
      "line": 12,
      "language": "python",
      "docstring": "Researcher persona with deep analysis focus.\n\nThis persona specializes in:\n- Systematic investigation and methodical exploration\n- Deep dive analysis of complex topics\n- Identifying patterns and connections\n- Building comprehensive understanding\n- Evidence-based reasoning\n\nThe Researcher persona approaches investigations with rigor and thoroughness,\nseeking to uncover underlying principles and detailed insights.",
      "bases": [
        "Persona"
      ],
      "methods": [
        "__init__",
        "invoke"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "create_researcher",
          "file": "model_chorus/src/model_chorus/workflows/study/personas/researcher.py",
          "line": 125,
          "context": [
            "create_researcher"
          ]
        },
        {
          "instantiator": "test_researcher_init",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 241,
          "context": [
            "TestResearcherPersona",
            "test_researcher_init"
          ]
        },
        {
          "instantiator": "test_researcher_init_custom_temperature",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 249,
          "context": [
            "TestResearcherPersona",
            "test_researcher_init_custom_temperature"
          ]
        },
        {
          "instantiator": "test_researcher_prompt_template",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 255,
          "context": [
            "TestResearcherPersona",
            "test_researcher_prompt_template"
          ]
        },
        {
          "instantiator": "test_researcher_invoke_returns_response",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 263,
          "context": [
            "TestResearcherPersona",
            "test_researcher_invoke_returns_response"
          ]
        },
        {
          "instantiator": "test_researcher_invoke_includes_findings",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 272,
          "context": [
            "TestResearcherPersona",
            "test_researcher_invoke_includes_findings"
          ]
        },
        {
          "instantiator": "test_researcher_invoke_discovery_phase",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 283,
          "context": [
            "TestResearcherPersona",
            "test_researcher_invoke_discovery_phase"
          ]
        },
        {
          "instantiator": "test_researcher_invoke_validation_phase",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 292,
          "context": [
            "TestResearcherPersona",
            "test_researcher_invoke_validation_phase"
          ]
        },
        {
          "instantiator": "test_researcher_invoke_metadata",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 301,
          "context": [
            "TestResearcherPersona",
            "test_researcher_invoke_metadata"
          ]
        },
        {
          "instantiator": "test_researcher_invoke_includes_prompt_in_findings",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 313,
          "context": [
            "TestResearcherPersona",
            "test_researcher_invoke_includes_prompt_in_findings"
          ]
        },
        {
          "instantiator": "test_persona_temperature_affects_generation",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 595,
          "context": [
            "TestPersonaIntegration",
            "test_persona_temperature_affects_generation"
          ]
        },
        {
          "instantiator": "test_persona_temperature_affects_generation",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 596,
          "context": [
            "TestPersonaIntegration",
            "test_persona_temperature_affects_generation"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 12
    },
    {
      "name": "InvestigationStateMachine",
      "file": "model_chorus/src/model_chorus/workflows/study/state_machine.py",
      "line": 17,
      "language": "python",
      "docstring": "State machine for managing investigation phase transitions.\n\nEnforces valid phase transitions and provides methods for checking\ntransition validity and progressing through investigation phases.\n\nValid transitions:\n    DISCOVERY \u2192 VALIDATION\n    VALIDATION \u2192 PLANNING or VALIDATION \u2192 DISCOVERY (if more discovery needed)\n    PLANNING \u2192 COMPLETE or PLANNING \u2192 DISCOVERY (if gaps found)\n    COMPLETE \u2192 (terminal state)\n\nAttributes:\n    current_phase: Current investigation phase\n    state: StudyState instance being managed",
      "bases": [],
      "methods": [
        "__init__",
        "can_transition",
        "transition",
        "get_next_phase",
        "get_valid_transitions",
        "is_terminal",
        "advance_to_next",
        "reset_to_discovery",
        "update_confidence",
        "should_escalate_phase",
        "get_confidence_threshold"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "state_machine",
          "file": "model_chorus/tests/workflows/study/test_state_machine.py",
          "line": 33,
          "context": [
            "TestInvestigationStateMachineTransitions",
            "state_machine"
          ]
        },
        {
          "instantiator": "state_machine",
          "file": "model_chorus/tests/workflows/study/test_state_machine.py",
          "line": 278,
          "context": [
            "TestConfidenceLevelProgression",
            "state_machine"
          ]
        },
        {
          "instantiator": "state_machine",
          "file": "model_chorus/tests/workflows/study/test_state_machine.py",
          "line": 388,
          "context": [
            "TestStateTransitionIntegration",
            "state_machine"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 3
    },
    {
      "name": "StudyWorkflow",
      "file": "model_chorus/src/model_chorus/workflows/study/study_workflow.py",
      "line": 32,
      "language": "python",
      "docstring": "Persona-based collaborative research workflow.\n\nThis workflow implements systematic investigation through multiple personas\nwith distinct expertise, enabling collaborative exploration of complex topics\nthrough role-based orchestration and conversation threading.\n\nArchitecture:\n- Multi-persona role orchestration with intelligent routing\n- PersonaRouter for context-aware persona selection\n- Conversation threading and memory\n- Systematic hypothesis exploration\n- Persona-specific expertise and perspectives\n\nKey Features:\n- Intelligent persona routing based on investigation phase and context\n- Fallback routing for graceful error handling\n- Role-based investigation with distinct personas\n- Conversation threading for multi-turn exploration\n- Systematic knowledge building\n- Collaborative analysis and synthesis\n- Inherits conversation support from BaseWorkflow\n\nThe StudyWorkflow is ideal for:\n- Complex topic exploration requiring multiple perspectives\n- Research investigations with specialized knowledge domains\n- Collaborative problem analysis\n- Systematic learning and knowledge building\n- Multi-faceted topic investigation\n\nWorkflow Pattern:\n1. **Persona Assignment**: Intelligently route to appropriate persona via PersonaRouter\n2. **Collaborative Exploration**: Personas investigate from their perspectives\n3. **Synthesis**: Combine insights into comprehensive understanding\n\nAttributes:\n    provider: Primary ModelProvider for persona invocations\n    fallback_providers: Optional fallback providers\n    persona_router: PersonaRouter instance for intelligent persona selection\n\nExample:\n    >>> from model_chorus.providers import ClaudeProvider\n    >>> from model_chorus.workflows.study import StudyWorkflow\n    >>> from model_chorus.core.conversation import ConversationMemory\n    >>>\n    >>> # Create provider and conversation memory\n    >>> provider = ClaudeProvider()\n    >>> memory = ConversationMemory()\n    >>>\n    >>> # Create workflow\n    >>> workflow = StudyWorkflow(provider, conversation_memory=memory)\n    >>>\n    >>> # Conduct research\n    >>> result = await workflow.run(\n    ...     \"Explore the implementation patterns of authentication systems\"\n    ... )\n    >>> print(result.synthesis)\n    >>>\n    >>> # Continue investigation\n    >>> result2 = await workflow.run(\n    ...     \"Dive deeper into OAuth 2.0 flow patterns\",\n    ...     continuation_id=result.metadata.get('thread_id')\n    ... )",
      "bases": [
        "BaseWorkflow"
      ],
      "methods": [
        "__init__",
        "run",
        "_setup_personas",
        "_conduct_investigation",
        "_synthesize_findings",
        "get_routing_history"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "start",
          "file": "model_chorus/src/model_chorus/cli/study_commands.py",
          "line": 247,
          "context": [
            "start"
          ]
        },
        {
          "instantiator": "study_next",
          "file": "model_chorus/src/model_chorus/cli/study_commands.py",
          "line": 495,
          "context": [
            "study_next"
          ]
        },
        {
          "instantiator": "test_workflow_has_router",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 336,
          "context": [
            "TestStudyWorkflowIntegration",
            "test_workflow_has_router"
          ]
        },
        {
          "instantiator": "test_workflow_routing_history_access",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 363,
          "context": [
            "TestStudyWorkflowIntegration",
            "test_workflow_routing_history_access"
          ]
        },
        {
          "instantiator": "test_init_with_provider",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 30,
          "context": [
            "TestStudyWorkflowInitialization",
            "test_init_with_provider"
          ]
        },
        {
          "instantiator": "test_init_with_fallback_providers",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 46,
          "context": [
            "TestStudyWorkflowInitialization",
            "test_init_with_fallback_providers"
          ]
        },
        {
          "instantiator": "test_init_provider_none_raises_error",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 56,
          "context": [
            "TestStudyWorkflowInitialization",
            "test_init_provider_none_raises_error"
          ]
        },
        {
          "instantiator": "test_init_with_conversation_memory",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 64,
          "context": [
            "TestStudyWorkflowInitialization",
            "test_init_with_conversation_memory"
          ]
        },
        {
          "instantiator": "test_init_persona_router_ready",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 73,
          "context": [
            "TestStudyWorkflowInitialization",
            "test_init_persona_router_ready"
          ]
        },
        {
          "instantiator": "test_init_with_config",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 86,
          "context": [
            "TestStudyWorkflowInitialization",
            "test_init_with_config"
          ]
        },
        {
          "instantiator": "workflow",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 104,
          "context": [
            "TestStudyWorkflowRun",
            "workflow"
          ]
        },
        {
          "instantiator": "workflow",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 239,
          "context": [
            "TestStudyWorkflowPersonaSetup",
            "workflow"
          ]
        },
        {
          "instantiator": "workflow_with_memory",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 305,
          "context": [
            "TestStudyWorkflowConversationHandling",
            "workflow_with_memory"
          ]
        },
        {
          "instantiator": "workflow_without_memory",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 310,
          "context": [
            "TestStudyWorkflowConversationHandling",
            "workflow_without_memory"
          ]
        },
        {
          "instantiator": "workflow",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 381,
          "context": [
            "TestStudyWorkflowInvestigation",
            "workflow"
          ]
        },
        {
          "instantiator": "workflow",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 460,
          "context": [
            "TestStudyWorkflowSynthesis",
            "workflow"
          ]
        },
        {
          "instantiator": "workflow",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 523,
          "context": [
            "TestStudyWorkflowErrorHandling",
            "workflow"
          ]
        },
        {
          "instantiator": "workflow",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 562,
          "context": [
            "TestStudyWorkflowRoutingHistory",
            "workflow"
          ]
        },
        {
          "instantiator": "workflow_with_memory",
          "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
          "line": 600,
          "context": [
            "TestStudyWorkflowIntegration",
            "workflow_with_memory"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 19
    },
    {
      "name": "ThinkDeepWorkflow",
      "file": "model_chorus/src/model_chorus/workflows/thinkdeep.py",
      "line": 28,
      "language": "python",
      "docstring": "Extended reasoning workflow with systematic investigation and hypothesis tracking.\n\nThis workflow provides multi-step investigation capabilities where hypotheses\nare formed, tested, and refined across conversation turns. It maintains state\nincluding hypothesis evolution, investigation steps, confidence levels, and\nrelevant files examined.\n\nKey features:\n- Single provider with extended reasoning\n- Hypothesis tracking and evolution\n- Investigation step progression\n- Confidence level tracking\n- File examination history\n- State persistence across turns via conversation threading\n\nThe ThinkDeepWorkflow is ideal for:\n- Complex problem analysis requiring systematic investigation\n- Debugging scenarios with hypothesis testing\n- Architecture decisions with evidence-based reasoning\n- Security analysis with confidence tracking\n- Any task requiring methodical, step-by-step investigation\n\nExample:\n    >>> from model_chorus.providers import ClaudeProvider\n    >>> from model_chorus.workflows import ThinkDeepWorkflow\n    >>> from model_chorus.core.conversation import ConversationMemory\n    >>>\n    >>> # Create provider and conversation memory\n    >>> provider = ClaudeProvider()\n    >>> memory = ConversationMemory()\n    >>>\n    >>> # Create workflow\n    >>> workflow = ThinkDeepWorkflow(provider, conversation_memory=memory)\n    >>>\n    >>> # First step (creates new investigation)\n    >>> result1 = await workflow.run(\n    ...     \"Why is authentication failing intermittently?\",\n    ...     files=[\"src/auth.py\", \"tests/test_auth.py\"]\n    ... )\n    >>> thread_id = result1.metadata.get('thread_id')\n    >>>\n    >>> # Follow-up investigation (continues thread with state)\n    >>> result2 = await workflow.run(\n    ...     \"Check if it's related to async/await patterns\",\n    ...     continuation_id=thread_id,\n    ...     files=[\"src/services/user.py\"]\n    ... )\n    >>>\n    >>> # Check investigation state\n    >>> state = workflow.get_investigation_state(thread_id)\n    >>> print(f\"Hypotheses: {len(state.hypotheses)}\")\n    >>> print(f\"Confidence: {state.current_confidence}\")",
      "bases": [
        "BaseWorkflow"
      ],
      "methods": [
        "__init__",
        "run",
        "_get_or_create_state",
        "_save_state",
        "_merge_file_lists",
        "_build_investigation_prompt",
        "_extract_findings",
        "_perform_expert_validation",
        "_build_expert_validation_prompt",
        "get_investigation_state",
        "add_hypothesis",
        "update_hypothesis",
        "validate_hypothesis",
        "disprove_hypothesis",
        "get_active_hypotheses",
        "get_all_hypotheses",
        "update_confidence",
        "get_confidence",
        "is_investigation_complete",
        "get_investigation_summary",
        "get_provider",
        "validate_config",
        "__repr__"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "basic_investigation_example",
          "file": "model_chorus/examples/thinkdeep_example.py",
          "line": 38,
          "context": [
            "basic_investigation_example"
          ]
        },
        {
          "instantiator": "multi_step_investigation_example",
          "file": "model_chorus/examples/thinkdeep_example.py",
          "line": 118,
          "context": [
            "multi_step_investigation_example"
          ]
        },
        {
          "instantiator": "investigation_with_expert_validation",
          "file": "model_chorus/examples/thinkdeep_example.py",
          "line": 237,
          "context": [
            "investigation_with_expert_validation"
          ]
        },
        {
          "instantiator": "hypothesis_management_example",
          "file": "model_chorus/examples/thinkdeep_example.py",
          "line": 289,
          "context": [
            "hypothesis_management_example"
          ]
        },
        {
          "instantiator": "confidence_progression_example",
          "file": "model_chorus/examples/thinkdeep_example.py",
          "line": 378,
          "context": [
            "confidence_progression_example"
          ]
        },
        {
          "instantiator": "thinkdeep",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1188,
          "context": [
            "thinkdeep"
          ]
        },
        {
          "instantiator": "thinkdeep_status",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1386,
          "context": [
            "thinkdeep_status"
          ]
        },
        {
          "instantiator": "test_mixed_workflow_concurrent_execution",
          "file": "tests/test_concurrent_conversations.py",
          "line": 265,
          "context": [
            "TestConcurrentConversationHandling",
            "test_mixed_workflow_concurrent_execution"
          ]
        },
        {
          "instantiator": "test_architectural_decision_rest_vs_graphql",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 56,
          "context": [
            "TestArchitecturalDecisionScenarios",
            "test_architectural_decision_rest_vs_graphql"
          ]
        },
        {
          "instantiator": "test_architectural_decision_database_selection",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 198,
          "context": [
            "TestArchitecturalDecisionScenarios",
            "test_architectural_decision_database_selection"
          ]
        },
        {
          "instantiator": "test_bug_investigation_api_slowness",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 280,
          "context": [
            "TestBugInvestigationScenarios",
            "test_bug_investigation_api_slowness"
          ]
        },
        {
          "instantiator": "test_bug_investigation_intermittent_crash",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 466,
          "context": [
            "TestBugInvestigationScenarios",
            "test_bug_investigation_intermittent_crash"
          ]
        },
        {
          "instantiator": "test_long_investigation_with_hypothesis_pivots",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 626,
          "context": [
            "TestComplexMultiStepReasoning",
            "test_long_investigation_with_hypothesis_pivots"
          ]
        },
        {
          "instantiator": "test_investigation_with_multiple_evidence_types",
          "file": "tests/test_thinkdeep_complex.py",
          "line": 733,
          "context": [
            "TestComplexMultiStepReasoning",
            "test_investigation_with_multiple_evidence_types"
          ]
        },
        {
          "instantiator": "test_expert_validation_enabled_with_expert_provider",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 57,
          "context": [
            "TestExpertProviderIntegration",
            "test_expert_validation_enabled_with_expert_provider"
          ]
        },
        {
          "instantiator": "test_expert_validation_disabled_without_expert_provider",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 73,
          "context": [
            "TestExpertProviderIntegration",
            "test_expert_validation_disabled_without_expert_provider"
          ]
        },
        {
          "instantiator": "test_expert_validation_explicit_disable_via_config",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 88,
          "context": [
            "TestExpertProviderIntegration",
            "test_expert_validation_explicit_disable_via_config"
          ]
        },
        {
          "instantiator": "test_expert_validation_explicit_enable_via_config",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 105,
          "context": [
            "TestExpertProviderIntegration",
            "test_expert_validation_explicit_enable_via_config"
          ]
        },
        {
          "instantiator": "test_expert_validation_triggered_at_medium_confidence",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 161,
          "context": [
            "TestExpertValidationTriggering",
            "test_expert_validation_triggered_at_medium_confidence"
          ]
        },
        {
          "instantiator": "test_expert_validation_not_triggered_at_exploring_confidence",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 202,
          "context": [
            "TestExpertValidationTriggering",
            "test_expert_validation_not_triggered_at_exploring_confidence"
          ]
        },
        {
          "instantiator": "test_expert_validation_triggered_at_high_confidence",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 248,
          "context": [
            "TestExpertValidationTriggering",
            "test_expert_validation_triggered_at_high_confidence"
          ]
        },
        {
          "instantiator": "test_expert_validation_not_triggered_when_disabled",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 289,
          "context": [
            "TestExpertValidationTriggering",
            "test_expert_validation_not_triggered_when_disabled"
          ]
        },
        {
          "instantiator": "test_expert_validation_result_included_in_metadata",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 359,
          "context": [
            "TestExpertValidationResultHandling",
            "test_expert_validation_result_included_in_metadata"
          ]
        },
        {
          "instantiator": "test_expert_validation_conversation_history_updated",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 403,
          "context": [
            "TestExpertValidationResultHandling",
            "test_expert_validation_conversation_history_updated"
          ]
        },
        {
          "instantiator": "test_expert_validation_failure_does_not_crash_investigation",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 469,
          "context": [
            "TestExpertValidationErrorHandling",
            "test_expert_validation_failure_does_not_crash_investigation"
          ]
        },
        {
          "instantiator": "test_expert_validation_timeout_handling",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 512,
          "context": [
            "TestExpertValidationErrorHandling",
            "test_expert_validation_timeout_handling"
          ]
        },
        {
          "instantiator": "test_expert_validation_with_empty_response",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 557,
          "context": [
            "TestExpertValidationErrorHandling",
            "test_expert_validation_with_empty_response"
          ]
        },
        {
          "instantiator": "test_expert_validation_validates_hypothesis",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 624,
          "context": [
            "TestExpertValidationWithHypotheses",
            "test_expert_validation_validates_hypothesis"
          ]
        },
        {
          "instantiator": "test_expert_validation_with_multiple_hypotheses",
          "file": "tests/test_thinkdeep_expert_validation.py",
          "line": 678,
          "context": [
            "TestExpertValidationWithHypotheses",
            "test_expert_validation_with_multiple_hypotheses"
          ]
        },
        {
          "instantiator": "test_single_investigation_step_execution",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 69,
          "context": [
            "TestInvestigationStepExecution",
            "test_single_investigation_step_execution"
          ]
        },
        {
          "instantiator": "test_investigation_step_creates_investigation_step_object",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 113,
          "context": [
            "TestInvestigationStepExecution",
            "test_investigation_step_creates_investigation_step_object"
          ]
        },
        {
          "instantiator": "test_multi_step_investigation_progression",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 145,
          "context": [
            "TestInvestigationStepExecution",
            "test_multi_step_investigation_progression"
          ]
        },
        {
          "instantiator": "test_investigation_step_tracks_files_checked",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 226,
          "context": [
            "TestInvestigationStepExecution",
            "test_investigation_step_tracks_files_checked"
          ]
        },
        {
          "instantiator": "test_relevant_files_merge_into_state_and_metadata",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 279,
          "context": [
            "TestInvestigationStepExecution",
            "test_relevant_files_merge_into_state_and_metadata"
          ]
        },
        {
          "instantiator": "test_investigation_step_with_no_files",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 351,
          "context": [
            "TestInvestigationStepExecution",
            "test_investigation_step_with_no_files"
          ]
        },
        {
          "instantiator": "test_investigation_step_confidence_tracking",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 378,
          "context": [
            "TestInvestigationStepExecution",
            "test_investigation_step_confidence_tracking"
          ]
        },
        {
          "instantiator": "test_investigation_step_with_hypothesis_integration",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 437,
          "context": [
            "TestInvestigationStepExecution",
            "test_investigation_step_with_hypothesis_integration"
          ]
        },
        {
          "instantiator": "test_investigation_step_findings_extraction",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 502,
          "context": [
            "TestInvestigationStepExecution",
            "test_investigation_step_findings_extraction"
          ]
        },
        {
          "instantiator": "test_investigation_step_with_expert_validation",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 546,
          "context": [
            "TestInvestigationStepExecution",
            "test_investigation_step_with_expert_validation"
          ]
        },
        {
          "instantiator": "test_investigation_step_metadata_completeness",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 591,
          "context": [
            "TestInvestigationStepExecution",
            "test_investigation_step_metadata_completeness"
          ]
        },
        {
          "instantiator": "test_investigation_step_error_handling",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 636,
          "context": [
            "TestInvestigationStepExecution",
            "test_investigation_step_error_handling"
          ]
        },
        {
          "instantiator": "test_empty_provider_response_reports_error",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 661,
          "context": [
            "TestInvestigationStepExecution",
            "test_empty_provider_response_reports_error"
          ]
        },
        {
          "instantiator": "test_investigation_without_conversation_memory",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 699,
          "context": [
            "TestInvestigationStepExecution",
            "test_investigation_without_conversation_memory"
          ]
        },
        {
          "instantiator": "test_add_hypothesis_to_investigation",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 744,
          "context": [
            "TestHypothesisEvolution",
            "test_add_hypothesis_to_investigation"
          ]
        },
        {
          "instantiator": "test_update_hypothesis_with_evidence",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 783,
          "context": [
            "TestHypothesisEvolution",
            "test_update_hypothesis_with_evidence"
          ]
        },
        {
          "instantiator": "test_validate_hypothesis",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 828,
          "context": [
            "TestHypothesisEvolution",
            "test_validate_hypothesis"
          ]
        },
        {
          "instantiator": "test_disprove_hypothesis",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 869,
          "context": [
            "TestHypothesisEvolution",
            "test_disprove_hypothesis"
          ]
        },
        {
          "instantiator": "test_multiple_hypothesis_evolution",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 910,
          "context": [
            "TestHypothesisEvolution",
            "test_multiple_hypothesis_evolution"
          ]
        },
        {
          "instantiator": "test_get_active_hypotheses",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 981,
          "context": [
            "TestHypothesisEvolution",
            "test_get_active_hypotheses"
          ]
        },
        {
          "instantiator": "test_get_all_hypotheses",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1020,
          "context": [
            "TestHypothesisEvolution",
            "test_get_all_hypotheses"
          ]
        },
        {
          "instantiator": "test_hypothesis_persistence_across_turns",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1052,
          "context": [
            "TestHypothesisEvolution",
            "test_hypothesis_persistence_across_turns"
          ]
        },
        {
          "instantiator": "test_hypothesis_update_with_status_change",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1137,
          "context": [
            "TestHypothesisEvolution",
            "test_hypothesis_update_with_status_change"
          ]
        },
        {
          "instantiator": "test_hypothesis_not_found_handling",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1181,
          "context": [
            "TestHypothesisEvolution",
            "test_hypothesis_not_found_handling"
          ]
        },
        {
          "instantiator": "test_hypothesis_metadata_tracking",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1227,
          "context": [
            "TestHypothesisEvolution",
            "test_hypothesis_metadata_tracking"
          ]
        },
        {
          "instantiator": "test_initial_confidence_level",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1281,
          "context": [
            "TestConfidenceProgression",
            "test_initial_confidence_level"
          ]
        },
        {
          "instantiator": "test_update_confidence_level",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1310,
          "context": [
            "TestConfidenceProgression",
            "test_update_confidence_level"
          ]
        },
        {
          "instantiator": "test_get_confidence_level",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1348,
          "context": [
            "TestConfidenceProgression",
            "test_get_confidence_level"
          ]
        },
        {
          "instantiator": "test_confidence_progression_across_steps",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1371,
          "context": [
            "TestConfidenceProgression",
            "test_confidence_progression_across_steps"
          ]
        },
        {
          "instantiator": "test_confidence_tracked_in_metadata",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1465,
          "context": [
            "TestConfidenceProgression",
            "test_confidence_tracked_in_metadata"
          ]
        },
        {
          "instantiator": "test_invalid_confidence_level_rejected",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1496,
          "context": [
            "TestConfidenceProgression",
            "test_invalid_confidence_level_rejected"
          ]
        },
        {
          "instantiator": "test_confidence_complete_progression",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1525,
          "context": [
            "TestConfidenceProgression",
            "test_confidence_complete_progression"
          ]
        },
        {
          "instantiator": "test_investigation_completion_criteria",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1573,
          "context": [
            "TestConfidenceProgression",
            "test_investigation_completion_criteria"
          ]
        },
        {
          "instantiator": "test_investigation_summary_includes_confidence",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1617,
          "context": [
            "TestConfidenceProgression",
            "test_investigation_summary_includes_confidence"
          ]
        },
        {
          "instantiator": "test_confidence_cannot_decrease",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1653,
          "context": [
            "TestConfidenceProgression",
            "test_confidence_cannot_decrease"
          ]
        },
        {
          "instantiator": "test_confidence_persistence_across_turns",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1679,
          "context": [
            "TestConfidenceProgression",
            "test_confidence_persistence_across_turns"
          ]
        },
        {
          "instantiator": "test_five_step_investigation_with_hypothesis_evolution",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1760,
          "context": [
            "TestEndToEndIntegration",
            "test_five_step_investigation_with_hypothesis_evolution"
          ]
        },
        {
          "instantiator": "test_complete_investigation_workflow",
          "file": "tests/test_thinkdeep_workflow.py",
          "line": 1960,
          "context": [
            "TestEndToEndIntegration",
            "test_complete_investigation_workflow"
          ]
        },
        {
          "instantiator": "test_consensus_to_thinkdeep_to_chat_workflow",
          "file": "tests/test_workflow_integration_chaining.py",
          "line": 141,
          "context": [
            "TestConsensusThinkDeepChatChaining",
            "test_consensus_to_thinkdeep_to_chat_workflow"
          ]
        },
        {
          "instantiator": "test_workflow_chain_context_isolation",
          "file": "tests/test_workflow_integration_chaining.py",
          "line": 245,
          "context": [
            "TestConsensusThinkDeepChatChaining",
            "test_workflow_chain_context_isolation"
          ]
        },
        {
          "instantiator": "test_workflow_chain_context_isolation",
          "file": "tests/test_workflow_integration_chaining.py",
          "line": 250,
          "context": [
            "TestConsensusThinkDeepChatChaining",
            "test_workflow_chain_context_isolation"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 70
    },
    {
      "name": "TestMultiProviderChat",
      "file": "model_chorus/tests/test_chat_integration.py",
      "line": 71,
      "language": "python",
      "docstring": "Test chat functionality across multiple providers.",
      "bases": [],
      "methods": [
        "test_basic_conversation",
        "test_multi_turn_conversation",
        "test_conversation_with_file_context",
        "test_conversation_persistence"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestChatErrorHandling",
      "file": "model_chorus/tests/test_chat_integration.py",
      "line": 180,
      "language": "python",
      "docstring": "Test error handling in chat workflow.",
      "bases": [],
      "methods": [
        "test_invalid_continuation_id",
        "test_empty_prompt",
        "test_very_long_conversation"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestChatThreadManagement",
      "file": "model_chorus/tests/test_chat_integration.py",
      "line": 234,
      "language": "python",
      "docstring": "Test conversation thread management.",
      "bases": [],
      "methods": [
        "test_multiple_concurrent_threads",
        "test_thread_retrieval"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestLongConversations",
      "file": "model_chorus/tests/test_chat_integration.py",
      "line": 288,
      "language": "python",
      "docstring": "Test handling of long multi-turn conversations (20+ turns).",
      "bases": [],
      "methods": [
        "test_20_turn_conversation",
        "test_25_turn_conversation_with_context_retention",
        "test_conversation_length_tracking",
        "test_long_conversation_with_file_references",
        "test_conversation_stability_under_load"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestChatWorkflowInitialization",
      "file": "model_chorus/tests/test_chat_workflow.py",
      "line": 52,
      "language": "python",
      "docstring": "Test ChatWorkflow initialization.",
      "bases": [],
      "methods": [
        "test_initialization_with_provider",
        "test_initialization_without_memory",
        "test_initialization_without_provider_raises_error",
        "test_validate_config",
        "test_get_provider"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestConversationInitiation",
      "file": "model_chorus/tests/test_chat_workflow.py",
      "line": 88,
      "language": "python",
      "docstring": "Test conversation creation and initiation.",
      "bases": [],
      "methods": [
        "test_new_conversation_creates_thread_id",
        "test_new_conversation_has_response",
        "test_new_conversation_without_memory",
        "test_provider_generate_called_with_correct_params"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestConversationContinuation",
      "file": "model_chorus/tests/test_chat_workflow.py",
      "line": 140,
      "language": "python",
      "docstring": "Test conversation continuation functionality.",
      "bases": [],
      "methods": [
        "test_continuation_uses_same_thread_id",
        "test_continuation_includes_history",
        "test_continuation_tracks_message_count",
        "test_multiple_continuations"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestFileContext",
      "file": "model_chorus/tests/test_chat_workflow.py",
      "line": 222,
      "language": "python",
      "docstring": "Test file context handling.",
      "bases": [],
      "methods": [
        "test_file_context_included_in_prompt",
        "test_multiple_files_included",
        "test_file_not_found_handled_gracefully",
        "test_file_references_stored_in_conversation"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestConversationTracking",
      "file": "model_chorus/tests/test_chat_workflow.py",
      "line": 303,
      "language": "python",
      "docstring": "Test conversation history and tracking.",
      "bases": [],
      "methods": [
        "test_get_thread_retrieves_conversation",
        "test_get_thread_returns_none_for_invalid_id",
        "test_get_thread_without_memory_returns_none",
        "test_get_message_count"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestErrorHandling",
      "file": "model_chorus/tests/test_chat_workflow.py",
      "line": 348,
      "language": "python",
      "docstring": "Test error handling in ChatWorkflow.",
      "bases": [],
      "methods": [
        "test_provider_error_handled",
        "test_get_result_returns_last_result"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestCitation",
      "file": "model_chorus/tests/test_citation.py",
      "line": 19,
      "language": "python",
      "docstring": "Test suite for Citation model.",
      "bases": [],
      "methods": [
        "test_citation_creation",
        "test_citation_minimal_creation",
        "test_citation_empty_source",
        "test_citation_confidence_bounds",
        "test_citation_various_source_types",
        "test_citation_location_formats",
        "test_citation_metadata_flexibility",
        "test_citation_serialization",
        "test_citation_json_serialization",
        "test_citation_from_dict",
        "test_citation_json_roundtrip"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestCitationMap",
      "file": "model_chorus/tests/test_citation.py",
      "line": 227,
      "language": "python",
      "docstring": "Test suite for CitationMap model.",
      "bases": [],
      "methods": [
        "test_citation_map_creation",
        "test_citation_map_minimal_creation",
        "test_citation_map_empty_claim_id",
        "test_citation_map_empty_claim_text",
        "test_citation_map_strength_bounds",
        "test_citation_map_single_citation",
        "test_citation_map_multiple_citations",
        "test_citation_map_metadata_flexibility",
        "test_citation_map_serialization",
        "test_citation_map_json_serialization",
        "test_citation_map_json_roundtrip",
        "test_citation_map_nested_validation"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestCitationIntegration",
      "file": "model_chorus/tests/test_citation.py",
      "line": 507,
      "language": "python",
      "docstring": "Test integration scenarios for citation tracking.",
      "bases": [],
      "methods": [
        "test_claim_evidence_mapping",
        "test_multiple_claims_same_source",
        "test_citation_strength_calculation",
        "test_citation_filtering_by_confidence",
        "test_argument_workflow_citation_tracking"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestClaudeProvider",
      "file": "model_chorus/tests/test_claude_provider.py",
      "line": 13,
      "language": "python",
      "docstring": "Test suite for ClaudeProvider.",
      "bases": [],
      "methods": [
        "test_initialization",
        "test_build_command_basic",
        "test_build_command_with_model",
        "test_build_command_without_system_prompt",
        "test_parse_response_success",
        "test_parse_response_failure",
        "test_parse_response_invalid_json",
        "test_generate_success",
        "test_generate_with_retry",
        "test_generate_all_retries_fail",
        "test_supports_vision",
        "test_supports_thinking",
        "test_read_only_mode_allowed_tools",
        "test_read_only_mode_disallowed_tools"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestCodexProvider",
      "file": "model_chorus/tests/test_codex_provider.py",
      "line": 13,
      "language": "python",
      "docstring": "Test suite for CodexProvider.",
      "bases": [],
      "methods": [
        "test_initialization",
        "test_build_command_basic",
        "test_build_command_with_model",
        "test_build_command_with_images",
        "test_parse_response_success",
        "test_parse_response_failure",
        "test_parse_response_invalid_jsonl",
        "test_parse_response_missing_agent_message",
        "test_generate_success",
        "test_generate_with_retry",
        "test_generate_all_retries_fail",
        "test_supports_vision",
        "test_supports_function_calling",
        "test_read_only_sandbox_mode",
        "test_non_interactive_approval_mode"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestConfigLoader",
      "file": "model_chorus/tests/test_config.py",
      "line": 25,
      "language": "python",
      "docstring": "Test suite for ConfigLoader class.",
      "bases": [],
      "methods": [
        "test_find_config_file_in_current_dir",
        "test_find_config_file_in_parent_dir",
        "test_find_config_file_yaml_extension",
        "test_find_config_file_json_extension",
        "test_find_config_file_not_found",
        "test_load_yaml_config_global_defaults",
        "test_load_yaml_config_workflow_specific",
        "test_load_json_config",
        "test_invalid_provider_raises_error",
        "test_invalid_temperature_raises_error",
        "test_invalid_workflow_name_raises_error",
        "test_invalid_consensus_strategy_raises_error",
        "test_get_default_provider_workflow_specific",
        "test_get_default_provider_fallback",
        "test_get_workflow_default_temperature",
        "test_get_default_providers_multi",
        "test_load_empty_config",
        "test_load_minimal_config",
        "test_generation_defaults_validation",
        "test_workflow_config_validation",
        "test_workflow_config_provider_normalization",
        "test_model_chorus_config_complete",
        "test_get_config_loader_singleton",
        "test_load_nonexistent_file_raises_error",
        "test_load_invalid_yaml_raises_error",
        "test_load_invalid_json_raises_error"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestWorkflowConfigValidation",
      "file": "model_chorus/tests/test_config.py",
      "line": 408,
      "language": "python",
      "docstring": "Test suite for workflow-specific configuration validation.",
      "bases": [],
      "methods": [
        "test_thinkdeep_thinking_mode_validation",
        "test_research_citation_style_validation",
        "test_research_depth_validation",
        "test_consensus_strategy_validation"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestComplexConfigScenarios",
      "file": "model_chorus/tests/test_config.py",
      "line": 455,
      "language": "python",
      "docstring": "Test suite for complex real-world configuration scenarios.",
      "bases": [],
      "methods": [
        "test_full_config_all_workflows",
        "test_precedence_workflow_overrides_global"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestConsensusWorkflow",
      "file": "model_chorus/tests/test_consensus_workflow.py",
      "line": 12,
      "language": "python",
      "docstring": "Test suite for ConsensusWorkflow.",
      "bases": [],
      "methods": [
        "test_initialization",
        "test_initialization_multiple_providers",
        "test_initialization_with_strategy",
        "test_execute_all_responses_strategy",
        "test_execute_first_valid_strategy",
        "test_execute_with_parameters",
        "test_execute_all_providers_fail"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestConversationMemory",
      "file": "model_chorus/tests/test_conversation.py",
      "line": 22,
      "language": "python",
      "docstring": "Test suite for ConversationMemory class.",
      "bases": [],
      "methods": [
        "test_create_thread_generates_valid_uuid",
        "test_create_thread_unique_ids",
        "test_create_thread_with_initial_context",
        "test_create_thread_persists_to_file",
        "test_create_thread_with_parent",
        "test_add_message_to_thread",
        "test_add_multiple_messages",
        "test_add_message_with_metadata",
        "test_get_messages_returns_chronological_order",
        "test_message_persistence_across_instances",
        "test_thread_context_window_management",
        "test_get_thread_context_includes_state"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestGeminiIntegration",
      "file": "model_chorus/tests/test_gemini_integration.py",
      "line": 13,
      "language": "python",
      "docstring": "Integration tests for Gemini provider.",
      "bases": [],
      "methods": [
        "provider",
        "simple_request",
        "test_gemini_cli_available",
        "test_build_command_basic",
        "test_build_command_with_model",
        "test_generate_simple_query",
        "test_parse_response_format",
        "test_parse_response_error_handling",
        "test_supports_vision",
        "test_supports_thinking"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestIdeateWorkflowInitialization",
      "file": "model_chorus/tests/test_ideate_workflow.py",
      "line": 172,
      "language": "python",
      "docstring": "Test IdeateWorkflow initialization.",
      "bases": [],
      "methods": [
        "test_initialization_with_provider",
        "test_initialization_without_provider_raises_error",
        "test_validate_config",
        "test_get_provider"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestConvergentAnalysis",
      "file": "model_chorus/tests/test_ideate_workflow.py",
      "line": 197,
      "language": "python",
      "docstring": "Test convergent analysis functionality.",
      "bases": [],
      "methods": [
        "test_convergent_analysis_with_brainstorming_result",
        "test_convergent_analysis_metadata",
        "test_convergent_analysis_raises_error_on_empty_result",
        "test_convergent_analysis_custom_criteria"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestIdeaExtraction",
      "file": "model_chorus/tests/test_ideate_workflow.py",
      "line": 265,
      "language": "python",
      "docstring": "Test idea extraction from brainstorming results.",
      "bases": [],
      "methods": [
        "test_extract_ideas_from_brainstorming",
        "test_extract_ideas_preserves_perspectives"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestIdeaClustering",
      "file": "model_chorus/tests/test_ideate_workflow.py",
      "line": 304,
      "language": "python",
      "docstring": "Test idea clustering functionality.",
      "bases": [],
      "methods": [
        "test_cluster_ideas"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestIdeaScoring",
      "file": "model_chorus/tests/test_ideate_workflow.py",
      "line": 331,
      "language": "python",
      "docstring": "Test idea scoring functionality.",
      "bases": [],
      "methods": [
        "test_score_ideas"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestCompleteIdeation",
      "file": "model_chorus/tests/test_ideate_workflow.py",
      "line": 361,
      "language": "python",
      "docstring": "Test complete ideation workflow (divergent + convergent).",
      "bases": [],
      "methods": [
        "test_run_complete_ideation",
        "test_complete_ideation_with_custom_parameters"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestIntegration",
      "file": "model_chorus/tests/test_integration.py",
      "line": 17,
      "language": "python",
      "docstring": "Integration test suite.",
      "bases": [],
      "methods": [
        "test_end_to_end_consensus",
        "test_provider_initialization_and_generation",
        "test_error_handling_across_workflow",
        "test_multiple_strategy_comparison",
        "test_concurrent_provider_execution"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestEmbeddingComputation",
      "file": "model_chorus/tests/test_semantic_similarity.py",
      "line": 27,
      "language": "python",
      "docstring": "Test embedding computation and caching.",
      "bases": [],
      "methods": [
        "test_compute_embedding_returns_array",
        "test_compute_embedding_normalization",
        "test_compute_embedding_caching",
        "test_compute_embedding_case_insensitive",
        "test_compute_embedding_empty_string"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestCosineSimilarity",
      "file": "model_chorus/tests/test_semantic_similarity.py",
      "line": 81,
      "language": "python",
      "docstring": "Test cosine similarity computation.",
      "bases": [],
      "methods": [
        "test_cosine_similarity_identical",
        "test_cosine_similarity_range",
        "test_cosine_similarity_similar_text",
        "test_cosine_similarity_different_text"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestClaimSimilarity",
      "file": "model_chorus/tests/test_semantic_similarity.py",
      "line": 123,
      "language": "python",
      "docstring": "Test claim-to-claim similarity computation.",
      "bases": [],
      "methods": [
        "test_compute_claim_similarity_identical",
        "test_compute_claim_similarity_similar",
        "test_compute_claim_similarity_different",
        "test_compute_claim_similarity_symmetric"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestFindSimilarClaims",
      "file": "model_chorus/tests/test_semantic_similarity.py",
      "line": 163,
      "language": "python",
      "docstring": "Test finding similar claims in citation maps.",
      "bases": [],
      "methods": [
        "sample_citation_maps",
        "test_find_similar_claims_basic",
        "test_find_similar_claims_threshold",
        "test_find_similar_claims_top_k",
        "test_find_similar_claims_sorted",
        "test_find_similar_claims_empty_list"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestBatchSimilarity",
      "file": "model_chorus/tests/test_semantic_similarity.py",
      "line": 252,
      "language": "python",
      "docstring": "Test batch similarity computation.",
      "bases": [],
      "methods": [
        "test_compute_claim_similarity_batch_shape",
        "test_compute_claim_similarity_batch_diagonal",
        "test_compute_claim_similarity_batch_symmetric",
        "test_compute_claim_similarity_batch_range"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestCitationIntegration",
      "file": "model_chorus/tests/test_semantic_similarity.py",
      "line": 308,
      "language": "python",
      "docstring": "Test integration with Citation model.",
      "bases": [],
      "methods": [
        "test_add_similarity_to_citation_with_snippet",
        "test_add_similarity_to_citation_without_snippet",
        "test_add_similarity_preserves_existing_metadata"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestDuplicateDetection",
      "file": "model_chorus/tests/test_semantic_similarity.py",
      "line": 358,
      "language": "python",
      "docstring": "Test duplicate claim detection.",
      "bases": [],
      "methods": [
        "test_find_duplicate_claims_basic",
        "test_find_duplicate_claims_high_threshold",
        "test_find_duplicate_claims_no_duplicates",
        "test_find_duplicate_claims_empty_list",
        "test_find_duplicate_claims_single_item"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestEdgeCases",
      "file": "model_chorus/tests/test_semantic_similarity.py",
      "line": 469,
      "language": "python",
      "docstring": "Test edge cases and error handling.",
      "bases": [],
      "methods": [
        "test_empty_claim_text",
        "test_very_long_claim",
        "test_special_characters",
        "test_unicode_characters"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestKMeansClustering",
      "file": "model_chorus/tests/test_semantic_similarity.py",
      "line": 500,
      "language": "python",
      "docstring": "Test K-means clustering functionality.",
      "bases": [],
      "methods": [
        "diverse_citation_maps",
        "test_cluster_claims_kmeans_basic",
        "test_cluster_claims_kmeans_empty_list",
        "test_cluster_claims_kmeans_single_cluster",
        "test_cluster_claims_kmeans_too_many_clusters",
        "test_cluster_claims_kmeans_reproducibility"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestHierarchicalClustering",
      "file": "model_chorus/tests/test_semantic_similarity.py",
      "line": 597,
      "language": "python",
      "docstring": "Test hierarchical clustering functionality.",
      "bases": [],
      "methods": [
        "sample_maps",
        "test_cluster_claims_hierarchical_basic",
        "test_cluster_claims_hierarchical_empty_list",
        "test_cluster_claims_hierarchical_linkage_methods",
        "test_cluster_claims_hierarchical_too_many_clusters"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestClusterRepresentative",
      "file": "model_chorus/tests/test_semantic_similarity.py",
      "line": 665,
      "language": "python",
      "docstring": "Test cluster representative selection.",
      "bases": [],
      "methods": [
        "test_get_cluster_representative_basic",
        "test_get_cluster_representative_single_item",
        "test_get_cluster_representative_empty_cluster"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestClusterStatistics",
      "file": "model_chorus/tests/test_semantic_similarity.py",
      "line": 717,
      "language": "python",
      "docstring": "Test cluster statistics computation.",
      "bases": [],
      "methods": [
        "test_compute_cluster_statistics_basic",
        "test_compute_cluster_statistics_empty",
        "test_compute_cluster_statistics_single_item_clusters"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestClusteringIntegration",
      "file": "model_chorus/tests/test_semantic_similarity.py",
      "line": 768,
      "language": "python",
      "docstring": "Test end-to-end clustering workflows.",
      "bases": [],
      "methods": [
        "test_kmeans_to_statistics_pipeline",
        "test_hierarchical_to_statistics_pipeline"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestStateManager",
      "file": "model_chorus/tests/test_state.py",
      "line": 23,
      "language": "python",
      "docstring": "Test suite for StateManager class.",
      "bases": [],
      "methods": [
        "test_set_and_get_state",
        "test_get_state_object_with_metadata",
        "test_update_state_existing",
        "test_update_state_nonexistent",
        "test_delete_state",
        "test_list_workflows",
        "test_clear_all",
        "test_concurrent_set_state",
        "test_concurrent_read_write",
        "test_state_isolation",
        "test_serialize_state",
        "test_deserialize_state",
        "test_roundtrip_serialization",
        "test_export_state",
        "test_import_state",
        "test_deserialize_invalid_json",
        "test_file_persistence_on_set",
        "test_load_from_disk",
        "test_load_all_from_disk",
        "test_sync_to_disk",
        "test_delete_removes_file",
        "test_persistence_disabled_no_files",
        "test_get_nonexistent_workflow",
        "test_delete_nonexistent_workflow",
        "test_serialize_nonexistent",
        "test_import_malformed_json",
        "test_state_timestamps_update",
        "test_schema_version_preservation",
        "test_get_default_state_manager"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestStateManagerExportImportRoundtrip",
      "file": "model_chorus/tests/test_state.py",
      "line": 609,
      "language": "python",
      "docstring": "Test complete export/import workflow.",
      "bases": [],
      "methods": [
        "test_export_import_roundtrip"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestStateManagerFileRecovery",
      "file": "model_chorus/tests/test_state.py",
      "line": 647,
      "language": "python",
      "docstring": "Test state recovery after simulated process restart.",
      "bases": [],
      "methods": [
        "test_process_restart_recovery"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestConfidenceLevel",
      "file": "model_chorus/tests/test_thinkdeep_models.py",
      "line": 25,
      "language": "python",
      "docstring": "Test suite for ConfidenceLevel enum.",
      "bases": [],
      "methods": [
        "test_confidence_level_values",
        "test_confidence_level_count",
        "test_confidence_level_progression",
        "test_confidence_level_string_representation"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestHypothesis",
      "file": "model_chorus/tests/test_thinkdeep_models.py",
      "line": 69,
      "language": "python",
      "docstring": "Test suite for Hypothesis model.",
      "bases": [],
      "methods": [
        "test_hypothesis_creation",
        "test_hypothesis_default_values",
        "test_hypothesis_all_statuses",
        "test_hypothesis_invalid_status",
        "test_hypothesis_empty_hypothesis_text",
        "test_hypothesis_with_multiple_evidence",
        "test_hypothesis_serialization",
        "test_hypothesis_json_serialization",
        "test_hypothesis_from_dict"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestInvestigationStep",
      "file": "model_chorus/tests/test_thinkdeep_models.py",
      "line": 180,
      "language": "python",
      "docstring": "Test suite for InvestigationStep model.",
      "bases": [],
      "methods": [
        "test_investigation_step_creation",
        "test_investigation_step_default_files",
        "test_investigation_step_multiple_files",
        "test_investigation_step_number_validation",
        "test_investigation_step_empty_findings",
        "test_investigation_step_empty_confidence",
        "test_investigation_step_serialization",
        "test_investigation_step_json_roundtrip"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestThinkDeepState",
      "file": "model_chorus/tests/test_thinkdeep_models.py",
      "line": 314,
      "language": "python",
      "docstring": "Test suite for ThinkDeepState model.",
      "bases": [],
      "methods": [
        "test_thinkdeep_state_creation",
        "test_thinkdeep_state_default_values",
        "test_thinkdeep_state_multiple_hypotheses",
        "test_thinkdeep_state_multiple_steps",
        "test_thinkdeep_state_file_accumulation",
        "test_thinkdeep_state_complex_scenario",
        "test_thinkdeep_state_serialization",
        "test_thinkdeep_state_json_roundtrip",
        "test_thinkdeep_state_nested_validation"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestModelIntegration",
      "file": "model_chorus/tests/test_thinkdeep_models.py",
      "line": 592,
      "language": "python",
      "docstring": "Test integration scenarios using multiple models together.",
      "bases": [],
      "methods": [
        "test_hypothesis_lifecycle",
        "test_investigation_progression",
        "test_multiple_hypothesis_tracking"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestPersonaResponse",
      "file": "model_chorus/tests/workflows/study/test_personas.py",
      "line": 30,
      "language": "python",
      "docstring": "Test suite for PersonaResponse dataclass.",
      "bases": [],
      "methods": [
        "test_persona_response_init",
        "test_persona_response_with_findings",
        "test_persona_response_with_confidence_update",
        "test_persona_response_with_metadata",
        "test_persona_response_full_initialization"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestPersona",
      "file": "model_chorus/tests/workflows/study/test_personas.py",
      "line": 80,
      "language": "python",
      "docstring": "Test suite for Persona base class.",
      "bases": [],
      "methods": [
        "test_persona_init",
        "test_persona_init_custom_temperature",
        "test_persona_init_custom_max_tokens",
        "test_persona_invoke_returns_response",
        "test_persona_invoke_with_context",
        "test_persona_invoke_includes_metadata"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestPersonaRegistry",
      "file": "model_chorus/tests/workflows/study/test_personas.py",
      "line": 152,
      "language": "python",
      "docstring": "Test suite for PersonaRegistry.",
      "bases": [],
      "methods": [
        "test_registry_init",
        "test_registry_register_persona",
        "test_registry_register_multiple_personas",
        "test_registry_register_duplicate_raises_error",
        "test_registry_get_persona",
        "test_registry_get_nonexistent_persona",
        "test_registry_list_all"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestResearcherPersona",
      "file": "model_chorus/tests/workflows/study/test_personas.py",
      "line": 236,
      "language": "python",
      "docstring": "Test suite for ResearcherPersona.",
      "bases": [],
      "methods": [
        "test_researcher_init",
        "test_researcher_init_custom_temperature",
        "test_researcher_prompt_template",
        "test_researcher_invoke_returns_response",
        "test_researcher_invoke_includes_findings",
        "test_researcher_invoke_discovery_phase",
        "test_researcher_invoke_validation_phase",
        "test_researcher_invoke_metadata",
        "test_researcher_invoke_includes_prompt_in_findings",
        "test_create_researcher_factory",
        "test_create_researcher_factory_with_params"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestCriticPersona",
      "file": "model_chorus/tests/workflows/study/test_personas.py",
      "line": 337,
      "language": "python",
      "docstring": "Test suite for CriticPersona.",
      "bases": [],
      "methods": [
        "test_critic_init",
        "test_critic_init_custom_temperature",
        "test_critic_prompt_template",
        "test_critic_invoke_returns_response",
        "test_critic_invoke_includes_findings",
        "test_critic_invoke_metadata",
        "test_create_critic_factory",
        "test_create_critic_factory_with_params"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestPlannerPersona",
      "file": "model_chorus/tests/workflows/study/test_personas.py",
      "line": 407,
      "language": "python",
      "docstring": "Test suite for PlannerPersona.",
      "bases": [],
      "methods": [
        "test_planner_init",
        "test_planner_init_custom_temperature",
        "test_planner_prompt_template",
        "test_planner_invoke_returns_response",
        "test_planner_invoke_includes_findings",
        "test_create_planner_factory",
        "test_create_planner_factory_with_params"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestPersonaFactories",
      "file": "model_chorus/tests/workflows/study/test_personas.py",
      "line": 466,
      "language": "python",
      "docstring": "Test suite for persona factory functions.",
      "bases": [],
      "methods": [
        "test_create_default_personas",
        "test_create_default_personas_types",
        "test_create_default_personas_independent",
        "test_get_default_registry",
        "test_get_default_registry_has_researcher",
        "test_get_default_registry_has_critic",
        "test_get_default_registry_has_planner",
        "test_get_default_registry_independent"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestPersonaIntegration",
      "file": "model_chorus/tests/workflows/study/test_personas.py",
      "line": 537,
      "language": "python",
      "docstring": "Integration tests for persona system.",
      "bases": [],
      "methods": [
        "test_registry_with_all_personas",
        "test_persona_responses_structure",
        "test_different_personas_different_findings",
        "test_persona_temperature_affects_generation",
        "test_persona_max_tokens_configuration"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestRoutingSkillInvocation",
      "file": "model_chorus/tests/workflows/study/test_routing.py",
      "line": 19,
      "language": "python",
      "docstring": "Test routing skill invocation and JSON output.",
      "bases": [],
      "methods": [
        "test_routing_skill_invocation",
        "test_routing_different_phases",
        "test_routing_with_findings",
        "test_routing_complete_phase"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestFallbackRouting",
      "file": "model_chorus/tests/workflows/study/test_routing.py",
      "line": 151,
      "language": "python",
      "docstring": "Test fallback routing when context analysis fails.",
      "bases": [],
      "methods": [
        "test_fallback_routing_on_exception",
        "test_fallback_for_all_phases",
        "test_fallback_provides_valid_guidance"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestRoutingHistory",
      "file": "model_chorus/tests/workflows/study/test_routing.py",
      "line": 249,
      "language": "python",
      "docstring": "Test routing history tracking.",
      "bases": [],
      "methods": [
        "test_routing_history_recorded",
        "test_routing_history_filtering",
        "test_routing_history_limit"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestStudyWorkflowIntegration",
      "file": "model_chorus/tests/workflows/study/test_routing.py",
      "line": 324,
      "language": "python",
      "docstring": "Test PersonaRouter integration with StudyWorkflow.",
      "bases": [],
      "methods": [
        "test_workflow_has_router",
        "test_workflow_routing_history_access"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestInvestigationStateMachineTransitions",
      "file": "model_chorus/tests/workflows/study/test_state_machine.py",
      "line": 17,
      "language": "python",
      "docstring": "Test suite for state machine phase transitions.",
      "bases": [],
      "methods": [
        "initial_state",
        "state_machine",
        "test_discovery_to_validation_transition",
        "test_validation_to_planning_transition",
        "test_planning_to_complete_transition",
        "test_validation_back_to_discovery",
        "test_planning_back_to_discovery",
        "test_invalid_discovery_to_planning",
        "test_invalid_discovery_to_complete",
        "test_invalid_transition_from_complete",
        "test_get_next_phase",
        "test_get_valid_transitions",
        "test_advance_to_next",
        "test_reset_to_discovery",
        "test_reset_from_complete_raises_error",
        "test_reset_from_discovery_is_noop",
        "test_transition_with_reason"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestConfidenceLevelProgression",
      "file": "model_chorus/tests/workflows/study/test_state_machine.py",
      "line": 266,
      "language": "python",
      "docstring": "Test suite for confidence level progression logic.",
      "bases": [],
      "methods": [
        "state_machine",
        "test_update_confidence",
        "test_should_escalate_from_discovery_low_confidence",
        "test_should_escalate_from_discovery_medium_confidence",
        "test_should_escalate_from_discovery_high_confidence",
        "test_should_escalate_from_validation_high_confidence",
        "test_should_escalate_from_validation_medium_confidence",
        "test_should_escalate_from_planning",
        "test_should_escalate_from_complete",
        "test_confidence_threshold_discovery",
        "test_confidence_threshold_validation",
        "test_confidence_threshold_planning",
        "test_confidence_threshold_complete",
        "test_confidence_threshold_current_phase"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestStateTransitionIntegration",
      "file": "model_chorus/tests/workflows/study/test_state_machine.py",
      "line": 376,
      "language": "python",
      "docstring": "Integration tests for state transitions with confidence.",
      "bases": [],
      "methods": [
        "state_machine",
        "test_full_investigation_flow",
        "test_investigation_with_backtrack",
        "test_multiple_confidence_updates_in_phase"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestStudyWorkflowInitialization",
      "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
      "line": 22,
      "language": "python",
      "docstring": "Test suite for StudyWorkflow initialization.",
      "bases": [],
      "methods": [
        "test_init_with_provider",
        "test_init_with_fallback_providers",
        "test_init_provider_none_raises_error",
        "test_init_with_conversation_memory",
        "test_init_persona_router_ready",
        "test_init_with_config"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestStudyWorkflowRun",
      "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
      "line": 91,
      "language": "python",
      "docstring": "Test suite for StudyWorkflow.run() method.",
      "bases": [],
      "methods": [
        "mock_provider",
        "workflow",
        "test_run_with_valid_prompt",
        "test_run_empty_prompt_raises_error",
        "test_run_whitespace_prompt_raises_error",
        "test_run_returns_workflow_result",
        "test_run_result_metadata_structure",
        "test_run_result_steps_is_list",
        "test_run_result_steps_are_workflow_steps",
        "test_run_creates_thread_id",
        "test_run_with_continuation_id",
        "test_run_without_continuation_is_not_continuation",
        "test_run_metadata_timestamp_format",
        "test_run_synthesis_is_string"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestStudyWorkflowPersonaSetup",
      "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
      "line": 226,
      "language": "python",
      "docstring": "Test suite for persona setup in StudyWorkflow.",
      "bases": [],
      "methods": [
        "mock_provider",
        "workflow",
        "test_setup_personas_default",
        "test_setup_personas_default_structure",
        "test_setup_personas_custom",
        "test_setup_personas_empty_list",
        "test_run_personas_in_metadata"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestStudyWorkflowConversationHandling",
      "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
      "line": 291,
      "language": "python",
      "docstring": "Test suite for conversation memory integration in StudyWorkflow.",
      "bases": [],
      "methods": [
        "mock_provider",
        "workflow_with_memory",
        "workflow_without_memory",
        "test_run_creates_thread_in_memory",
        "test_run_stores_messages_in_memory",
        "test_run_without_memory_still_works",
        "test_run_reuses_thread_on_continuation"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestStudyWorkflowInvestigation",
      "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
      "line": 368,
      "language": "python",
      "docstring": "Test suite for investigation flow in StudyWorkflow.",
      "bases": [],
      "methods": [
        "mock_provider",
        "workflow",
        "test_investigation_returns_steps",
        "test_investigation_steps_have_metadata",
        "test_investigation_includes_available_personas",
        "test_investigation_empty_personas"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestStudyWorkflowSynthesis",
      "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
      "line": 447,
      "language": "python",
      "docstring": "Test suite for synthesis in StudyWorkflow.",
      "bases": [],
      "methods": [
        "mock_provider",
        "workflow",
        "test_synthesize_findings_returns_string",
        "test_synthesize_findings_empty_steps",
        "test_synthesize_findings_multiple_steps",
        "test_synthesize_includes_step_count"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestStudyWorkflowErrorHandling",
      "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
      "line": 510,
      "language": "python",
      "docstring": "Test suite for error handling in StudyWorkflow.",
      "bases": [],
      "methods": [
        "mock_provider",
        "workflow",
        "test_run_error_returns_false_success",
        "test_run_captures_error_message"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestStudyWorkflowRoutingHistory",
      "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
      "line": 549,
      "language": "python",
      "docstring": "Test suite for routing history access in StudyWorkflow.",
      "bases": [],
      "methods": [
        "mock_provider",
        "workflow",
        "test_get_routing_history_available",
        "test_get_routing_history_with_limit",
        "test_get_routing_history_with_investigation_id"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestStudyWorkflowIntegration",
      "file": "model_chorus/tests/workflows/study/test_study_workflow.py",
      "line": 586,
      "language": "python",
      "docstring": "Integration tests for StudyWorkflow.",
      "bases": [],
      "methods": [
        "mock_provider",
        "workflow_with_memory",
        "test_full_workflow_execution",
        "test_conversation_continuation_flow",
        "test_workflow_with_custom_personas",
        "test_router_persona_count"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestArgumentWorkflowInitialization",
      "file": "tests/test_argument_workflow.py",
      "line": 56,
      "language": "python",
      "docstring": "Test ArgumentWorkflow initialization.",
      "bases": [],
      "methods": [
        "test_initialization_with_provider",
        "test_initialization_without_memory",
        "test_initialization_without_provider_raises_error",
        "test_validate_config",
        "test_get_provider"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestRoleCreation",
      "file": "tests/test_argument_workflow.py",
      "line": 92,
      "language": "python",
      "docstring": "Test role creation methods.",
      "bases": [],
      "methods": [
        "test_create_creator_role",
        "test_create_skeptic_role",
        "test_create_moderator_role"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestArgumentMapGeneration",
      "file": "tests/test_argument_workflow.py",
      "line": 132,
      "language": "python",
      "docstring": "Test ArgumentMap generation.",
      "bases": [],
      "methods": [
        "test_generate_argument_map",
        "test_argument_map_creator_perspective",
        "test_argument_map_skeptic_perspective",
        "test_argument_map_moderator_perspective"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestArgumentWorkflowExecution",
      "file": "tests/test_argument_workflow.py",
      "line": 252,
      "language": "python",
      "docstring": "Test ArgumentWorkflow execution.",
      "bases": [],
      "methods": [
        "test_workflow_execution_with_mocked_orchestrator",
        "test_workflow_metadata"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestConversationThreading",
      "file": "tests/test_argument_workflow.py",
      "line": 381,
      "language": "python",
      "docstring": "Test conversation threading and continuation.",
      "bases": [],
      "methods": [
        "test_new_conversation_creates_thread",
        "test_continuation_uses_existing_thread"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestErrorHandling",
      "file": "tests/test_argument_workflow.py",
      "line": 458,
      "language": "python",
      "docstring": "Test error handling.",
      "bases": [],
      "methods": [
        "test_workflow_handles_orchestration_failure",
        "test_workflow_handles_insufficient_responses"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestCitationFormatting",
      "file": "tests/test_citation.py",
      "line": 108,
      "language": "python",
      "docstring": "Test citation formatting in different styles.",
      "bases": [],
      "methods": [
        "test_format_apa_complete",
        "test_format_apa_minimal",
        "test_format_mla_complete",
        "test_format_mla_minimal",
        "test_format_chicago_complete",
        "test_format_chicago_minimal",
        "test_format_file_citation_apa",
        "test_format_doi_citation_apa",
        "test_format_unsupported_style_raises_error",
        "test_year_extraction_from_full_date"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestCitationMapFormatting",
      "file": "tests/test_citation.py",
      "line": 200,
      "language": "python",
      "docstring": "Test CitationMap formatting.",
      "bases": [],
      "methods": [
        "test_format_citation_map_with_claim",
        "test_format_citation_map_without_claim",
        "test_format_citation_map_mla_style",
        "test_format_citation_map_empty"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestCitationValidation",
      "file": "tests/test_citation.py",
      "line": 245,
      "language": "python",
      "docstring": "Test citation validation logic.",
      "bases": [],
      "methods": [
        "test_validate_complete_citation_passes",
        "test_validate_minimal_citation_has_recommendations",
        "test_validate_empty_source_fails",
        "test_validate_whitespace_source_fails",
        "test_validate_confidence_out_of_range_low",
        "test_validate_confidence_out_of_range_high",
        "test_validate_recognized_source_formats",
        "test_validate_unrecognized_source_format"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestCitationConfidenceScoring",
      "file": "tests/test_citation.py",
      "line": 345,
      "language": "python",
      "docstring": "Test citation confidence calculation.",
      "bases": [],
      "methods": [
        "test_calculate_confidence_complete_citation",
        "test_calculate_confidence_minimal_citation",
        "test_confidence_academic_source_bonus",
        "test_confidence_doi_source_bonus",
        "test_confidence_https_vs_http",
        "test_confidence_location_specificity_bonus",
        "test_confidence_weighted_formula"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestCitationMapConfidenceScoring",
      "file": "tests/test_citation.py",
      "line": 457,
      "language": "python",
      "docstring": "Test CitationMap confidence calculation.",
      "bases": [],
      "methods": [
        "test_calculate_map_confidence_complete",
        "test_calculate_map_confidence_empty",
        "test_calculate_map_confidence_formula",
        "test_calculate_map_confidence_count_plateau"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestCitationStyleEnum",
      "file": "tests/test_citation.py",
      "line": 524,
      "language": "python",
      "docstring": "Test CitationStyle enum.",
      "bases": [],
      "methods": [
        "test_citation_style_values",
        "test_citation_style_string_comparison"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestArgumentCommand",
      "file": "tests/test_cli_integration.py",
      "line": 101,
      "language": "python",
      "docstring": "Test suite for 'argument' CLI command.",
      "bases": [],
      "methods": [
        "test_argument_basic_invocation",
        "test_argument_with_provider_option",
        "test_argument_with_continuation",
        "test_argument_with_file",
        "test_argument_with_nonexistent_file",
        "test_argument_with_temperature",
        "test_argument_with_output_file",
        "test_argument_verbose_mode",
        "test_argument_invalid_provider"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestIdeateCommand",
      "file": "tests/test_cli_integration.py",
      "line": 346,
      "language": "python",
      "docstring": "Test suite for 'ideate' CLI command.",
      "bases": [],
      "methods": [
        "test_ideate_basic_invocation",
        "test_ideate_with_num_ideas",
        "test_ideate_with_high_temperature",
        "test_ideate_with_continuation",
        "test_ideate_with_files",
        "test_ideate_with_output"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestThinkDeepCommand",
      "file": "tests/test_cli_integration.py",
      "line": 520,
      "language": "python",
      "docstring": "Test suite for 'thinkdeep' CLI command.",
      "bases": [],
      "methods": [
        "test_thinkdeep_missing_legacy_file_warns_and_continues",
        "test_thinkdeep_remaps_legacy_file",
        "test_thinkdeep_relevant_files_option",
        "test_thinkdeep_relevant_files_missing_errors"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestErrorHandling",
      "file": "tests/test_cli_integration.py",
      "line": 690,
      "language": "python",
      "docstring": "Test suite for error handling and edge cases.",
      "bases": [],
      "methods": [
        "test_empty_prompt",
        "test_workflow_failure",
        "test_keyboard_interrupt",
        "test_very_long_prompt",
        "test_special_characters_in_prompt"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestCommandIntegration",
      "file": "tests/test_cli_integration.py",
      "line": 787,
      "language": "python",
      "docstring": "Test suite for cross-command integration.",
      "bases": [],
      "methods": [
        "test_all_commands_available",
        "test_help_shows_all_commands",
        "test_common_options_work_across_commands"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestClusterResult",
      "file": "tests/test_clustering.py",
      "line": 33,
      "language": "python",
      "docstring": "Test suite for ClusterResult dataclass.",
      "bases": [],
      "methods": [
        "test_cluster_result_creation",
        "test_cluster_result_repr"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestSemanticClustering",
      "file": "tests/test_clustering.py",
      "line": 73,
      "language": "python",
      "docstring": "Test suite for SemanticClustering class.",
      "bases": [],
      "methods": [
        "clustering",
        "mock_model",
        "test_initialization",
        "test_lazy_model_loading",
        "test_compute_embeddings_basic",
        "test_compute_embeddings_caching",
        "test_compute_embeddings_no_cache",
        "test_compute_similarity_cosine",
        "test_compute_similarity_euclidean",
        "test_compute_similarity_dot",
        "test_compute_similarity_invalid_metric",
        "test_cluster_kmeans_basic",
        "test_cluster_hierarchical_basic",
        "test_cluster_hierarchical_linkages",
        "test_name_cluster_basic",
        "test_name_cluster_empty",
        "test_name_cluster_long_text",
        "test_summarize_cluster_basic",
        "test_summarize_cluster_empty",
        "test_summarize_cluster_truncation",
        "test_score_cluster_basic",
        "test_score_cluster_empty",
        "test_cluster_end_to_end",
        "test_cluster_with_hierarchical",
        "test_cluster_empty_texts",
        "test_cluster_more_clusters_than_texts",
        "test_cluster_invalid_method",
        "test_cluster_single_text",
        "test_cluster_reproducibility"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestClusteringIntegration",
      "file": "tests/test_clustering.py",
      "line": 407,
      "language": "python",
      "docstring": "Integration tests that verify clustering with real sentence-transformers (if available).",
      "bases": [],
      "methods": [
        "test_real_clustering_with_semantics"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestConcurrentConversationHandling",
      "file": "tests/test_concurrent_conversations.py",
      "line": 26,
      "language": "python",
      "docstring": "Test suite for concurrent conversation handling.\n\nValidates that ConversationMemory and workflows can handle high concurrency\nscenarios with proper thread isolation and performance.",
      "bases": [],
      "methods": [
        "mock_provider",
        "conversation_memory",
        "test_100_concurrent_chat_conversations",
        "test_concurrent_multi_turn_conversations",
        "test_mixed_workflow_concurrent_execution",
        "test_performance_scalability"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestPolarityOpposition",
      "file": "tests/test_contradiction.py",
      "line": 21,
      "language": "python",
      "docstring": "Test polarity opposition detection.",
      "bases": [],
      "methods": [
        "test_clear_positive_negative_opposition",
        "test_negation_opposition",
        "test_no_opposition_similar_polarity",
        "test_numerical_opposition_strengthens_confidence"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestSeverityAssessment",
      "file": "tests/test_contradiction.py",
      "line": 66,
      "language": "python",
      "docstring": "Test contradiction severity assessment.",
      "bases": [],
      "methods": [
        "test_critical_severity_high_similarity_strong_polarity",
        "test_major_severity_high_similarity_weak_polarity",
        "test_moderate_severity_medium_similarity",
        "test_minor_severity_low_similarity",
        "test_moderate_severity_high_similarity_no_opposition"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestContradictionExplanation",
      "file": "tests/test_contradiction.py",
      "line": 120,
      "language": "python",
      "docstring": "Test contradiction explanation generation.",
      "bases": [],
      "methods": [
        "test_explanation_includes_polarity_info",
        "test_explanation_severity_critical",
        "test_explanation_severity_moderate",
        "test_explanation_severity_minor"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestReconciliationSuggestions",
      "file": "tests/test_contradiction.py",
      "line": 170,
      "language": "python",
      "docstring": "Test reconciliation suggestion generation.",
      "bases": [],
      "methods": [
        "test_critical_suggestion_mentions_reliability",
        "test_major_suggestion_mentions_context",
        "test_moderate_suggestion_mentions_differences",
        "test_minor_no_suggestion"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestContradictionModel",
      "file": "tests/test_contradiction.py",
      "line": 201,
      "language": "python",
      "docstring": "Test Contradiction Pydantic model.",
      "bases": [],
      "methods": [
        "test_valid_contradiction_creation",
        "test_confidence_validation_in_range",
        "test_confidence_validation_too_high",
        "test_confidence_validation_too_low",
        "test_different_claim_ids_validation"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestContradictionDetection",
      "file": "tests/test_contradiction.py",
      "line": 285,
      "language": "python",
      "docstring": "Test end-to-end contradiction detection.",
      "bases": [],
      "methods": [
        "test_detect_clear_contradiction",
        "test_no_contradiction_unrelated_claims",
        "test_no_contradiction_similar_polarity"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestBatchContradictionDetection",
      "file": "tests/test_contradiction.py",
      "line": 341,
      "language": "python",
      "docstring": "Test batch contradiction detection.",
      "bases": [],
      "methods": [
        "test_detect_contradictions_in_batch",
        "test_batch_no_contradictions"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestRealisticScenarios",
      "file": "tests/test_contradiction.py",
      "line": 386,
      "language": "python",
      "docstring": "Test realistic contradiction scenarios.",
      "bases": [],
      "methods": [
        "test_medical_accuracy_contradiction",
        "test_performance_metric_contradiction"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestGapModel",
      "file": "tests/test_gap_analysis.py",
      "line": 22,
      "language": "python",
      "docstring": "Test Gap Pydantic model.",
      "bases": [],
      "methods": [
        "test_valid_gap_creation",
        "test_confidence_validation_in_range",
        "test_confidence_validation_too_high",
        "test_confidence_validation_too_low"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestSeverityAssessment",
      "file": "tests/test_gap_analysis.py",
      "line": 91,
      "language": "python",
      "docstring": "Test gap severity assessment logic.",
      "bases": [],
      "methods": [
        "test_evidence_gap_critical_no_citations",
        "test_evidence_gap_major_no_citations_low_expectation",
        "test_evidence_gap_moderate_insufficient_citations",
        "test_logical_gap_major_no_support",
        "test_logical_gap_moderate_with_support",
        "test_support_gap_moderate",
        "test_assumption_gap_moderate_no_logic",
        "test_assumption_gap_minor_with_logic"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestGapRecommendations",
      "file": "tests/test_gap_analysis.py",
      "line": 167,
      "language": "python",
      "docstring": "Test gap recommendation generation.",
      "bases": [],
      "methods": [
        "test_evidence_recommendation_critical",
        "test_evidence_recommendation_minor",
        "test_logical_recommendation",
        "test_support_recommendation",
        "test_assumption_recommendation"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestMissingEvidenceDetection",
      "file": "tests/test_gap_analysis.py",
      "line": 222,
      "language": "python",
      "docstring": "Test detection of missing evidence gaps.",
      "bases": [],
      "methods": [
        "test_detect_missing_evidence_no_citations",
        "test_detect_missing_evidence_insufficient_citations",
        "test_no_gap_sufficient_citations",
        "test_evidence_gap_metadata"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestLogicalGapDetection",
      "file": "tests/test_gap_analysis.py",
      "line": 280,
      "language": "python",
      "docstring": "Test detection of logical gaps.",
      "bases": [],
      "methods": [
        "test_detect_logical_gap_conclusion_without_support",
        "test_no_logical_gap_with_support",
        "test_no_logical_gap_non_conclusion_claim",
        "test_conclusion_indicators_detected"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestUnsupportedClaimsDetection",
      "file": "tests/test_gap_analysis.py",
      "line": 336,
      "language": "python",
      "docstring": "Test batch detection of unsupported claims.",
      "bases": [],
      "methods": [
        "test_detect_multiple_unsupported_claims",
        "test_detect_no_gaps_all_supported",
        "test_custom_minimum_citations"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestComprehensiveGapDetection",
      "file": "tests/test_gap_analysis.py",
      "line": 382,
      "language": "python",
      "docstring": "Test comprehensive gap detection combining all types.",
      "bases": [],
      "methods": [
        "test_detect_multiple_gap_types",
        "test_detect_no_gaps_complete_argument",
        "test_gap_detection_with_mixed_quality"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestRealisticScenarios",
      "file": "tests/test_gap_analysis.py",
      "line": 472,
      "language": "python",
      "docstring": "Test realistic gap detection scenarios.",
      "bases": [],
      "methods": [
        "test_policy_argument_with_gaps",
        "test_well_supported_scientific_claim",
        "test_argumentative_essay_analysis"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestIdeateWorkflowInitialization",
      "file": "tests/test_ideate_workflow.py",
      "line": 149,
      "language": "python",
      "docstring": "Test IdeateWorkflow initialization.",
      "bases": [],
      "methods": [
        "test_initialization_with_provider",
        "test_initialization_without_memory",
        "test_initialization_without_provider_raises_error",
        "test_validate_config",
        "test_get_provider"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestBasicIdeation",
      "file": "tests/test_ideate_workflow.py",
      "line": 186,
      "language": "python",
      "docstring": "Test basic ideation methods.",
      "bases": [],
      "methods": [
        "test_run_basic_ideation",
        "test_run_with_empty_prompt_raises_error",
        "test_run_with_continuation_id",
        "test_run_with_custom_temperature",
        "test_run_updates_conversation_memory"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestRoleCreation",
      "file": "tests/test_ideate_workflow.py",
      "line": 252,
      "language": "python",
      "docstring": "Test brainstormer role creation.",
      "bases": [],
      "methods": [
        "test_create_brainstormer_role_practical",
        "test_create_brainstormer_role_innovative",
        "test_create_brainstormer_role_user_focused"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestParallelBrainstorming",
      "file": "tests/test_ideate_workflow.py",
      "line": 281,
      "language": "python",
      "docstring": "Test parallel brainstorming functionality.",
      "bases": [],
      "methods": [
        "test_run_parallel_brainstorming",
        "test_parallel_brainstorming_empty_prompt_raises_error",
        "test_parallel_brainstorming_empty_provider_map_raises_error"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestConvergentAnalysis",
      "file": "tests/test_ideate_workflow.py",
      "line": 348,
      "language": "python",
      "docstring": "Test convergent analysis functionality.",
      "bases": [],
      "methods": [
        "mock_brainstorming_result",
        "test_run_convergent_analysis",
        "test_convergent_analysis_without_brainstorming_raises_error",
        "test_idea_extraction",
        "test_idea_clustering",
        "test_idea_scoring"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestInteractiveSelection",
      "file": "tests/test_ideate_workflow.py",
      "line": 492,
      "language": "python",
      "docstring": "Test interactive selection functionality.",
      "bases": [],
      "methods": [
        "mock_convergent_result",
        "test_parse_selection_input_single_number",
        "test_parse_selection_input_comma_separated",
        "test_parse_selection_input_range",
        "test_parse_selection_input_all",
        "test_parse_selection_input_none",
        "test_parse_selection_input_invalid_range",
        "test_parse_selection_input_with_max_selections"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestElaboration",
      "file": "tests/test_ideate_workflow.py",
      "line": 580,
      "language": "python",
      "docstring": "Test elaboration functionality.",
      "bases": [],
      "methods": [
        "mock_selection_result",
        "test_run_elaboration",
        "test_elaboration_without_selection_raises_error",
        "test_elaborate_cluster",
        "test_parse_outline_sections"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestCompleteIdeation",
      "file": "tests/test_ideate_workflow.py",
      "line": 679,
      "language": "python",
      "docstring": "Test complete ideation workflow.",
      "bases": [],
      "methods": [
        "test_run_complete_ideation",
        "test_complete_ideation_empty_prompt_raises_error",
        "test_complete_ideation_empty_provider_map_raises_error"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestErrorHandling",
      "file": "tests/test_ideate_workflow.py",
      "line": 746,
      "language": "python",
      "docstring": "Test error handling and edge cases.",
      "bases": [],
      "methods": [
        "test_provider_generation_failure",
        "test_extraction_with_no_brainstorming_steps",
        "test_clustering_with_no_extracted_ideas",
        "test_scoring_with_no_clusters"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestSystemPrompts",
      "file": "tests/test_ideate_workflow.py",
      "line": 814,
      "language": "python",
      "docstring": "Test system prompt generation.",
      "bases": [],
      "methods": [
        "test_get_ideation_system_prompt",
        "test_get_extraction_system_prompt",
        "test_get_clustering_system_prompt",
        "test_get_scoring_system_prompt",
        "test_get_elaboration_system_prompt"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestPromptFraming",
      "file": "tests/test_ideate_workflow.py",
      "line": 856,
      "language": "python",
      "docstring": "Test prompt framing methods.",
      "bases": [],
      "methods": [
        "test_frame_ideation_prompt_initial",
        "test_frame_ideation_prompt_continuation"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestMemoryManagement",
      "file": "tests/test_memory_management.py",
      "line": 23,
      "language": "python",
      "docstring": "Test suite for memory management with long conversations.\n\nValidates that ConversationMemory properly manages memory when dealing\nwith long-running conversations with many messages.",
      "bases": [],
      "methods": [
        "mock_provider",
        "conversation_memory",
        "test_long_conversation_memory_stability",
        "test_multiple_long_conversations_memory_isolation",
        "test_memory_efficiency_with_large_messages",
        "test_concurrent_long_conversations_memory"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestCLIProvidersImplementInterface",
      "file": "tests/test_providers/test_cli_interface.py",
      "line": 27,
      "language": "python",
      "docstring": "Test that all CLI providers implement the ModelProvider interface.",
      "bases": [],
      "methods": [
        "providers",
        "test_all_providers_inherit_from_base",
        "test_all_providers_inherit_from_cli_provider",
        "test_all_providers_have_generate_method",
        "test_all_providers_have_build_command_method",
        "test_all_providers_have_parse_response_method",
        "test_all_providers_have_supports_vision_method",
        "test_all_providers_have_get_available_models_method",
        "test_all_providers_return_models",
        "test_all_providers_have_provider_name",
        "test_all_providers_have_cli_command",
        "test_build_command_returns_list",
        "test_build_command_includes_cli_command",
        "test_supports_vision_returns_bool"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "MockGenerationRequest",
      "file": "tests/test_role_orchestration.py",
      "line": 31,
      "language": "python",
      "docstring": "Mock GenerationRequest for testing.",
      "bases": [],
      "methods": [],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "MockGenerationResponse",
      "file": "tests/test_role_orchestration.py",
      "line": 40,
      "language": "python",
      "docstring": "Mock GenerationResponse for testing.",
      "bases": [],
      "methods": [
        "__post_init__"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "generate",
          "file": "tests/test_role_orchestration.py",
          "line": 88,
          "context": [
            "MockProvider",
            "generate"
          ]
        },
        {
          "instantiator": "test_orchestration_result_creation_full",
          "file": "tests/test_role_orchestration.py",
          "line": 257,
          "context": [
            "TestOrchestrationResult",
            "test_orchestration_result_creation_full"
          ]
        },
        {
          "instantiator": "test_build_synthesis_prompt",
          "file": "tests/test_role_orchestration.py",
          "line": 700,
          "context": [
            "TestRoleOrchestrator",
            "test_build_synthesis_prompt"
          ]
        },
        {
          "instantiator": "test_build_synthesis_prompt",
          "file": "tests/test_role_orchestration.py",
          "line": 701,
          "context": [
            "TestRoleOrchestrator",
            "test_build_synthesis_prompt"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 4
    },
    {
      "name": "MockProvider",
      "file": "tests/test_role_orchestration.py",
      "line": 51,
      "language": "python",
      "docstring": "Mock provider for testing orchestration.",
      "bases": [],
      "methods": [
        "__init__",
        "generate"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [
        {
          "instantiator": "simple_providers",
          "file": "tests/test_role_orchestration.py",
          "line": 295,
          "context": [
            "TestRoleOrchestrator",
            "simple_providers"
          ]
        },
        {
          "instantiator": "simple_providers",
          "file": "tests/test_role_orchestration.py",
          "line": 296,
          "context": [
            "TestRoleOrchestrator",
            "simple_providers"
          ]
        },
        {
          "instantiator": "test_resolve_provider_case_variation",
          "file": "tests/test_role_orchestration.py",
          "line": 343,
          "context": [
            "TestRoleOrchestrator",
            "test_resolve_provider_case_variation"
          ]
        },
        {
          "instantiator": "test_resolve_provider_hyphen_variation",
          "file": "tests/test_role_orchestration.py",
          "line": 352,
          "context": [
            "TestRoleOrchestrator",
            "test_resolve_provider_hyphen_variation"
          ]
        },
        {
          "instantiator": "test_execute_sequential_partial_failure",
          "file": "tests/test_role_orchestration.py",
          "line": 415,
          "context": [
            "TestRoleOrchestrator",
            "test_execute_sequential_partial_failure"
          ]
        },
        {
          "instantiator": "test_execute_sequential_partial_failure",
          "file": "tests/test_role_orchestration.py",
          "line": 416,
          "context": [
            "TestRoleOrchestrator",
            "test_execute_sequential_partial_failure"
          ]
        },
        {
          "instantiator": "test_execute_parallel_partial_failure",
          "file": "tests/test_role_orchestration.py",
          "line": 463,
          "context": [
            "TestRoleOrchestrator",
            "test_execute_parallel_partial_failure"
          ]
        },
        {
          "instantiator": "test_execute_parallel_partial_failure",
          "file": "tests/test_role_orchestration.py",
          "line": 464,
          "context": [
            "TestRoleOrchestrator",
            "test_execute_parallel_partial_failure"
          ]
        },
        {
          "instantiator": "test_synthesize_ai_strategy_custom_provider",
          "file": "tests/test_role_orchestration.py",
          "line": 569,
          "context": [
            "TestRoleOrchestrator",
            "test_synthesize_ai_strategy_custom_provider"
          ]
        },
        {
          "instantiator": "test_synthesize_ai_strategy_fallback_on_failure",
          "file": "tests/test_role_orchestration.py",
          "line": 607,
          "context": [
            "TestRoleOrchestrator",
            "test_synthesize_ai_strategy_fallback_on_failure"
          ]
        },
        {
          "instantiator": "test_synthesize_ai_strategy_fallback_on_failure",
          "file": "tests/test_role_orchestration.py",
          "line": 608,
          "context": [
            "TestRoleOrchestrator",
            "test_synthesize_ai_strategy_fallback_on_failure"
          ]
        }
      ],
      "imported_by": [],
      "instantiation_count": 11
    },
    {
      "name": "TestModelRole",
      "file": "tests/test_role_orchestration.py",
      "line": 94,
      "language": "python",
      "docstring": "Test suite for ModelRole class.",
      "bases": [],
      "methods": [
        "test_model_role_creation_minimal",
        "test_model_role_creation_full",
        "test_stance_validation_valid",
        "test_stance_validation_invalid",
        "test_temperature_validation_valid",
        "test_temperature_validation_invalid",
        "test_max_tokens_validation_valid",
        "test_max_tokens_validation_invalid",
        "test_get_full_prompt_base_only",
        "test_get_full_prompt_with_system",
        "test_get_full_prompt_with_stance",
        "test_get_full_prompt_with_all",
        "test_role_length_validation",
        "test_model_name_validation"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestOrchestrationResult",
      "file": "tests/test_role_orchestration.py",
      "line": 239,
      "language": "python",
      "docstring": "Test suite for OrchestrationResult dataclass.",
      "bases": [],
      "methods": [
        "test_orchestration_result_creation_minimal",
        "test_orchestration_result_creation_full"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestRoleOrchestrator",
      "file": "tests/test_role_orchestration.py",
      "line": 280,
      "language": "python",
      "docstring": "Test suite for RoleOrchestrator class.",
      "bases": [],
      "methods": [
        "simple_roles",
        "simple_providers",
        "test_orchestrator_initialization_minimal",
        "test_orchestrator_initialization_custom",
        "test_orchestrator_initialization_empty_roles",
        "test_orchestrator_initialization_unsupported_pattern",
        "test_resolve_provider_exact_match",
        "test_resolve_provider_case_variation",
        "test_resolve_provider_hyphen_variation",
        "test_resolve_provider_not_found",
        "test_execute_sequential_success",
        "test_execute_sequential_with_context",
        "test_execute_sequential_partial_failure",
        "test_execute_parallel_success",
        "test_execute_parallel_partial_failure",
        "test_execute_parallel_maintains_order",
        "test_synthesize_none_strategy",
        "test_synthesize_concatenate_strategy",
        "test_synthesize_structured_strategy",
        "test_synthesize_ai_strategy_default_provider",
        "test_synthesize_ai_strategy_custom_provider",
        "test_synthesize_ai_strategy_custom_prompt",
        "test_synthesize_ai_strategy_fallback_on_failure",
        "test_synthesize_ai_strategy_no_responses",
        "test_synthesize_unknown_strategy",
        "test_role_prompt_customization",
        "test_build_synthesis_prompt"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestEnums",
      "file": "tests/test_role_orchestration.py",
      "line": 716,
      "language": "python",
      "docstring": "Test suite for enum classes.",
      "bases": [],
      "methods": [
        "test_orchestration_pattern_values",
        "test_synthesis_strategy_values"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestArchitecturalDecisionScenarios",
      "file": "tests/test_thinkdeep_complex.py",
      "line": 26,
      "language": "python",
      "docstring": "Test suite for architectural decision making scenarios.",
      "bases": [],
      "methods": [
        "mock_provider",
        "conversation_memory",
        "test_architectural_decision_rest_vs_graphql",
        "test_architectural_decision_database_selection"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestBugInvestigationScenarios",
      "file": "tests/test_thinkdeep_complex.py",
      "line": 250,
      "language": "python",
      "docstring": "Test suite for systematic bug investigation scenarios.",
      "bases": [],
      "methods": [
        "mock_provider",
        "conversation_memory",
        "test_bug_investigation_api_slowness",
        "test_bug_investigation_intermittent_crash"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestComplexMultiStepReasoning",
      "file": "tests/test_thinkdeep_complex.py",
      "line": 597,
      "language": "python",
      "docstring": "Test suite for complex multi-step reasoning scenarios.",
      "bases": [],
      "methods": [
        "mock_provider",
        "conversation_memory",
        "test_long_investigation_with_hypothesis_pivots",
        "test_investigation_with_multiple_evidence_types"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestExpertProviderIntegration",
      "file": "tests/test_thinkdeep_expert_validation.py",
      "line": 27,
      "language": "python",
      "docstring": "Test suite for expert provider integration in ThinkDeepWorkflow.",
      "bases": [],
      "methods": [
        "mock_provider",
        "mock_expert_provider",
        "conversation_memory",
        "test_expert_validation_enabled_with_expert_provider",
        "test_expert_validation_disabled_without_expert_provider",
        "test_expert_validation_explicit_disable_via_config",
        "test_expert_validation_explicit_enable_via_config"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestExpertValidationTriggering",
      "file": "tests/test_thinkdeep_expert_validation.py",
      "line": 116,
      "language": "python",
      "docstring": "Test suite for expert validation triggering logic.",
      "bases": [],
      "methods": [
        "mock_provider",
        "mock_expert_provider",
        "conversation_memory",
        "test_expert_validation_triggered_at_medium_confidence",
        "test_expert_validation_not_triggered_at_exploring_confidence",
        "test_expert_validation_triggered_at_high_confidence",
        "test_expert_validation_not_triggered_when_disabled"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestExpertValidationResultHandling",
      "file": "tests/test_thinkdeep_expert_validation.py",
      "line": 314,
      "language": "python",
      "docstring": "Test suite for handling expert validation results.",
      "bases": [],
      "methods": [
        "mock_provider",
        "mock_expert_provider",
        "conversation_memory",
        "test_expert_validation_result_included_in_metadata",
        "test_expert_validation_conversation_history_updated"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestExpertValidationErrorHandling",
      "file": "tests/test_thinkdeep_expert_validation.py",
      "line": 428,
      "language": "python",
      "docstring": "Test suite for error handling in expert validation.",
      "bases": [],
      "methods": [
        "mock_provider",
        "mock_expert_provider",
        "conversation_memory",
        "test_expert_validation_failure_does_not_crash_investigation",
        "test_expert_validation_timeout_handling",
        "test_expert_validation_with_empty_response"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestExpertValidationWithHypotheses",
      "file": "tests/test_thinkdeep_expert_validation.py",
      "line": 579,
      "language": "python",
      "docstring": "Test suite for expert validation interaction with hypotheses.",
      "bases": [],
      "methods": [
        "mock_provider",
        "mock_expert_provider",
        "conversation_memory",
        "test_expert_validation_validates_hypothesis",
        "test_expert_validation_with_multiple_hypotheses"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestInvestigationStepExecution",
      "file": "tests/test_thinkdeep_workflow.py",
      "line": 29,
      "language": "python",
      "docstring": "Test suite for investigation step execution in ThinkDeepWorkflow.",
      "bases": [],
      "methods": [
        "mock_provider",
        "mock_expert_provider",
        "conversation_memory",
        "test_single_investigation_step_execution",
        "test_investigation_step_creates_investigation_step_object",
        "test_multi_step_investigation_progression",
        "test_investigation_step_tracks_files_checked",
        "test_relevant_files_merge_into_state_and_metadata",
        "test_investigation_step_with_no_files",
        "test_investigation_step_confidence_tracking",
        "test_investigation_step_with_hypothesis_integration",
        "test_investigation_step_findings_extraction",
        "test_investigation_step_with_expert_validation",
        "test_investigation_step_metadata_completeness",
        "test_investigation_step_error_handling",
        "test_empty_provider_response_reports_error",
        "test_investigation_without_conversation_memory"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestHypothesisEvolution",
      "file": "tests/test_thinkdeep_workflow.py",
      "line": 714,
      "language": "python",
      "docstring": "Test suite for hypothesis evolution in ThinkDeepWorkflow.",
      "bases": [],
      "methods": [
        "mock_provider",
        "conversation_memory",
        "test_add_hypothesis_to_investigation",
        "test_update_hypothesis_with_evidence",
        "test_validate_hypothesis",
        "test_disprove_hypothesis",
        "test_multiple_hypothesis_evolution",
        "test_get_active_hypotheses",
        "test_get_all_hypotheses",
        "test_hypothesis_persistence_across_turns",
        "test_hypothesis_update_with_status_change",
        "test_hypothesis_not_found_handling",
        "test_hypothesis_metadata_tracking"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestConfidenceProgression",
      "file": "tests/test_thinkdeep_workflow.py",
      "line": 1251,
      "language": "python",
      "docstring": "Test suite for confidence level progression in ThinkDeepWorkflow.",
      "bases": [],
      "methods": [
        "mock_provider",
        "conversation_memory",
        "test_initial_confidence_level",
        "test_update_confidence_level",
        "test_get_confidence_level",
        "test_confidence_progression_across_steps",
        "test_confidence_tracked_in_metadata",
        "test_invalid_confidence_level_rejected",
        "test_confidence_complete_progression",
        "test_investigation_completion_criteria",
        "test_investigation_summary_includes_confidence",
        "test_confidence_cannot_decrease",
        "test_confidence_persistence_across_turns"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestEndToEndIntegration",
      "file": "tests/test_thinkdeep_workflow.py",
      "line": 1729,
      "language": "python",
      "docstring": "End-to-end integration tests for complete investigation scenarios.",
      "bases": [],
      "methods": [
        "mock_provider",
        "conversation_memory",
        "test_five_step_investigation_with_hypothesis_evolution",
        "test_complete_investigation_workflow"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    },
    {
      "name": "TestConsensusThinkDeepChatChaining",
      "file": "tests/test_workflow_integration_chaining.py",
      "line": 31,
      "language": "python",
      "docstring": "Test suite for consensus \u2192 thinkdeep \u2192 chat workflow integration.\n\nThis pattern demonstrates using multiple orchestration strategies in sequence:\n1. Consensus: Gather multi-model opinions on a decision\n2. ThinkDeep: Investigate specific concerns raised\n3. Chat: Refine understanding and get practical recommendations",
      "bases": [],
      "methods": [
        "mock_provider",
        "mock_provider_2",
        "conversation_memory",
        "test_consensus_to_thinkdeep_to_chat_workflow",
        "test_workflow_chain_context_isolation",
        "test_consensus_without_continuation_support"
      ],
      "properties": [],
      "is_exported": false,
      "is_public": true,
      "instantiated_by": [],
      "imported_by": []
    }
  ],
  "functions": [
    {
      "name": "example_argument_basic",
      "file": "examples/workflow_examples.py",
      "line": 37,
      "language": "python",
      "docstring": "Example 1: Basic argument analysis.\n\nDemonstrates the simplest use case - analyzing a single argument/claim\nthrough dialectical reasoning (Creator \u2192 Skeptic \u2192 Moderator).",
      "parameters": [],
      "return_type": null,
      "complexity": 4,
      "decorators": [],
      "is_async": true,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "print",
          "file": "unknown",
          "line": 44,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 45,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 46,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 61,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 63,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 69,
          "call_type": "function_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 73,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 74,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 75,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 76,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 80,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 81,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 82,
          "call_type": "function_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 85,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 86,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 88,
          "call_type": "function_call"
        }
      ]
    },
    {
      "name": "example_argument_with_files",
      "file": "examples/workflow_examples.py",
      "line": 91,
      "language": "python",
      "docstring": "Example 2: Argument analysis with file context.\n\nShows how to provide supporting documents/context files to enrich\nthe argument analysis with specific data or background information.",
      "parameters": [],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": true,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "print",
          "file": "unknown",
          "line": 98,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 99,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 100,
          "call_type": "function_call"
        },
        {
          "name": "mkdir",
          "file": "unknown",
          "line": 104,
          "call_type": "method_call"
        },
        {
          "name": "write_text",
          "file": "unknown",
          "line": 105,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 123,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 124,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 126,
          "call_type": "method_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 128,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 133,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 134,
          "call_type": "function_call"
        },
        {
          "name": "unlink",
          "file": "unknown",
          "line": 137,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "example_argument_continuation",
      "file": "examples/workflow_examples.py",
      "line": 140,
      "language": "python",
      "docstring": "Example 3: Continuing an argument analysis.\n\nDemonstrates how to use conversation threading to continue\na previous analysis with follow-up questions or new angles.",
      "parameters": [],
      "return_type": null,
      "complexity": 3,
      "decorators": [],
      "is_async": true,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "print",
          "file": "unknown",
          "line": 147,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 148,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 149,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 156,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 157,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 162,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 166,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 169,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 170,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 176,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 177,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 178,
          "call_type": "function_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 178,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "example_argument_custom_config",
      "file": "examples/workflow_examples.py",
      "line": 181,
      "language": "python",
      "docstring": "Example 4: Argument analysis with custom configuration.\n\nShows how to customize the argument workflow with different\nparameters like temperature, max_tokens, and system prompts.",
      "parameters": [],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": true,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "print",
          "file": "unknown",
          "line": 188,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 189,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 190,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 198,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 200,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 208,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 209,
          "call_type": "function_call"
        }
      ]
    },
    {
      "name": "example_ideate_basic",
      "file": "examples/workflow_examples.py",
      "line": 216,
      "language": "python",
      "docstring": "Example 5: Basic ideation/brainstorming.\n\nDemonstrates simple creative idea generation with default parameters.",
      "parameters": [],
      "return_type": null,
      "complexity": 4,
      "decorators": [],
      "is_async": true,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "print",
          "file": "unknown",
          "line": 222,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 223,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 224,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 232,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 234,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 241,
          "call_type": "function_call"
        },
        {
          "name": "enumerate",
          "file": "unknown",
          "line": 244,
          "call_type": "function_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 245,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 246,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 247,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 248,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 252,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 253,
          "call_type": "function_call"
        }
      ]
    },
    {
      "name": "example_ideate_high_creativity",
      "file": "examples/workflow_examples.py",
      "line": 256,
      "language": "python",
      "docstring": "Example 6: High-creativity brainstorming.\n\nUses maximum temperature for highly creative, unconventional ideas.",
      "parameters": [],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": true,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "print",
          "file": "unknown",
          "line": 262,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 263,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 264,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 272,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 273,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 275,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 282,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 283,
          "call_type": "function_call"
        }
      ]
    },
    {
      "name": "example_ideate_with_constraints",
      "file": "examples/workflow_examples.py",
      "line": 286,
      "language": "python",
      "docstring": "Example 7: Ideation with constraints/criteria.\n\nDemonstrates how to guide idea generation with specific constraints\nor requirements via system prompts.",
      "parameters": [],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": true,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "print",
          "file": "unknown",
          "line": 293,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 294,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 295,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 311,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 312,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 314,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 322,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 323,
          "call_type": "function_call"
        }
      ]
    },
    {
      "name": "example_ideate_refine",
      "file": "examples/workflow_examples.py",
      "line": 326,
      "language": "python",
      "docstring": "Example 8: Refining specific ideas through continuation.\n\nShows how to use threading to drill down into specific ideas\nand develop them further.",
      "parameters": [],
      "return_type": null,
      "complexity": 3,
      "decorators": [],
      "is_async": true,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "print",
          "file": "unknown",
          "line": 333,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 334,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 335,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 342,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 343,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 349,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 353,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 353,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 356,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 357,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 364,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 365,
          "call_type": "function_call"
        }
      ]
    },
    {
      "name": "example_error_handling",
      "file": "examples/workflow_examples.py",
      "line": 372,
      "language": "python",
      "docstring": "Example 13: Proper error handling across workflows.\n\nDemonstrates best practices for handling workflow failures.",
      "parameters": [],
      "return_type": null,
      "complexity": 3,
      "decorators": [],
      "is_async": true,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "print",
          "file": "unknown",
          "line": 378,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 379,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 380,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 387,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 393,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 394,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 397,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 398,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 399,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 400,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 401,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 405,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 406,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 407,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 408,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 409,
          "call_type": "function_call"
        }
      ]
    },
    {
      "name": "example_output_management",
      "file": "examples/workflow_examples.py",
      "line": 412,
      "language": "python",
      "docstring": "Example 14: Managing workflow outputs.\n\nShows how to save, load, and process workflow results.",
      "parameters": [],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": true,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "print",
          "file": "unknown",
          "line": 418,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 419,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 420,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 429,
          "call_type": "method_call"
        },
        {
          "name": "isoformat",
          "file": "unknown",
          "line": 439,
          "call_type": "method_call"
        },
        {
          "name": "now",
          "file": "unknown",
          "line": 439,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 444,
          "call_type": "method_call"
        },
        {
          "name": "enumerate",
          "file": "unknown",
          "line": 448,
          "call_type": "function_call"
        },
        {
          "name": "write_text",
          "file": "unknown",
          "line": 454,
          "call_type": "method_call"
        },
        {
          "name": "dumps",
          "file": "unknown",
          "line": 454,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 455,
          "call_type": "function_call"
        },
        {
          "name": "loads",
          "file": "unknown",
          "line": 458,
          "call_type": "method_call"
        },
        {
          "name": "read_text",
          "file": "unknown",
          "line": 458,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 459,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 459,
          "call_type": "function_call"
        },
        {
          "name": "unlink",
          "file": "unknown",
          "line": 462,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "example_provider_comparison",
      "file": "examples/workflow_examples.py",
      "line": 465,
      "language": "python",
      "docstring": "Example 15: Comparing results across providers.\n\nDemonstrates running the same query with different providers\nto compare outputs.",
      "parameters": [],
      "return_type": null,
      "complexity": 4,
      "decorators": [],
      "is_async": true,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "print",
          "file": "unknown",
          "line": 472,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 473,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 474,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 486,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 491,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 497,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 498,
          "call_type": "function_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 498,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 499,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 499,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 502,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 505,
          "call_type": "function_call"
        }
      ]
    },
    {
      "name": "run_all_examples",
      "file": "examples/workflow_examples.py",
      "line": 512,
      "language": "python",
      "docstring": "Run all examples in sequence.",
      "parameters": [],
      "return_type": null,
      "complexity": 4,
      "decorators": [],
      "is_async": true,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "main",
          "file": "examples/workflow_examples.py",
          "line": 585,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "print",
          "file": "unknown",
          "line": 528,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 529,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 530,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 531,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 531,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 534,
          "call_type": "function_call"
        },
        {
          "name": "example_func",
          "file": "unknown",
          "line": 536,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 538,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 541,
          "call_type": "function_call"
        },
        {
          "name": "print_exc",
          "file": "unknown",
          "line": 543,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 545,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 546,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 547,
          "call_type": "function_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "run_specific_example",
      "file": "examples/workflow_examples.py",
      "line": 550,
      "language": "python",
      "docstring": "Run a specific example by name.",
      "parameters": [
        {
          "name": "example_name",
          "type": "str",
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": true,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "main",
          "file": "examples/workflow_examples.py",
          "line": 582,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "get",
          "file": "unknown",
          "line": 566,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 568,
          "call_type": "function_call"
        },
        {
          "name": "example_func",
          "file": "unknown",
          "line": 569,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 571,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 572,
          "call_type": "function_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 572,
          "call_type": "method_call"
        },
        {
          "name": "keys",
          "file": "unknown",
          "line": 572,
          "call_type": "method_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "main",
      "file": "examples/workflow_examples.py",
      "line": 575,
      "language": "python",
      "docstring": "Main entry point.",
      "parameters": [],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "<module>",
          "file": "examples/workflow_examples.py",
          "line": 589,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/examples/basic_workflow.py",
          "line": 105,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/examples/chat_example.py",
          "line": 216,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/examples/provider_integration.py",
          "line": 157,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/examples/thinkdeep_example.py",
          "line": 467,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1771,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 956,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
          "line": 210,
          "call_type": "method_call"
        },
        {
          "name": "<module>",
          "file": "tests/workflows/study/memory/test_cache.py",
          "line": 229,
          "call_type": "method_call"
        }
      ],
      "calls": [
        {
          "name": "len",
          "file": "unknown",
          "line": 579,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 582,
          "call_type": "method_call"
        },
        {
          "name": "run_specific_example",
          "file": "unknown",
          "line": 582,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 585,
          "call_type": "method_call"
        },
        {
          "name": "run_all_examples",
          "file": "unknown",
          "line": 585,
          "call_type": "function_call"
        }
      ],
      "call_count": 9
    },
    {
      "name": "main",
      "file": "model_chorus/examples/basic_workflow.py",
      "line": 56,
      "language": "python",
      "docstring": "Main entry point for the example.",
      "parameters": [],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": true,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "<module>",
          "file": "examples/workflow_examples.py",
          "line": 589,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/examples/basic_workflow.py",
          "line": 105,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/examples/chat_example.py",
          "line": 216,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/examples/provider_integration.py",
          "line": 157,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/examples/thinkdeep_example.py",
          "line": 467,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1771,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 956,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
          "line": 210,
          "call_type": "method_call"
        },
        {
          "name": "<module>",
          "file": "tests/workflows/study/memory/test_cache.py",
          "line": 229,
          "call_type": "method_call"
        }
      ],
      "calls": [
        {
          "name": "print",
          "file": "unknown",
          "line": 66,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 67,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 68,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 69,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 70,
          "call_type": "function_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 73,
          "call_type": "method_call"
        },
        {
          "name": "workflow_class",
          "file": "unknown",
          "line": 76,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 81,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 82,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 85,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 88,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 89,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 90,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 91,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 92,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 92,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 95,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 96,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 97,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 99,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 100,
          "call_type": "function_call"
        }
      ],
      "call_count": 9
    },
    {
      "name": "basic_chat_example",
      "file": "model_chorus/examples/chat_example.py",
      "line": 19,
      "language": "python",
      "docstring": "Basic chat conversation without continuation.",
      "parameters": [],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": true,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "main",
          "file": "model_chorus/examples/chat_example.py",
          "line": 199,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "print",
          "file": "unknown",
          "line": 21,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 22,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 23,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 36,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 42,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 43,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 45,
          "call_type": "function_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "multi_turn_conversation_example",
      "file": "model_chorus/examples/chat_example.py",
      "line": 48,
      "language": "python",
      "docstring": "Multi-turn conversation with continuation.",
      "parameters": [],
      "return_type": null,
      "complexity": 4,
      "decorators": [],
      "is_async": true,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "main",
          "file": "model_chorus/examples/chat_example.py",
          "line": 202,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "print",
          "file": "unknown",
          "line": 50,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 51,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 52,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 65,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 66,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 72,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 76,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 77,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 80,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 81,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 88,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 89,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 90,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 93,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 94,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 101,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 102,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 103,
          "call_type": "function_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "chat_with_file_context_example",
      "file": "model_chorus/examples/chat_example.py",
      "line": 106,
      "language": "python",
      "docstring": "Chat with file context included.",
      "parameters": [],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": true,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "main",
          "file": "model_chorus/examples/chat_example.py",
          "line": 205,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "print",
          "file": "unknown",
          "line": 108,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 109,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 110,
          "call_type": "function_call"
        },
        {
          "name": "write_text",
          "file": "unknown",
          "line": 114,
          "call_type": "method_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 136,
          "call_type": "method_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 138,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 143,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 144,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 146,
          "call_type": "function_call"
        },
        {
          "name": "unlink",
          "file": "unknown",
          "line": 149,
          "call_type": "method_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "conversation_tracking_example",
      "file": "model_chorus/examples/chat_example.py",
      "line": 152,
      "language": "python",
      "docstring": "Demonstrate conversation history tracking.",
      "parameters": [],
      "return_type": null,
      "complexity": 5,
      "decorators": [],
      "is_async": true,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "main",
          "file": "model_chorus/examples/chat_example.py",
          "line": 208,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "print",
          "file": "unknown",
          "line": 154,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 155,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 156,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 169,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 170,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 175,
          "call_type": "function_call"
        },
        {
          "name": "get_thread",
          "file": "unknown",
          "line": 181,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 183,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 184,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 185,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 185,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 186,
          "call_type": "function_call"
        },
        {
          "name": "enumerate",
          "file": "unknown",
          "line": 189,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 190,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 191,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 193,
          "call_type": "function_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 193,
          "call_type": "method_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "main",
      "file": "model_chorus/examples/chat_example.py",
      "line": 196,
      "language": "python",
      "docstring": "Run all examples.",
      "parameters": [],
      "return_type": null,
      "complexity": 1,
      "decorators": [],
      "is_async": true,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "<module>",
          "file": "examples/workflow_examples.py",
          "line": 589,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/examples/basic_workflow.py",
          "line": 105,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/examples/chat_example.py",
          "line": 216,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/examples/provider_integration.py",
          "line": 157,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/examples/thinkdeep_example.py",
          "line": 467,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1771,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 956,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
          "line": 210,
          "call_type": "method_call"
        },
        {
          "name": "<module>",
          "file": "tests/workflows/study/memory/test_cache.py",
          "line": 229,
          "call_type": "method_call"
        }
      ],
      "calls": [
        {
          "name": "basic_chat_example",
          "file": "unknown",
          "line": 199,
          "call_type": "function_call"
        },
        {
          "name": "multi_turn_conversation_example",
          "file": "unknown",
          "line": 202,
          "call_type": "function_call"
        },
        {
          "name": "chat_with_file_context_example",
          "file": "unknown",
          "line": 205,
          "call_type": "function_call"
        },
        {
          "name": "conversation_tracking_example",
          "file": "unknown",
          "line": 208,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 210,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 211,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 212,
          "call_type": "function_call"
        }
      ],
      "call_count": 9
    },
    {
      "name": "main",
      "file": "model_chorus/examples/provider_integration.py",
      "line": 101,
      "language": "python",
      "docstring": "Main entry point for the provider example.",
      "parameters": [],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": true,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "<module>",
          "file": "examples/workflow_examples.py",
          "line": 589,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/examples/basic_workflow.py",
          "line": 105,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/examples/chat_example.py",
          "line": 216,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/examples/provider_integration.py",
          "line": 157,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/examples/thinkdeep_example.py",
          "line": 467,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1771,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 956,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
          "line": 210,
          "call_type": "method_call"
        },
        {
          "name": "<module>",
          "file": "tests/workflows/study/memory/test_cache.py",
          "line": 229,
          "call_type": "method_call"
        }
      ],
      "calls": [
        {
          "name": "print",
          "file": "unknown",
          "line": 104,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 105,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 110,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 111,
          "call_type": "function_call"
        },
        {
          "name": "validate_api_key",
          "file": "unknown",
          "line": 111,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 114,
          "call_type": "function_call"
        },
        {
          "name": "get_available_models",
          "file": "unknown",
          "line": 115,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 116,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 117,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 118,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 121,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 122,
          "call_type": "function_call"
        },
        {
          "name": "supports_vision",
          "file": "unknown",
          "line": 122,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 123,
          "call_type": "function_call"
        },
        {
          "name": "supports_vision",
          "file": "unknown",
          "line": 123,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 124,
          "call_type": "function_call"
        },
        {
          "name": "supports_capability",
          "file": "unknown",
          "line": 124,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 134,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 135,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 136,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 137,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 138,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 139,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 140,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 143,
          "call_type": "function_call"
        },
        {
          "name": "generate",
          "file": "unknown",
          "line": 144,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 146,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 147,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 148,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 149,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 150,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 151,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 152,
          "call_type": "function_call"
        }
      ],
      "call_count": 9
    },
    {
      "name": "basic_investigation_example",
      "file": "model_chorus/examples/thinkdeep_example.py",
      "line": 27,
      "language": "python",
      "docstring": "Basic single-step investigation.",
      "parameters": [],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": true,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "main",
          "file": "model_chorus/examples/thinkdeep_example.py",
          "line": 440,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "print",
          "file": "unknown",
          "line": 29,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 30,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 31,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 44,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 54,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 55,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 56,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 57,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 58,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 60,
          "call_type": "function_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "multi_step_investigation_example",
      "file": "model_chorus/examples/thinkdeep_example.py",
      "line": 63,
      "language": "python",
      "docstring": "Multi-step investigation showing hypothesis evolution and confidence progression.\n\nThis example demonstrates a systematic investigation of a performance issue,\nshowing how hypotheses are formed, tested, and confidence evolves across steps.",
      "parameters": [],
      "return_type": null,
      "complexity": 10,
      "decorators": [],
      "is_async": true,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "main",
          "file": "model_chorus/examples/thinkdeep_example.py",
          "line": 443,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "print",
          "file": "unknown",
          "line": 70,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 71,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 72,
          "call_type": "function_call"
        },
        {
          "name": "items",
          "file": "unknown",
          "line": 110,
          "call_type": "method_call"
        },
        {
          "name": "write_text",
          "file": "unknown",
          "line": 111,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 124,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 125,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 132,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 136,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 137,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 138,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 139,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 140,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 143,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 144,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 152,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 153,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 154,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 155,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 156,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 159,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 160,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 168,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 169,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 170,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 171,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 172,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 175,
          "call_type": "function_call"
        },
        {
          "name": "get_investigation_state",
          "file": "unknown",
          "line": 176,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 178,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 178,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 179,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 180,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 180,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 181,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 181,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 184,
          "call_type": "function_call"
        },
        {
          "name": "enumerate",
          "file": "unknown",
          "line": 185,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 186,
          "call_type": "function_call"
        },
        {
          "name": "upper",
          "file": "unknown",
          "line": 186,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 188,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 188,
          "call_type": "function_call"
        },
        {
          "name": "keys",
          "file": "unknown",
          "line": 191,
          "call_type": "method_call"
        },
        {
          "name": "unlink",
          "file": "unknown",
          "line": 192,
          "call_type": "method_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "investigation_with_expert_validation",
      "file": "model_chorus/examples/thinkdeep_example.py",
      "line": 195,
      "language": "python",
      "docstring": "Investigation with expert validation from a different model.\n\nDemonstrates how ThinkDeep can use a second model for validation\nand additional insights when confidence hasn't reached \"certain\" level.",
      "parameters": [],
      "return_type": null,
      "complexity": 4,
      "decorators": [],
      "is_async": true,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "main",
          "file": "model_chorus/examples/thinkdeep_example.py",
          "line": 446,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "print",
          "file": "unknown",
          "line": 202,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 203,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 204,
          "call_type": "function_call"
        },
        {
          "name": "write_text",
          "file": "unknown",
          "line": 208,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 245,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 246,
          "call_type": "method_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 248,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 256,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 257,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 258,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 261,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 262,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 265,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 266,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 267,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 269,
          "call_type": "function_call"
        },
        {
          "name": "unlink",
          "file": "unknown",
          "line": 272,
          "call_type": "method_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "hypothesis_management_example",
      "file": "model_chorus/examples/thinkdeep_example.py",
      "line": 275,
      "language": "python",
      "docstring": "Demonstrate manual hypothesis management and state inspection.\n\nShows how to programmatically add, update, and track hypotheses\nduring an investigation.",
      "parameters": [],
      "return_type": null,
      "complexity": 6,
      "decorators": [],
      "is_async": true,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "main",
          "file": "model_chorus/examples/thinkdeep_example.py",
          "line": 449,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "print",
          "file": "unknown",
          "line": 282,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 283,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 284,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 295,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 296,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 302,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 306,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 307,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 310,
          "call_type": "function_call"
        },
        {
          "name": "add_hypothesis",
          "file": "unknown",
          "line": 311,
          "call_type": "method_call"
        },
        {
          "name": "add_hypothesis",
          "file": "unknown",
          "line": 318,
          "call_type": "method_call"
        },
        {
          "name": "get_investigation_summary",
          "file": "unknown",
          "line": 325,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 327,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 328,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 329,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 330,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 333,
          "call_type": "function_call"
        },
        {
          "name": "get_active_hypotheses",
          "file": "unknown",
          "line": 334,
          "call_type": "method_call"
        },
        {
          "name": "enumerate",
          "file": "unknown",
          "line": 335,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 336,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 337,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 337,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 340,
          "call_type": "function_call"
        },
        {
          "name": "update_hypothesis",
          "file": "unknown",
          "line": 343,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 349,
          "call_type": "function_call"
        },
        {
          "name": "update_confidence",
          "file": "unknown",
          "line": 352,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 353,
          "call_type": "function_call"
        },
        {
          "name": "get_confidence",
          "file": "unknown",
          "line": 353,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 356,
          "call_type": "function_call"
        },
        {
          "name": "get_investigation_summary",
          "file": "unknown",
          "line": 357,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 359,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 360,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 361,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 362,
          "call_type": "function_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "confidence_progression_example",
      "file": "model_chorus/examples/thinkdeep_example.py",
      "line": 365,
      "language": "python",
      "docstring": "Demonstrate confidence progression through investigation steps.\n\nShows how confidence should naturally increase as evidence accumulates\nand hypotheses are validated.",
      "parameters": [],
      "return_type": null,
      "complexity": 5,
      "decorators": [],
      "is_async": true,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "main",
          "file": "model_chorus/examples/thinkdeep_example.py",
          "line": 452,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "print",
          "file": "unknown",
          "line": 372,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 373,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 374,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 387,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 388,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 395,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 396,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 399,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 400,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 407,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 408,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 411,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 412,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 419,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 420,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 423,
          "call_type": "function_call"
        },
        {
          "name": "enumerate",
          "file": "unknown",
          "line": 425,
          "call_type": "function_call"
        },
        {
          "name": "index",
          "file": "unknown",
          "line": 426,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 427,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 428,
          "call_type": "function_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "main",
      "file": "model_chorus/examples/thinkdeep_example.py",
      "line": 431,
      "language": "python",
      "docstring": "Run all examples.",
      "parameters": [],
      "return_type": null,
      "complexity": 1,
      "decorators": [],
      "is_async": true,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "<module>",
          "file": "examples/workflow_examples.py",
          "line": 589,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/examples/basic_workflow.py",
          "line": 105,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/examples/chat_example.py",
          "line": 216,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/examples/provider_integration.py",
          "line": 157,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/examples/thinkdeep_example.py",
          "line": 467,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1771,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 956,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
          "line": 210,
          "call_type": "method_call"
        },
        {
          "name": "<module>",
          "file": "tests/workflows/study/memory/test_cache.py",
          "line": 229,
          "call_type": "method_call"
        }
      ],
      "calls": [
        {
          "name": "print",
          "file": "unknown",
          "line": 433,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 434,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 435,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 436,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 437,
          "call_type": "function_call"
        },
        {
          "name": "basic_investigation_example",
          "file": "unknown",
          "line": 440,
          "call_type": "function_call"
        },
        {
          "name": "multi_step_investigation_example",
          "file": "unknown",
          "line": 443,
          "call_type": "function_call"
        },
        {
          "name": "investigation_with_expert_validation",
          "file": "unknown",
          "line": 446,
          "call_type": "function_call"
        },
        {
          "name": "hypothesis_management_example",
          "file": "unknown",
          "line": 449,
          "call_type": "function_call"
        },
        {
          "name": "confidence_progression_example",
          "file": "unknown",
          "line": 452,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 454,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 455,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 456,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 457,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 458,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 459,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 460,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 461,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 462,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 463,
          "call_type": "function_call"
        }
      ],
      "call_count": 9
    },
    {
      "name": "_find_project_root",
      "file": "model_chorus/src/model_chorus/cli/main.py",
      "line": 41,
      "language": "python",
      "docstring": "Traverse upward from the starting path to locate the project root.",
      "parameters": [
        {
          "name": "start_path",
          "type": "Path",
          "default": null
        }
      ],
      "return_type": "Path",
      "complexity": 4,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": false,
      "callers": [
        {
          "name": "<module>",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 50,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "exists",
          "file": "unknown",
          "line": 44,
          "call_type": "method_call"
        },
        {
          "name": "exists",
          "file": "unknown",
          "line": 44,
          "call_type": "method_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "_format_path_for_display",
      "file": "model_chorus/src/model_chorus/cli/main.py",
      "line": 59,
      "language": "python",
      "docstring": "Return a repository-relative path when possible for cleaner display.",
      "parameters": [
        {
          "name": "path",
          "type": "Path",
          "default": null
        }
      ],
      "return_type": "str",
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": false,
      "callers": [
        {
          "name": "resolve_context_files",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 129,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "str",
          "file": "unknown",
          "line": 62,
          "call_type": "function_call"
        },
        {
          "name": "relative_to",
          "file": "unknown",
          "line": 62,
          "call_type": "method_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 64,
          "call_type": "function_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "resolve_context_files",
      "file": "model_chorus/src/model_chorus/cli/main.py",
      "line": 67,
      "language": "python",
      "docstring": "Normalize and resolve context file paths with legacy mapping support.\n\nArgs:\n    files: Raw string (comma-separated) or iterable of file paths.\n\nReturns:\n    Tuple containing:\n        resolved_paths: Paths that exist after normalization/mapping.\n        remapped_notices: Descriptions of legacy paths that were remapped.\n        missing_files: Original entries that could not be resolved.",
      "parameters": [
        {
          "name": "files",
          "type": "Optional[Union[str, Sequence[str]]]",
          "default": null
        }
      ],
      "return_type": "Tuple[List[str], List[str], List[str]]",
      "complexity": 13,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "thinkdeep",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1202,
          "call_type": "function_call"
        },
        {
          "name": "thinkdeep",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1213,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "isinstance",
          "file": "unknown",
          "line": 84,
          "call_type": "function_call"
        },
        {
          "name": "strip",
          "file": "unknown",
          "line": 85,
          "call_type": "method_call"
        },
        {
          "name": "split",
          "file": "unknown",
          "line": 85,
          "call_type": "method_call"
        },
        {
          "name": "strip",
          "file": "unknown",
          "line": 85,
          "call_type": "method_call"
        },
        {
          "name": "strip",
          "file": "unknown",
          "line": 87,
          "call_type": "method_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 87,
          "call_type": "function_call"
        },
        {
          "name": "strip",
          "file": "unknown",
          "line": 87,
          "call_type": "method_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 87,
          "call_type": "function_call"
        },
        {
          "name": "cwd",
          "file": "unknown",
          "line": 92,
          "call_type": "method_call"
        },
        {
          "name": "strip",
          "file": "unknown",
          "line": 95,
          "call_type": "method_call"
        },
        {
          "name": "replace",
          "file": "unknown",
          "line": 96,
          "call_type": "method_call"
        },
        {
          "name": "expanduser",
          "file": "unknown",
          "line": 97,
          "call_type": "method_call"
        },
        {
          "name": "is_absolute",
          "file": "unknown",
          "line": 102,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 103,
          "call_type": "method_call"
        },
        {
          "name": "resolve",
          "file": "unknown",
          "line": 103,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 105,
          "call_type": "method_call"
        },
        {
          "name": "resolve",
          "file": "unknown",
          "line": 105,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 106,
          "call_type": "method_call"
        },
        {
          "name": "resolve",
          "file": "unknown",
          "line": 106,
          "call_type": "method_call"
        },
        {
          "name": "relative_to",
          "file": "unknown",
          "line": 110,
          "call_type": "method_call"
        },
        {
          "name": "resolve",
          "file": "unknown",
          "line": 114,
          "call_type": "method_call"
        },
        {
          "name": "insert",
          "file": "unknown",
          "line": 115,
          "call_type": "method_call"
        },
        {
          "name": "set",
          "file": "unknown",
          "line": 119,
          "call_type": "function_call"
        },
        {
          "name": "as_posix",
          "file": "unknown",
          "line": 121,
          "call_type": "method_call"
        },
        {
          "name": "add",
          "file": "unknown",
          "line": 123,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 124,
          "call_type": "method_call"
        },
        {
          "name": "next",
          "file": "unknown",
          "line": 126,
          "call_type": "function_call"
        },
        {
          "name": "exists",
          "file": "unknown",
          "line": 126,
          "call_type": "method_call"
        },
        {
          "name": "_format_path_for_display",
          "file": "unknown",
          "line": 129,
          "call_type": "function_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 130,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 132,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 134,
          "call_type": "method_call"
        }
      ],
      "call_count": 2
    },
    {
      "name": "get_config",
      "file": "model_chorus/src/model_chorus/cli/main.py",
      "line": 145,
      "language": "python",
      "docstring": "Get the config loader instance, initializing if needed.",
      "parameters": [],
      "return_type": null,
      "complexity": 3,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "chat",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 262,
          "call_type": "function_call"
        },
        {
          "name": "argument",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 469,
          "call_type": "function_call"
        },
        {
          "name": "ideate",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 672,
          "call_type": "function_call"
        },
        {
          "name": "consensus",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 874,
          "call_type": "function_call"
        },
        {
          "name": "thinkdeep",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1117,
          "call_type": "function_call"
        },
        {
          "name": "_config_show",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1518,
          "call_type": "function_call"
        },
        {
          "name": "_config_show",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1519,
          "call_type": "method_call"
        },
        {
          "name": "_config_validate",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1579,
          "call_type": "function_call"
        },
        {
          "name": "start",
          "file": "model_chorus/src/model_chorus/cli/study_commands.py",
          "line": 183,
          "call_type": "function_call"
        },
        {
          "name": "study_next",
          "file": "model_chorus/src/model_chorus/cli/study_commands.py",
          "line": 437,
          "call_type": "function_call"
        },
        {
          "name": "get_workflow_default",
          "file": "model_chorus/src/model_chorus/core/config.py",
          "line": 241,
          "call_type": "method_call"
        },
        {
          "name": "get_default_provider",
          "file": "model_chorus/src/model_chorus/core/config.py",
          "line": 269,
          "call_type": "method_call"
        },
        {
          "name": "get_default_providers",
          "file": "model_chorus/src/model_chorus/core/config.py",
          "line": 296,
          "call_type": "method_call"
        },
        {
          "name": "get_fallback_providers",
          "file": "model_chorus/src/model_chorus/core/config.py",
          "line": 315,
          "call_type": "method_call"
        },
        {
          "name": "get_provider_model",
          "file": "model_chorus/src/model_chorus/core/config.py",
          "line": 365,
          "call_type": "method_call"
        },
        {
          "name": "get_config",
          "file": "model_chorus/src/model_chorus/core/config.py",
          "line": 413,
          "call_type": "method_call"
        }
      ],
      "calls": [
        {
          "name": "get_config_loader",
          "file": "unknown",
          "line": 149,
          "call_type": "function_call"
        },
        {
          "name": "load_config",
          "file": "unknown",
          "line": 151,
          "call_type": "method_call"
        }
      ],
      "call_count": 16
    },
    {
      "name": "get_install_command",
      "file": "model_chorus/src/model_chorus/cli/main.py",
      "line": 158,
      "language": "python",
      "docstring": "Get installation command for a provider CLI.\n\nArgs:\n    provider: Provider name (claude, gemini, codex, cursor-agent)\n\nReturns:\n    Installation command string",
      "parameters": [
        {
          "name": "provider",
          "type": "str",
          "default": null
        }
      ],
      "return_type": "str",
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "chat",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 286,
          "call_type": "function_call"
        },
        {
          "name": "argument",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 491,
          "call_type": "function_call"
        },
        {
          "name": "ideate",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 694,
          "call_type": "function_call"
        },
        {
          "name": "list_providers",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1723,
          "call_type": "function_call"
        },
        {
          "name": "start",
          "file": "model_chorus/src/model_chorus/cli/study_commands.py",
          "line": 211,
          "call_type": "function_call"
        },
        {
          "name": "study_next",
          "file": "model_chorus/src/model_chorus/cli/study_commands.py",
          "line": 459,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "get",
          "file": "unknown",
          "line": 173,
          "call_type": "method_call"
        },
        {
          "name": "lower",
          "file": "unknown",
          "line": 173,
          "call_type": "method_call"
        }
      ],
      "call_count": 6
    },
    {
      "name": "get_provider_by_name",
      "file": "model_chorus/src/model_chorus/cli/main.py",
      "line": 176,
      "language": "python",
      "docstring": "Get provider instance by name.\n\nArgs:\n    name: Provider name (claude, gemini, codex, cursor-agent)\n    timeout: Timeout in seconds for provider operations (default: 120)\n\nReturns:\n    Provider instance",
      "parameters": [
        {
          "name": "name",
          "type": "str",
          "default": null
        },
        {
          "name": "timeout",
          "type": "int",
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "chat",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 276,
          "call_type": "function_call"
        },
        {
          "name": "chat",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 302,
          "call_type": "function_call"
        },
        {
          "name": "argument",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 481,
          "call_type": "function_call"
        },
        {
          "name": "argument",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 507,
          "call_type": "function_call"
        },
        {
          "name": "ideate",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 684,
          "call_type": "function_call"
        },
        {
          "name": "ideate",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 710,
          "call_type": "function_call"
        },
        {
          "name": "consensus",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 903,
          "call_type": "function_call"
        },
        {
          "name": "thinkdeep",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1143,
          "call_type": "function_call"
        },
        {
          "name": "thinkdeep",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1171,
          "call_type": "function_call"
        },
        {
          "name": "start",
          "file": "model_chorus/src/model_chorus/cli/study_commands.py",
          "line": 201,
          "call_type": "function_call"
        },
        {
          "name": "start",
          "file": "model_chorus/src/model_chorus/cli/study_commands.py",
          "line": 227,
          "call_type": "function_call"
        },
        {
          "name": "study_next",
          "file": "model_chorus/src/model_chorus/cli/study_commands.py",
          "line": 449,
          "call_type": "function_call"
        },
        {
          "name": "study_next",
          "file": "model_chorus/src/model_chorus/cli/study_commands.py",
          "line": 475,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "get",
          "file": "unknown",
          "line": 193,
          "call_type": "method_call"
        },
        {
          "name": "lower",
          "file": "unknown",
          "line": 193,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 195,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 196,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 196,
          "call_type": "method_call"
        },
        {
          "name": "keys",
          "file": "unknown",
          "line": 196,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 197,
          "call_type": "method_call"
        },
        {
          "name": "provider_class",
          "file": "unknown",
          "line": 199,
          "call_type": "function_call"
        }
      ],
      "call_count": 13
    },
    {
      "name": "chat",
      "file": "model_chorus/src/model_chorus/cli/main.py",
      "line": 203,
      "language": "python",
      "docstring": "Chat with a single AI model with conversation continuity.\n\nExample:\n    # Start new conversation\n    model-chorus chat \"What is quantum computing?\" -p claude\n\n    # Continue conversation\n    model-chorus chat \"Give me an example\" --continue thread-id-123\n\n    # Include files\n    model-chorus chat \"Review this code\" -f src/main.py -f tests/test_main.py",
      "parameters": [
        {
          "name": "prompt",
          "type": "str",
          "default": null
        },
        {
          "name": "provider",
          "type": "Optional[str]",
          "default": null
        },
        {
          "name": "continuation_id",
          "type": "Optional[str]",
          "default": null
        },
        {
          "name": "files",
          "type": "Optional[List[str]]",
          "default": null
        },
        {
          "name": "system",
          "type": "Optional[str]",
          "default": null
        },
        {
          "name": "output",
          "type": "Optional[Path]",
          "default": null
        },
        {
          "name": "verbose",
          "type": "bool",
          "default": null
        },
        {
          "name": "skip_provider_check",
          "type": "bool",
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 27,
      "decorators": [
        "app.command()"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "Option",
          "file": "unknown",
          "line": 204,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 205,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 211,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 218,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 224,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 229,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 235,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 241,
          "call_type": "method_call"
        },
        {
          "name": "get_config",
          "file": "unknown",
          "line": 262,
          "call_type": "function_call"
        },
        {
          "name": "get_default_provider",
          "file": "unknown",
          "line": 264,
          "call_type": "method_call"
        },
        {
          "name": "get_workflow_default",
          "file": "unknown",
          "line": 266,
          "call_type": "method_call"
        },
        {
          "name": "get_workflow_default",
          "file": "unknown",
          "line": 269,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 273,
          "call_type": "method_call"
        },
        {
          "name": "get_provider_by_name",
          "file": "unknown",
          "line": 276,
          "call_type": "function_call"
        },
        {
          "name": "int",
          "file": "unknown",
          "line": 276,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 278,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 281,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 283,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 285,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 286,
          "call_type": "method_call"
        },
        {
          "name": "get_install_command",
          "file": "unknown",
          "line": 286,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 287,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 288,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 290,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 291,
          "call_type": "method_call"
        },
        {
          "name": "get_workflow_default",
          "file": "unknown",
          "line": 294,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 298,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 298,
          "call_type": "method_call"
        },
        {
          "name": "get_provider_by_name",
          "file": "unknown",
          "line": 302,
          "call_type": "function_call"
        },
        {
          "name": "int",
          "file": "unknown",
          "line": 302,
          "call_type": "function_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 303,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 305,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 308,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 321,
          "call_type": "method_call"
        },
        {
          "name": "construct_prompt_with_files",
          "file": "unknown",
          "line": 323,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 326,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 327,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 327,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 328,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 330,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 332,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 332,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 333,
          "call_type": "method_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 336,
          "call_type": "method_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 337,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 348,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 351,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 352,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 353,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 355,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 357,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 359,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 360,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 363,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 364,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 367,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 369,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 369,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 379,
          "call_type": "method_call"
        },
        {
          "name": "write_text",
          "file": "unknown",
          "line": 386,
          "call_type": "method_call"
        },
        {
          "name": "dumps",
          "file": "unknown",
          "line": 386,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 387,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 389,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 392,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 393,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 396,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 397,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 399,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 402,
          "call_type": "method_call"
        },
        {
          "name": "format_exc",
          "file": "unknown",
          "line": 402,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 403,
          "call_type": "method_call"
        },
        {
          "name": "command",
          "file": "unknown",
          "line": 202,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "argument",
      "file": "model_chorus/src/model_chorus/cli/main.py",
      "line": 407,
      "language": "python",
      "docstring": "Analyze arguments through structured dialectical reasoning.\n\nThe argument workflow uses role-based orchestration to examine claims from\nmultiple perspectives: Creator (thesis), Skeptic (critique), and Moderator (synthesis).\n\nExample:\n    # Analyze an argument\n    model-chorus argument \"Universal basic income would reduce poverty\"\n\n    # Continue analysis\n    model-chorus argument \"What about inflation?\" --continue thread-id-123\n\n    # Include supporting files\n    model-chorus argument \"Review this proposal\" -f proposal.md -f data.csv",
      "parameters": [
        {
          "name": "prompt",
          "type": "str",
          "default": null
        },
        {
          "name": "provider",
          "type": "Optional[str]",
          "default": null
        },
        {
          "name": "continuation_id",
          "type": "Optional[str]",
          "default": null
        },
        {
          "name": "files",
          "type": "Optional[List[str]]",
          "default": null
        },
        {
          "name": "system",
          "type": "Optional[str]",
          "default": null
        },
        {
          "name": "output",
          "type": "Optional[Path]",
          "default": null
        },
        {
          "name": "verbose",
          "type": "bool",
          "default": null
        },
        {
          "name": "skip_provider_check",
          "type": "bool",
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 25,
      "decorators": [
        "app.command()"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "Option",
          "file": "unknown",
          "line": 408,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 409,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 415,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 422,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 428,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 433,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 439,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 445,
          "call_type": "method_call"
        },
        {
          "name": "get_config",
          "file": "unknown",
          "line": 469,
          "call_type": "function_call"
        },
        {
          "name": "get_default_provider",
          "file": "unknown",
          "line": 471,
          "call_type": "method_call"
        },
        {
          "name": "get_workflow_default",
          "file": "unknown",
          "line": 474,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 478,
          "call_type": "method_call"
        },
        {
          "name": "get_provider_by_name",
          "file": "unknown",
          "line": 481,
          "call_type": "function_call"
        },
        {
          "name": "int",
          "file": "unknown",
          "line": 481,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 483,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 486,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 488,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 490,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 491,
          "call_type": "method_call"
        },
        {
          "name": "get_install_command",
          "file": "unknown",
          "line": 491,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 492,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 493,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 495,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 496,
          "call_type": "method_call"
        },
        {
          "name": "get_workflow_default",
          "file": "unknown",
          "line": 499,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 503,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 503,
          "call_type": "method_call"
        },
        {
          "name": "get_provider_by_name",
          "file": "unknown",
          "line": 507,
          "call_type": "function_call"
        },
        {
          "name": "int",
          "file": "unknown",
          "line": 507,
          "call_type": "function_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 508,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 510,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 513,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 526,
          "call_type": "method_call"
        },
        {
          "name": "construct_prompt_with_files",
          "file": "unknown",
          "line": 528,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 531,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 532,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 532,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 540,
          "call_type": "method_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 541,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 551,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 552,
          "call_type": "method_call"
        },
        {
          "name": "enumerate",
          "file": "unknown",
          "line": 556,
          "call_type": "function_call"
        },
        {
          "name": "hasattr",
          "file": "unknown",
          "line": 557,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 558,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 559,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 563,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 564,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 568,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 568,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 569,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 569,
          "call_type": "method_call"
        },
        {
          "name": "hasattr",
          "file": "unknown",
          "line": 578,
          "call_type": "function_call"
        },
        {
          "name": "hasattr",
          "file": "unknown",
          "line": 580,
          "call_type": "function_call"
        },
        {
          "name": "enumerate",
          "file": "unknown",
          "line": 582,
          "call_type": "function_call"
        },
        {
          "name": "open",
          "file": "unknown",
          "line": 587,
          "call_type": "function_call"
        },
        {
          "name": "dump",
          "file": "unknown",
          "line": 588,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 590,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 593,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 594,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 596,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 599,
          "call_type": "method_call"
        },
        {
          "name": "format_exc",
          "file": "unknown",
          "line": 599,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 600,
          "call_type": "method_call"
        },
        {
          "name": "command",
          "file": "unknown",
          "line": 406,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "ideate",
      "file": "model_chorus/src/model_chorus/cli/main.py",
      "line": 604,
      "language": "python",
      "docstring": "Generate creative ideas through structured brainstorming.\n\nThe ideate workflow uses enhanced creative prompting to generate diverse\nand innovative ideas for any topic or problem.\n\nExample:\n    # Generate ideas\n    model-chorus ideate \"New features for a task management app\"\n\n    # Control creativity and quantity\n    model-chorus ideate \"Marketing campaign ideas\" -n 10 -t 1.0\n\n    # Continue brainstorming\n    model-chorus ideate \"Refine the third idea\" --continue thread-id-123",
      "parameters": [
        {
          "name": "prompt",
          "type": "str",
          "default": null
        },
        {
          "name": "provider",
          "type": "Optional[str]",
          "default": null
        },
        {
          "name": "continuation_id",
          "type": "Optional[str]",
          "default": null
        },
        {
          "name": "files",
          "type": "Optional[List[str]]",
          "default": null
        },
        {
          "name": "num_ideas",
          "type": "int",
          "default": null
        },
        {
          "name": "system",
          "type": "Optional[str]",
          "default": null
        },
        {
          "name": "output",
          "type": "Optional[Path]",
          "default": null
        },
        {
          "name": "verbose",
          "type": "bool",
          "default": null
        },
        {
          "name": "skip_provider_check",
          "type": "bool",
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 25,
      "decorators": [
        "app.command()"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "Option",
          "file": "unknown",
          "line": 605,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 606,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 612,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 619,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 625,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 631,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 636,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 642,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 648,
          "call_type": "method_call"
        },
        {
          "name": "get_config",
          "file": "unknown",
          "line": 672,
          "call_type": "function_call"
        },
        {
          "name": "get_default_provider",
          "file": "unknown",
          "line": 674,
          "call_type": "method_call"
        },
        {
          "name": "get_workflow_default",
          "file": "unknown",
          "line": 677,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 681,
          "call_type": "method_call"
        },
        {
          "name": "get_provider_by_name",
          "file": "unknown",
          "line": 684,
          "call_type": "function_call"
        },
        {
          "name": "int",
          "file": "unknown",
          "line": 684,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 686,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 689,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 691,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 693,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 694,
          "call_type": "method_call"
        },
        {
          "name": "get_install_command",
          "file": "unknown",
          "line": 694,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 695,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 696,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 698,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 699,
          "call_type": "method_call"
        },
        {
          "name": "get_workflow_default",
          "file": "unknown",
          "line": 702,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 706,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 706,
          "call_type": "method_call"
        },
        {
          "name": "get_provider_by_name",
          "file": "unknown",
          "line": 710,
          "call_type": "function_call"
        },
        {
          "name": "int",
          "file": "unknown",
          "line": 710,
          "call_type": "function_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 711,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 713,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 716,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 729,
          "call_type": "method_call"
        },
        {
          "name": "construct_prompt_with_files",
          "file": "unknown",
          "line": 731,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 734,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 735,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 735,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 736,
          "call_type": "method_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 746,
          "call_type": "method_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 747,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 757,
          "call_type": "method_call"
        },
        {
          "name": "enumerate",
          "file": "unknown",
          "line": 761,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 762,
          "call_type": "method_call"
        },
        {
          "name": "hasattr",
          "file": "unknown",
          "line": 762,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 763,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 767,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 768,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 772,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 772,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 773,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 773,
          "call_type": "method_call"
        },
        {
          "name": "hasattr",
          "file": "unknown",
          "line": 782,
          "call_type": "function_call"
        },
        {
          "name": "hasattr",
          "file": "unknown",
          "line": 784,
          "call_type": "function_call"
        },
        {
          "name": "enumerate",
          "file": "unknown",
          "line": 786,
          "call_type": "function_call"
        },
        {
          "name": "open",
          "file": "unknown",
          "line": 791,
          "call_type": "function_call"
        },
        {
          "name": "dump",
          "file": "unknown",
          "line": 792,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 794,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 797,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 798,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 800,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 803,
          "call_type": "method_call"
        },
        {
          "name": "format_exc",
          "file": "unknown",
          "line": 803,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 804,
          "call_type": "method_call"
        },
        {
          "name": "command",
          "file": "unknown",
          "line": 603,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "construct_prompt_with_files",
      "file": "model_chorus/src/model_chorus/cli/main.py",
      "line": 806,
      "language": "python",
      "docstring": "Construct a prompt by prepending the content of files.",
      "parameters": [
        {
          "name": "prompt",
          "type": "str",
          "default": null
        },
        {
          "name": "files",
          "type": "Optional[List[str]]",
          "default": null
        }
      ],
      "return_type": "str",
      "complexity": 4,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "chat",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 323,
          "call_type": "function_call"
        },
        {
          "name": "argument",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 528,
          "call_type": "function_call"
        },
        {
          "name": "ideate",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 731,
          "call_type": "function_call"
        },
        {
          "name": "consensus",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 894,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "exists",
          "file": "unknown",
          "line": 813,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 814,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 815,
          "call_type": "method_call"
        },
        {
          "name": "open",
          "file": "unknown",
          "line": 816,
          "call_type": "function_call"
        },
        {
          "name": "read",
          "file": "unknown",
          "line": 817,
          "call_type": "method_call"
        }
      ],
      "call_count": 4
    },
    {
      "name": "consensus",
      "file": "model_chorus/src/model_chorus/cli/main.py",
      "line": 823,
      "language": "python",
      "docstring": "Run consensus workflow across multiple AI models.\n\nExample:\n    model-chorus consensus \"Explain quantum computing\" -p claude -p gemini -s synthesize",
      "parameters": [
        {
          "name": "prompt",
          "type": "str",
          "default": null
        },
        {
          "name": "providers",
          "type": "Optional[List[str]]",
          "default": null
        },
        {
          "name": "strategy",
          "type": "Optional[str]",
          "default": null
        },
        {
          "name": "files",
          "type": "Optional[List[str]]",
          "default": null
        },
        {
          "name": "system",
          "type": "Optional[str]",
          "default": null
        },
        {
          "name": "timeout",
          "type": "Optional[float]",
          "default": null
        },
        {
          "name": "output",
          "type": "Optional[Path]",
          "default": null
        },
        {
          "name": "verbose",
          "type": "bool",
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 26,
      "decorators": [
        "app.command()"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "Option",
          "file": "unknown",
          "line": 824,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 825,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 831,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 837,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 843,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 848,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 853,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 859,
          "call_type": "method_call"
        },
        {
          "name": "get_config",
          "file": "unknown",
          "line": 874,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 875,
          "call_type": "function_call"
        },
        {
          "name": "get_default_providers",
          "file": "unknown",
          "line": 876,
          "call_type": "method_call"
        },
        {
          "name": "get_workflow_default",
          "file": "unknown",
          "line": 878,
          "call_type": "method_call"
        },
        {
          "name": "get_workflow_default",
          "file": "unknown",
          "line": 880,
          "call_type": "method_call"
        },
        {
          "name": "get_workflow_default",
          "file": "unknown",
          "line": 882,
          "call_type": "method_call"
        },
        {
          "name": "upper",
          "file": "unknown",
          "line": 886,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 888,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 889,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 890,
          "call_type": "method_call"
        },
        {
          "name": "lower",
          "file": "unknown",
          "line": 890,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 892,
          "call_type": "method_call"
        },
        {
          "name": "construct_prompt_with_files",
          "file": "unknown",
          "line": 894,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 898,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 898,
          "call_type": "method_call"
        },
        {
          "name": "get_provider_by_name",
          "file": "unknown",
          "line": 903,
          "call_type": "function_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 904,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 906,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 908,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 909,
          "call_type": "method_call"
        },
        {
          "name": "lower",
          "file": "unknown",
          "line": 920,
          "call_type": "method_call"
        },
        {
          "name": "get_provider_model",
          "file": "unknown",
          "line": 921,
          "call_type": "method_call"
        },
        {
          "name": "dict",
          "file": "unknown",
          "line": 923,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 928,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 933,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 942,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 943,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 943,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 944,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 944,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 945,
          "call_type": "method_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 948,
          "call_type": "method_call"
        },
        {
          "name": "execute",
          "file": "unknown",
          "line": 948,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 951,
          "call_type": "method_call"
        },
        {
          "name": "add_column",
          "file": "unknown",
          "line": 955,
          "call_type": "method_call"
        },
        {
          "name": "add_column",
          "file": "unknown",
          "line": 956,
          "call_type": "method_call"
        },
        {
          "name": "add_column",
          "file": "unknown",
          "line": 957,
          "call_type": "method_call"
        },
        {
          "name": "add_row",
          "file": "unknown",
          "line": 962,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 965,
          "call_type": "function_call"
        },
        {
          "name": "add_row",
          "file": "unknown",
          "line": 968,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 974,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 975,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 980,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 982,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 983,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 985,
          "call_type": "method_call"
        },
        {
          "name": "items",
          "file": "unknown",
          "line": 1001,
          "call_type": "method_call"
        },
        {
          "name": "write_text",
          "file": "unknown",
          "line": 1007,
          "call_type": "method_call"
        },
        {
          "name": "dumps",
          "file": "unknown",
          "line": 1007,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1008,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1012,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 1013,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 1015,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1016,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 1017,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1020,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 1021,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1023,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1026,
          "call_type": "method_call"
        },
        {
          "name": "format_exc",
          "file": "unknown",
          "line": 1026,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 1027,
          "call_type": "method_call"
        },
        {
          "name": "command",
          "file": "unknown",
          "line": 822,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "thinkdeep",
      "file": "model_chorus/src/model_chorus/cli/main.py",
      "line": 1031,
      "language": "python",
      "docstring": "Start a ThinkDeep investigation for systematic problem analysis.\n\nThinkDeep provides multi-step investigation with explicit hypothesis tracking,\nconfidence progression, and state management across investigation steps.\n\nExample:\n    # Start new investigation\n    model-chorus thinkdeep --step \"Investigate why API latency increased\" --step-number 1 --total-steps 3 --next-step-required --findings \"Examining deployment logs\" --confidence exploring\n\n    # Continue investigation\n    model-chorus thinkdeep --continuation-id \"thread-123\" --step \"Check database query performance\" --step-number 2 --total-steps 3 --next-step-required --findings \"Found N+1 query pattern\" --confidence medium --hypothesis \"N+1 queries causing slowdown\"\n\n    # Final step (omit --next-step-required)\n    model-chorus thinkdeep --continuation-id \"thread-123\" --step \"Verify fix resolves issue\" --step-number 3 --total-steps 3 --findings \"Latency reduced to baseline\" --confidence high --hypothesis \"Confirmed: N+1 queries were root cause\"",
      "parameters": [
        {
          "name": "step",
          "type": "str",
          "default": null
        },
        {
          "name": "step_number",
          "type": "int",
          "default": null
        },
        {
          "name": "total_steps",
          "type": "int",
          "default": null
        },
        {
          "name": "next_step_required",
          "type": "bool",
          "default": null
        },
        {
          "name": "findings",
          "type": "str",
          "default": null
        },
        {
          "name": "model",
          "type": "Optional[str]",
          "default": null
        },
        {
          "name": "continuation_id",
          "type": "Optional[str]",
          "default": null
        },
        {
          "name": "hypothesis",
          "type": "Optional[str]",
          "default": null
        },
        {
          "name": "confidence",
          "type": "str",
          "default": null
        },
        {
          "name": "files_checked",
          "type": "Optional[str]",
          "default": null
        },
        {
          "name": "relevant_files",
          "type": "Optional[str]",
          "default": null
        },
        {
          "name": "thinking_mode",
          "type": "Optional[str]",
          "default": null
        },
        {
          "name": "use_assistant_model",
          "type": "bool",
          "default": null
        },
        {
          "name": "output",
          "type": "Optional[Path]",
          "default": null
        },
        {
          "name": "verbose",
          "type": "bool",
          "default": null
        },
        {
          "name": "skip_provider_check",
          "type": "bool",
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 56,
      "decorators": [
        "app.command()"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "Option",
          "file": "unknown",
          "line": 1032,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 1033,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 1034,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 1035,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 1040,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 1041,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 1046,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 1051,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 1056,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 1061,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 1066,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 1071,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 1076,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 1081,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 1087,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 1093,
          "call_type": "method_call"
        },
        {
          "name": "get_config",
          "file": "unknown",
          "line": 1117,
          "call_type": "function_call"
        },
        {
          "name": "get_default_provider",
          "file": "unknown",
          "line": 1119,
          "call_type": "method_call"
        },
        {
          "name": "get_workflow_default",
          "file": "unknown",
          "line": 1121,
          "call_type": "method_call"
        },
        {
          "name": "get_workflow_default",
          "file": "unknown",
          "line": 1124,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1129,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 1129,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 1130,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1135,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 1135,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 1136,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1140,
          "call_type": "method_call"
        },
        {
          "name": "get_provider_by_name",
          "file": "unknown",
          "line": 1143,
          "call_type": "function_call"
        },
        {
          "name": "int",
          "file": "unknown",
          "line": 1143,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1145,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1147,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 1148,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1154,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1155,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1157,
          "call_type": "method_call"
        },
        {
          "name": "sleep",
          "file": "unknown",
          "line": 1159,
          "call_type": "method_call"
        },
        {
          "name": "get_fallback_providers_excluding",
          "file": "unknown",
          "line": 1163,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1167,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 1167,
          "call_type": "method_call"
        },
        {
          "name": "get_provider_by_name",
          "file": "unknown",
          "line": 1171,
          "call_type": "function_call"
        },
        {
          "name": "int",
          "file": "unknown",
          "line": 1171,
          "call_type": "function_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 1172,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1174,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1177,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1197,
          "call_type": "method_call"
        },
        {
          "name": "resolve_context_files",
          "file": "unknown",
          "line": 1202,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1205,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1207,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 1207,
          "call_type": "method_call"
        },
        {
          "name": "resolve_context_files",
          "file": "unknown",
          "line": 1213,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1216,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1218,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 1218,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 1219,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1223,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1224,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1225,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1226,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1228,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1230,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1232,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 1232,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1234,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 1234,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1235,
          "call_type": "method_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 1238,
          "call_type": "method_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 1239,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1257,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 1260,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 1261,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1263,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1264,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1265,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1267,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1268,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1270,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 1270,
          "call_type": "function_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 1271,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1273,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 1273,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 1274,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1276,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 1276,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1277,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1280,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1281,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 1284,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1285,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1286,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 1289,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1291,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 1291,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 1312,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 1315,
          "call_type": "function_call"
        },
        {
          "name": "write_text",
          "file": "unknown",
          "line": 1318,
          "call_type": "method_call"
        },
        {
          "name": "dumps",
          "file": "unknown",
          "line": 1318,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1319,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1323,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1324,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1326,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1329,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 1330,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1333,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 1334,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1336,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1339,
          "call_type": "method_call"
        },
        {
          "name": "format_exc",
          "file": "unknown",
          "line": 1339,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 1340,
          "call_type": "method_call"
        },
        {
          "name": "command",
          "file": "unknown",
          "line": 1030,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "thinkdeep_status",
      "file": "model_chorus/src/model_chorus/cli/main.py",
      "line": 1344,
      "language": "python",
      "docstring": "Inspect the state of an ongoing ThinkDeep investigation.\n\nShows current hypotheses, confidence level, investigation progress,\nand optionally all steps and examined files.\n\nExample:\n    # View basic status\n    model-chorus thinkdeep-status thread-id-123\n\n    # View with all steps\n    model-chorus thinkdeep-status thread-id-123 --steps\n\n    # View with files\n    model-chorus thinkdeep-status thread-id-123 --files --verbose",
      "parameters": [
        {
          "name": "thread_id",
          "type": "str",
          "default": null
        },
        {
          "name": "show_steps",
          "type": "bool",
          "default": null
        },
        {
          "name": "show_files",
          "type": "bool",
          "default": null
        },
        {
          "name": "verbose",
          "type": "bool",
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 18,
      "decorators": [
        "app.command(name='thinkdeep-status')"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "Argument",
          "file": "unknown",
          "line": 1345,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 1346,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 1351,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 1356,
          "call_type": "method_call"
        },
        {
          "name": "get_investigation_state",
          "file": "unknown",
          "line": 1392,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1395,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1396,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 1397,
          "call_type": "method_call"
        },
        {
          "name": "get_investigation_summary",
          "file": "unknown",
          "line": 1400,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1403,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1404,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1407,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1408,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 1408,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1409,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 1409,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1410,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 1410,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1413,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1414,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1415,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1416,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1420,
          "call_type": "method_call"
        },
        {
          "name": "enumerate",
          "file": "unknown",
          "line": 1421,
          "call_type": "function_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 1422,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1427,
          "call_type": "method_call"
        },
        {
          "name": "upper",
          "file": "unknown",
          "line": 1427,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1429,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 1429,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1431,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1433,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1437,
          "call_type": "method_call"
        },
        {
          "name": "enumerate",
          "file": "unknown",
          "line": 1438,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1439,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1440,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1441,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 1441,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1443,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 1446,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1447,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1451,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1453,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1455,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1458,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 1459,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1461,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1464,
          "call_type": "method_call"
        },
        {
          "name": "format_exc",
          "file": "unknown",
          "line": 1464,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 1465,
          "call_type": "method_call"
        },
        {
          "name": "command",
          "file": "unknown",
          "line": 1343,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "config_cmd",
      "file": "model_chorus/src/model_chorus/cli/main.py",
      "line": 1469,
      "language": "python",
      "docstring": "Manage ModelChorus configuration.\n\nSubcommands:\n    show     - Display current effective configuration\n    validate - Validate .model-chorusrc file\n    init     - Generate sample .model-chorusrc file\n\nExamples:\n    model-chorus config show\n    model-chorus config validate\n    model-chorus config init",
      "parameters": [
        {
          "name": "subcommand",
          "type": "str",
          "default": null
        },
        {
          "name": "verbose",
          "type": "bool",
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 7,
      "decorators": [
        "app.command(name='config')"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "Argument",
          "file": "unknown",
          "line": 1470,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 1474,
          "call_type": "method_call"
        },
        {
          "name": "_config_show",
          "file": "unknown",
          "line": 1496,
          "call_type": "function_call"
        },
        {
          "name": "_config_validate",
          "file": "unknown",
          "line": 1498,
          "call_type": "function_call"
        },
        {
          "name": "_config_init",
          "file": "unknown",
          "line": 1500,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1502,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1503,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 1504,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1506,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 1507,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1509,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1512,
          "call_type": "method_call"
        },
        {
          "name": "format_exc",
          "file": "unknown",
          "line": 1512,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 1513,
          "call_type": "method_call"
        },
        {
          "name": "command",
          "file": "unknown",
          "line": 1468,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "_config_show",
      "file": "model_chorus/src/model_chorus/cli/main.py",
      "line": 1516,
      "language": "python",
      "docstring": "Show current effective configuration.",
      "parameters": [
        {
          "name": "verbose",
          "type": "bool",
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 15,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": false,
      "callers": [
        {
          "name": "config_cmd",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1496,
          "call_type": "function_call"
        },
        {
          "name": "_config_validate",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1599,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "get_config",
          "file": "unknown",
          "line": 1518,
          "call_type": "function_call"
        },
        {
          "name": "get_config",
          "file": "unknown",
          "line": 1519,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1521,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1525,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1527,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1530,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1532,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1534,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1537,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1539,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1541,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1543,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1545,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1549,
          "call_type": "method_call"
        },
        {
          "name": "items",
          "file": "unknown",
          "line": 1550,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1551,
          "call_type": "method_call"
        },
        {
          "name": "model_dump",
          "file": "unknown",
          "line": 1552,
          "call_type": "method_call"
        },
        {
          "name": "items",
          "file": "unknown",
          "line": 1553,
          "call_type": "method_call"
        },
        {
          "name": "isinstance",
          "file": "unknown",
          "line": 1554,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1555,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 1555,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1557,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1561,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1564,
          "call_type": "method_call"
        },
        {
          "name": "get_default_providers",
          "file": "unknown",
          "line": 1566,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1567,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 1567,
          "call_type": "method_call"
        },
        {
          "name": "get_default_provider",
          "file": "unknown",
          "line": 1569,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1570,
          "call_type": "method_call"
        },
        {
          "name": "get_workflow_default",
          "file": "unknown",
          "line": 1571,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1572,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1574,
          "call_type": "method_call"
        }
      ],
      "call_count": 2
    },
    {
      "name": "_config_validate",
      "file": "model_chorus/src/model_chorus/cli/main.py",
      "line": 1577,
      "language": "python",
      "docstring": "Validate .model-chorusrc file.",
      "parameters": [
        {
          "name": "verbose",
          "type": "bool",
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 4,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": false,
      "callers": [
        {
          "name": "config_cmd",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1498,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "get_config",
          "file": "unknown",
          "line": 1579,
          "call_type": "function_call"
        },
        {
          "name": "find_config_file",
          "file": "unknown",
          "line": 1582,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1585,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1586,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1587,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 1588,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1590,
          "call_type": "method_call"
        },
        {
          "name": "load_config",
          "file": "unknown",
          "line": 1594,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1595,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1598,
          "call_type": "method_call"
        },
        {
          "name": "_config_show",
          "file": "unknown",
          "line": 1599,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1601,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1602,
          "call_type": "method_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 1602,
          "call_type": "function_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 1603,
          "call_type": "method_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "_config_init",
      "file": "model_chorus/src/model_chorus/cli/main.py",
      "line": 1606,
      "language": "python",
      "docstring": "Initialize a sample .model-chorusrc file.",
      "parameters": [
        {
          "name": "verbose",
          "type": "bool",
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 4,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": false,
      "callers": [
        {
          "name": "config_cmd",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1500,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "cwd",
          "file": "unknown",
          "line": 1609,
          "call_type": "method_call"
        },
        {
          "name": "exists",
          "file": "unknown",
          "line": 1611,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1612,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1613,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 1614,
          "call_type": "method_call"
        },
        {
          "name": "open",
          "file": "unknown",
          "line": 1657,
          "call_type": "function_call"
        },
        {
          "name": "write",
          "file": "unknown",
          "line": 1658,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1660,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1661,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1662,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1665,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1666,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1668,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 1669,
          "call_type": "method_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "list_providers",
      "file": "model_chorus/src/model_chorus/cli/main.py",
      "line": 1673,
      "language": "python",
      "docstring": "List all available providers and their models.\n\nUse --check to verify which providers are actually installed and working.",
      "parameters": [
        {
          "name": "check",
          "type": "bool",
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 8,
      "decorators": [
        "app.command()"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "Option",
          "file": "unknown",
          "line": 1674,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1691,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1700,
          "call_type": "method_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 1707,
          "call_type": "method_call"
        },
        {
          "name": "check_all",
          "file": "unknown",
          "line": 1707,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1716,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1717,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1718,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1719,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1722,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1723,
          "call_type": "method_call"
        },
        {
          "name": "get_install_command",
          "file": "unknown",
          "line": 1723,
          "call_type": "function_call"
        },
        {
          "name": "get_available_models",
          "file": "unknown",
          "line": 1725,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1726,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 1726,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1729,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 1729,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1731,
          "call_type": "method_call"
        },
        {
          "name": "items",
          "file": "unknown",
          "line": 1734,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1735,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1736,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1737,
          "call_type": "method_call"
        },
        {
          "name": "get_available_models",
          "file": "unknown",
          "line": 1739,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1740,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 1740,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1744,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 1744,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1746,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1748,
          "call_type": "method_call"
        },
        {
          "name": "command",
          "file": "unknown",
          "line": 1672,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "version",
      "file": "model_chorus/src/model_chorus/cli/main.py",
      "line": 1754,
      "language": "python",
      "docstring": "Show version information.",
      "parameters": [],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "app.command()"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "print",
          "file": "unknown",
          "line": 1756,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1757,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1758,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1759,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1760,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1761,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 1762,
          "call_type": "method_call"
        },
        {
          "name": "command",
          "file": "unknown",
          "line": 1753,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "main",
      "file": "model_chorus/src/model_chorus/cli/main.py",
      "line": 1765,
      "language": "python",
      "docstring": "Main entry point for CLI.",
      "parameters": [],
      "return_type": null,
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "<module>",
          "file": "examples/workflow_examples.py",
          "line": 589,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/examples/basic_workflow.py",
          "line": 105,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/examples/chat_example.py",
          "line": 216,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/examples/provider_integration.py",
          "line": 157,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/examples/thinkdeep_example.py",
          "line": 467,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1771,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 956,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
          "line": 210,
          "call_type": "method_call"
        },
        {
          "name": "<module>",
          "file": "tests/workflows/study/memory/test_cache.py",
          "line": 229,
          "call_type": "method_call"
        }
      ],
      "calls": [
        {
          "name": "app",
          "file": "unknown",
          "line": 1767,
          "call_type": "function_call"
        }
      ],
      "call_count": 9
    },
    {
      "name": "check_package_installed",
      "file": "model_chorus/src/model_chorus/cli/setup.py",
      "line": 24,
      "language": "python",
      "docstring": "Check if model-chorus package is installed.\n\nReturns:\n    Dict with installation status and details",
      "parameters": [],
      "return_type": "Dict[str, Any]",
      "complexity": 5,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "check_version_compatibility",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 132,
          "call_type": "function_call"
        },
        {
          "name": "main",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 899,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "run",
          "file": "unknown",
          "line": 31,
          "call_type": "method_call"
        },
        {
          "name": "split",
          "file": "unknown",
          "line": 40,
          "call_type": "method_call"
        },
        {
          "name": "strip",
          "file": "unknown",
          "line": 40,
          "call_type": "method_call"
        },
        {
          "name": "split",
          "file": "unknown",
          "line": 44,
          "call_type": "method_call"
        },
        {
          "name": "lower",
          "file": "unknown",
          "line": 45,
          "call_type": "method_call"
        },
        {
          "name": "strip",
          "file": "unknown",
          "line": 45,
          "call_type": "method_call"
        },
        {
          "name": "strip",
          "file": "unknown",
          "line": 45,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 49,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 50,
          "call_type": "method_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 60,
          "call_type": "function_call"
        }
      ],
      "call_count": 2
    },
    {
      "name": "install_package",
      "file": "model_chorus/src/model_chorus/cli/setup.py",
      "line": 64,
      "language": "python",
      "docstring": "Install model-chorus package.\n\nArgs:\n    dev_mode: If True, install in editable mode with -e flag\n\nReturns:\n    Dict with installation result",
      "parameters": [
        {
          "name": "dev_mode",
          "type": "bool",
          "default": null
        }
      ],
      "return_type": "Dict[str, Any]",
      "complexity": 4,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "main",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 905,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "run",
          "file": "unknown",
          "line": 81,
          "call_type": "method_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 103,
          "call_type": "function_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "check_version_compatibility",
      "file": "model_chorus/src/model_chorus/cli/setup.py",
      "line": 107,
      "language": "python",
      "docstring": "Check if installed package version matches plugin version.\n\nCompares the version from .claude-plugin/plugin.json with the installed\npackage version. If package version is lower, recommends reinstall.\n\nReturns:\n    Dict with compatibility status and version details",
      "parameters": [],
      "return_type": "Dict[str, Any]",
      "complexity": 9,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "main",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 901,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "cwd",
          "file": "unknown",
          "line": 118,
          "call_type": "method_call"
        },
        {
          "name": "exists",
          "file": "unknown",
          "line": 121,
          "call_type": "method_call"
        },
        {
          "name": "open",
          "file": "unknown",
          "line": 122,
          "call_type": "function_call"
        },
        {
          "name": "load",
          "file": "unknown",
          "line": 123,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 124,
          "call_type": "method_call"
        },
        {
          "name": "check_package_installed",
          "file": "unknown",
          "line": 132,
          "call_type": "function_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 134,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 140,
          "call_type": "method_call"
        },
        {
          "name": "parse_version",
          "file": "unknown",
          "line": 160,
          "call_type": "function_call"
        },
        {
          "name": "parse_version",
          "file": "unknown",
          "line": 161,
          "call_type": "function_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 190,
          "call_type": "function_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "check_available_providers",
      "file": "model_chorus/src/model_chorus/cli/setup.py",
      "line": 195,
      "language": "python",
      "docstring": "Check which CLI providers are available on the system.\n\nReturns:\n    Dict with available provider names and details",
      "parameters": [],
      "return_type": "Dict[str, Any]",
      "complexity": 5,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "create_express_config",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 417,
          "call_type": "function_call"
        },
        {
          "name": "create_tiered_config",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 526,
          "call_type": "function_call"
        },
        {
          "name": "main",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 903,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "run",
          "file": "unknown",
          "line": 231,
          "call_type": "method_call"
        },
        {
          "name": "check_all",
          "file": "unknown",
          "line": 231,
          "call_type": "function_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 235,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 237,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 242,
          "call_type": "function_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 250,
          "call_type": "function_call"
        }
      ],
      "call_count": 3
    },
    {
      "name": "check_config_exists",
      "file": "model_chorus/src/model_chorus/cli/setup.py",
      "line": 254,
      "language": "python",
      "docstring": "Check if .model-chorusrc config file exists.\n\nArgs:\n    project_root: Project root directory (defaults to cwd)\n\nReturns:\n    Dict with config file status",
      "parameters": [
        {
          "name": "project_root",
          "type": "Optional[Path]",
          "default": null
        }
      ],
      "return_type": "Dict[str, Any]",
      "complexity": 4,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "main",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 907,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "cwd",
          "file": "unknown",
          "line": 264,
          "call_type": "method_call"
        },
        {
          "name": "exists",
          "file": "unknown",
          "line": 275,
          "call_type": "method_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 278,
          "call_type": "function_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "create_config_file",
      "file": "model_chorus/src/model_chorus/cli/setup.py",
      "line": 288,
      "language": "python",
      "docstring": "Create .model-chorusrc configuration file.\n\nArgs:\n    project_root: Project root directory (defaults to cwd)\n    default_provider: Default AI provider\n    timeout: Default timeout in seconds\n    available_providers: List of available providers for model config\n    workflows: Workflow-specific configurations (optional)\n\nReturns:\n    Dict with creation result",
      "parameters": [
        {
          "name": "project_root",
          "type": "Optional[Path]",
          "default": null
        },
        {
          "name": "default_provider",
          "type": "str",
          "default": null
        },
        {
          "name": "timeout",
          "type": "float",
          "default": null
        },
        {
          "name": "available_providers",
          "type": "Optional[List[str]]",
          "default": null
        },
        {
          "name": "workflows",
          "type": "Optional[Dict[str, Any]]",
          "default": null
        }
      ],
      "return_type": "Dict[str, Any]",
      "complexity": 16,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "create_express_config",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 476,
          "call_type": "function_call"
        },
        {
          "name": "create_tiered_config",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 583,
          "call_type": "function_call"
        },
        {
          "name": "main",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 909,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "cwd",
          "file": "unknown",
          "line": 308,
          "call_type": "method_call"
        },
        {
          "name": "exists",
          "file": "unknown",
          "line": 313,
          "call_type": "method_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 317,
          "call_type": "function_call"
        },
        {
          "name": "items",
          "file": "unknown",
          "line": 355,
          "call_type": "method_call"
        },
        {
          "name": "items",
          "file": "unknown",
          "line": 368,
          "call_type": "method_call"
        },
        {
          "name": "items",
          "file": "unknown",
          "line": 370,
          "call_type": "method_call"
        },
        {
          "name": "isinstance",
          "file": "unknown",
          "line": 371,
          "call_type": "function_call"
        },
        {
          "name": "open",
          "file": "unknown",
          "line": 379,
          "call_type": "function_call"
        },
        {
          "name": "write",
          "file": "unknown",
          "line": 380,
          "call_type": "method_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 385,
          "call_type": "function_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 391,
          "call_type": "function_call"
        }
      ],
      "call_count": 3
    },
    {
      "name": "create_express_config",
      "file": "model_chorus/src/model_chorus/cli/setup.py",
      "line": 395,
      "language": "python",
      "docstring": "Create Express (zero-question) .model-chorusrc configuration.\n\nAuto-detects available providers and configures with smart defaults:\n- Primary provider: first available (claude \u2192 gemini \u2192 codex \u2192 cursor-agent)\n- Fallbacks: all other available providers\n- Default models: configured for each available provider\n- Timeout: 120s (standard)\n- All workflows configured with balanced settings\n\nArgs:\n    project_root: Project root directory (defaults to cwd)\n\nReturns:\n    Dict with creation result",
      "parameters": [
        {
          "name": "project_root",
          "type": "Optional[Path]",
          "default": null
        }
      ],
      "return_type": "Dict[str, Any]",
      "complexity": 8,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "main",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 914,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "cwd",
          "file": "unknown",
          "line": 414,
          "call_type": "method_call"
        },
        {
          "name": "check_available_providers",
          "file": "unknown",
          "line": 417,
          "call_type": "function_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 418,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 469,
          "call_type": "function_call"
        },
        {
          "name": "create_config_file",
          "file": "unknown",
          "line": 476,
          "call_type": "function_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "create_tiered_config",
      "file": "model_chorus/src/model_chorus/cli/setup.py",
      "line": 485,
      "language": "python",
      "docstring": "Create tiered .model-chorusrc configuration file.\n\nArgs:\n    project_root: Project root directory (defaults to cwd)\n    tier: Configuration tier (quick, standard, advanced)\n    default_provider: Default AI provider\n    consensus_providers: Providers for consensus workflow (standard+)\n    consensus_strategy: Strategy for consensus workflow (standard+)\n    thinkdeep_thinking_mode: Thinking mode for thinkdeep (standard+)\n    ideate_providers: Providers for ideate workflow (standard+)\n    workflow_overrides: Additional workflow overrides (advanced)\n\nReturns:\n    Dict with creation result",
      "parameters": [
        {
          "name": "project_root",
          "type": "Optional[Path]",
          "default": null
        },
        {
          "name": "tier",
          "type": "str",
          "default": null
        },
        {
          "name": "default_provider",
          "type": "str",
          "default": null
        },
        {
          "name": "consensus_providers",
          "type": "Optional[list]",
          "default": null
        },
        {
          "name": "consensus_strategy",
          "type": "str",
          "default": null
        },
        {
          "name": "thinkdeep_thinking_mode",
          "type": "str",
          "default": null
        },
        {
          "name": "ideate_providers",
          "type": "Optional[list]",
          "default": null
        },
        {
          "name": "workflow_overrides",
          "type": "Optional[Dict[str, Dict[str, Any]]]",
          "default": null
        }
      ],
      "return_type": "Dict[str, Any]",
      "complexity": 13,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "main",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 916,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "cwd",
          "file": "unknown",
          "line": 513,
          "call_type": "method_call"
        },
        {
          "name": "exists",
          "file": "unknown",
          "line": 518,
          "call_type": "method_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 522,
          "call_type": "function_call"
        },
        {
          "name": "check_available_providers",
          "file": "unknown",
          "line": 526,
          "call_type": "function_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 527,
          "call_type": "method_call"
        },
        {
          "name": "items",
          "file": "unknown",
          "line": 576,
          "call_type": "method_call"
        },
        {
          "name": "update",
          "file": "unknown",
          "line": 578,
          "call_type": "method_call"
        },
        {
          "name": "create_config_file",
          "file": "unknown",
          "line": 583,
          "call_type": "function_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "validate_config",
      "file": "model_chorus/src/model_chorus/cli/setup.py",
      "line": 592,
      "language": "python",
      "docstring": "Validate .model-chorusrc configuration file.\n\nArgs:\n    project_root: Project root directory (defaults to cwd)\n\nReturns:\n    Dict with validation result",
      "parameters": [
        {
          "name": "project_root",
          "type": "Optional[Path]",
          "default": null
        }
      ],
      "return_type": "Dict[str, Any]",
      "complexity": 5,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "main",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 926,
          "call_type": "function_call"
        },
        {
          "name": "test_validate_config",
          "file": "model_chorus/tests/test_chat_workflow.py",
          "line": 81,
          "call_type": "method_call"
        },
        {
          "name": "test_validate_config",
          "file": "model_chorus/tests/test_ideate_workflow.py",
          "line": 190,
          "call_type": "method_call"
        },
        {
          "name": "test_validate_config",
          "file": "tests/test_argument_workflow.py",
          "line": 85,
          "call_type": "method_call"
        },
        {
          "name": "test_validate_config",
          "file": "tests/test_ideate_workflow.py",
          "line": 179,
          "call_type": "method_call"
        }
      ],
      "calls": [
        {
          "name": "cwd",
          "file": "unknown",
          "line": 602,
          "call_type": "method_call"
        },
        {
          "name": "find_config_file",
          "file": "unknown",
          "line": 614,
          "call_type": "method_call"
        },
        {
          "name": "load_config",
          "file": "unknown",
          "line": 623,
          "call_type": "method_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 627,
          "call_type": "function_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 632,
          "call_type": "function_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 633,
          "call_type": "function_call"
        }
      ],
      "call_count": 5
    },
    {
      "name": "check_permissions",
      "file": "model_chorus/src/model_chorus/cli/setup.py",
      "line": 637,
      "language": "python",
      "docstring": "Check if Claude Code permissions are configured.\n\nArgs:\n    project_root: Project root directory (defaults to cwd)\n\nReturns:\n    Dict with permissions status",
      "parameters": [
        {
          "name": "project_root",
          "type": "Optional[Path]",
          "default": null
        }
      ],
      "return_type": "Dict[str, Any]",
      "complexity": 4,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "main",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 928,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "cwd",
          "file": "unknown",
          "line": 647,
          "call_type": "method_call"
        },
        {
          "name": "exists",
          "file": "unknown",
          "line": 651,
          "call_type": "method_call"
        },
        {
          "name": "open",
          "file": "unknown",
          "line": 658,
          "call_type": "function_call"
        },
        {
          "name": "load",
          "file": "unknown",
          "line": 659,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 661,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 661,
          "call_type": "method_call"
        },
        {
          "name": "any",
          "file": "unknown",
          "line": 664,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 668,
          "call_type": "function_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 674,
          "call_type": "function_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "add_to_gitignore",
      "file": "model_chorus/src/model_chorus/cli/setup.py",
      "line": 678,
      "language": "python",
      "docstring": "Add .model-chorusrc to project .gitignore.\n\nArgs:\n    project_root: Project root directory (defaults to cwd)\n\nReturns:\n    Dict with result",
      "parameters": [
        {
          "name": "project_root",
          "type": "Optional[Path]",
          "default": null
        }
      ],
      "return_type": "Dict[str, Any]",
      "complexity": 10,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "main",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 932,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "cwd",
          "file": "unknown",
          "line": 690,
          "call_type": "method_call"
        },
        {
          "name": "exists",
          "file": "unknown",
          "line": 703,
          "call_type": "method_call"
        },
        {
          "name": "open",
          "file": "unknown",
          "line": 705,
          "call_type": "function_call"
        },
        {
          "name": "read",
          "file": "unknown",
          "line": 706,
          "call_type": "method_call"
        },
        {
          "name": "set",
          "file": "unknown",
          "line": 716,
          "call_type": "function_call"
        },
        {
          "name": "strip",
          "file": "unknown",
          "line": 716,
          "call_type": "method_call"
        },
        {
          "name": "split",
          "file": "unknown",
          "line": 716,
          "call_type": "method_call"
        },
        {
          "name": "open",
          "file": "unknown",
          "line": 728,
          "call_type": "function_call"
        },
        {
          "name": "endswith",
          "file": "unknown",
          "line": 730,
          "call_type": "method_call"
        },
        {
          "name": "write",
          "file": "unknown",
          "line": 731,
          "call_type": "method_call"
        },
        {
          "name": "write",
          "file": "unknown",
          "line": 734,
          "call_type": "method_call"
        },
        {
          "name": "write",
          "file": "unknown",
          "line": 736,
          "call_type": "method_call"
        },
        {
          "name": "write",
          "file": "unknown",
          "line": 738,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 742,
          "call_type": "function_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 744,
          "call_type": "function_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "add_permissions",
      "file": "model_chorus/src/model_chorus/cli/setup.py",
      "line": 753,
      "language": "python",
      "docstring": "Add ModelChorus permissions to .claude/settings.local.json.\n\nArgs:\n    project_root: Project root directory (defaults to cwd)\n\nReturns:\n    Dict with result",
      "parameters": [
        {
          "name": "project_root",
          "type": "Optional[Path]",
          "default": null
        }
      ],
      "return_type": "Dict[str, Any]",
      "complexity": 9,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "main",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 930,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "cwd",
          "file": "unknown",
          "line": 765,
          "call_type": "method_call"
        },
        {
          "name": "mkdir",
          "file": "unknown",
          "line": 776,
          "call_type": "method_call"
        },
        {
          "name": "exists",
          "file": "unknown",
          "line": 779,
          "call_type": "method_call"
        },
        {
          "name": "open",
          "file": "unknown",
          "line": 781,
          "call_type": "function_call"
        },
        {
          "name": "load",
          "file": "unknown",
          "line": 782,
          "call_type": "method_call"
        },
        {
          "name": "set",
          "file": "unknown",
          "line": 802,
          "call_type": "function_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 807,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 808,
          "call_type": "method_call"
        },
        {
          "name": "open",
          "file": "unknown",
          "line": 812,
          "call_type": "function_call"
        },
        {
          "name": "dump",
          "file": "unknown",
          "line": 813,
          "call_type": "method_call"
        },
        {
          "name": "write",
          "file": "unknown",
          "line": 814,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 818,
          "call_type": "function_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 820,
          "call_type": "function_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "main",
      "file": "model_chorus/src/model_chorus/cli/setup.py",
      "line": 829,
      "language": "python",
      "docstring": "CLI entry point for setup commands.",
      "parameters": [],
      "return_type": null,
      "complexity": 20,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "<module>",
          "file": "examples/workflow_examples.py",
          "line": 589,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/examples/basic_workflow.py",
          "line": 105,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/examples/chat_example.py",
          "line": 216,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/examples/provider_integration.py",
          "line": 157,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/examples/thinkdeep_example.py",
          "line": 467,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1771,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 956,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
          "line": 210,
          "call_type": "method_call"
        },
        {
          "name": "<module>",
          "file": "tests/workflows/study/memory/test_cache.py",
          "line": 229,
          "call_type": "method_call"
        }
      ],
      "calls": [
        {
          "name": "ArgumentParser",
          "file": "unknown",
          "line": 833,
          "call_type": "method_call"
        },
        {
          "name": "add_subparsers",
          "file": "unknown",
          "line": 834,
          "call_type": "method_call"
        },
        {
          "name": "add_parser",
          "file": "unknown",
          "line": 837,
          "call_type": "method_call"
        },
        {
          "name": "add_parser",
          "file": "unknown",
          "line": 840,
          "call_type": "method_call"
        },
        {
          "name": "add_parser",
          "file": "unknown",
          "line": 843,
          "call_type": "method_call"
        },
        {
          "name": "add_parser",
          "file": "unknown",
          "line": 846,
          "call_type": "method_call"
        },
        {
          "name": "add_argument",
          "file": "unknown",
          "line": 847,
          "call_type": "method_call"
        },
        {
          "name": "add_parser",
          "file": "unknown",
          "line": 850,
          "call_type": "method_call"
        },
        {
          "name": "add_argument",
          "file": "unknown",
          "line": 851,
          "call_type": "method_call"
        },
        {
          "name": "add_parser",
          "file": "unknown",
          "line": 854,
          "call_type": "method_call"
        },
        {
          "name": "add_argument",
          "file": "unknown",
          "line": 855,
          "call_type": "method_call"
        },
        {
          "name": "add_argument",
          "file": "unknown",
          "line": 856,
          "call_type": "method_call"
        },
        {
          "name": "add_parser",
          "file": "unknown",
          "line": 859,
          "call_type": "method_call"
        },
        {
          "name": "add_argument",
          "file": "unknown",
          "line": 860,
          "call_type": "method_call"
        },
        {
          "name": "add_parser",
          "file": "unknown",
          "line": 863,
          "call_type": "method_call"
        },
        {
          "name": "add_argument",
          "file": "unknown",
          "line": 864,
          "call_type": "method_call"
        },
        {
          "name": "add_argument",
          "file": "unknown",
          "line": 865,
          "call_type": "method_call"
        },
        {
          "name": "add_argument",
          "file": "unknown",
          "line": 866,
          "call_type": "method_call"
        },
        {
          "name": "add_argument",
          "file": "unknown",
          "line": 868,
          "call_type": "method_call"
        },
        {
          "name": "add_argument",
          "file": "unknown",
          "line": 869,
          "call_type": "method_call"
        },
        {
          "name": "add_argument",
          "file": "unknown",
          "line": 870,
          "call_type": "method_call"
        },
        {
          "name": "add_argument",
          "file": "unknown",
          "line": 871,
          "call_type": "method_call"
        },
        {
          "name": "add_parser",
          "file": "unknown",
          "line": 874,
          "call_type": "method_call"
        },
        {
          "name": "add_argument",
          "file": "unknown",
          "line": 875,
          "call_type": "method_call"
        },
        {
          "name": "add_parser",
          "file": "unknown",
          "line": 878,
          "call_type": "method_call"
        },
        {
          "name": "add_argument",
          "file": "unknown",
          "line": 879,
          "call_type": "method_call"
        },
        {
          "name": "add_parser",
          "file": "unknown",
          "line": 882,
          "call_type": "method_call"
        },
        {
          "name": "add_argument",
          "file": "unknown",
          "line": 883,
          "call_type": "method_call"
        },
        {
          "name": "add_parser",
          "file": "unknown",
          "line": 886,
          "call_type": "method_call"
        },
        {
          "name": "add_argument",
          "file": "unknown",
          "line": 887,
          "call_type": "method_call"
        },
        {
          "name": "parse_args",
          "file": "unknown",
          "line": 889,
          "call_type": "method_call"
        },
        {
          "name": "print_help",
          "file": "unknown",
          "line": 892,
          "call_type": "method_call"
        },
        {
          "name": "exit",
          "file": "unknown",
          "line": 893,
          "call_type": "method_call"
        },
        {
          "name": "hasattr",
          "file": "unknown",
          "line": 895,
          "call_type": "function_call"
        },
        {
          "name": "check_package_installed",
          "file": "unknown",
          "line": 899,
          "call_type": "function_call"
        },
        {
          "name": "check_version_compatibility",
          "file": "unknown",
          "line": 901,
          "call_type": "function_call"
        },
        {
          "name": "check_available_providers",
          "file": "unknown",
          "line": 903,
          "call_type": "function_call"
        },
        {
          "name": "install_package",
          "file": "unknown",
          "line": 905,
          "call_type": "function_call"
        },
        {
          "name": "check_config_exists",
          "file": "unknown",
          "line": 907,
          "call_type": "function_call"
        },
        {
          "name": "create_config_file",
          "file": "unknown",
          "line": 909,
          "call_type": "function_call"
        },
        {
          "name": "create_express_config",
          "file": "unknown",
          "line": 914,
          "call_type": "function_call"
        },
        {
          "name": "create_tiered_config",
          "file": "unknown",
          "line": 916,
          "call_type": "function_call"
        },
        {
          "name": "validate_config",
          "file": "unknown",
          "line": 926,
          "call_type": "function_call"
        },
        {
          "name": "check_permissions",
          "file": "unknown",
          "line": 928,
          "call_type": "function_call"
        },
        {
          "name": "add_permissions",
          "file": "unknown",
          "line": 930,
          "call_type": "function_call"
        },
        {
          "name": "add_to_gitignore",
          "file": "unknown",
          "line": 932,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 934,
          "call_type": "function_call"
        },
        {
          "name": "dumps",
          "file": "unknown",
          "line": 934,
          "call_type": "method_call"
        },
        {
          "name": "exit",
          "file": "unknown",
          "line": 935,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 938,
          "call_type": "function_call"
        },
        {
          "name": "dumps",
          "file": "unknown",
          "line": 938,
          "call_type": "method_call"
        },
        {
          "name": "exit",
          "file": "unknown",
          "line": 942,
          "call_type": "method_call"
        },
        {
          "name": "exit",
          "file": "unknown",
          "line": 944,
          "call_type": "method_call"
        },
        {
          "name": "exit",
          "file": "unknown",
          "line": 946,
          "call_type": "method_call"
        },
        {
          "name": "exit",
          "file": "unknown",
          "line": 948,
          "call_type": "method_call"
        },
        {
          "name": "exit",
          "file": "unknown",
          "line": 950,
          "call_type": "method_call"
        },
        {
          "name": "exit",
          "file": "unknown",
          "line": 952,
          "call_type": "method_call"
        }
      ],
      "call_count": 9
    },
    {
      "name": "get_config",
      "file": "model_chorus/src/model_chorus/cli/study_commands.py",
      "line": 43,
      "language": "python",
      "docstring": "Get the config loader instance, initializing if needed.",
      "parameters": [],
      "return_type": null,
      "complexity": 3,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "chat",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 262,
          "call_type": "function_call"
        },
        {
          "name": "argument",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 469,
          "call_type": "function_call"
        },
        {
          "name": "ideate",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 672,
          "call_type": "function_call"
        },
        {
          "name": "consensus",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 874,
          "call_type": "function_call"
        },
        {
          "name": "thinkdeep",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1117,
          "call_type": "function_call"
        },
        {
          "name": "_config_show",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1518,
          "call_type": "function_call"
        },
        {
          "name": "_config_show",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1519,
          "call_type": "method_call"
        },
        {
          "name": "_config_validate",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1579,
          "call_type": "function_call"
        },
        {
          "name": "start",
          "file": "model_chorus/src/model_chorus/cli/study_commands.py",
          "line": 183,
          "call_type": "function_call"
        },
        {
          "name": "study_next",
          "file": "model_chorus/src/model_chorus/cli/study_commands.py",
          "line": 437,
          "call_type": "function_call"
        },
        {
          "name": "get_workflow_default",
          "file": "model_chorus/src/model_chorus/core/config.py",
          "line": 241,
          "call_type": "method_call"
        },
        {
          "name": "get_default_provider",
          "file": "model_chorus/src/model_chorus/core/config.py",
          "line": 269,
          "call_type": "method_call"
        },
        {
          "name": "get_default_providers",
          "file": "model_chorus/src/model_chorus/core/config.py",
          "line": 296,
          "call_type": "method_call"
        },
        {
          "name": "get_fallback_providers",
          "file": "model_chorus/src/model_chorus/core/config.py",
          "line": 315,
          "call_type": "method_call"
        },
        {
          "name": "get_provider_model",
          "file": "model_chorus/src/model_chorus/core/config.py",
          "line": 365,
          "call_type": "method_call"
        },
        {
          "name": "get_config",
          "file": "model_chorus/src/model_chorus/core/config.py",
          "line": 413,
          "call_type": "method_call"
        }
      ],
      "calls": [
        {
          "name": "get_config_loader",
          "file": "unknown",
          "line": 47,
          "call_type": "function_call"
        },
        {
          "name": "load_config",
          "file": "unknown",
          "line": 49,
          "call_type": "method_call"
        }
      ],
      "call_count": 16
    },
    {
      "name": "get_install_command",
      "file": "model_chorus/src/model_chorus/cli/study_commands.py",
      "line": 56,
      "language": "python",
      "docstring": "Get installation command for a provider CLI.\n\nArgs:\n    provider: Provider name (claude, gemini, codex, cursor-agent)\n\nReturns:\n    Installation command string",
      "parameters": [
        {
          "name": "provider",
          "type": "str",
          "default": null
        }
      ],
      "return_type": "str",
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "chat",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 286,
          "call_type": "function_call"
        },
        {
          "name": "argument",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 491,
          "call_type": "function_call"
        },
        {
          "name": "ideate",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 694,
          "call_type": "function_call"
        },
        {
          "name": "list_providers",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1723,
          "call_type": "function_call"
        },
        {
          "name": "start",
          "file": "model_chorus/src/model_chorus/cli/study_commands.py",
          "line": 211,
          "call_type": "function_call"
        },
        {
          "name": "study_next",
          "file": "model_chorus/src/model_chorus/cli/study_commands.py",
          "line": 459,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "get",
          "file": "unknown",
          "line": 71,
          "call_type": "method_call"
        },
        {
          "name": "lower",
          "file": "unknown",
          "line": 71,
          "call_type": "method_call"
        }
      ],
      "call_count": 6
    },
    {
      "name": "get_provider_by_name",
      "file": "model_chorus/src/model_chorus/cli/study_commands.py",
      "line": 74,
      "language": "python",
      "docstring": "Get provider instance by name.\n\nArgs:\n    name: Provider name (claude, gemini, codex, cursor-agent)\n    timeout: Timeout in seconds for provider operations (default: 120)\n\nReturns:\n    Provider instance",
      "parameters": [
        {
          "name": "name",
          "type": "str",
          "default": null
        },
        {
          "name": "timeout",
          "type": "int",
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "chat",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 276,
          "call_type": "function_call"
        },
        {
          "name": "chat",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 302,
          "call_type": "function_call"
        },
        {
          "name": "argument",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 481,
          "call_type": "function_call"
        },
        {
          "name": "argument",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 507,
          "call_type": "function_call"
        },
        {
          "name": "ideate",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 684,
          "call_type": "function_call"
        },
        {
          "name": "ideate",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 710,
          "call_type": "function_call"
        },
        {
          "name": "consensus",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 903,
          "call_type": "function_call"
        },
        {
          "name": "thinkdeep",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1143,
          "call_type": "function_call"
        },
        {
          "name": "thinkdeep",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1171,
          "call_type": "function_call"
        },
        {
          "name": "start",
          "file": "model_chorus/src/model_chorus/cli/study_commands.py",
          "line": 201,
          "call_type": "function_call"
        },
        {
          "name": "start",
          "file": "model_chorus/src/model_chorus/cli/study_commands.py",
          "line": 227,
          "call_type": "function_call"
        },
        {
          "name": "study_next",
          "file": "model_chorus/src/model_chorus/cli/study_commands.py",
          "line": 449,
          "call_type": "function_call"
        },
        {
          "name": "study_next",
          "file": "model_chorus/src/model_chorus/cli/study_commands.py",
          "line": 475,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "get",
          "file": "unknown",
          "line": 91,
          "call_type": "method_call"
        },
        {
          "name": "lower",
          "file": "unknown",
          "line": 91,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 93,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 94,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 94,
          "call_type": "method_call"
        },
        {
          "name": "keys",
          "file": "unknown",
          "line": 94,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 95,
          "call_type": "method_call"
        },
        {
          "name": "provider_class",
          "file": "unknown",
          "line": 97,
          "call_type": "function_call"
        }
      ],
      "call_count": 13
    },
    {
      "name": "start",
      "file": "model_chorus/src/model_chorus/cli/study_commands.py",
      "line": 101,
      "language": "python",
      "docstring": "Conduct persona-based collaborative research.\n\nThe STUDY workflow provides multi-persona investigation with role-based\norchestration, enabling collaborative exploration of complex topics through\nspecialized personas with distinct expertise.\n\nExample:\n    # Start new investigation\n    model-chorus study start --scenario \"Explore authentication system patterns\"\n\n    # Continue investigation\n    model-chorus study start --scenario \"Deep dive into OAuth 2.0\" --continue thread-id-123\n\n    # Include files\n    model-chorus study start --scenario \"Analyze this codebase\" -f src/auth.py -f tests/test_auth.py\n\n    # Specify personas\n    model-chorus study start --scenario \"Security analysis\" --persona SecurityExpert --persona Architect",
      "parameters": [
        {
          "name": "scenario",
          "type": "str",
          "default": null
        },
        {
          "name": "provider",
          "type": "Optional[str]",
          "default": null
        },
        {
          "name": "continuation_id",
          "type": "Optional[str]",
          "default": null
        },
        {
          "name": "files",
          "type": "Optional[List[str]]",
          "default": null
        },
        {
          "name": "personas",
          "type": "Optional[List[str]]",
          "default": null
        },
        {
          "name": "system",
          "type": "Optional[str]",
          "default": null
        },
        {
          "name": "temperature",
          "type": "Optional[float]",
          "default": null
        },
        {
          "name": "max_tokens",
          "type": "Optional[int]",
          "default": null
        },
        {
          "name": "output",
          "type": "Optional[Path]",
          "default": null
        },
        {
          "name": "verbose",
          "type": "bool",
          "default": null
        },
        {
          "name": "skip_provider_check",
          "type": "bool",
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 43,
      "decorators": [
        "study_app.command()"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "test_concurrent_set_state",
          "file": "model_chorus/tests/test_state.py",
          "line": 174,
          "call_type": "method_call"
        },
        {
          "name": "test_concurrent_read_write",
          "file": "model_chorus/tests/test_state.py",
          "line": 221,
          "call_type": "method_call"
        },
        {
          "name": "test_concurrent_read_write",
          "file": "model_chorus/tests/test_state.py",
          "line": 227,
          "call_type": "method_call"
        }
      ],
      "calls": [
        {
          "name": "Option",
          "file": "unknown",
          "line": 102,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 103,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 109,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 116,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 122,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 127,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 132,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 138,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 143,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 149,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 155,
          "call_type": "method_call"
        },
        {
          "name": "get_config",
          "file": "unknown",
          "line": 183,
          "call_type": "function_call"
        },
        {
          "name": "get_default_provider",
          "file": "unknown",
          "line": 185,
          "call_type": "method_call"
        },
        {
          "name": "get_workflow_default",
          "file": "unknown",
          "line": 187,
          "call_type": "method_call"
        },
        {
          "name": "get_workflow_default",
          "file": "unknown",
          "line": 189,
          "call_type": "method_call"
        },
        {
          "name": "get_workflow_default",
          "file": "unknown",
          "line": 191,
          "call_type": "method_call"
        },
        {
          "name": "get_workflow_default",
          "file": "unknown",
          "line": 194,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 198,
          "call_type": "method_call"
        },
        {
          "name": "get_provider_by_name",
          "file": "unknown",
          "line": 201,
          "call_type": "function_call"
        },
        {
          "name": "int",
          "file": "unknown",
          "line": 201,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 203,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 206,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 208,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 210,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 211,
          "call_type": "method_call"
        },
        {
          "name": "get_install_command",
          "file": "unknown",
          "line": 211,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 212,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 213,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 215,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 216,
          "call_type": "method_call"
        },
        {
          "name": "get_workflow_default",
          "file": "unknown",
          "line": 219,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 223,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 223,
          "call_type": "method_call"
        },
        {
          "name": "get_provider_by_name",
          "file": "unknown",
          "line": 227,
          "call_type": "function_call"
        },
        {
          "name": "int",
          "file": "unknown",
          "line": 227,
          "call_type": "function_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 228,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 230,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 233,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 255,
          "call_type": "method_call"
        },
        {
          "name": "exists",
          "file": "unknown",
          "line": 260,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 261,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 262,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 265,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 266,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 266,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 267,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 269,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 271,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 271,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 273,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 273,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 274,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 279,
          "call_type": "method_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 288,
          "call_type": "method_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 289,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 300,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 303,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 304,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 305,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 307,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 309,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 311,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 313,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 313,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 314,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 318,
          "call_type": "method_call"
        },
        {
          "name": "enumerate",
          "file": "unknown",
          "line": 319,
          "call_type": "function_call"
        },
        {
          "name": "hasattr",
          "file": "unknown",
          "line": 320,
          "call_type": "function_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 320,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 321,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 322,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 323,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 326,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 327,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 330,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 332,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 332,
          "call_type": "method_call"
        },
        {
          "name": "hasattr",
          "file": "unknown",
          "line": 344,
          "call_type": "function_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 344,
          "call_type": "method_call"
        },
        {
          "name": "hasattr",
          "file": "unknown",
          "line": 346,
          "call_type": "function_call"
        },
        {
          "name": "enumerate",
          "file": "unknown",
          "line": 348,
          "call_type": "function_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 351,
          "call_type": "method_call"
        },
        {
          "name": "write_text",
          "file": "unknown",
          "line": 357,
          "call_type": "method_call"
        },
        {
          "name": "dumps",
          "file": "unknown",
          "line": 357,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 358,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 360,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 363,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 364,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 367,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 368,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 370,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 373,
          "call_type": "method_call"
        },
        {
          "name": "format_exc",
          "file": "unknown",
          "line": 373,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 374,
          "call_type": "method_call"
        },
        {
          "name": "command",
          "file": "unknown",
          "line": 100,
          "call_type": "method_call"
        }
      ],
      "call_count": 3
    },
    {
      "name": "study_next",
      "file": "model_chorus/src/model_chorus/cli/study_commands.py",
      "line": 378,
      "language": "python",
      "docstring": "Continue an existing STUDY investigation.\n\nThis command automatically continues an investigation using the existing\nthread context and personas. It's a convenience wrapper around the study\ncommand with automatic continuation.\n\nThe command retrieves the investigation's conversation history and prompts\nthe next investigation step based on the current state.\n\nExample:\n    # Continue investigation with automatic next step\n    model-chorus study-next --investigation thread-id-123\n\n    # Continue with additional files\n    model-chorus study-next --investigation thread-id-123 -f new_data.py\n\n    # Continue with specific provider\n    model-chorus study-next --investigation thread-id-123 -p gemini",
      "parameters": [
        {
          "name": "investigation",
          "type": "str",
          "default": null
        },
        {
          "name": "provider",
          "type": "Optional[str]",
          "default": null
        },
        {
          "name": "files",
          "type": "Optional[List[str]]",
          "default": null
        },
        {
          "name": "max_tokens",
          "type": "Optional[int]",
          "default": null
        },
        {
          "name": "output",
          "type": "Optional[Path]",
          "default": null
        },
        {
          "name": "verbose",
          "type": "bool",
          "default": null
        },
        {
          "name": "skip_provider_check",
          "type": "bool",
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 34,
      "decorators": [
        "study_app.command(name='next')"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "Option",
          "file": "unknown",
          "line": 379,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 380,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 386,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 392,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 397,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 403,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 409,
          "call_type": "method_call"
        },
        {
          "name": "get_config",
          "file": "unknown",
          "line": 437,
          "call_type": "function_call"
        },
        {
          "name": "get_default_provider",
          "file": "unknown",
          "line": 439,
          "call_type": "method_call"
        },
        {
          "name": "get_workflow_default",
          "file": "unknown",
          "line": 442,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 446,
          "call_type": "method_call"
        },
        {
          "name": "get_provider_by_name",
          "file": "unknown",
          "line": 449,
          "call_type": "function_call"
        },
        {
          "name": "int",
          "file": "unknown",
          "line": 449,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 451,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 454,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 456,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 458,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 459,
          "call_type": "method_call"
        },
        {
          "name": "get_install_command",
          "file": "unknown",
          "line": 459,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 460,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 461,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 463,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 464,
          "call_type": "method_call"
        },
        {
          "name": "get_workflow_default",
          "file": "unknown",
          "line": 467,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 471,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 471,
          "call_type": "method_call"
        },
        {
          "name": "get_provider_by_name",
          "file": "unknown",
          "line": 475,
          "call_type": "function_call"
        },
        {
          "name": "int",
          "file": "unknown",
          "line": 475,
          "call_type": "function_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 476,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 478,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 481,
          "call_type": "method_call"
        },
        {
          "name": "get_thread",
          "file": "unknown",
          "line": 487,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 489,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 490,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 491,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 492,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 502,
          "call_type": "method_call"
        },
        {
          "name": "exists",
          "file": "unknown",
          "line": 507,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 508,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 509,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 512,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 513,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 514,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 515,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 515,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 517,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 517,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 518,
          "call_type": "method_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 529,
          "call_type": "method_call"
        },
        {
          "name": "run",
          "file": "unknown",
          "line": 530,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 541,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 544,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 545,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 547,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 549,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 549,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 550,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 554,
          "call_type": "method_call"
        },
        {
          "name": "enumerate",
          "file": "unknown",
          "line": 555,
          "call_type": "function_call"
        },
        {
          "name": "hasattr",
          "file": "unknown",
          "line": 556,
          "call_type": "function_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 556,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 557,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 558,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 559,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 562,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 563,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 566,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 568,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 568,
          "call_type": "method_call"
        },
        {
          "name": "hasattr",
          "file": "unknown",
          "line": 579,
          "call_type": "function_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 579,
          "call_type": "method_call"
        },
        {
          "name": "hasattr",
          "file": "unknown",
          "line": 581,
          "call_type": "function_call"
        },
        {
          "name": "enumerate",
          "file": "unknown",
          "line": 583,
          "call_type": "function_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 586,
          "call_type": "method_call"
        },
        {
          "name": "write_text",
          "file": "unknown",
          "line": 592,
          "call_type": "method_call"
        },
        {
          "name": "dumps",
          "file": "unknown",
          "line": 592,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 593,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 595,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 598,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 599,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 602,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 603,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 605,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 608,
          "call_type": "method_call"
        },
        {
          "name": "format_exc",
          "file": "unknown",
          "line": 608,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 609,
          "call_type": "method_call"
        },
        {
          "name": "command",
          "file": "unknown",
          "line": 377,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "study_view",
      "file": "model_chorus/src/model_chorus/cli/study_commands.py",
      "line": 613,
      "language": "python",
      "docstring": "View memory and conversation history for a STUDY investigation.\n\nThis command displays the conversation memory for an investigation,\nincluding all messages, persona contributions, and investigation metadata.\nUseful for reviewing investigation history and debugging.\n\nExample:\n    # View investigation summary\n    model-chorus study-view --investigation thread-id-123\n\n    # View all messages\n    model-chorus study-view --investigation thread-id-123 --show-all\n\n    # Filter by persona\n    model-chorus study-view --investigation thread-id-123 --persona Researcher\n\n    # Output as JSON\n    model-chorus study-view --investigation thread-id-123 --json",
      "parameters": [
        {
          "name": "investigation",
          "type": "str",
          "default": null
        },
        {
          "name": "persona",
          "type": "Optional[str]",
          "default": null
        },
        {
          "name": "show_all",
          "type": "bool",
          "default": null
        },
        {
          "name": "format_json",
          "type": "bool",
          "default": null
        },
        {
          "name": "verbose",
          "type": "bool",
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 31,
      "decorators": [
        "study_app.command(name='view')"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "Option",
          "file": "unknown",
          "line": 614,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 615,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 620,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 625,
          "call_type": "method_call"
        },
        {
          "name": "Option",
          "file": "unknown",
          "line": 630,
          "call_type": "method_call"
        },
        {
          "name": "get_thread",
          "file": "unknown",
          "line": 662,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 664,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 665,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 666,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 667,
          "call_type": "method_call"
        },
        {
          "name": "hasattr",
          "file": "unknown",
          "line": 671,
          "call_type": "function_call"
        },
        {
          "name": "lower",
          "file": "unknown",
          "line": 677,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 677,
          "call_type": "method_call"
        },
        {
          "name": "lower",
          "file": "unknown",
          "line": 677,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 680,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 681,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 681,
          "call_type": "function_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 682,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 688,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 689,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 689,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 694,
          "call_type": "function_call"
        },
        {
          "name": "hasattr",
          "file": "unknown",
          "line": 695,
          "call_type": "function_call"
        },
        {
          "name": "hasattr",
          "file": "unknown",
          "line": 700,
          "call_type": "function_call"
        },
        {
          "name": "isinstance",
          "file": "unknown",
          "line": 697,
          "call_type": "function_call"
        },
        {
          "name": "hasattr",
          "file": "unknown",
          "line": 698,
          "call_type": "function_call"
        },
        {
          "name": "isoformat",
          "file": "unknown",
          "line": 698,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 708,
          "call_type": "method_call"
        },
        {
          "name": "dumps",
          "file": "unknown",
          "line": 708,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 712,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 713,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 714,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 714,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 716,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 716,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 717,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 721,
          "call_type": "method_call"
        },
        {
          "name": "items",
          "file": "unknown",
          "line": 722,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 723,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 724,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 728,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 730,
          "call_type": "method_call"
        },
        {
          "name": "enumerate",
          "file": "unknown",
          "line": 731,
          "call_type": "function_call"
        },
        {
          "name": "hasattr",
          "file": "unknown",
          "line": 733,
          "call_type": "function_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 733,
          "call_type": "method_call"
        },
        {
          "name": "hasattr",
          "file": "unknown",
          "line": 736,
          "call_type": "function_call"
        },
        {
          "name": "isinstance",
          "file": "unknown",
          "line": 737,
          "call_type": "function_call"
        },
        {
          "name": "strftime",
          "file": "unknown",
          "line": 740,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 745,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 746,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 747,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 749,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 753,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 755,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 758,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 759,
          "call_type": "method_call"
        },
        {
          "name": "any",
          "file": "unknown",
          "line": 762,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 762,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 763,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 764,
          "call_type": "function_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 765,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 767,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 770,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 771,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 773,
          "call_type": "method_call"
        },
        {
          "name": "print",
          "file": "unknown",
          "line": 776,
          "call_type": "method_call"
        },
        {
          "name": "format_exc",
          "file": "unknown",
          "line": 776,
          "call_type": "method_call"
        },
        {
          "name": "Exit",
          "file": "unknown",
          "line": 777,
          "call_type": "method_call"
        },
        {
          "name": "command",
          "file": "unknown",
          "line": 612,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "get_config_loader",
      "file": "model_chorus/src/model_chorus/core/config.py",
      "line": 385,
      "language": "python",
      "docstring": "Get the global config loader instance.",
      "parameters": [],
      "return_type": "ConfigLoader",
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "get_config",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 149,
          "call_type": "function_call"
        },
        {
          "name": "get_config",
          "file": "model_chorus/src/model_chorus/cli/study_commands.py",
          "line": 47,
          "call_type": "function_call"
        },
        {
          "name": "load_config",
          "file": "model_chorus/src/model_chorus/core/config.py",
          "line": 402,
          "call_type": "function_call"
        },
        {
          "name": "get_config",
          "file": "model_chorus/src/model_chorus/core/config.py",
          "line": 412,
          "call_type": "function_call"
        },
        {
          "name": "test_get_config_loader_singleton",
          "file": "model_chorus/tests/test_config.py",
          "line": 369,
          "call_type": "function_call"
        },
        {
          "name": "test_get_config_loader_singleton",
          "file": "model_chorus/tests/test_config.py",
          "line": 370,
          "call_type": "function_call"
        }
      ],
      "calls": [],
      "call_count": 6
    },
    {
      "name": "load_config",
      "file": "model_chorus/src/model_chorus/core/config.py",
      "line": 393,
      "language": "python",
      "docstring": "Load configuration (convenience function).\n\nArgs:\n    config_path: Optional explicit path to config file\n\nReturns:\n    Loaded configuration",
      "parameters": [
        {
          "name": "config_path",
          "type": "Optional[Path]",
          "default": null
        }
      ],
      "return_type": "ModelChorusConfig",
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "get_config",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 151,
          "call_type": "method_call"
        },
        {
          "name": "_config_validate",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1594,
          "call_type": "method_call"
        },
        {
          "name": "validate_config",
          "file": "model_chorus/src/model_chorus/cli/setup.py",
          "line": 623,
          "call_type": "method_call"
        },
        {
          "name": "get_config",
          "file": "model_chorus/src/model_chorus/cli/study_commands.py",
          "line": 49,
          "call_type": "method_call"
        },
        {
          "name": "get_config",
          "file": "model_chorus/src/model_chorus/core/config.py",
          "line": 222,
          "call_type": "method_call"
        },
        {
          "name": "load_config",
          "file": "model_chorus/src/model_chorus/core/config.py",
          "line": 403,
          "call_type": "method_call"
        },
        {
          "name": "test_load_yaml_config_global_defaults",
          "file": "model_chorus/tests/test_config.py",
          "line": 100,
          "call_type": "method_call"
        },
        {
          "name": "test_load_yaml_config_workflow_specific",
          "file": "model_chorus/tests/test_config.py",
          "line": 124,
          "call_type": "method_call"
        },
        {
          "name": "test_load_json_config",
          "file": "model_chorus/tests/test_config.py",
          "line": 151,
          "call_type": "method_call"
        },
        {
          "name": "test_invalid_provider_raises_error",
          "file": "model_chorus/tests/test_config.py",
          "line": 169,
          "call_type": "method_call"
        },
        {
          "name": "test_invalid_temperature_raises_error",
          "file": "model_chorus/tests/test_config.py",
          "line": 183,
          "call_type": "method_call"
        },
        {
          "name": "test_invalid_workflow_name_raises_error",
          "file": "model_chorus/tests/test_config.py",
          "line": 198,
          "call_type": "method_call"
        },
        {
          "name": "test_invalid_consensus_strategy_raises_error",
          "file": "model_chorus/tests/test_config.py",
          "line": 213,
          "call_type": "method_call"
        },
        {
          "name": "test_get_default_provider_workflow_specific",
          "file": "model_chorus/tests/test_config.py",
          "line": 231,
          "call_type": "method_call"
        },
        {
          "name": "test_get_default_provider_fallback",
          "file": "model_chorus/tests/test_config.py",
          "line": 242,
          "call_type": "method_call"
        },
        {
          "name": "test_get_workflow_default_temperature",
          "file": "model_chorus/tests/test_config.py",
          "line": 259,
          "call_type": "method_call"
        },
        {
          "name": "test_get_default_providers_multi",
          "file": "model_chorus/tests/test_config.py",
          "line": 281,
          "call_type": "method_call"
        },
        {
          "name": "test_load_empty_config",
          "file": "model_chorus/tests/test_config.py",
          "line": 296,
          "call_type": "method_call"
        },
        {
          "name": "test_load_minimal_config",
          "file": "model_chorus/tests/test_config.py",
          "line": 308,
          "call_type": "method_call"
        },
        {
          "name": "test_load_nonexistent_file_raises_error",
          "file": "model_chorus/tests/test_config.py",
          "line": 385,
          "call_type": "method_call"
        },
        {
          "name": "test_load_invalid_yaml_raises_error",
          "file": "model_chorus/tests/test_config.py",
          "line": 395,
          "call_type": "method_call"
        },
        {
          "name": "test_load_invalid_json_raises_error",
          "file": "model_chorus/tests/test_config.py",
          "line": 405,
          "call_type": "method_call"
        },
        {
          "name": "test_full_config_all_workflows",
          "file": "model_chorus/tests/test_config.py",
          "line": 491,
          "call_type": "method_call"
        },
        {
          "name": "test_precedence_workflow_overrides_global",
          "file": "model_chorus/tests/test_config.py",
          "line": 518,
          "call_type": "method_call"
        }
      ],
      "calls": [
        {
          "name": "find_config_file",
          "file": "unknown",
          "line": 155,
          "call_type": "method_call"
        },
        {
          "name": "exists",
          "file": "unknown",
          "line": 160,
          "call_type": "method_call"
        },
        {
          "name": "open",
          "file": "unknown",
          "line": 166,
          "call_type": "function_call"
        },
        {
          "name": "read",
          "file": "unknown",
          "line": 167,
          "call_type": "method_call"
        },
        {
          "name": "_parse_config_content",
          "file": "unknown",
          "line": 170,
          "call_type": "method_call"
        },
        {
          "name": "get_config_loader",
          "file": "unknown",
          "line": 402,
          "call_type": "function_call"
        },
        {
          "name": "load_config",
          "file": "unknown",
          "line": 403,
          "call_type": "method_call"
        }
      ],
      "call_count": 24
    },
    {
      "name": "get_config",
      "file": "model_chorus/src/model_chorus/core/config.py",
      "line": 406,
      "language": "python",
      "docstring": "Get the current configuration (convenience function).\n\nReturns:\n    Current configuration",
      "parameters": [],
      "return_type": "ModelChorusConfig",
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "chat",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 262,
          "call_type": "function_call"
        },
        {
          "name": "argument",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 469,
          "call_type": "function_call"
        },
        {
          "name": "ideate",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 672,
          "call_type": "function_call"
        },
        {
          "name": "consensus",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 874,
          "call_type": "function_call"
        },
        {
          "name": "thinkdeep",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1117,
          "call_type": "function_call"
        },
        {
          "name": "_config_show",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1518,
          "call_type": "function_call"
        },
        {
          "name": "_config_show",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1519,
          "call_type": "method_call"
        },
        {
          "name": "_config_validate",
          "file": "model_chorus/src/model_chorus/cli/main.py",
          "line": 1579,
          "call_type": "function_call"
        },
        {
          "name": "start",
          "file": "model_chorus/src/model_chorus/cli/study_commands.py",
          "line": 183,
          "call_type": "function_call"
        },
        {
          "name": "study_next",
          "file": "model_chorus/src/model_chorus/cli/study_commands.py",
          "line": 437,
          "call_type": "function_call"
        },
        {
          "name": "get_workflow_default",
          "file": "model_chorus/src/model_chorus/core/config.py",
          "line": 241,
          "call_type": "method_call"
        },
        {
          "name": "get_default_provider",
          "file": "model_chorus/src/model_chorus/core/config.py",
          "line": 269,
          "call_type": "method_call"
        },
        {
          "name": "get_default_providers",
          "file": "model_chorus/src/model_chorus/core/config.py",
          "line": 296,
          "call_type": "method_call"
        },
        {
          "name": "get_fallback_providers",
          "file": "model_chorus/src/model_chorus/core/config.py",
          "line": 315,
          "call_type": "method_call"
        },
        {
          "name": "get_provider_model",
          "file": "model_chorus/src/model_chorus/core/config.py",
          "line": 365,
          "call_type": "method_call"
        },
        {
          "name": "get_config",
          "file": "model_chorus/src/model_chorus/core/config.py",
          "line": 413,
          "call_type": "method_call"
        }
      ],
      "calls": [
        {
          "name": "load_config",
          "file": "unknown",
          "line": 222,
          "call_type": "method_call"
        },
        {
          "name": "get_config_loader",
          "file": "unknown",
          "line": 412,
          "call_type": "function_call"
        },
        {
          "name": "get_config",
          "file": "unknown",
          "line": 413,
          "call_type": "method_call"
        }
      ],
      "call_count": 16
    },
    {
      "name": "_import_semantic_functions",
      "file": "model_chorus/src/model_chorus/core/contradiction.py",
      "line": 207,
      "language": "python",
      "docstring": "Import semantic similarity functions from workflows.argument.semantic.",
      "parameters": [],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": false,
      "callers": [
        {
          "name": "detect_contradiction",
          "file": "model_chorus/src/model_chorus/core/contradiction.py",
          "line": 519,
          "call_type": "function_call"
        }
      ],
      "calls": [],
      "call_count": 1
    },
    {
      "name": "_import_citation_map",
      "file": "model_chorus/src/model_chorus/core/contradiction.py",
      "line": 222,
      "language": "python",
      "docstring": "Import CitationMap model.",
      "parameters": [],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": false,
      "callers": [],
      "calls": []
    },
    {
      "name": "detect_polarity_opposition",
      "file": "model_chorus/src/model_chorus/core/contradiction.py",
      "line": 248,
      "language": "python",
      "docstring": "Detect if two claims have opposing polarity (positive vs negative).\n\nUses keyword-based analysis to identify claims that make opposite\nassertions about the same topic.\n\nArgs:\n    claim_text_1: First claim text\n    claim_text_2: Second claim text\n\nReturns:\n    Tuple of (has_opposition, confidence)\n    - has_opposition: True if claims have opposing polarity\n    - confidence: Confidence in polarity detection (0.0-1.0)\n\nExample:\n    >>> has_opp, conf = detect_polarity_opposition(\n    ...     \"AI improves accuracy by 23%\",\n    ...     \"AI reduces accuracy by 15%\"\n    ... )\n    >>> print(f\"Opposition: {has_opp}, Confidence: {conf:.2f}\")\n    Opposition: True, Confidence: 0.80",
      "parameters": [
        {
          "name": "claim_text_1",
          "type": "str",
          "default": null
        },
        {
          "name": "claim_text_2",
          "type": "str",
          "default": null
        }
      ],
      "return_type": "Tuple[bool, float]",
      "complexity": 10,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "detect_contradiction",
          "file": "model_chorus/src/model_chorus/core/contradiction.py",
          "line": 529,
          "call_type": "function_call"
        },
        {
          "name": "test_clear_positive_negative_opposition",
          "file": "tests/test_contradiction.py",
          "line": 29,
          "call_type": "function_call"
        },
        {
          "name": "test_negation_opposition",
          "file": "tests/test_contradiction.py",
          "line": 39,
          "call_type": "function_call"
        },
        {
          "name": "test_no_opposition_similar_polarity",
          "file": "tests/test_contradiction.py",
          "line": 49,
          "call_type": "function_call"
        },
        {
          "name": "test_numerical_opposition_strengthens_confidence",
          "file": "tests/test_contradiction.py",
          "line": 59,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "lower",
          "file": "unknown",
          "line": 275,
          "call_type": "method_call"
        },
        {
          "name": "lower",
          "file": "unknown",
          "line": 276,
          "call_type": "method_call"
        },
        {
          "name": "any",
          "file": "unknown",
          "line": 279,
          "call_type": "function_call"
        },
        {
          "name": "any",
          "file": "unknown",
          "line": 280,
          "call_type": "function_call"
        },
        {
          "name": "any",
          "file": "unknown",
          "line": 281,
          "call_type": "function_call"
        },
        {
          "name": "any",
          "file": "unknown",
          "line": 284,
          "call_type": "function_call"
        },
        {
          "name": "any",
          "file": "unknown",
          "line": 285,
          "call_type": "function_call"
        },
        {
          "name": "any",
          "file": "unknown",
          "line": 286,
          "call_type": "function_call"
        },
        {
          "name": "min",
          "file": "unknown",
          "line": 305,
          "call_type": "function_call"
        },
        {
          "name": "findall",
          "file": "unknown",
          "line": 310,
          "call_type": "method_call"
        },
        {
          "name": "findall",
          "file": "unknown",
          "line": 311,
          "call_type": "method_call"
        },
        {
          "name": "min",
          "file": "unknown",
          "line": 315,
          "call_type": "function_call"
        }
      ],
      "call_count": 5
    },
    {
      "name": "assess_contradiction_severity",
      "file": "model_chorus/src/model_chorus/core/contradiction.py",
      "line": 320,
      "language": "python",
      "docstring": "Assess the severity of a contradiction based on multiple factors.\n\nCombines semantic similarity and polarity opposition to classify\ncontradiction severity.\n\nArgs:\n    semantic_similarity: Cosine similarity between claims (0.0-1.0)\n    has_polarity_opposition: Whether claims have opposing polarity\n    polarity_confidence: Confidence in polarity detection (0.0-1.0)\n\nReturns:\n    ContradictionSeverity enum value\n\nSeverity Rules:\n    - High similarity (>0.7) + strong polarity opposition = CRITICAL\n    - High similarity (>0.7) + weak polarity opposition = MAJOR\n    - Moderate similarity (0.5-0.7) + polarity opposition = MODERATE\n    - Low similarity (<0.5) + polarity opposition = MINOR\n\nExample:\n    >>> severity = assess_contradiction_severity(\n    ...     semantic_similarity=0.85,\n    ...     has_polarity_opposition=True,\n    ...     polarity_confidence=0.8\n    ... )\n    >>> print(severity)\n    ContradictionSeverity.CRITICAL",
      "parameters": [
        {
          "name": "semantic_similarity",
          "type": "float",
          "default": null
        },
        {
          "name": "has_polarity_opposition",
          "type": "bool",
          "default": null
        },
        {
          "name": "polarity_confidence",
          "type": "float",
          "default": null
        }
      ],
      "return_type": "ContradictionSeverity",
      "complexity": 7,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "detect_contradiction",
          "file": "model_chorus/src/model_chorus/core/contradiction.py",
          "line": 537,
          "call_type": "function_call"
        },
        {
          "name": "test_critical_severity_high_similarity_strong_polarity",
          "file": "tests/test_contradiction.py",
          "line": 71,
          "call_type": "function_call"
        },
        {
          "name": "test_major_severity_high_similarity_weak_polarity",
          "file": "tests/test_contradiction.py",
          "line": 81,
          "call_type": "function_call"
        },
        {
          "name": "test_moderate_severity_medium_similarity",
          "file": "tests/test_contradiction.py",
          "line": 91,
          "call_type": "function_call"
        },
        {
          "name": "test_minor_severity_low_similarity",
          "file": "tests/test_contradiction.py",
          "line": 101,
          "call_type": "function_call"
        },
        {
          "name": "test_moderate_severity_high_similarity_no_opposition",
          "file": "tests/test_contradiction.py",
          "line": 111,
          "call_type": "function_call"
        }
      ],
      "calls": [],
      "call_count": 6
    },
    {
      "name": "generate_contradiction_explanation",
      "file": "model_chorus/src/model_chorus/core/contradiction.py",
      "line": 376,
      "language": "python",
      "docstring": "Generate human-readable explanation for a detected contradiction.\n\nCreates a detailed explanation describing why two claims contradict,\nincluding semantic similarity scores and polarity analysis.\n\nArgs:\n    severity: Assessed severity level of the contradiction\n    semantic_similarity: Cosine similarity between claims (0.0-1.0)\n    has_polarity_opposition: Whether claims have opposing polarity\n    polarity_confidence: Confidence in polarity detection (0.0-1.0)\n\nReturns:\n    Formatted explanation string describing the contradiction\n\nExample:\n    >>> explanation = generate_contradiction_explanation(\n    ...     severity=ContradictionSeverity.CRITICAL,\n    ...     semantic_similarity=0.85,\n    ...     has_polarity_opposition=True,\n    ...     polarity_confidence=0.8\n    ... )\n    >>> print(explanation)\n    Claims have opposing polarity (confidence: 0.80). Semantic similarity: 0.85. Claims are highly related but present contradictory assertions",
      "parameters": [
        {
          "name": "severity",
          "type": "ContradictionSeverity",
          "default": null
        },
        {
          "name": "semantic_similarity",
          "type": "float",
          "default": null
        },
        {
          "name": "has_polarity_opposition",
          "type": "bool",
          "default": null
        },
        {
          "name": "polarity_confidence",
          "type": "float",
          "default": null
        }
      ],
      "return_type": "str",
      "complexity": 4,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "detect_contradiction",
          "file": "model_chorus/src/model_chorus/core/contradiction.py",
          "line": 544,
          "call_type": "function_call"
        },
        {
          "name": "test_explanation_includes_polarity_info",
          "file": "tests/test_contradiction.py",
          "line": 125,
          "call_type": "function_call"
        },
        {
          "name": "test_explanation_severity_critical",
          "file": "tests/test_contradiction.py",
          "line": 138,
          "call_type": "function_call"
        },
        {
          "name": "test_explanation_severity_moderate",
          "file": "tests/test_contradiction.py",
          "line": 149,
          "call_type": "function_call"
        },
        {
          "name": "test_explanation_severity_minor",
          "file": "tests/test_contradiction.py",
          "line": 160,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "append",
          "file": "unknown",
          "line": 410,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 414,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 419,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 423,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 427,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 431,
          "call_type": "method_call"
        }
      ],
      "call_count": 5
    },
    {
      "name": "generate_reconciliation_suggestion",
      "file": "model_chorus/src/model_chorus/core/contradiction.py",
      "line": 434,
      "language": "python",
      "docstring": "Generate reconciliation suggestion based on contradiction severity.\n\nProvides actionable guidance for investigating and resolving contradictions.\nHigher severity contradictions receive more urgent recommendations.\n\nArgs:\n    severity: Severity level of the contradiction\n\nReturns:\n    Suggestion string for CRITICAL/MAJOR/MODERATE, None for MINOR\n\nExample:\n    >>> suggestion = generate_reconciliation_suggestion(ContradictionSeverity.CRITICAL)\n    >>> print(suggestion)\n    Investigate source reliability and experimental conditions. One or both claims may be incorrect.",
      "parameters": [
        {
          "name": "severity",
          "type": "ContradictionSeverity",
          "default": null
        }
      ],
      "return_type": "Optional[str]",
      "complexity": 4,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "detect_contradiction",
          "file": "model_chorus/src/model_chorus/core/contradiction.py",
          "line": 552,
          "call_type": "function_call"
        },
        {
          "name": "test_critical_suggestion_mentions_reliability",
          "file": "tests/test_contradiction.py",
          "line": 175,
          "call_type": "function_call"
        },
        {
          "name": "test_major_suggestion_mentions_context",
          "file": "tests/test_contradiction.py",
          "line": 182,
          "call_type": "function_call"
        },
        {
          "name": "test_moderate_suggestion_mentions_differences",
          "file": "tests/test_contradiction.py",
          "line": 189,
          "call_type": "function_call"
        },
        {
          "name": "test_minor_no_suggestion",
          "file": "tests/test_contradiction.py",
          "line": 196,
          "call_type": "function_call"
        }
      ],
      "calls": [],
      "call_count": 5
    },
    {
      "name": "detect_contradiction",
      "file": "model_chorus/src/model_chorus/core/contradiction.py",
      "line": 473,
      "language": "python",
      "docstring": "Detect contradiction between two claims.\n\nMain entry point for contradiction detection. Analyzes semantic\nsimilarity and polarity opposition to determine if claims contradict.\n\nArgs:\n    claim_1_id: Identifier for first claim\n    claim_1_text: Text of first claim\n    claim_2_id: Identifier for second claim\n    claim_2_text: Text of second claim\n    similarity_threshold: Minimum similarity to consider (default: 0.3)\n    model_name: Sentence transformer model to use\n\nReturns:\n    Contradiction object if contradiction detected, None otherwise\n\nDetection Logic:\n    1. Compute semantic similarity\n    2. If similarity < threshold: likely unrelated, return None\n    3. Detect polarity opposition\n    4. If no polarity opposition and low similarity: return None\n    5. Assess severity\n    6. Generate explanation\n    7. Return Contradiction object\n\nExample:\n    >>> contra = detect_contradiction(\n    ...     \"claim-1\", \"AI improves accuracy by 23%\",\n    ...     \"claim-2\", \"AI reduces accuracy by 15%\"\n    ... )\n    >>> if contra:\n    ...     print(f\"Severity: {contra.severity}\")\n    ...     print(f\"Confidence: {contra.confidence}\")\n    Severity: ContradictionSeverity.CRITICAL\n    Confidence: 0.87",
      "parameters": [
        {
          "name": "claim_1_id",
          "type": "str",
          "default": null
        },
        {
          "name": "claim_1_text",
          "type": "str",
          "default": null
        },
        {
          "name": "claim_2_id",
          "type": "str",
          "default": null
        },
        {
          "name": "claim_2_text",
          "type": "str",
          "default": null
        },
        {
          "name": "similarity_threshold",
          "type": "float",
          "default": null
        },
        {
          "name": "model_name",
          "type": "str",
          "default": null
        }
      ],
      "return_type": "Optional[Contradiction]",
      "complexity": 3,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "detect_contradictions_batch",
          "file": "model_chorus/src/model_chorus/core/contradiction.py",
          "line": 614,
          "call_type": "function_call"
        },
        {
          "name": "test_detect_clear_contradiction",
          "file": "tests/test_contradiction.py",
          "line": 293,
          "call_type": "function_call"
        },
        {
          "name": "test_no_contradiction_unrelated_claims",
          "file": "tests/test_contradiction.py",
          "line": 311,
          "call_type": "function_call"
        },
        {
          "name": "test_no_contradiction_similar_polarity",
          "file": "tests/test_contradiction.py",
          "line": 327,
          "call_type": "function_call"
        },
        {
          "name": "test_medical_accuracy_contradiction",
          "file": "tests/test_contradiction.py",
          "line": 392,
          "call_type": "function_call"
        },
        {
          "name": "test_performance_metric_contradiction",
          "file": "tests/test_contradiction.py",
          "line": 410,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "_import_semantic_functions",
          "file": "unknown",
          "line": 519,
          "call_type": "function_call"
        },
        {
          "name": "compute_claim_similarity",
          "file": "unknown",
          "line": 522,
          "call_type": "function_call"
        },
        {
          "name": "detect_polarity_opposition",
          "file": "unknown",
          "line": 529,
          "call_type": "function_call"
        },
        {
          "name": "assess_contradiction_severity",
          "file": "unknown",
          "line": 537,
          "call_type": "function_call"
        },
        {
          "name": "generate_contradiction_explanation",
          "file": "unknown",
          "line": 544,
          "call_type": "function_call"
        },
        {
          "name": "generate_reconciliation_suggestion",
          "file": "unknown",
          "line": 552,
          "call_type": "function_call"
        },
        {
          "name": "round",
          "file": "unknown",
          "line": 566,
          "call_type": "function_call"
        },
        {
          "name": "round",
          "file": "unknown",
          "line": 568,
          "call_type": "function_call"
        }
      ],
      "call_count": 6
    },
    {
      "name": "detect_contradictions_batch",
      "file": "model_chorus/src/model_chorus/core/contradiction.py",
      "line": 577,
      "language": "python",
      "docstring": "Detect contradictions in a batch of claims.\n\nEfficiently compares all pairs of claims to find contradictions.\nUseful for analyzing collections of claims from multiple sources.\n\nArgs:\n    claims: List of (claim_id, claim_text) tuples\n    similarity_threshold: Minimum similarity to consider (default: 0.3)\n    model_name: Sentence transformer model to use\n\nReturns:\n    List of detected Contradiction objects\n\nExample:\n    >>> claims = [\n    ...     (\"claim-1\", \"AI improves accuracy\"),\n    ...     (\"claim-2\", \"AI reduces accuracy\"),\n    ...     (\"claim-3\", \"Weather is sunny\"),\n    ... ]\n    >>> contradictions = detect_contradictions_batch(claims)\n    >>> print(f\"Found {len(contradictions)} contradictions\")\n    Found 1 contradictions",
      "parameters": [
        {
          "name": "claims",
          "type": "List[Tuple[str, str]]",
          "default": null
        },
        {
          "name": "similarity_threshold",
          "type": "float",
          "default": null
        },
        {
          "name": "model_name",
          "type": "str",
          "default": null
        }
      ],
      "return_type": "List[Contradiction]",
      "complexity": 4,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "test_detect_contradictions_in_batch",
          "file": "tests/test_contradiction.py",
          "line": 355,
          "call_type": "function_call"
        },
        {
          "name": "test_batch_no_contradictions",
          "file": "tests/test_contradiction.py",
          "line": 377,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "range",
          "file": "unknown",
          "line": 609,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 609,
          "call_type": "function_call"
        },
        {
          "name": "range",
          "file": "unknown",
          "line": 610,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 610,
          "call_type": "function_call"
        },
        {
          "name": "detect_contradiction",
          "file": "unknown",
          "line": 614,
          "call_type": "function_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 622,
          "call_type": "method_call"
        }
      ],
      "call_count": 2
    },
    {
      "name": "_import_citation_map",
      "file": "model_chorus/src/model_chorus/core/gap_analysis.py",
      "line": 191,
      "language": "python",
      "docstring": "Import CitationMap model.",
      "parameters": [],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": false,
      "callers": [],
      "calls": []
    },
    {
      "name": "assess_gap_severity",
      "file": "model_chorus/src/model_chorus/core/gap_analysis.py",
      "line": 200,
      "language": "python",
      "docstring": "Assess the severity of a gap based on type and context.\n\nCombines gap type, citation coverage, and logical support to\nclassify gap severity.\n\nArgs:\n    gap_type: Type of gap detected\n    citation_count: Number of citations supporting the claim\n    expected_citations: Expected number of citations for this type of claim\n    has_supporting_logic: Whether logical support/reasoning is present\n\nReturns:\n    GapSeverity enum value\n\nSeverity Rules:\n    - EVIDENCE gap with 0 citations = MAJOR or CRITICAL\n    - LOGICAL gap without supporting logic = MAJOR\n    - SUPPORT gap = MODERATE\n    - ASSUMPTION gap = MINOR to MODERATE\n\nExample:\n    >>> severity = assess_gap_severity(\n    ...     gap_type=GapType.EVIDENCE,\n    ...     citation_count=0,\n    ...     expected_citations=2\n    ... )\n    >>> print(severity)\n    GapSeverity.MAJOR",
      "parameters": [
        {
          "name": "gap_type",
          "type": "GapType",
          "default": null
        },
        {
          "name": "citation_count",
          "type": "int",
          "default": null
        },
        {
          "name": "expected_citations",
          "type": "int",
          "default": null
        },
        {
          "name": "has_supporting_logic",
          "type": "bool",
          "default": null
        }
      ],
      "return_type": "GapSeverity",
      "complexity": 10,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "detect_missing_evidence",
          "file": "model_chorus/src/model_chorus/core/gap_analysis.py",
          "line": 367,
          "call_type": "function_call"
        },
        {
          "name": "detect_logical_gaps",
          "file": "model_chorus/src/model_chorus/core/gap_analysis.py",
          "line": 449,
          "call_type": "function_call"
        },
        {
          "name": "test_evidence_gap_critical_no_citations",
          "file": "tests/test_gap_analysis.py",
          "line": 96,
          "call_type": "function_call"
        },
        {
          "name": "test_evidence_gap_major_no_citations_low_expectation",
          "file": "tests/test_gap_analysis.py",
          "line": 106,
          "call_type": "function_call"
        },
        {
          "name": "test_evidence_gap_moderate_insufficient_citations",
          "file": "tests/test_gap_analysis.py",
          "line": 116,
          "call_type": "function_call"
        },
        {
          "name": "test_logical_gap_major_no_support",
          "file": "tests/test_gap_analysis.py",
          "line": 126,
          "call_type": "function_call"
        },
        {
          "name": "test_logical_gap_moderate_with_support",
          "file": "tests/test_gap_analysis.py",
          "line": 135,
          "call_type": "function_call"
        },
        {
          "name": "test_support_gap_moderate",
          "file": "tests/test_gap_analysis.py",
          "line": 144,
          "call_type": "function_call"
        },
        {
          "name": "test_assumption_gap_moderate_no_logic",
          "file": "tests/test_gap_analysis.py",
          "line": 150,
          "call_type": "function_call"
        },
        {
          "name": "test_assumption_gap_minor_with_logic",
          "file": "tests/test_gap_analysis.py",
          "line": 159,
          "call_type": "function_call"
        }
      ],
      "calls": [],
      "call_count": 10
    },
    {
      "name": "generate_gap_recommendation",
      "file": "model_chorus/src/model_chorus/core/gap_analysis.py",
      "line": 271,
      "language": "python",
      "docstring": "Generate actionable recommendation for addressing a gap.\n\nProvides specific guidance based on gap type and severity to help\nimprove argument completeness and validity.\n\nArgs:\n    gap_type: Type of gap detected\n    severity: Severity level of the gap\n    claim_text: Text of the claim with the gap\n\nReturns:\n    Recommendation string with actionable guidance\n\nExample:\n    >>> rec = generate_gap_recommendation(\n    ...     GapType.EVIDENCE,\n    ...     GapSeverity.MAJOR,\n    ...     \"AI improves accuracy\"\n    ... )\n    >>> print(rec)\n    Add empirical evidence with specific citations. Find peer-reviewed studies or data supporting this claim.",
      "parameters": [
        {
          "name": "gap_type",
          "type": "GapType",
          "default": null
        },
        {
          "name": "severity",
          "type": "GapSeverity",
          "default": null
        },
        {
          "name": "claim_text",
          "type": "str",
          "default": null
        }
      ],
      "return_type": "str",
      "complexity": 6,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "detect_missing_evidence",
          "file": "model_chorus/src/model_chorus/core/gap_analysis.py",
          "line": 380,
          "call_type": "function_call"
        },
        {
          "name": "detect_logical_gaps",
          "file": "model_chorus/src/model_chorus/core/gap_analysis.py",
          "line": 459,
          "call_type": "function_call"
        },
        {
          "name": "test_evidence_recommendation_critical",
          "file": "tests/test_gap_analysis.py",
          "line": 172,
          "call_type": "function_call"
        },
        {
          "name": "test_evidence_recommendation_minor",
          "file": "tests/test_gap_analysis.py",
          "line": 183,
          "call_type": "function_call"
        },
        {
          "name": "test_logical_recommendation",
          "file": "tests/test_gap_analysis.py",
          "line": 193,
          "call_type": "function_call"
        },
        {
          "name": "test_support_recommendation",
          "file": "tests/test_gap_analysis.py",
          "line": 203,
          "call_type": "function_call"
        },
        {
          "name": "test_assumption_recommendation",
          "file": "tests/test_gap_analysis.py",
          "line": 213,
          "call_type": "function_call"
        }
      ],
      "calls": [],
      "call_count": 7
    },
    {
      "name": "detect_missing_evidence",
      "file": "model_chorus/src/model_chorus/core/gap_analysis.py",
      "line": 332,
      "language": "python",
      "docstring": "Detect if a claim lacks adequate evidential support.\n\nAnalyzes citation coverage to identify claims that need more\nempirical support or references.\n\nArgs:\n    claim_id: Identifier for the claim\n    claim_text: Text of the claim to analyze\n    citations: Optional list of Citation objects supporting this claim\n    expected_citation_count: Minimum expected citations for this claim type\n\nReturns:\n    Gap object if evidence gap detected, None otherwise\n\nExample:\n    >>> gap = detect_missing_evidence(\n    ...     \"claim-1\",\n    ...     \"AI reduces diagnostic errors by 40%\",\n    ...     citations=[]\n    ... )\n    >>> if gap:\n    ...     print(f\"Gap type: {gap.gap_type}, Severity: {gap.severity}\")\n    Gap type: GapType.EVIDENCE, Severity: GapSeverity.MAJOR",
      "parameters": [
        {
          "name": "claim_id",
          "type": "str",
          "default": null
        },
        {
          "name": "claim_text",
          "type": "str",
          "default": null
        },
        {
          "name": "citations",
          "type": "Optional[List[Any]]",
          "default": null
        },
        {
          "name": "expected_citation_count",
          "type": "int",
          "default": null
        }
      ],
      "return_type": "Optional[Gap]",
      "complexity": 3,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "detect_unsupported_claims",
          "file": "model_chorus/src/model_chorus/core/gap_analysis.py",
          "line": 511,
          "call_type": "function_call"
        },
        {
          "name": "detect_gaps",
          "file": "model_chorus/src/model_chorus/core/gap_analysis.py",
          "line": 567,
          "call_type": "function_call"
        },
        {
          "name": "test_detect_missing_evidence_no_citations",
          "file": "tests/test_gap_analysis.py",
          "line": 227,
          "call_type": "function_call"
        },
        {
          "name": "test_detect_missing_evidence_insufficient_citations",
          "file": "tests/test_gap_analysis.py",
          "line": 242,
          "call_type": "function_call"
        },
        {
          "name": "test_no_gap_sufficient_citations",
          "file": "tests/test_gap_analysis.py",
          "line": 255,
          "call_type": "function_call"
        },
        {
          "name": "test_evidence_gap_metadata",
          "file": "tests/test_gap_analysis.py",
          "line": 266,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "len",
          "file": "unknown",
          "line": 363,
          "call_type": "function_call"
        },
        {
          "name": "assess_gap_severity",
          "file": "unknown",
          "line": 367,
          "call_type": "function_call"
        },
        {
          "name": "generate_gap_recommendation",
          "file": "unknown",
          "line": 380,
          "call_type": "function_call"
        },
        {
          "name": "min",
          "file": "unknown",
          "line": 385,
          "call_type": "function_call"
        }
      ],
      "call_count": 6
    },
    {
      "name": "detect_logical_gaps",
      "file": "model_chorus/src/model_chorus/core/gap_analysis.py",
      "line": 408,
      "language": "python",
      "docstring": "Detect logical gaps or missing reasoning steps.\n\nAnalyzes whether a claim has adequate logical support or if there\nare missing steps in the reasoning chain.\n\nArgs:\n    claim_id: Identifier for the claim\n    claim_text: Text of the claim to analyze\n    supporting_claims: Optional list of supporting claim texts\n\nReturns:\n    Gap object if logical gap detected, None otherwise\n\nExample:\n    >>> gap = detect_logical_gaps(\n    ...     \"claim-1\",\n    ...     \"Therefore, we should implement policy X\",\n    ...     supporting_claims=[]\n    ... )\n    >>> if gap:\n    ...     print(f\"Detected: {gap.description}\")",
      "parameters": [
        {
          "name": "claim_id",
          "type": "str",
          "default": null
        },
        {
          "name": "claim_text",
          "type": "str",
          "default": null
        },
        {
          "name": "supporting_claims",
          "type": "Optional[List[str]]",
          "default": null
        }
      ],
      "return_type": "Optional[Gap]",
      "complexity": 4,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "detect_gaps",
          "file": "model_chorus/src/model_chorus/core/gap_analysis.py",
          "line": 577,
          "call_type": "function_call"
        },
        {
          "name": "test_detect_logical_gap_conclusion_without_support",
          "file": "tests/test_gap_analysis.py",
          "line": 285,
          "call_type": "function_call"
        },
        {
          "name": "test_no_logical_gap_with_support",
          "file": "tests/test_gap_analysis.py",
          "line": 298,
          "call_type": "function_call"
        },
        {
          "name": "test_no_logical_gap_non_conclusion_claim",
          "file": "tests/test_gap_analysis.py",
          "line": 308,
          "call_type": "function_call"
        },
        {
          "name": "test_conclusion_indicators_detected",
          "file": "tests/test_gap_analysis.py",
          "line": 328,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "len",
          "file": "unknown",
          "line": 436,
          "call_type": "function_call"
        },
        {
          "name": "lower",
          "file": "unknown",
          "line": 444,
          "call_type": "method_call"
        },
        {
          "name": "any",
          "file": "unknown",
          "line": 445,
          "call_type": "function_call"
        },
        {
          "name": "assess_gap_severity",
          "file": "unknown",
          "line": 449,
          "call_type": "function_call"
        },
        {
          "name": "generate_gap_recommendation",
          "file": "unknown",
          "line": 459,
          "call_type": "function_call"
        }
      ],
      "call_count": 5
    },
    {
      "name": "detect_unsupported_claims",
      "file": "model_chorus/src/model_chorus/core/gap_analysis.py",
      "line": 484,
      "language": "python",
      "docstring": "Detect unsupported claims in a collection.\n\nBatch analysis to identify all claims lacking adequate citation support.\n\nArgs:\n    claims: List of (claim_id, claim_text, citations) tuples\n    min_citations_per_claim: Minimum expected citations per claim\n\nReturns:\n    List of Gap objects for unsupported claims\n\nExample:\n    >>> claims = [\n    ...     (\"claim-1\", \"AI improves accuracy\", []),\n    ...     (\"claim-2\", \"Studies show benefits\", [citation1, citation2]),\n    ... ]\n    >>> gaps = detect_unsupported_claims(claims)\n    >>> print(f\"Found {len(gaps)} unsupported claims\")",
      "parameters": [
        {
          "name": "claims",
          "type": "List[tuple[str, str, Optional[List[Any]]]]",
          "default": null
        },
        {
          "name": "min_citations_per_claim",
          "type": "int",
          "default": null
        }
      ],
      "return_type": "List[Gap]",
      "complexity": 3,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "test_detect_multiple_unsupported_claims",
          "file": "tests/test_gap_analysis.py",
          "line": 347,
          "call_type": "function_call"
        },
        {
          "name": "test_detect_no_gaps_all_supported",
          "file": "tests/test_gap_analysis.py",
          "line": 363,
          "call_type": "function_call"
        },
        {
          "name": "test_custom_minimum_citations",
          "file": "tests/test_gap_analysis.py",
          "line": 374,
          "call_type": "function_call"
        },
        {
          "name": "test_custom_minimum_citations",
          "file": "tests/test_gap_analysis.py",
          "line": 378,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "detect_missing_evidence",
          "file": "unknown",
          "line": 511,
          "call_type": "function_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 519,
          "call_type": "method_call"
        }
      ],
      "call_count": 4
    },
    {
      "name": "detect_gaps",
      "file": "model_chorus/src/model_chorus/core/gap_analysis.py",
      "line": 524,
      "language": "python",
      "docstring": "Main entry point for comprehensive gap detection.\n\nAnalyzes a collection of claims to identify evidence gaps, logical gaps,\nand other weaknesses in argument structure.\n\nArgs:\n    claims: List of claim dictionaries with keys:\n        - claim_id: Unique identifier\n        - claim_text: Claim text\n        - citations: Optional list of citations\n        - supporting_claims: Optional list of supporting claim texts\n    min_citations_per_claim: Minimum expected citations per claim\n\nReturns:\n    List of all detected Gap objects\n\nExample:\n    >>> claims = [\n    ...     {\n    ...         \"claim_id\": \"claim-1\",\n    ...         \"claim_text\": \"Universal basic income reduces poverty\",\n    ...         \"citations\": [],\n    ...         \"supporting_claims\": []\n    ...     }\n    ... ]\n    >>> gaps = detect_gaps(claims)\n    >>> for gap in gaps:\n    ...     print(f\"{gap.gap_type}: {gap.description}\")",
      "parameters": [
        {
          "name": "claims",
          "type": "List[Dict[str, Any]]",
          "default": null
        },
        {
          "name": "min_citations_per_claim",
          "type": "int",
          "default": null
        }
      ],
      "return_type": "List[Gap]",
      "complexity": 4,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "test_detect_multiple_gap_types",
          "file": "tests/test_gap_analysis.py",
          "line": 402,
          "call_type": "function_call"
        },
        {
          "name": "test_detect_no_gaps_complete_argument",
          "file": "tests/test_gap_analysis.py",
          "line": 428,
          "call_type": "function_call"
        },
        {
          "name": "test_gap_detection_with_mixed_quality",
          "file": "tests/test_gap_analysis.py",
          "line": 455,
          "call_type": "function_call"
        },
        {
          "name": "test_policy_argument_with_gaps",
          "file": "tests/test_gap_analysis.py",
          "line": 492,
          "call_type": "function_call"
        },
        {
          "name": "test_well_supported_scientific_claim",
          "file": "tests/test_gap_analysis.py",
          "line": 515,
          "call_type": "function_call"
        },
        {
          "name": "test_argumentative_essay_analysis",
          "file": "tests/test_gap_analysis.py",
          "line": 549,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "get",
          "file": "unknown",
          "line": 561,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 562,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 563,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 564,
          "call_type": "method_call"
        },
        {
          "name": "detect_missing_evidence",
          "file": "unknown",
          "line": 567,
          "call_type": "function_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 574,
          "call_type": "method_call"
        },
        {
          "name": "detect_logical_gaps",
          "file": "unknown",
          "line": 577,
          "call_type": "function_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 583,
          "call_type": "method_call"
        }
      ],
      "call_count": 6
    },
    {
      "name": "set_progress_enabled",
      "file": "model_chorus/src/model_chorus/core/progress.py",
      "line": 19,
      "language": "python",
      "docstring": "Enable or disable progress output.\n\nArgs:\n    enabled: True to enable progress output, False to disable",
      "parameters": [
        {
          "name": "enabled",
          "type": "bool",
          "default": null
        }
      ],
      "return_type": "None",
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "is_progress_enabled",
      "file": "model_chorus/src/model_chorus/core/progress.py",
      "line": 30,
      "language": "python",
      "docstring": "Check if progress output is enabled.",
      "parameters": [],
      "return_type": "bool",
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "emit_progress",
      "file": "model_chorus/src/model_chorus/core/progress.py",
      "line": 35,
      "language": "python",
      "docstring": "Emit a progress update to stderr.\n\nProgress messages are sent to stderr so they don't interfere with\nstdout output (which may be parsed as JSON or redirected).\n\nArgs:\n    message: Progress message to display\n    prefix: Optional prefix (e.g., role name, stage name)\n    style: Rich style for the message (default: cyan)\n\nExample:\n    >>> emit_progress(\"Analyzing argument...\", prefix=\"Creator\")\n    [Creator] Analyzing argument...\n\n    >>> emit_progress(\"Generating response...\")\n    Generating response...",
      "parameters": [
        {
          "name": "message",
          "type": "str",
          "default": null
        },
        {
          "name": "prefix",
          "type": "Optional[str]",
          "default": null
        },
        {
          "name": "style",
          "type": "str",
          "default": null
        }
      ],
      "return_type": "None",
      "complexity": 3,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "emit_stage",
          "file": "model_chorus/src/model_chorus/core/progress.py",
          "line": 80,
          "call_type": "function_call"
        },
        {
          "name": "emit_provider_start",
          "file": "model_chorus/src/model_chorus/core/progress.py",
          "line": 94,
          "call_type": "function_call"
        },
        {
          "name": "emit_provider_complete",
          "file": "model_chorus/src/model_chorus/core/progress.py",
          "line": 114,
          "call_type": "function_call"
        },
        {
          "name": "emit_workflow_start",
          "file": "model_chorus/src/model_chorus/core/progress.py",
          "line": 134,
          "call_type": "function_call"
        },
        {
          "name": "emit_workflow_complete",
          "file": "model_chorus/src/model_chorus/core/progress.py",
          "line": 148,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "model_chorus/src/model_chorus/workflows/thinkdeep.py",
          "line": 291,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "model_chorus/src/model_chorus/workflows/thinkdeep.py",
          "line": 292,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "print",
          "file": "unknown",
          "line": 66,
          "call_type": "method_call"
        }
      ],
      "call_count": 7
    },
    {
      "name": "emit_stage",
      "file": "model_chorus/src/model_chorus/core/progress.py",
      "line": 69,
      "language": "python",
      "docstring": "Emit a workflow stage indicator.\n\nArgs:\n    stage: Stage name (e.g., \"Creator\", \"Skeptic\", \"Moderator\")\n\nExample:\n    >>> emit_stage(\"Creator\")\n    [Creator] Generating initial perspective...",
      "parameters": [
        {
          "name": "stage",
          "type": "str",
          "default": null
        }
      ],
      "return_type": "None",
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "run",
          "file": "model_chorus/src/model_chorus/workflows/argument/argument_workflow.py",
          "line": 484,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "emit_progress",
          "file": "unknown",
          "line": 80,
          "call_type": "function_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "emit_provider_start",
      "file": "model_chorus/src/model_chorus/core/progress.py",
      "line": 83,
      "language": "python",
      "docstring": "Emit progress for provider execution start.\n\nArgs:\n    provider: Provider name\n\nExample:\n    >>> emit_provider_start(\"claude\")\n    [claude] Executing...",
      "parameters": [
        {
          "name": "provider",
          "type": "str",
          "default": null
        }
      ],
      "return_type": "None",
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "_execute_provider",
          "file": "model_chorus/src/model_chorus/workflows/consensus.py",
          "line": 156,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "emit_progress",
          "file": "unknown",
          "line": 94,
          "call_type": "function_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "emit_provider_complete",
      "file": "model_chorus/src/model_chorus/core/progress.py",
      "line": 97,
      "language": "python",
      "docstring": "Emit progress for provider execution completion.\n\nArgs:\n    provider: Provider name\n    duration: Optional execution duration in seconds\n\nExample:\n    >>> emit_provider_complete(\"claude\", 2.3)\n    [claude] Complete (2.3s)",
      "parameters": [
        {
          "name": "provider",
          "type": "str",
          "default": null
        },
        {
          "name": "duration",
          "type": "Optional[float]",
          "default": null
        }
      ],
      "return_type": "None",
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "_execute_provider",
          "file": "model_chorus/src/model_chorus/workflows/consensus.py",
          "line": 179,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "emit_progress",
          "file": "unknown",
          "line": 114,
          "call_type": "function_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "emit_workflow_start",
      "file": "model_chorus/src/model_chorus/core/progress.py",
      "line": 117,
      "language": "python",
      "docstring": "Emit workflow start with optional time estimate.\n\nArgs:\n    workflow: Workflow name\n    estimated_duration: Optional human-readable duration estimate\n\nExample:\n    >>> emit_workflow_start(\"argument\", \"15-30s\")\n    Starting argument workflow (estimated: 15-30s)...",
      "parameters": [
        {
          "name": "workflow",
          "type": "str",
          "default": null
        },
        {
          "name": "estimated_duration",
          "type": "Optional[str]",
          "default": null
        }
      ],
      "return_type": "None",
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "run",
          "file": "model_chorus/src/model_chorus/workflows/argument/argument_workflow.py",
          "line": 481,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "model_chorus/src/model_chorus/workflows/chat.py",
          "line": 223,
          "call_type": "function_call"
        },
        {
          "name": "execute",
          "file": "model_chorus/src/model_chorus/workflows/consensus.py",
          "line": 216,
          "call_type": "function_call"
        },
        {
          "name": "run_complete_ideation",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 1517,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "model_chorus/src/model_chorus/workflows/study/study_workflow.py",
          "line": 216,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "model_chorus/src/model_chorus/workflows/thinkdeep.py",
          "line": 283,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "emit_progress",
          "file": "unknown",
          "line": 134,
          "call_type": "function_call"
        }
      ],
      "call_count": 6
    },
    {
      "name": "emit_workflow_complete",
      "file": "model_chorus/src/model_chorus/core/progress.py",
      "line": 137,
      "language": "python",
      "docstring": "Emit workflow completion.\n\nArgs:\n    workflow: Workflow name\n\nExample:\n    >>> emit_workflow_complete(\"argument\")\n    \u2713 argument workflow complete",
      "parameters": [
        {
          "name": "workflow",
          "type": "str",
          "default": null
        }
      ],
      "return_type": "None",
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "run",
          "file": "model_chorus/src/model_chorus/workflows/argument/argument_workflow.py",
          "line": 595,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "model_chorus/src/model_chorus/workflows/chat.py",
          "line": 282,
          "call_type": "function_call"
        },
        {
          "name": "execute",
          "file": "model_chorus/src/model_chorus/workflows/consensus.py",
          "line": 266,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py",
          "line": 271,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "model_chorus/src/model_chorus/workflows/study/study_workflow.py",
          "line": 284,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "model_chorus/src/model_chorus/workflows/thinkdeep.py",
          "line": 414,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "emit_progress",
          "file": "unknown",
          "line": 148,
          "call_type": "function_call"
        }
      ],
      "call_count": 6
    },
    {
      "name": "get_read_only_system_prompt",
      "file": "model_chorus/src/model_chorus/core/prompts.py",
      "line": 11,
      "language": "python",
      "docstring": "Generate system prompt informing AI of read-only tool constraints.\n\nThis prompt should be prepended to workflow-specific system prompts\nto set expectations about available tool capabilities when operating\nvia external CLI tools.\n\nThe constraints are enforced at the CLI provider level (no --yolo flag\nfor Gemini, etc.), but this prompt ensures the AI understands the\nlimitations upfront, preventing wasted API tokens on failed attempts.\n\nReturns:\n    System prompt text describing read-only constraints",
      "parameters": [],
      "return_type": "str",
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "prepend_system_constraints",
          "file": "model_chorus/src/model_chorus/core/prompts.py",
          "line": 65,
          "call_type": "function_call"
        }
      ],
      "calls": [],
      "call_count": 1
    },
    {
      "name": "prepend_system_constraints",
      "file": "model_chorus/src/model_chorus/core/prompts.py",
      "line": 45,
      "language": "python",
      "docstring": "Prepend read-only environment constraints to a custom system prompt.\n\nCombines the read-only constraints with any workflow-specific\nsystem prompt instructions. Constraints are prepended so they\nestablish context before task-specific guidance.\n\nArgs:\n    custom_prompt: Optional workflow-specific system prompt.\n                  If None, returns just the constraints.\n\nReturns:\n    Combined system prompt with constraints prepended\n\nExample:\n    >>> ideation_prompt = \"You are a creative brainstorming expert...\"\n    >>> final_prompt = prepend_system_constraints(ideation_prompt)\n    >>> # Returns constraints + ideation prompt",
      "parameters": [
        {
          "name": "custom_prompt",
          "type": "Optional[str]",
          "default": null
        }
      ],
      "return_type": "str",
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "_create_creator_role",
          "file": "model_chorus/src/model_chorus/workflows/argument/argument_workflow.py",
          "line": 161,
          "call_type": "function_call"
        },
        {
          "name": "_create_skeptic_role",
          "file": "model_chorus/src/model_chorus/workflows/argument/argument_workflow.py",
          "line": 206,
          "call_type": "function_call"
        },
        {
          "name": "_create_moderator_role",
          "file": "model_chorus/src/model_chorus/workflows/argument/argument_workflow.py",
          "line": 253,
          "call_type": "function_call"
        },
        {
          "name": "run",
          "file": "model_chorus/src/model_chorus/workflows/chat.py",
          "line": 209,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "get_read_only_system_prompt",
          "file": "unknown",
          "line": 65,
          "call_type": "function_call"
        }
      ],
      "call_count": 4
    },
    {
      "name": "get_default_state_manager",
      "file": "model_chorus/src/model_chorus/core/state.py",
      "line": 517,
      "language": "python",
      "docstring": "Get singleton default state manager instance.\n\nReturns:\n    Default StateManager instance\n\nExample:\n    >>> from model_chorus.core.state import get_default_state_manager\n    >>> manager = get_default_state_manager()\n    >>> manager.set_state(\"my_workflow\", {\"step\": 1})",
      "parameters": [],
      "return_type": "StateManager",
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "test_get_default_state_manager",
          "file": "model_chorus/tests/test_state.py",
          "line": 596,
          "call_type": "function_call"
        },
        {
          "name": "test_get_default_state_manager",
          "file": "model_chorus/tests/test_state.py",
          "line": 597,
          "call_type": "function_call"
        }
      ],
      "calls": [],
      "call_count": 2
    },
    {
      "name": "format_citation",
      "file": "model_chorus/src/model_chorus/utils/citation_formatter.py",
      "line": 23,
      "language": "python",
      "docstring": "Format a Citation object according to the specified style.\n\nArgs:\n    citation: The Citation object to format\n    style: The citation style to use (APA, MLA, or Chicago)\n\nReturns:\n    Formatted citation string according to the specified style\n\nExample:\n    >>> from model_chorus.core.models import Citation\n    >>> from model_chorus.utils.citation_formatter import format_citation, CitationStyle\n    >>> c = Citation(\n    ...     source=\"https://arxiv.org/abs/2401.12345\",\n    ...     confidence=0.95,\n    ...     metadata={\"author\": \"Smith, J.\", \"year\": \"2024\", \"title\": \"Machine Learning\"}\n    ... )\n    >>> format_citation(c, CitationStyle.APA)\n    'Smith, J. (2024). Machine Learning. Retrieved from https://arxiv.org/abs/2401.12345'",
      "parameters": [
        {
          "name": "citation",
          "type": "'Citation'",
          "default": null
        },
        {
          "name": "style",
          "type": "CitationStyle",
          "default": null
        }
      ],
      "return_type": "str",
      "complexity": 4,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "format_citation_map",
          "file": "model_chorus/src/model_chorus/utils/citation_formatter.py",
          "line": 214,
          "call_type": "function_call"
        },
        {
          "name": "test_format_apa_complete",
          "file": "tests/test_citation.py",
          "line": 113,
          "call_type": "function_call"
        },
        {
          "name": "test_format_apa_minimal",
          "file": "tests/test_citation.py",
          "line": 123,
          "call_type": "function_call"
        },
        {
          "name": "test_format_mla_complete",
          "file": "tests/test_citation.py",
          "line": 130,
          "call_type": "function_call"
        },
        {
          "name": "test_format_mla_minimal",
          "file": "tests/test_citation.py",
          "line": 140,
          "call_type": "function_call"
        },
        {
          "name": "test_format_chicago_complete",
          "file": "tests/test_citation.py",
          "line": 146,
          "call_type": "function_call"
        },
        {
          "name": "test_format_chicago_minimal",
          "file": "tests/test_citation.py",
          "line": 156,
          "call_type": "function_call"
        },
        {
          "name": "test_format_file_citation_apa",
          "file": "tests/test_citation.py",
          "line": 162,
          "call_type": "function_call"
        },
        {
          "name": "test_format_doi_citation_apa",
          "file": "tests/test_citation.py",
          "line": 172,
          "call_type": "function_call"
        },
        {
          "name": "test_format_unsupported_style_raises_error",
          "file": "tests/test_citation.py",
          "line": 182,
          "call_type": "function_call"
        },
        {
          "name": "test_year_extraction_from_full_date",
          "file": "tests/test_citation.py",
          "line": 196,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "_format_apa",
          "file": "unknown",
          "line": 49,
          "call_type": "function_call"
        },
        {
          "name": "_format_mla",
          "file": "unknown",
          "line": 51,
          "call_type": "function_call"
        },
        {
          "name": "_format_chicago",
          "file": "unknown",
          "line": 53,
          "call_type": "function_call"
        }
      ],
      "call_count": 11
    },
    {
      "name": "_format_apa",
      "file": "model_chorus/src/model_chorus/utils/citation_formatter.py",
      "line": 58,
      "language": "python",
      "docstring": "Format citation in APA style.\n\nAPA format: Author(s). (Year). Title. Source.\n\nArgs:\n    citation: The Citation object to format\n\nReturns:\n    APA-formatted citation string",
      "parameters": [
        {
          "name": "citation",
          "type": "'Citation'",
          "default": null
        }
      ],
      "return_type": "str",
      "complexity": 6,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": false,
      "callers": [
        {
          "name": "format_citation",
          "file": "model_chorus/src/model_chorus/utils/citation_formatter.py",
          "line": 49,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "get",
          "file": "unknown",
          "line": 73,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 75,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 78,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 78,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 81,
          "call_type": "function_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 81,
          "call_type": "function_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 81,
          "call_type": "function_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 81,
          "call_type": "function_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 82,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 85,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 87,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 93,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 95,
          "call_type": "method_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "_format_mla",
      "file": "model_chorus/src/model_chorus/utils/citation_formatter.py",
      "line": 98,
      "language": "python",
      "docstring": "Format citation in MLA style.\n\nMLA format: Author(s). \"Title.\" Source, Year. Location.\n\nArgs:\n    citation: The Citation object to format\n\nReturns:\n    MLA-formatted citation string",
      "parameters": [
        {
          "name": "citation",
          "type": "'Citation'",
          "default": null
        }
      ],
      "return_type": "str",
      "complexity": 6,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": false,
      "callers": [
        {
          "name": "format_citation",
          "file": "model_chorus/src/model_chorus/utils/citation_formatter.py",
          "line": 51,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "get",
          "file": "unknown",
          "line": 113,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 115,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 118,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 120,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 123,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 126,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 126,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 128,
          "call_type": "function_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 128,
          "call_type": "function_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 128,
          "call_type": "function_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 128,
          "call_type": "function_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 129,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 133,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 135,
          "call_type": "method_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "_format_chicago",
      "file": "model_chorus/src/model_chorus/utils/citation_formatter.py",
      "line": 138,
      "language": "python",
      "docstring": "Format citation in Chicago style.\n\nChicago format: Author(s). \"Title.\" Source (Year): Location.\n\nArgs:\n    citation: The Citation object to format\n\nReturns:\n    Chicago-formatted citation string",
      "parameters": [
        {
          "name": "citation",
          "type": "'Citation'",
          "default": null
        }
      ],
      "return_type": "str",
      "complexity": 6,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": false,
      "callers": [
        {
          "name": "format_citation",
          "file": "model_chorus/src/model_chorus/utils/citation_formatter.py",
          "line": 53,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "get",
          "file": "unknown",
          "line": 153,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 155,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 158,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 160,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 166,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 166,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 168,
          "call_type": "function_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 168,
          "call_type": "function_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 168,
          "call_type": "function_call"
        },
        {
          "name": "str",
          "file": "unknown",
          "line": 168,
          "call_type": "function_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 175,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 177,
          "call_type": "method_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "format_citation_map",
      "file": "model_chorus/src/model_chorus/utils/citation_formatter.py",
      "line": 180,
      "language": "python",
      "docstring": "Format a CitationMap object with all its citations.\n\nArgs:\n    citation_map: The CitationMap object to format\n    style: The citation style to use (APA, MLA, or Chicago)\n    include_claim: Whether to include the claim text in the output\n\nReturns:\n    Formatted string with claim and all citations\n\nExample:\n    >>> formatted = format_citation_map(cm, CitationStyle.APA, include_claim=True)\n    >>> print(formatted)\n    Claim: Machine learning improves accuracy by 23%\n\n    Citations:\n    1. Smith, J. (2024). ML Research. Retrieved from https://arxiv.org/abs/2401.12345\n    2. Doe, A. (2024). AI Studies. Retrieved from paper2.pdf",
      "parameters": [
        {
          "name": "citation_map",
          "type": "'CitationMap'",
          "default": null
        },
        {
          "name": "style",
          "type": "CitationStyle",
          "default": null
        },
        {
          "name": "include_claim",
          "type": "bool",
          "default": null
        }
      ],
      "return_type": "str",
      "complexity": 4,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "test_format_citation_map_with_claim",
          "file": "tests/test_citation.py",
          "line": 205,
          "call_type": "function_call"
        },
        {
          "name": "test_format_citation_map_without_claim",
          "file": "tests/test_citation.py",
          "line": 216,
          "call_type": "function_call"
        },
        {
          "name": "test_format_citation_map_mla_style",
          "file": "tests/test_citation.py",
          "line": 225,
          "call_type": "function_call"
        },
        {
          "name": "test_format_citation_map_empty",
          "file": "tests/test_citation.py",
          "line": 234,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "append",
          "file": "unknown",
          "line": 208,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 209,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 212,
          "call_type": "method_call"
        },
        {
          "name": "enumerate",
          "file": "unknown",
          "line": 213,
          "call_type": "function_call"
        },
        {
          "name": "format_citation",
          "file": "unknown",
          "line": 214,
          "call_type": "function_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 215,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 217,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 219,
          "call_type": "method_call"
        }
      ],
      "call_count": 4
    },
    {
      "name": "validate_citation",
      "file": "model_chorus/src/model_chorus/utils/citation_formatter.py",
      "line": 227,
      "language": "python",
      "docstring": "Validate a Citation object for completeness and quality.\n\nArgs:\n    citation: The Citation object to validate\n\nReturns:\n    Tuple of (is_valid, issues) where:\n    - is_valid: True if citation meets minimum requirements\n    - issues: List of validation issue messages\n\nExample:\n    >>> is_valid, issues = validate_citation(citation)\n    >>> if not is_valid:\n    ...     print(f\"Validation issues: {', '.join(issues)}\")",
      "parameters": [
        {
          "name": "citation",
          "type": "'Citation'",
          "default": null
        }
      ],
      "return_type": "Tuple[bool, List[str]]",
      "complexity": 14,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "test_validate_complete_citation_passes",
          "file": "tests/test_citation.py",
          "line": 250,
          "call_type": "function_call"
        },
        {
          "name": "test_validate_minimal_citation_has_recommendations",
          "file": "tests/test_citation.py",
          "line": 258,
          "call_type": "function_call"
        },
        {
          "name": "test_validate_whitespace_source_fails",
          "file": "tests/test_citation.py",
          "line": 277,
          "call_type": "function_call"
        },
        {
          "name": "test_validate_confidence_out_of_range_low",
          "file": "tests/test_citation.py",
          "line": 289,
          "call_type": "function_call"
        },
        {
          "name": "test_validate_confidence_out_of_range_high",
          "file": "tests/test_citation.py",
          "line": 299,
          "call_type": "function_call"
        },
        {
          "name": "test_validate_recognized_source_formats",
          "file": "tests/test_citation.py",
          "line": 322,
          "call_type": "function_call"
        },
        {
          "name": "test_validate_unrecognized_source_format",
          "file": "tests/test_citation.py",
          "line": 335,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "strip",
          "file": "unknown",
          "line": 247,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 248,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 251,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 256,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 257,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 259,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 259,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 260,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 262,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 263,
          "call_type": "method_call"
        },
        {
          "name": "lower",
          "file": "unknown",
          "line": 266,
          "call_type": "method_call"
        },
        {
          "name": "startswith",
          "file": "unknown",
          "line": 268,
          "call_type": "method_call"
        },
        {
          "name": "startswith",
          "file": "unknown",
          "line": 269,
          "call_type": "method_call"
        },
        {
          "name": "endswith",
          "file": "unknown",
          "line": 270,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 273,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 275,
          "call_type": "function_call"
        }
      ],
      "call_count": 7
    },
    {
      "name": "calculate_citation_confidence",
      "file": "model_chorus/src/model_chorus/utils/citation_formatter.py",
      "line": 279,
      "language": "python",
      "docstring": "Calculate a detailed confidence score for a citation's reliability.\n\nEvaluates multiple factors:\n- Base confidence score (from citation.confidence)\n- Metadata completeness (author, year, title presence)\n- Source quality (URL vs file, academic domains)\n- Location specificity (page numbers, sections)\n\nArgs:\n    citation: The Citation object to score\n\nReturns:\n    Dictionary with:\n    - overall_confidence: Final confidence score (0.0-1.0)\n    - base_confidence: Original confidence value\n    - metadata_score: Completeness score for metadata (0.0-1.0)\n    - source_quality_score: Quality score for source type (0.0-1.0)\n    - location_score: Specificity score for location (0.0-1.0)\n    - factors: Detailed breakdown of scoring factors\n\nExample:\n    >>> scores = calculate_citation_confidence(citation)\n    >>> print(f\"Overall confidence: {scores['overall_confidence']:.2f}\")\n    >>> print(f\"Metadata completeness: {scores['metadata_score']:.2f}\")",
      "parameters": [
        {
          "name": "citation",
          "type": "'Citation'",
          "default": null
        }
      ],
      "return_type": "Dict[str, Any]",
      "complexity": 11,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "calculate_citation_map_confidence",
          "file": "model_chorus/src/model_chorus/utils/citation_formatter.py",
          "line": 404,
          "call_type": "function_call"
        },
        {
          "name": "test_calculate_confidence_complete_citation",
          "file": "tests/test_citation.py",
          "line": 350,
          "call_type": "function_call"
        },
        {
          "name": "test_calculate_confidence_minimal_citation",
          "file": "tests/test_citation.py",
          "line": 367,
          "call_type": "function_call"
        },
        {
          "name": "test_confidence_academic_source_bonus",
          "file": "tests/test_citation.py",
          "line": 382,
          "call_type": "function_call"
        },
        {
          "name": "test_confidence_doi_source_bonus",
          "file": "tests/test_citation.py",
          "line": 394,
          "call_type": "function_call"
        },
        {
          "name": "test_confidence_https_vs_http",
          "file": "tests/test_citation.py",
          "line": 411,
          "call_type": "function_call"
        },
        {
          "name": "test_confidence_https_vs_http",
          "file": "tests/test_citation.py",
          "line": 412,
          "call_type": "function_call"
        },
        {
          "name": "test_confidence_location_specificity_bonus",
          "file": "tests/test_citation.py",
          "line": 420,
          "call_type": "function_call"
        },
        {
          "name": "test_confidence_location_specificity_bonus",
          "file": "tests/test_citation.py",
          "line": 429,
          "call_type": "function_call"
        },
        {
          "name": "test_confidence_location_specificity_bonus",
          "file": "tests/test_citation.py",
          "line": 438,
          "call_type": "function_call"
        },
        {
          "name": "test_confidence_weighted_formula",
          "file": "tests/test_citation.py",
          "line": 444,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "bool",
          "file": "unknown",
          "line": 313,
          "call_type": "function_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 313,
          "call_type": "method_call"
        },
        {
          "name": "bool",
          "file": "unknown",
          "line": 314,
          "call_type": "function_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 314,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 314,
          "call_type": "method_call"
        },
        {
          "name": "bool",
          "file": "unknown",
          "line": 315,
          "call_type": "function_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 315,
          "call_type": "method_call"
        },
        {
          "name": "bool",
          "file": "unknown",
          "line": 316,
          "call_type": "function_call"
        },
        {
          "name": "sum",
          "file": "unknown",
          "line": 318,
          "call_type": "function_call"
        },
        {
          "name": "values",
          "file": "unknown",
          "line": 318,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 318,
          "call_type": "function_call"
        },
        {
          "name": "lower",
          "file": "unknown",
          "line": 321,
          "call_type": "method_call"
        },
        {
          "name": "startswith",
          "file": "unknown",
          "line": 326,
          "call_type": "method_call"
        },
        {
          "name": "startswith",
          "file": "unknown",
          "line": 328,
          "call_type": "method_call"
        },
        {
          "name": "endswith",
          "file": "unknown",
          "line": 330,
          "call_type": "method_call"
        },
        {
          "name": "lower",
          "file": "unknown",
          "line": 336,
          "call_type": "method_call"
        },
        {
          "name": "any",
          "file": "unknown",
          "line": 340,
          "call_type": "function_call"
        },
        {
          "name": "any",
          "file": "unknown",
          "line": 342,
          "call_type": "function_call"
        },
        {
          "name": "round",
          "file": "unknown",
          "line": 354,
          "call_type": "function_call"
        },
        {
          "name": "round",
          "file": "unknown",
          "line": 356,
          "call_type": "function_call"
        },
        {
          "name": "round",
          "file": "unknown",
          "line": 357,
          "call_type": "function_call"
        },
        {
          "name": "round",
          "file": "unknown",
          "line": 358,
          "call_type": "function_call"
        }
      ],
      "call_count": 11
    },
    {
      "name": "calculate_citation_map_confidence",
      "file": "model_chorus/src/model_chorus/utils/citation_formatter.py",
      "line": 367,
      "language": "python",
      "docstring": "Calculate aggregate confidence scores for a CitationMap.\n\nEvaluates the overall quality of citations supporting a claim.\n\nArgs:\n    citation_map: The CitationMap object to score\n\nReturns:\n    Dictionary with:\n    - overall_confidence: Aggregate confidence for the claim (0.0-1.0)\n    - citation_count: Number of citations\n    - average_citation_confidence: Mean confidence across citations\n    - min_confidence: Lowest confidence citation\n    - max_confidence: Highest confidence citation\n    - strength: Original strength value from CitationMap\n    - individual_scores: List of confidence scores per citation\n\nExample:\n    >>> scores = calculate_citation_map_confidence(citation_map)\n    >>> print(f\"Claim supported by {scores['citation_count']} citations\")\n    >>> print(f\"Overall confidence: {scores['overall_confidence']:.2f}\")",
      "parameters": [
        {
          "name": "citation_map",
          "type": "'CitationMap'",
          "default": null
        }
      ],
      "return_type": "Dict[str, Any]",
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "test_calculate_map_confidence_complete",
          "file": "tests/test_citation.py",
          "line": 462,
          "call_type": "function_call"
        },
        {
          "name": "test_calculate_map_confidence_empty",
          "file": "tests/test_citation.py",
          "line": 474,
          "call_type": "function_call"
        },
        {
          "name": "test_calculate_map_confidence_formula",
          "file": "tests/test_citation.py",
          "line": 485,
          "call_type": "function_call"
        },
        {
          "name": "test_calculate_map_confidence_count_plateau",
          "file": "tests/test_citation.py",
          "line": 512,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "calculate_citation_confidence",
          "file": "unknown",
          "line": 404,
          "call_type": "function_call"
        },
        {
          "name": "sum",
          "file": "unknown",
          "line": 411,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 411,
          "call_type": "function_call"
        },
        {
          "name": "min",
          "file": "unknown",
          "line": 412,
          "call_type": "function_call"
        },
        {
          "name": "max",
          "file": "unknown",
          "line": 413,
          "call_type": "function_call"
        },
        {
          "name": "min",
          "file": "unknown",
          "line": 419,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 419,
          "call_type": "function_call"
        },
        {
          "name": "round",
          "file": "unknown",
          "line": 428,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 429,
          "call_type": "function_call"
        },
        {
          "name": "round",
          "file": "unknown",
          "line": 430,
          "call_type": "function_call"
        },
        {
          "name": "round",
          "file": "unknown",
          "line": 431,
          "call_type": "function_call"
        },
        {
          "name": "round",
          "file": "unknown",
          "line": 432,
          "call_type": "function_call"
        }
      ],
      "call_count": 4
    },
    {
      "name": "_get_model",
      "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
      "line": 24,
      "language": "python",
      "docstring": "Get or initialize the sentence transformer model.\n\nUses lazy loading to avoid loading the model until needed.\nModel is cached globally to avoid repeated loading.\n\nArgs:\n    model_name: Name of the sentence transformer model to use\n\nReturns:\n    SentenceTransformer instance",
      "parameters": [
        {
          "name": "model_name",
          "type": "str",
          "default": null
        }
      ],
      "return_type": "SentenceTransformer",
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": false,
      "callers": [
        {
          "name": "_compute_embedding_cached",
          "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
          "line": 72,
          "call_type": "function_call"
        }
      ],
      "calls": [],
      "call_count": 1
    },
    {
      "name": "_normalize_text",
      "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
      "line": 43,
      "language": "python",
      "docstring": "Normalize text for consistent embedding computation.\n\nArgs:\n    text: Input text to normalize\n\nReturns:\n    Normalized text (lowercase, stripped whitespace)",
      "parameters": [
        {
          "name": "text",
          "type": "str",
          "default": null
        }
      ],
      "return_type": "str",
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": false,
      "callers": [
        {
          "name": "compute_embedding",
          "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
          "line": 105,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "lower",
          "file": "unknown",
          "line": 53,
          "call_type": "method_call"
        },
        {
          "name": "strip",
          "file": "unknown",
          "line": 53,
          "call_type": "method_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "_compute_embedding_cached",
      "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
      "line": 57,
      "language": "python",
      "docstring": "Internal cached embedding computation.\n\nUses text hash as cache key to enable LRU caching while avoiding\nunhashable numpy arrays as cache keys.\n\nArgs:\n    text_hash: SHA256 hash of the normalized text (for cache key)\n    text: Actual text to compute embedding for\n    model_name: Model to use for embedding\n\nReturns:\n    Embedding vector as numpy array",
      "parameters": [
        {
          "name": "text_hash",
          "type": "str",
          "default": null
        },
        {
          "name": "text",
          "type": "str",
          "default": null
        },
        {
          "name": "model_name",
          "type": "str",
          "default": null
        }
      ],
      "return_type": "np.ndarray",
      "complexity": 1,
      "decorators": [
        "lru_cache(maxsize=1000)"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": false,
      "callers": [
        {
          "name": "compute_embedding",
          "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
          "line": 110,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "_get_model",
          "file": "unknown",
          "line": 72,
          "call_type": "function_call"
        },
        {
          "name": "encode",
          "file": "unknown",
          "line": 73,
          "call_type": "method_call"
        },
        {
          "name": "lru_cache",
          "file": "unknown",
          "line": 56,
          "call_type": "function_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "compute_embedding",
      "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
      "line": 77,
      "language": "python",
      "docstring": "Compute semantic embedding for text using sentence transformers.\n\nEmbeddings are cached using LRU cache to avoid recomputing for\nduplicate text. Text is normalized before embedding computation\nfor consistency.\n\nArgs:\n    text: Text to compute embedding for\n    model_name: Sentence transformer model name (default: all-MiniLM-L6-v2)\n    normalize: Whether to normalize text before embedding (default: True)\n\nReturns:\n    Normalized embedding vector as numpy array (unit length if model normalizes)\n\nExample:\n    >>> emb1 = compute_embedding(\"Machine learning improves accuracy\")\n    >>> emb2 = compute_embedding(\"ML enhances precision\")\n    >>> similarity = cosine_similarity(emb1, emb2)\n    >>> print(f\"Similarity: {similarity:.3f}\")\n    Similarity: 0.847",
      "parameters": [
        {
          "name": "text",
          "type": "str",
          "default": null
        },
        {
          "name": "model_name",
          "type": "str",
          "default": null
        },
        {
          "name": "normalize",
          "type": "bool",
          "default": null
        }
      ],
      "return_type": "np.ndarray",
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "compute_claim_similarity",
          "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
          "line": 170,
          "call_type": "function_call"
        },
        {
          "name": "compute_claim_similarity",
          "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
          "line": 171,
          "call_type": "function_call"
        },
        {
          "name": "find_similar_claims",
          "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
          "line": 214,
          "call_type": "function_call"
        },
        {
          "name": "find_similar_claims",
          "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
          "line": 219,
          "call_type": "function_call"
        },
        {
          "name": "compute_claim_similarity_batch",
          "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
          "line": 265,
          "call_type": "function_call"
        },
        {
          "name": "cluster_claims_kmeans",
          "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
          "line": 444,
          "call_type": "function_call"
        },
        {
          "name": "cluster_claims_hierarchical",
          "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
          "line": 505,
          "call_type": "function_call"
        },
        {
          "name": "get_cluster_representative",
          "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
          "line": 552,
          "call_type": "function_call"
        },
        {
          "name": "score_cluster_separation",
          "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
          "line": 834,
          "call_type": "function_call"
        },
        {
          "name": "score_clustering_quality",
          "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
          "line": 959,
          "call_type": "function_call"
        },
        {
          "name": "test_compute_embedding_returns_array",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 33,
          "call_type": "function_call"
        },
        {
          "name": "test_compute_embedding_normalization",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 42,
          "call_type": "function_call"
        },
        {
          "name": "test_compute_embedding_caching",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 53,
          "call_type": "function_call"
        },
        {
          "name": "test_compute_embedding_caching",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 56,
          "call_type": "function_call"
        },
        {
          "name": "test_compute_embedding_case_insensitive",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 66,
          "call_type": "function_call"
        },
        {
          "name": "test_compute_embedding_case_insensitive",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 67,
          "call_type": "function_call"
        },
        {
          "name": "test_compute_embedding_empty_string",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 75,
          "call_type": "function_call"
        },
        {
          "name": "test_cosine_similarity_identical",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 87,
          "call_type": "function_call"
        },
        {
          "name": "test_cosine_similarity_range",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 95,
          "call_type": "function_call"
        },
        {
          "name": "test_cosine_similarity_range",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 96,
          "call_type": "function_call"
        },
        {
          "name": "test_cosine_similarity_similar_text",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 104,
          "call_type": "function_call"
        },
        {
          "name": "test_cosine_similarity_similar_text",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 105,
          "call_type": "function_call"
        },
        {
          "name": "test_cosine_similarity_different_text",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 114,
          "call_type": "function_call"
        },
        {
          "name": "test_cosine_similarity_different_text",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 115,
          "call_type": "function_call"
        },
        {
          "name": "test_empty_claim_text",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 475,
          "call_type": "function_call"
        },
        {
          "name": "test_very_long_claim",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 482,
          "call_type": "function_call"
        },
        {
          "name": "test_special_characters",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 489,
          "call_type": "function_call"
        },
        {
          "name": "test_unicode_characters",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 496,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "_normalize_text",
          "file": "unknown",
          "line": 105,
          "call_type": "function_call"
        },
        {
          "name": "hexdigest",
          "file": "unknown",
          "line": 108,
          "call_type": "method_call"
        },
        {
          "name": "sha256",
          "file": "unknown",
          "line": 108,
          "call_type": "method_call"
        },
        {
          "name": "encode",
          "file": "unknown",
          "line": 108,
          "call_type": "method_call"
        },
        {
          "name": "_compute_embedding_cached",
          "file": "unknown",
          "line": 110,
          "call_type": "function_call"
        }
      ],
      "call_count": 28
    },
    {
      "name": "cosine_similarity",
      "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
      "line": 113,
      "language": "python",
      "docstring": "Compute cosine similarity between two embedding vectors.\n\nAssumes embeddings are already normalized (unit length).\nIf normalized, this reduces to simple dot product.\n\nArgs:\n    embedding1: First embedding vector\n    embedding2: Second embedding vector\n\nReturns:\n    Cosine similarity score (0.0 to 1.0)\n    - 1.0 = identical/very similar\n    - 0.0 = completely dissimilar\n    - 0.5 = moderate similarity\n\nExample:\n    >>> emb1 = compute_embedding(\"hello world\")\n    >>> emb2 = compute_embedding(\"hello world\")\n    >>> cosine_similarity(emb1, emb2)\n    1.0",
      "parameters": [
        {
          "name": "embedding1",
          "type": "np.ndarray",
          "default": null
        },
        {
          "name": "embedding2",
          "type": "np.ndarray",
          "default": null
        }
      ],
      "return_type": "float",
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "compute_claim_similarity",
          "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
          "line": 172,
          "call_type": "function_call"
        },
        {
          "name": "find_similar_claims",
          "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
          "line": 220,
          "call_type": "function_call"
        },
        {
          "name": "get_cluster_representative",
          "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
          "line": 559,
          "call_type": "function_call"
        },
        {
          "name": "test_cosine_similarity_identical",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 89,
          "call_type": "function_call"
        },
        {
          "name": "test_cosine_similarity_range",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 98,
          "call_type": "function_call"
        },
        {
          "name": "test_cosine_similarity_similar_text",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 107,
          "call_type": "function_call"
        },
        {
          "name": "test_cosine_similarity_different_text",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 117,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "dot",
          "file": "unknown",
          "line": 137,
          "call_type": "method_call"
        },
        {
          "name": "float",
          "file": "unknown",
          "line": 139,
          "call_type": "function_call"
        },
        {
          "name": "clip",
          "file": "unknown",
          "line": 139,
          "call_type": "method_call"
        }
      ],
      "call_count": 7
    },
    {
      "name": "compute_claim_similarity",
      "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
      "line": 142,
      "language": "python",
      "docstring": "Compute semantic similarity between two claim texts.\n\nArgs:\n    claim1: First claim text\n    claim2: Second claim text\n    model_name: Sentence transformer model to use\n\nReturns:\n    Similarity score (0.0 to 1.0)\n    - >= 0.9: Very similar (likely duplicates)\n    - 0.7-0.9: Similar (related claims)\n    - 0.5-0.7: Moderate similarity (overlapping topics)\n    - < 0.5: Different claims\n\nExample:\n    >>> score = compute_claim_similarity(\n    ...     \"AI improves software quality\",\n    ...     \"Artificial intelligence enhances code quality\"\n    ... )\n    >>> print(f\"Similarity: {score:.3f}\")\n    Similarity: 0.875",
      "parameters": [
        {
          "name": "claim1",
          "type": "str",
          "default": null
        },
        {
          "name": "claim2",
          "type": "str",
          "default": null
        },
        {
          "name": "model_name",
          "type": "str",
          "default": null
        }
      ],
      "return_type": "float",
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "detect_contradiction",
          "file": "model_chorus/src/model_chorus/core/contradiction.py",
          "line": 522,
          "call_type": "function_call"
        },
        {
          "name": "add_similarity_to_citation",
          "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
          "line": 317,
          "call_type": "function_call"
        },
        {
          "name": "test_compute_claim_similarity_identical",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 130,
          "call_type": "function_call"
        },
        {
          "name": "test_compute_claim_similarity_similar",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 139,
          "call_type": "function_call"
        },
        {
          "name": "test_compute_claim_similarity_different",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 148,
          "call_type": "function_call"
        },
        {
          "name": "test_compute_claim_similarity_symmetric",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 157,
          "call_type": "function_call"
        },
        {
          "name": "test_compute_claim_similarity_symmetric",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 158,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "compute_embedding",
          "file": "unknown",
          "line": 170,
          "call_type": "function_call"
        },
        {
          "name": "compute_embedding",
          "file": "unknown",
          "line": 171,
          "call_type": "function_call"
        },
        {
          "name": "cosine_similarity",
          "file": "unknown",
          "line": 172,
          "call_type": "function_call"
        }
      ],
      "call_count": 7
    },
    {
      "name": "find_similar_claims",
      "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
      "line": 175,
      "language": "python",
      "docstring": "Find citation maps with claims similar to the query claim.\n\nUses semantic similarity to identify related claims across a\ncollection of citation maps. Useful for:\n- Detecting duplicate claims\n- Finding supporting evidence for new claims\n- Clustering related arguments\n\nArgs:\n    query_claim: Claim text to search for\n    citation_maps: List of CitationMap objects to search within\n    threshold: Minimum similarity score to include (default: 0.7)\n    top_k: Optional limit on number of results (returns top-k most similar)\n    model_name: Sentence transformer model to use\n\nReturns:\n    List of (CitationMap, similarity_score) tuples, sorted by similarity (descending)\n\nExample:\n    >>> maps = [citation_map1, citation_map2, citation_map3]\n    >>> results = find_similar_claims(\n    ...     \"Machine learning improves accuracy\",\n    ...     maps,\n    ...     threshold=0.7,\n    ...     top_k=5\n    ... )\n    >>> for cm, score in results:\n    ...     print(f\"{score:.3f}: {cm.claim_text}\")\n    0.892: ML models enhance prediction accuracy\n    0.745: AI systems improve results",
      "parameters": [
        {
          "name": "query_claim",
          "type": "str",
          "default": null
        },
        {
          "name": "citation_maps",
          "type": "List[CitationMap]",
          "default": null
        },
        {
          "name": "threshold",
          "type": "float",
          "default": null
        },
        {
          "name": "top_k",
          "type": "Optional[int]",
          "default": null
        },
        {
          "name": "model_name",
          "type": "str",
          "default": null
        }
      ],
      "return_type": "List[Tuple[CitationMap, float]]",
      "complexity": 4,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "test_find_similar_claims_basic",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 200,
          "call_type": "function_call"
        },
        {
          "name": "test_find_similar_claims_threshold",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 215,
          "call_type": "function_call"
        },
        {
          "name": "test_find_similar_claims_threshold",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 216,
          "call_type": "function_call"
        },
        {
          "name": "test_find_similar_claims_top_k",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 224,
          "call_type": "function_call"
        },
        {
          "name": "test_find_similar_claims_sorted",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 237,
          "call_type": "function_call"
        },
        {
          "name": "test_find_similar_claims_empty_list",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 247,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "compute_embedding",
          "file": "unknown",
          "line": 214,
          "call_type": "function_call"
        },
        {
          "name": "compute_embedding",
          "file": "unknown",
          "line": 219,
          "call_type": "function_call"
        },
        {
          "name": "cosine_similarity",
          "file": "unknown",
          "line": 220,
          "call_type": "function_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 223,
          "call_type": "method_call"
        },
        {
          "name": "sort",
          "file": "unknown",
          "line": 226,
          "call_type": "method_call"
        }
      ],
      "call_count": 6
    },
    {
      "name": "compute_claim_similarity_batch",
      "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
      "line": 235,
      "language": "python",
      "docstring": "Compute pairwise similarities for a batch of claims.\n\nMore efficient than calling compute_claim_similarity repeatedly,\nas it batches the embedding computation.\n\nArgs:\n    claims: List of claim texts\n    model_name: Sentence transformer model to use\n\nReturns:\n    NxN similarity matrix where result[i][j] = similarity(claims[i], claims[j])\n\nExample:\n    >>> claims = [\n    ...     \"AI improves quality\",\n    ...     \"ML enhances accuracy\",\n    ...     \"Weather is sunny\"\n    ... ]\n    >>> sim_matrix = compute_claim_similarity_batch(claims)\n    >>> print(sim_matrix.shape)\n    (3, 3)\n    >>> print(f\"Similarity[0,1]: {sim_matrix[0,1]:.3f}\")\n    Similarity[0,1]: 0.847",
      "parameters": [
        {
          "name": "claims",
          "type": "List[str]",
          "default": null
        },
        {
          "name": "model_name",
          "type": "str",
          "default": null
        }
      ],
      "return_type": "np.ndarray",
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "find_duplicate_claims",
          "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
          "line": 364,
          "call_type": "function_call"
        },
        {
          "name": "compute_cluster_statistics",
          "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
          "line": 727,
          "call_type": "function_call"
        },
        {
          "name": "score_cluster_coherence",
          "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
          "line": 782,
          "call_type": "function_call"
        },
        {
          "name": "test_compute_claim_similarity_batch_shape",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 263,
          "call_type": "function_call"
        },
        {
          "name": "test_compute_claim_similarity_batch_diagonal",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 275,
          "call_type": "function_call"
        },
        {
          "name": "test_compute_claim_similarity_batch_symmetric",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 289,
          "call_type": "function_call"
        },
        {
          "name": "test_compute_claim_similarity_batch_range",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 302,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "compute_embedding",
          "file": "unknown",
          "line": 265,
          "call_type": "function_call"
        },
        {
          "name": "array",
          "file": "unknown",
          "line": 266,
          "call_type": "method_call"
        },
        {
          "name": "dot",
          "file": "unknown",
          "line": 270,
          "call_type": "method_call"
        },
        {
          "name": "clip",
          "file": "unknown",
          "line": 273,
          "call_type": "method_call"
        }
      ],
      "call_count": 7
    },
    {
      "name": "add_similarity_to_citation",
      "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
      "line": 278,
      "language": "python",
      "docstring": "Add semantic similarity score to a citation's metadata.\n\nComputes similarity between the citation's snippet (if available)\nand a reference claim, storing the result in citation.metadata.\n\nArgs:\n    citation: Citation object to enhance\n    reference_claim: Claim text to compare against\n    model_name: Sentence transformer model to use\n\nReturns:\n    Enhanced Citation object with similarity_score in metadata\n\nExample:\n    >>> citation = Citation(\n    ...     source=\"paper.pdf\",\n    ...     confidence=0.9,\n    ...     snippet=\"ML improves accuracy by 23%\"\n    ... )\n    >>> enhanced = add_similarity_to_citation(\n    ...     citation,\n    ...     \"Machine learning enhances precision\"\n    ... )\n    >>> print(enhanced.metadata[\"similarity_score\"])\n    0.847",
      "parameters": [
        {
          "name": "citation",
          "type": "Citation",
          "default": null
        },
        {
          "name": "reference_claim",
          "type": "str",
          "default": null
        },
        {
          "name": "model_name",
          "type": "str",
          "default": null
        }
      ],
      "return_type": "Citation",
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "test_add_similarity_to_citation_with_snippet",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 321,
          "call_type": "function_call"
        },
        {
          "name": "test_add_similarity_to_citation_without_snippet",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 337,
          "call_type": "function_call"
        },
        {
          "name": "test_add_similarity_preserves_existing_metadata",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 351,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "compute_claim_similarity",
          "file": "unknown",
          "line": 317,
          "call_type": "function_call"
        },
        {
          "name": "round",
          "file": "unknown",
          "line": 323,
          "call_type": "function_call"
        }
      ],
      "call_count": 3
    },
    {
      "name": "find_duplicate_claims",
      "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
      "line": 329,
      "language": "python",
      "docstring": "Detect groups of duplicate or near-duplicate claims.\n\nUses high similarity threshold to identify claims that are\nessentially the same despite different wording.\n\nArgs:\n    citation_maps: List of CitationMap objects to check for duplicates\n    threshold: Minimum similarity to consider duplicates (default: 0.9)\n    model_name: Sentence transformer model to use\n\nReturns:\n    List of duplicate groups, where each group is a list of similar CitationMaps\n\nExample:\n    >>> maps = [citation_map1, citation_map2, citation_map3]\n    >>> duplicates = find_duplicate_claims(maps, threshold=0.9)\n    >>> for group in duplicates:\n    ...     print(f\"Found {len(group)} duplicates:\")\n    ...     for cm in group:\n    ...         print(f\"  - {cm.claim_text}\")\n    Found 2 duplicates:\n      - AI improves accuracy\n      - Artificial intelligence enhances precision",
      "parameters": [
        {
          "name": "citation_maps",
          "type": "List[CitationMap]",
          "default": null
        },
        {
          "name": "threshold",
          "type": "float",
          "default": null
        },
        {
          "name": "model_name",
          "type": "str",
          "default": null
        }
      ],
      "return_type": "List[List[CitationMap]]",
      "complexity": 8,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "test_find_duplicate_claims_basic",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 384,
          "call_type": "function_call"
        },
        {
          "name": "test_find_duplicate_claims_high_threshold",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 414,
          "call_type": "function_call"
        },
        {
          "name": "test_find_duplicate_claims_no_duplicates",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 442,
          "call_type": "function_call"
        },
        {
          "name": "test_find_duplicate_claims_empty_list",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 449,
          "call_type": "function_call"
        },
        {
          "name": "test_find_duplicate_claims_single_item",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 464,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "len",
          "file": "unknown",
          "line": 359,
          "call_type": "function_call"
        },
        {
          "name": "compute_claim_similarity_batch",
          "file": "unknown",
          "line": 364,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 367,
          "call_type": "function_call"
        },
        {
          "name": "range",
          "file": "unknown",
          "line": 371,
          "call_type": "function_call"
        },
        {
          "name": "range",
          "file": "unknown",
          "line": 380,
          "call_type": "function_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 382,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 386,
          "call_type": "function_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 387,
          "call_type": "method_call"
        }
      ],
      "call_count": 5
    },
    {
      "name": "cluster_claims_kmeans",
      "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
      "line": 397,
      "language": "python",
      "docstring": "Cluster claims using K-means algorithm on semantic embeddings.\n\nGroups claims into k clusters based on semantic similarity,\nuseful for organizing large collections of claims by topic.\n\nArgs:\n    citation_maps: List of CitationMap objects to cluster\n    n_clusters: Number of clusters to create (default: 3)\n    model_name: Sentence transformer model to use\n    random_state: Random seed for reproducibility\n\nReturns:\n    List of clusters, where each cluster is a list of CitationMaps\n\nRaises:\n    ValueError: If n_clusters > len(citation_maps)\n\nExample:\n    >>> maps = [cm1, cm2, cm3, cm4, cm5]\n    >>> clusters = cluster_claims_kmeans(maps, n_clusters=2)\n    >>> print(f\"Found {len(clusters)} clusters\")\n    Found 2 clusters\n    >>> for i, cluster in enumerate(clusters):\n    ...     print(f\"Cluster {i}: {len(cluster)} claims\")\n    Cluster 0: 3 claims\n    Cluster 1: 2 claims",
      "parameters": [
        {
          "name": "citation_maps",
          "type": "List[CitationMap]",
          "default": null
        },
        {
          "name": "n_clusters",
          "type": "int",
          "default": null
        },
        {
          "name": "model_name",
          "type": "str",
          "default": null
        },
        {
          "name": "random_state",
          "type": "int",
          "default": null
        }
      ],
      "return_type": "List[List[CitationMap]]",
      "complexity": 4,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "test_cluster_claims_kmeans_basic",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 556,
          "call_type": "function_call"
        },
        {
          "name": "test_cluster_claims_kmeans_empty_list",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 566,
          "call_type": "function_call"
        },
        {
          "name": "test_cluster_claims_kmeans_single_cluster",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 572,
          "call_type": "function_call"
        },
        {
          "name": "test_cluster_claims_kmeans_too_many_clusters",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 585,
          "call_type": "function_call"
        },
        {
          "name": "test_cluster_claims_kmeans_reproducibility",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 589,
          "call_type": "function_call"
        },
        {
          "name": "test_cluster_claims_kmeans_reproducibility",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 590,
          "call_type": "function_call"
        },
        {
          "name": "test_kmeans_to_statistics_pipeline",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 779,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "len",
          "file": "unknown",
          "line": 433,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 436,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 439,
          "call_type": "function_call"
        },
        {
          "name": "array",
          "file": "unknown",
          "line": 444,
          "call_type": "method_call"
        },
        {
          "name": "compute_embedding",
          "file": "unknown",
          "line": 444,
          "call_type": "function_call"
        },
        {
          "name": "fit_predict",
          "file": "unknown",
          "line": 448,
          "call_type": "method_call"
        },
        {
          "name": "range",
          "file": "unknown",
          "line": 451,
          "call_type": "function_call"
        },
        {
          "name": "enumerate",
          "file": "unknown",
          "line": 452,
          "call_type": "function_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 453,
          "call_type": "method_call"
        }
      ],
      "call_count": 7
    },
    {
      "name": "cluster_claims_hierarchical",
      "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
      "line": 458,
      "language": "python",
      "docstring": "Cluster claims using hierarchical clustering on semantic embeddings.\n\nUses agglomerative hierarchical clustering to group claims,\nbuilding a tree-based hierarchy and cutting at specified level.\n\nArgs:\n    citation_maps: List of CitationMap objects to cluster\n    n_clusters: Number of clusters to create (default: 3)\n    model_name: Sentence transformer model to use\n    linkage_method: Linkage method ('ward', 'complete', 'average', 'single')\n\nReturns:\n    List of clusters, where each cluster is a list of CitationMaps\n\nRaises:\n    ValueError: If n_clusters > len(citation_maps)\n\nExample:\n    >>> maps = [cm1, cm2, cm3, cm4, cm5]\n    >>> clusters = cluster_claims_hierarchical(\n    ...     maps,\n    ...     n_clusters=2,\n    ...     linkage_method=\"ward\"\n    ... )\n    >>> print(f\"Found {len(clusters)} clusters\")\n    Found 2 clusters",
      "parameters": [
        {
          "name": "citation_maps",
          "type": "List[CitationMap]",
          "default": null
        },
        {
          "name": "n_clusters",
          "type": "int",
          "default": null
        },
        {
          "name": "model_name",
          "type": "str",
          "default": null
        },
        {
          "name": "linkage_method",
          "type": "str",
          "default": null
        }
      ],
      "return_type": "List[List[CitationMap]]",
      "complexity": 4,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "test_cluster_claims_hierarchical_basic",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 632,
          "call_type": "function_call"
        },
        {
          "name": "test_cluster_claims_hierarchical_empty_list",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 640,
          "call_type": "function_call"
        },
        {
          "name": "test_cluster_claims_hierarchical_linkage_methods",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 647,
          "call_type": "function_call"
        },
        {
          "name": "test_cluster_claims_hierarchical_too_many_clusters",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 662,
          "call_type": "function_call"
        },
        {
          "name": "test_hierarchical_to_statistics_pipeline",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 798,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "len",
          "file": "unknown",
          "line": 494,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 497,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 500,
          "call_type": "function_call"
        },
        {
          "name": "array",
          "file": "unknown",
          "line": 505,
          "call_type": "method_call"
        },
        {
          "name": "compute_embedding",
          "file": "unknown",
          "line": 505,
          "call_type": "function_call"
        },
        {
          "name": "fit_predict",
          "file": "unknown",
          "line": 512,
          "call_type": "method_call"
        },
        {
          "name": "range",
          "file": "unknown",
          "line": 515,
          "call_type": "function_call"
        },
        {
          "name": "enumerate",
          "file": "unknown",
          "line": 516,
          "call_type": "function_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 517,
          "call_type": "method_call"
        }
      ],
      "call_count": 5
    },
    {
      "name": "get_cluster_representative",
      "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
      "line": 522,
      "language": "python",
      "docstring": "Find the most representative claim in a cluster (centroid).\n\nComputes the claim closest to the cluster centroid in embedding space,\nuseful for summarizing or labeling clusters.\n\nArgs:\n    cluster: List of CitationMaps in the cluster\n    model_name: Sentence transformer model to use\n\nReturns:\n    CitationMap closest to cluster centroid\n\nExample:\n    >>> cluster = [cm1, cm2, cm3]\n    >>> representative = get_cluster_representative(cluster)\n    >>> print(f\"Representative claim: {representative.claim_text}\")",
      "parameters": [
        {
          "name": "cluster",
          "type": "List[CitationMap]",
          "default": null
        },
        {
          "name": "model_name",
          "type": "str",
          "default": null
        }
      ],
      "return_type": "CitationMap",
      "complexity": 3,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "generate_cluster_name",
          "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
          "line": 600,
          "call_type": "function_call"
        },
        {
          "name": "summarize_cluster",
          "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
          "line": 651,
          "call_type": "function_call"
        },
        {
          "name": "compute_cluster_statistics",
          "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
          "line": 713,
          "call_type": "function_call"
        },
        {
          "name": "test_get_cluster_representative_basic",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 691,
          "call_type": "function_call"
        },
        {
          "name": "test_get_cluster_representative_single_item",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 707,
          "call_type": "function_call"
        },
        {
          "name": "test_get_cluster_representative_empty_cluster",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 714,
          "call_type": "function_call"
        },
        {
          "name": "test_hierarchical_to_statistics_pipeline",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 801,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "len",
          "file": "unknown",
          "line": 544,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 547,
          "call_type": "function_call"
        },
        {
          "name": "array",
          "file": "unknown",
          "line": 552,
          "call_type": "method_call"
        },
        {
          "name": "compute_embedding",
          "file": "unknown",
          "line": 552,
          "call_type": "function_call"
        },
        {
          "name": "mean",
          "file": "unknown",
          "line": 555,
          "call_type": "method_call"
        },
        {
          "name": "norm",
          "file": "unknown",
          "line": 556,
          "call_type": "method_call"
        },
        {
          "name": "cosine_similarity",
          "file": "unknown",
          "line": 559,
          "call_type": "function_call"
        },
        {
          "name": "argmax",
          "file": "unknown",
          "line": 560,
          "call_type": "method_call"
        }
      ],
      "call_count": 7
    },
    {
      "name": "generate_cluster_name",
      "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
      "line": 565,
      "language": "python",
      "docstring": "Generate a concise name for a cluster based on representative claims.\n\nUses extractive approach: identifies key terms from the cluster\nrepresentative claim and constructs a short descriptive name.\n\nArgs:\n    cluster: List of CitationMaps in the cluster\n    model_name: Sentence transformer model to use\n    max_words: Maximum words in generated name (default: 5)\n\nReturns:\n    Concise cluster name (e.g., \"AI Quality Improvement\")\n\nExample:\n    >>> cluster = [cm1, cm2, cm3]  # Claims about \"AI improves quality\"\n    >>> name = generate_cluster_name(cluster, max_words=4)\n    >>> print(name)\n    AI Quality Improvement",
      "parameters": [
        {
          "name": "cluster",
          "type": "List[CitationMap]",
          "default": null
        },
        {
          "name": "model_name",
          "type": "str",
          "default": null
        },
        {
          "name": "max_words",
          "type": "int",
          "default": null
        }
      ],
      "return_type": "str",
      "complexity": 3,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "score_clustering_quality",
          "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
          "line": 977,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "len",
          "file": "unknown",
          "line": 590,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 593,
          "call_type": "function_call"
        },
        {
          "name": "split",
          "file": "unknown",
          "line": 596,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 597,
          "call_type": "method_call"
        },
        {
          "name": "get_cluster_representative",
          "file": "unknown",
          "line": 600,
          "call_type": "function_call"
        },
        {
          "name": "split",
          "file": "unknown",
          "line": 605,
          "call_type": "method_call"
        },
        {
          "name": "join",
          "file": "unknown",
          "line": 609,
          "call_type": "method_call"
        },
        {
          "name": "capitalize",
          "file": "unknown",
          "line": 609,
          "call_type": "method_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "summarize_cluster",
      "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
      "line": 614,
      "language": "python",
      "docstring": "Generate a detailed summary of cluster themes.\n\nAnalyzes claims in cluster to identify common patterns\nand generates a descriptive summary.\n\nArgs:\n    cluster: List of CitationMaps in the cluster\n    model_name: Sentence transformer model to use\n    max_length: Maximum characters in summary (default: 150)\n\nReturns:\n    Cluster summary (1-2 sentences)\n\nExample:\n    >>> cluster = [cm1, cm2, cm3]\n    >>> summary = summarize_cluster(cluster)\n    >>> print(summary)\n    This cluster focuses on AI quality improvement claims.\n    All claims discuss machine learning enhancing accuracy.",
      "parameters": [
        {
          "name": "cluster",
          "type": "List[CitationMap]",
          "default": null
        },
        {
          "name": "model_name",
          "type": "str",
          "default": null
        },
        {
          "name": "max_length",
          "type": "int",
          "default": null
        }
      ],
      "return_type": "str",
      "complexity": 5,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "cluster",
          "file": "model_chorus/src/model_chorus/core/clustering.py",
          "line": 445,
          "call_type": "method_call"
        },
        {
          "name": "score_clustering_quality",
          "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
          "line": 981,
          "call_type": "function_call"
        },
        {
          "name": "test_summarize_cluster_basic",
          "file": "tests/test_clustering.py",
          "line": 269,
          "call_type": "method_call"
        },
        {
          "name": "test_summarize_cluster_empty",
          "file": "tests/test_clustering.py",
          "line": 276,
          "call_type": "method_call"
        },
        {
          "name": "test_summarize_cluster_truncation",
          "file": "tests/test_clustering.py",
          "line": 282,
          "call_type": "method_call"
        }
      ],
      "calls": [
        {
          "name": "len",
          "file": "unknown",
          "line": 640,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 643,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 646,
          "call_type": "function_call"
        },
        {
          "name": "get_cluster_representative",
          "file": "unknown",
          "line": 651,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 654,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 663,
          "call_type": "function_call"
        }
      ],
      "call_count": 5
    },
    {
      "name": "compute_cluster_statistics",
      "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
      "line": 669,
      "language": "python",
      "docstring": "Compute statistics and quality metrics for clusters.\n\nProvides insights into cluster quality, including size distribution,\nintra-cluster similarity, and representative claims.\n\nArgs:\n    clusters: List of clusters (each cluster is a list of CitationMaps)\n    model_name: Sentence transformer model to use\n\nReturns:\n    Dictionary with cluster statistics:\n    - num_clusters: Number of clusters\n    - cluster_sizes: List of cluster sizes\n    - avg_cluster_size: Average cluster size\n    - representatives: List of representative claims (one per cluster)\n    - intra_cluster_similarities: Average similarity within each cluster\n\nExample:\n    >>> stats = compute_cluster_statistics(clusters)\n    >>> print(f\"Number of clusters: {stats['num_clusters']}\")\n    >>> print(f\"Average cluster size: {stats['avg_cluster_size']:.1f}\")\n    >>> print(f\"Representatives: {stats['representatives']}\")",
      "parameters": [
        {
          "name": "clusters",
          "type": "List[List[CitationMap]]",
          "default": null
        },
        {
          "name": "model_name",
          "type": "str",
          "default": null
        }
      ],
      "return_type": "Dict[str, Any]",
      "complexity": 6,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "test_compute_cluster_statistics_basic",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 736,
          "call_type": "function_call"
        },
        {
          "name": "test_compute_cluster_statistics_empty",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 749,
          "call_type": "function_call"
        },
        {
          "name": "test_compute_cluster_statistics_single_item_clusters",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 762,
          "call_type": "function_call"
        },
        {
          "name": "test_kmeans_to_statistics_pipeline",
          "file": "model_chorus/tests/test_semantic_similarity.py",
          "line": 782,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "len",
          "file": "unknown",
          "line": 697,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 707,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 712,
          "call_type": "function_call"
        },
        {
          "name": "get_cluster_representative",
          "file": "unknown",
          "line": 713,
          "call_type": "function_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 714,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 716,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 721,
          "call_type": "function_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 722,
          "call_type": "method_call"
        },
        {
          "name": "compute_claim_similarity_batch",
          "file": "unknown",
          "line": 727,
          "call_type": "function_call"
        },
        {
          "name": "triu_indices_from",
          "file": "unknown",
          "line": 730,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 731,
          "call_type": "function_call"
        },
        {
          "name": "float",
          "file": "unknown",
          "line": 731,
          "call_type": "function_call"
        },
        {
          "name": "mean",
          "file": "unknown",
          "line": 731,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 733,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 736,
          "call_type": "function_call"
        },
        {
          "name": "float",
          "file": "unknown",
          "line": 738,
          "call_type": "function_call"
        },
        {
          "name": "mean",
          "file": "unknown",
          "line": 738,
          "call_type": "method_call"
        },
        {
          "name": "min",
          "file": "unknown",
          "line": 739,
          "call_type": "function_call"
        },
        {
          "name": "max",
          "file": "unknown",
          "line": 740,
          "call_type": "function_call"
        },
        {
          "name": "float",
          "file": "unknown",
          "line": 743,
          "call_type": "function_call"
        },
        {
          "name": "mean",
          "file": "unknown",
          "line": 743,
          "call_type": "method_call"
        }
      ],
      "call_count": 4
    },
    {
      "name": "score_cluster_coherence",
      "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
      "line": 747,
      "language": "python",
      "docstring": "Measure how tightly grouped claims are within a cluster.\n\nComputes average pairwise similarity between claims in the cluster.\nHigher scores indicate more coherent/similar claims.\n\nArgs:\n    cluster: List of CitationMaps in the cluster\n    model_name: Sentence transformer model to use\n\nReturns:\n    Coherence score (0.0 to 1.0)\n    - 1.0 = perfect coherence (all claims identical)\n    - 0.8-1.0 = high coherence (very similar claims)\n    - 0.5-0.8 = moderate coherence\n    - < 0.5 = low coherence (diverse claims)\n\nExample:\n    >>> cluster = [cm1, cm2, cm3]\n    >>> coherence = score_cluster_coherence(cluster)\n    >>> print(f\"Coherence: {coherence:.3f}\")\n    Coherence: 0.847",
      "parameters": [
        {
          "name": "cluster",
          "type": "List[CitationMap]",
          "default": null
        },
        {
          "name": "model_name",
          "type": "str",
          "default": null
        }
      ],
      "return_type": "float",
      "complexity": 4,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "score_clustering_quality",
          "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
          "line": 935,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "len",
          "file": "unknown",
          "line": 774,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 777,
          "call_type": "function_call"
        },
        {
          "name": "compute_claim_similarity_batch",
          "file": "unknown",
          "line": 782,
          "call_type": "function_call"
        },
        {
          "name": "triu_indices_from",
          "file": "unknown",
          "line": 785,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 787,
          "call_type": "function_call"
        },
        {
          "name": "float",
          "file": "unknown",
          "line": 790,
          "call_type": "function_call"
        },
        {
          "name": "mean",
          "file": "unknown",
          "line": 790,
          "call_type": "method_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "score_cluster_separation",
      "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
      "line": 794,
      "language": "python",
      "docstring": "Measure how distinct clusters are from each other.\n\nComputes average distance between cluster centroids.\nHigher scores indicate better separation between clusters.\n\nArgs:\n    clusters: List of clusters (each cluster is a list of CitationMaps)\n    model_name: Sentence transformer model to use\n\nReturns:\n    Separation score (0.0 to 1.0)\n    - 1.0 = perfect separation (clusters completely distinct)\n    - 0.7-1.0 = high separation (well-separated clusters)\n    - 0.5-0.7 = moderate separation\n    - < 0.5 = low separation (overlapping clusters)\n\nExample:\n    >>> clusters = [[cm1, cm2], [cm3, cm4]]\n    >>> separation = score_cluster_separation(clusters)\n    >>> print(f\"Separation: {separation:.3f}\")\n    Separation: 0.723",
      "parameters": [
        {
          "name": "clusters",
          "type": "List[List[CitationMap]]",
          "default": null
        },
        {
          "name": "model_name",
          "type": "str",
          "default": null
        }
      ],
      "return_type": "float",
      "complexity": 5,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "score_clustering_quality",
          "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
          "line": 941,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "len",
          "file": "unknown",
          "line": 821,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 825,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 827,
          "call_type": "function_call"
        },
        {
          "name": "array",
          "file": "unknown",
          "line": 834,
          "call_type": "method_call"
        },
        {
          "name": "compute_embedding",
          "file": "unknown",
          "line": 834,
          "call_type": "function_call"
        },
        {
          "name": "mean",
          "file": "unknown",
          "line": 837,
          "call_type": "method_call"
        },
        {
          "name": "norm",
          "file": "unknown",
          "line": 838,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 839,
          "call_type": "method_call"
        },
        {
          "name": "array",
          "file": "unknown",
          "line": 841,
          "call_type": "method_call"
        },
        {
          "name": "dot",
          "file": "unknown",
          "line": 845,
          "call_type": "method_call"
        },
        {
          "name": "triu_indices_from",
          "file": "unknown",
          "line": 849,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 851,
          "call_type": "function_call"
        },
        {
          "name": "float",
          "file": "unknown",
          "line": 855,
          "call_type": "function_call"
        },
        {
          "name": "mean",
          "file": "unknown",
          "line": 855,
          "call_type": "method_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "score_clustering_quality",
      "file": "model_chorus/src/model_chorus/workflows/argument/semantic.py",
      "line": 864,
      "language": "python",
      "docstring": "Compute comprehensive quality metrics for clustering results.\n\nCombines multiple metrics to provide overall assessment of\nclustering quality, including coherence, separation, and\ninterpretability measures.\n\nArgs:\n    clusters: List of clusters (each cluster is a list of CitationMaps)\n    model_name: Sentence transformer model to use\n\nReturns:\n    Dictionary with quality metrics:\n    - coherence_scores: List of coherence scores (one per cluster)\n    - avg_coherence: Average coherence across all clusters\n    - separation: Inter-cluster separation score\n    - silhouette_score: Sklearn silhouette coefficient (-1 to 1)\n    - quality_score: Overall quality (0.0 to 1.0)\n    - num_clusters: Number of clusters\n    - cluster_sizes: List of cluster sizes\n    - interpretability: Named clusters and summaries\n\nExample:\n    >>> clusters = [[cm1, cm2], [cm3, cm4]]\n    >>> quality = score_clustering_quality(clusters)\n    >>> print(f\"Quality: {quality['quality_score']:.3f}\")\n    >>> print(f\"Coherence: {quality['avg_coherence']:.3f}\")\n    >>> print(f\"Separation: {quality['separation']:.3f}\")\n    Quality: 0.812\n    Coherence: 0.847\n    Separation: 0.723",
      "parameters": [
        {
          "name": "clusters",
          "type": "List[List[CitationMap]]",
          "default": null
        },
        {
          "name": "model_name",
          "type": "str",
          "default": null
        }
      ],
      "return_type": "Dict[str, Any]",
      "complexity": 8,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "len",
          "file": "unknown",
          "line": 900,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 916,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 918,
          "call_type": "function_call"
        },
        {
          "name": "score_cluster_coherence",
          "file": "unknown",
          "line": 935,
          "call_type": "function_call"
        },
        {
          "name": "float",
          "file": "unknown",
          "line": 938,
          "call_type": "function_call"
        },
        {
          "name": "mean",
          "file": "unknown",
          "line": 938,
          "call_type": "method_call"
        },
        {
          "name": "score_cluster_separation",
          "file": "unknown",
          "line": 941,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 945,
          "call_type": "function_call"
        },
        {
          "name": "enumerate",
          "file": "unknown",
          "line": 952,
          "call_type": "function_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 954,
          "call_type": "method_call"
        },
        {
          "name": "append",
          "file": "unknown",
          "line": 955,
          "call_type": "method_call"
        },
        {
          "name": "array",
          "file": "unknown",
          "line": 958,
          "call_type": "method_call"
        },
        {
          "name": "compute_embedding",
          "file": "unknown",
          "line": 959,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 964,
          "call_type": "function_call"
        },
        {
          "name": "set",
          "file": "unknown",
          "line": 964,
          "call_type": "function_call"
        },
        {
          "name": "float",
          "file": "unknown",
          "line": 965,
          "call_type": "function_call"
        },
        {
          "name": "sklearn_silhouette",
          "file": "unknown",
          "line": 965,
          "call_type": "function_call"
        },
        {
          "name": "generate_cluster_name",
          "file": "unknown",
          "line": 977,
          "call_type": "function_call"
        },
        {
          "name": "summarize_cluster",
          "file": "unknown",
          "line": 981,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 991,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 992,
          "call_type": "function_call"
        }
      ]
    },
    {
      "name": "_select_persona_by_phase_and_state",
      "file": "model_chorus/src/model_chorus/workflows/study/context_analysis.py",
      "line": 196,
      "language": "python",
      "docstring": "Select persona based on investigation phase and current state.\n\nPhase-Based Selection Strategy:\n- DISCOVERY: Start with Researcher for initial exploration\n- VALIDATION: Use Critic to challenge assumptions and findings\n- PLANNING: Use Planner to synthesize into actionable roadmap\n- COMPLETE: No further persona needed (investigation complete)\n\nArgs:\n    phase: Current investigation phase\n    findings_count: Number of existing findings\n    has_questions: Whether there are unresolved questions\n    prior_persona: Previously consulted persona (to avoid repetition)\n\nReturns:\n    Tuple of (persona_name, reasoning, guidance_list)",
      "parameters": [
        {
          "name": "phase",
          "type": "str",
          "default": null
        },
        {
          "name": "findings_count",
          "type": "int",
          "default": null
        },
        {
          "name": "has_questions",
          "type": "bool",
          "default": null
        },
        {
          "name": "prior_persona",
          "type": "Optional[str]",
          "default": null
        }
      ],
      "return_type": "tuple[str, str, List[str]]",
      "complexity": 10,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": false,
      "callers": [
        {
          "name": "analyze_context",
          "file": "model_chorus/src/model_chorus/workflows/study/context_analysis.py",
          "line": 355,
          "call_type": "function_call"
        }
      ],
      "calls": [],
      "call_count": 1
    },
    {
      "name": "analyze_context",
      "file": "model_chorus/src/model_chorus/workflows/study/context_analysis.py",
      "line": 323,
      "language": "python",
      "docstring": "Analyze investigation context and determine next persona to consult.\n\nThis is the main entry point for the context analysis skill. Based on\nthe current investigation phase, confidence level, findings, and\nunresolved questions, it selects the most appropriate persona to\nconsult next.\n\nSelection Strategy:\n- DISCOVERY phase: Alternate between Researcher (exploration) and Critic (challenge)\n- VALIDATION phase: Primarily Critic (testing), with Researcher to fill gaps\n- PLANNING phase: Primarily Planner (synthesis), with fallback to Researcher/Critic if needed\n- COMPLETE phase: No further persona needed\n\nThe logic also considers:\n- Prior persona to avoid repetition\n- Presence of findings (do we have material to work with?)\n- Presence of unresolved questions (do we need more investigation?)\n\nArgs:\n    context_input: Validated context analysis input\n\nReturns:\n    ContextAnalysisResult with recommended persona and guidance",
      "parameters": [
        {
          "name": "context_input",
          "type": "ContextAnalysisInput",
          "default": null
        }
      ],
      "return_type": "ContextAnalysisResult",
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "route_next_persona",
          "file": "model_chorus/src/model_chorus/workflows/study/persona_router.py",
          "line": 247,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "len",
          "file": "unknown",
          "line": 350,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 351,
          "call_type": "function_call"
        },
        {
          "name": "_select_persona_by_phase_and_state",
          "file": "unknown",
          "line": 355,
          "call_type": "function_call"
        },
        {
          "name": "upper",
          "file": "unknown",
          "line": 361,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 363,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 364,
          "call_type": "function_call"
        }
      ],
      "call_count": 1
    },
    {
      "name": "create_default_personas",
      "file": "model_chorus/src/model_chorus/workflows/study/personas/__init__.py",
      "line": 25,
      "language": "python",
      "docstring": "Create the default set of personas for STUDY workflow.\n\nReturns:\n    List of default persona instances (Researcher, Critic, Planner)",
      "parameters": [],
      "return_type": "list",
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "get_default_registry",
          "file": "model_chorus/src/model_chorus/workflows/study/personas/__init__.py",
          "line": 47,
          "call_type": "function_call"
        },
        {
          "name": "test_create_default_personas",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 471,
          "call_type": "function_call"
        },
        {
          "name": "test_create_default_personas_types",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 480,
          "call_type": "function_call"
        },
        {
          "name": "test_create_default_personas_independent",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 488,
          "call_type": "function_call"
        },
        {
          "name": "test_create_default_personas_independent",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 489,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "create_researcher",
          "file": "unknown",
          "line": 33,
          "call_type": "function_call"
        },
        {
          "name": "create_critic",
          "file": "unknown",
          "line": 34,
          "call_type": "function_call"
        },
        {
          "name": "create_planner",
          "file": "unknown",
          "line": 35,
          "call_type": "function_call"
        }
      ],
      "call_count": 5
    },
    {
      "name": "get_default_registry",
      "file": "model_chorus/src/model_chorus/workflows/study/personas/__init__.py",
      "line": 39,
      "language": "python",
      "docstring": "Get a registry pre-populated with default personas.\n\nReturns:\n    PersonaRegistry with Researcher, Critic, and Planner registered",
      "parameters": [],
      "return_type": "PersonaRegistry",
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "__init__",
          "file": "model_chorus/src/model_chorus/workflows/study/study_workflow.py",
          "line": 130,
          "call_type": "function_call"
        },
        {
          "name": "test_get_default_registry",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 498,
          "call_type": "function_call"
        },
        {
          "name": "test_get_default_registry_has_researcher",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 505,
          "call_type": "function_call"
        },
        {
          "name": "test_get_default_registry_has_critic",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 513,
          "call_type": "function_call"
        },
        {
          "name": "test_get_default_registry_has_planner",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 521,
          "call_type": "function_call"
        },
        {
          "name": "test_get_default_registry_independent",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 529,
          "call_type": "function_call"
        },
        {
          "name": "test_get_default_registry_independent",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 530,
          "call_type": "function_call"
        },
        {
          "name": "test_registry_with_all_personas",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 542,
          "call_type": "function_call"
        },
        {
          "name": "test_persona_responses_structure",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 560,
          "call_type": "function_call"
        },
        {
          "name": "test_routing_skill_invocation",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 25,
          "call_type": "function_call"
        },
        {
          "name": "test_routing_different_phases",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 73,
          "call_type": "function_call"
        },
        {
          "name": "test_routing_with_findings",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 101,
          "call_type": "function_call"
        },
        {
          "name": "test_routing_complete_phase",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 130,
          "call_type": "function_call"
        },
        {
          "name": "test_fallback_routing_on_exception",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 156,
          "call_type": "function_call"
        },
        {
          "name": "test_fallback_for_all_phases",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 191,
          "call_type": "function_call"
        },
        {
          "name": "test_fallback_provides_valid_guidance",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 223,
          "call_type": "function_call"
        },
        {
          "name": "test_routing_history_recorded",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 254,
          "call_type": "function_call"
        },
        {
          "name": "test_routing_history_filtering",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 280,
          "call_type": "function_call"
        },
        {
          "name": "test_routing_history_limit",
          "file": "model_chorus/tests/workflows/study/test_routing.py",
          "line": 303,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "create_default_personas",
          "file": "unknown",
          "line": 47,
          "call_type": "function_call"
        },
        {
          "name": "register",
          "file": "unknown",
          "line": 48,
          "call_type": "method_call"
        }
      ],
      "call_count": 19
    },
    {
      "name": "create_critic",
      "file": "model_chorus/src/model_chorus/workflows/study/personas/critic.py",
      "line": 123,
      "language": "python",
      "docstring": "Factory function to create a Critic persona instance.\n\nArgs:\n    temperature: Generation temperature (default: 0.6 for focused critique)\n    max_tokens: Maximum tokens per response (default: 4096)\n\nReturns:\n    Configured CriticPersona instance",
      "parameters": [
        {
          "name": "temperature",
          "type": "float",
          "default": null
        },
        {
          "name": "max_tokens",
          "type": "int",
          "default": null
        }
      ],
      "return_type": "CriticPersona",
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "create_default_personas",
          "file": "model_chorus/src/model_chorus/workflows/study/personas/__init__.py",
          "line": 34,
          "call_type": "function_call"
        },
        {
          "name": "test_create_critic_factory",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 394,
          "call_type": "function_call"
        },
        {
          "name": "test_create_critic_factory_with_params",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 401,
          "call_type": "function_call"
        },
        {
          "name": "test_different_personas_different_findings",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 574,
          "call_type": "function_call"
        }
      ],
      "calls": [],
      "call_count": 4
    },
    {
      "name": "create_planner",
      "file": "model_chorus/src/model_chorus/workflows/study/personas/planner.py",
      "line": 124,
      "language": "python",
      "docstring": "Factory function to create a Planner persona instance.\n\nArgs:\n    temperature: Generation temperature (default: 0.7 for creative planning)\n    max_tokens: Maximum tokens per response (default: 4096)\n\nReturns:\n    Configured PlannerPersona instance",
      "parameters": [
        {
          "name": "temperature",
          "type": "float",
          "default": null
        },
        {
          "name": "max_tokens",
          "type": "int",
          "default": null
        }
      ],
      "return_type": "PlannerPersona",
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "create_default_personas",
          "file": "model_chorus/src/model_chorus/workflows/study/personas/__init__.py",
          "line": 35,
          "call_type": "function_call"
        },
        {
          "name": "test_create_planner_factory",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 453,
          "call_type": "function_call"
        },
        {
          "name": "test_create_planner_factory_with_params",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 460,
          "call_type": "function_call"
        },
        {
          "name": "test_different_personas_different_findings",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 575,
          "call_type": "function_call"
        }
      ],
      "calls": [],
      "call_count": 4
    },
    {
      "name": "create_researcher",
      "file": "model_chorus/src/model_chorus/workflows/study/personas/researcher.py",
      "line": 114,
      "language": "python",
      "docstring": "Factory function to create a Researcher persona instance.\n\nArgs:\n    temperature: Generation temperature (default: 0.7)\n    max_tokens: Maximum tokens per response (default: 4096)\n\nReturns:\n    Configured ResearcherPersona instance",
      "parameters": [
        {
          "name": "temperature",
          "type": "float",
          "default": null
        },
        {
          "name": "max_tokens",
          "type": "int",
          "default": null
        }
      ],
      "return_type": "ResearcherPersona",
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "create_default_personas",
          "file": "model_chorus/src/model_chorus/workflows/study/personas/__init__.py",
          "line": 33,
          "call_type": "function_call"
        },
        {
          "name": "test_create_researcher_factory",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 324,
          "call_type": "function_call"
        },
        {
          "name": "test_create_researcher_factory_with_params",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 331,
          "call_type": "function_call"
        },
        {
          "name": "test_different_personas_different_findings",
          "file": "model_chorus/tests/workflows/study/test_personas.py",
          "line": 573,
          "call_type": "function_call"
        }
      ],
      "calls": [],
      "call_count": 4
    },
    {
      "name": "mock_claude_response",
      "file": "model_chorus/tests/conftest.py",
      "line": 10,
      "language": "python",
      "docstring": "Mock response from Claude CLI --output-format json.",
      "parameters": [],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "mock_codex_response",
      "file": "model_chorus/tests/conftest.py",
      "line": 35,
      "language": "python",
      "docstring": "Mock JSONL response from Codex CLI --json.",
      "parameters": [],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "mock_subprocess_run",
      "file": "model_chorus/tests/conftest.py",
      "line": 45,
      "language": "python",
      "docstring": "Mock subprocess.run for CLI command execution.",
      "parameters": [],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "sample_generation_request",
      "file": "model_chorus/tests/conftest.py",
      "line": 55,
      "language": "python",
      "docstring": "Sample GenerationRequest for testing.",
      "parameters": [],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "is_provider_available",
      "file": "model_chorus/tests/test_chat_integration.py",
      "line": 18,
      "language": "python",
      "docstring": "Check if a provider is available (API key configured).",
      "parameters": [
        {
          "name": "provider_class",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [
        {
          "name": "<module>",
          "file": "model_chorus/tests/test_chat_integration.py",
          "line": 28,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/tests/test_chat_integration.py",
          "line": 29,
          "call_type": "function_call"
        },
        {
          "name": "<module>",
          "file": "model_chorus/tests/test_chat_integration.py",
          "line": 30,
          "call_type": "function_call"
        }
      ],
      "calls": [
        {
          "name": "provider_class",
          "file": "unknown",
          "line": 21,
          "call_type": "function_call"
        },
        {
          "name": "validate_api_key",
          "file": "unknown",
          "line": 22,
          "call_type": "method_call"
        }
      ],
      "call_count": 3
    },
    {
      "name": "conversation_memory",
      "file": "model_chorus/tests/test_chat_integration.py",
      "line": 35,
      "language": "python",
      "docstring": "Create ConversationMemory instance for testing.",
      "parameters": [],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "provider_name",
      "file": "model_chorus/tests/test_chat_integration.py",
      "line": 45,
      "language": "python",
      "docstring": "Parameterized fixture for provider names.",
      "parameters": [
        {
          "name": "request",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture(params=[pytest.param('claude', marks=pytest.mark.skipif(not CLAUDE_AVAILABLE, reason='Claude API not configured')), pytest.param('gemini', marks=pytest.mark.skipif(not GEMINI_AVAILABLE, reason='Gemini API not configured')), pytest.param('codex', marks=pytest.mark.skipif(not CODEX_AVAILABLE, reason='Codex API not configured'))])"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "fixture",
          "file": "unknown",
          "line": 40,
          "call_type": "method_call"
        },
        {
          "name": "param",
          "file": "unknown",
          "line": 41,
          "call_type": "method_call"
        },
        {
          "name": "skipif",
          "file": "unknown",
          "line": 41,
          "call_type": "method_call"
        },
        {
          "name": "param",
          "file": "unknown",
          "line": 42,
          "call_type": "method_call"
        },
        {
          "name": "skipif",
          "file": "unknown",
          "line": 42,
          "call_type": "method_call"
        },
        {
          "name": "param",
          "file": "unknown",
          "line": 43,
          "call_type": "method_call"
        },
        {
          "name": "skipif",
          "file": "unknown",
          "line": 43,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "provider",
      "file": "model_chorus/tests/test_chat_integration.py",
      "line": 51,
      "language": "python",
      "docstring": "Create provider instance based on provider name.",
      "parameters": [
        {
          "name": "provider_name",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "chat_workflow",
      "file": "model_chorus/tests/test_chat_integration.py",
      "line": 62,
      "language": "python",
      "docstring": "Create ChatWorkflow instance with real provider.",
      "parameters": [
        {
          "name": "provider",
          "type": null,
          "default": null
        },
        {
          "name": "conversation_memory",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "mock_provider",
      "file": "model_chorus/tests/test_chat_workflow.py",
      "line": 18,
      "language": "python",
      "docstring": "Mock ModelProvider for testing.",
      "parameters": [],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "conversation_memory",
      "file": "model_chorus/tests/test_chat_workflow.py",
      "line": 38,
      "language": "python",
      "docstring": "Create ConversationMemory instance for testing.",
      "parameters": [],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "chat_workflow",
      "file": "model_chorus/tests/test_chat_workflow.py",
      "line": 44,
      "language": "python",
      "docstring": "Create ChatWorkflow instance for testing.",
      "parameters": [
        {
          "name": "mock_provider",
          "type": null,
          "default": null
        },
        {
          "name": "conversation_memory",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "mock_provider",
      "file": "model_chorus/tests/test_ideate_workflow.py",
      "line": 18,
      "language": "python",
      "docstring": "Mock ModelProvider for testing.",
      "parameters": [],
      "return_type": null,
      "complexity": 8,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "ideate_workflow",
      "file": "model_chorus/tests/test_ideate_workflow.py",
      "line": 118,
      "language": "python",
      "docstring": "Create IdeateWorkflow instance for testing.",
      "parameters": [
        {
          "name": "mock_provider",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "mock_brainstorming_result",
      "file": "model_chorus/tests/test_ideate_workflow.py",
      "line": 124,
      "language": "python",
      "docstring": "Create mock brainstorming result for convergent analysis testing.",
      "parameters": [],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "review_json_path",
      "file": "model_chorus/tests/test_review_response.py",
      "line": 11,
      "language": "python",
      "docstring": "Path to the review JSON file.",
      "parameters": [],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "review_json_data",
      "file": "model_chorus/tests/test_review_response.py",
      "line": 20,
      "language": "python",
      "docstring": "Load review JSON data.",
      "parameters": [
        {
          "name": "review_json_path",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "open",
          "file": "unknown",
          "line": 22,
          "call_type": "function_call"
        },
        {
          "name": "load",
          "file": "unknown",
          "line": 23,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "test_review_json_exists",
      "file": "model_chorus/tests/test_review_response.py",
      "line": 26,
      "language": "python",
      "docstring": "Test that review JSON file exists.",
      "parameters": [
        {
          "name": "review_json_path",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "exists",
          "file": "unknown",
          "line": 28,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "test_review_json_valid_json",
      "file": "model_chorus/tests/test_review_response.py",
      "line": 31,
      "language": "python",
      "docstring": "Test that review JSON file contains valid JSON.",
      "parameters": [
        {
          "name": "review_json_path",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "open",
          "file": "unknown",
          "line": 33,
          "call_type": "function_call"
        },
        {
          "name": "load",
          "file": "unknown",
          "line": 34,
          "call_type": "method_call"
        },
        {
          "name": "isinstance",
          "file": "unknown",
          "line": 35,
          "call_type": "function_call"
        }
      ]
    },
    {
      "name": "test_review_json_has_required_fields",
      "file": "model_chorus/tests/test_review_response.py",
      "line": 38,
      "language": "python",
      "docstring": "Test that review JSON has all required top-level fields.",
      "parameters": [
        {
          "name": "review_json_data",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "test_overall_score_valid",
      "file": "model_chorus/tests/test_review_response.py",
      "line": 45,
      "language": "python",
      "docstring": "Test that overall_score is a valid integer between 0 and 10.",
      "parameters": [
        {
          "name": "review_json_data",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "isinstance",
          "file": "unknown",
          "line": 48,
          "call_type": "function_call"
        }
      ]
    },
    {
      "name": "test_recommendation_valid",
      "file": "model_chorus/tests/test_review_response.py",
      "line": 52,
      "language": "python",
      "docstring": "Test that recommendation is a valid value.",
      "parameters": [
        {
          "name": "review_json_data",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "isinstance",
          "file": "unknown",
          "line": 55,
          "call_type": "function_call"
        }
      ]
    },
    {
      "name": "test_dimension_scores_structure",
      "file": "model_chorus/tests/test_review_response.py",
      "line": 60,
      "language": "python",
      "docstring": "Test that dimension_scores has the expected structure.",
      "parameters": [
        {
          "name": "review_json_data",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "isinstance",
          "file": "unknown",
          "line": 63,
          "call_type": "function_call"
        },
        {
          "name": "items",
          "file": "unknown",
          "line": 66,
          "call_type": "method_call"
        },
        {
          "name": "isinstance",
          "file": "unknown",
          "line": 67,
          "call_type": "function_call"
        }
      ]
    },
    {
      "name": "test_issues_structure",
      "file": "model_chorus/tests/test_review_response.py",
      "line": 71,
      "language": "python",
      "docstring": "Test that issues list has the expected structure.",
      "parameters": [
        {
          "name": "review_json_data",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 3,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "isinstance",
          "file": "unknown",
          "line": 74,
          "call_type": "function_call"
        },
        {
          "name": "isinstance",
          "file": "unknown",
          "line": 78,
          "call_type": "function_call"
        },
        {
          "name": "lower",
          "file": "unknown",
          "line": 84,
          "call_type": "method_call"
        },
        {
          "name": "isinstance",
          "file": "unknown",
          "line": 88,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 89,
          "call_type": "function_call"
        }
      ]
    },
    {
      "name": "test_strengths_structure",
      "file": "model_chorus/tests/test_review_response.py",
      "line": 92,
      "language": "python",
      "docstring": "Test that strengths list has the expected structure.",
      "parameters": [
        {
          "name": "review_json_data",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "isinstance",
          "file": "unknown",
          "line": 95,
          "call_type": "function_call"
        },
        {
          "name": "isinstance",
          "file": "unknown",
          "line": 98,
          "call_type": "function_call"
        },
        {
          "name": "isinstance",
          "file": "unknown",
          "line": 101,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 102,
          "call_type": "function_call"
        }
      ]
    },
    {
      "name": "test_review_response_consistency",
      "file": "model_chorus/tests/test_review_response.py",
      "line": 105,
      "language": "python",
      "docstring": "Test consistency between overall_score and recommendation.",
      "parameters": [
        {
          "name": "review_json_data",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 3,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "test_issues_have_locations",
      "file": "model_chorus/tests/test_review_response.py",
      "line": 119,
      "language": "python",
      "docstring": "Test that issues have location information when applicable.",
      "parameters": [
        {
          "name": "review_json_data",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 4,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "isinstance",
          "file": "unknown",
          "line": 125,
          "call_type": "function_call"
        },
        {
          "name": "isinstance",
          "file": "unknown",
          "line": 129,
          "call_type": "function_call"
        }
      ]
    },
    {
      "name": "test_review_response_completeness",
      "file": "model_chorus/tests/test_review_response.py",
      "line": 132,
      "language": "python",
      "docstring": "Test that review response has meaningful content.",
      "parameters": [
        {
          "name": "review_json_data",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "len",
          "file": "unknown",
          "line": 138,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 138,
          "call_type": "function_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 143,
          "call_type": "function_call"
        }
      ]
    },
    {
      "name": "temp_db",
      "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
      "line": 22,
      "language": "python",
      "docstring": "Create a temporary database file for testing.",
      "parameters": [],
      "return_type": null,
      "complexity": 2,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "mkstemp",
          "file": "unknown",
          "line": 24,
          "call_type": "method_call"
        },
        {
          "name": "close",
          "file": "unknown",
          "line": 25,
          "call_type": "method_call"
        },
        {
          "name": "exists",
          "file": "unknown",
          "line": 28,
          "call_type": "method_call"
        },
        {
          "name": "unlink",
          "file": "unknown",
          "line": 29,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "storage",
      "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
      "line": 33,
      "language": "python",
      "docstring": "Create and initialize a LongTermStorage instance.",
      "parameters": [
        {
          "name": "temp_db",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "initialize",
          "file": "unknown",
          "line": 36,
          "call_type": "method_call"
        },
        {
          "name": "close",
          "file": "unknown",
          "line": 38,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "test_save_and_retrieve",
      "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
      "line": 41,
      "language": "python",
      "docstring": "Test that entries can be saved and retrieved correctly.",
      "parameters": [
        {
          "name": "storage",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "save",
          "file": "unknown",
          "line": 57,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 60,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "test_persistence_across_sessions",
      "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
      "line": 70,
      "language": "python",
      "docstring": "Test that data persists across storage instances (sessions).",
      "parameters": [
        {
          "name": "temp_db",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "initialize",
          "file": "unknown",
          "line": 82,
          "call_type": "method_call"
        },
        {
          "name": "save",
          "file": "unknown",
          "line": 83,
          "call_type": "method_call"
        },
        {
          "name": "close",
          "file": "unknown",
          "line": 84,
          "call_type": "method_call"
        },
        {
          "name": "initialize",
          "file": "unknown",
          "line": 88,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 89,
          "call_type": "method_call"
        },
        {
          "name": "close",
          "file": "unknown",
          "line": 90,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "test_query_by_investigation",
      "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
      "line": 98,
      "language": "python",
      "docstring": "Test querying entries by investigation ID.",
      "parameters": [
        {
          "name": "storage",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "range",
          "file": "unknown",
          "line": 101,
          "call_type": "function_call"
        },
        {
          "name": "save",
          "file": "unknown",
          "line": 108,
          "call_type": "method_call"
        },
        {
          "name": "query",
          "file": "unknown",
          "line": 112,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 115,
          "call_type": "function_call"
        },
        {
          "name": "all",
          "file": "unknown",
          "line": 116,
          "call_type": "function_call"
        }
      ]
    },
    {
      "name": "test_query_by_persona",
      "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
      "line": 119,
      "language": "python",
      "docstring": "Test querying entries by persona.",
      "parameters": [
        {
          "name": "storage",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "enumerate",
          "file": "unknown",
          "line": 123,
          "call_type": "function_call"
        },
        {
          "name": "save",
          "file": "unknown",
          "line": 130,
          "call_type": "method_call"
        },
        {
          "name": "query",
          "file": "unknown",
          "line": 134,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 136,
          "call_type": "function_call"
        }
      ]
    },
    {
      "name": "test_delete",
      "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
      "line": 140,
      "language": "python",
      "docstring": "Test deleting entries.",
      "parameters": [
        {
          "name": "storage",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "save",
          "file": "unknown",
          "line": 150,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 153,
          "call_type": "method_call"
        },
        {
          "name": "delete",
          "file": "unknown",
          "line": 156,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 160,
          "call_type": "method_call"
        },
        {
          "name": "delete",
          "file": "unknown",
          "line": 163,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "test_memory_references",
      "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
      "line": 166,
      "language": "python",
      "docstring": "Test that memory references are saved and retrieved.",
      "parameters": [
        {
          "name": "storage",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "save",
          "file": "unknown",
          "line": 178,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 181,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 183,
          "call_type": "function_call"
        }
      ]
    },
    {
      "name": "test_get_metadata",
      "file": "model_chorus/tests/workflows/study/memory/test_persistence.py",
      "line": 188,
      "language": "python",
      "docstring": "Test retrieving storage metadata.",
      "parameters": [
        {
          "name": "storage",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "range",
          "file": "unknown",
          "line": 191,
          "call_type": "function_call"
        },
        {
          "name": "save",
          "file": "unknown",
          "line": 198,
          "call_type": "method_call"
        },
        {
          "name": "get_metadata",
          "file": "unknown",
          "line": 201,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "mock_provider",
      "file": "tests/test_argument_workflow.py",
      "line": 22,
      "language": "python",
      "docstring": "Mock ModelProvider for testing.",
      "parameters": [],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "conversation_memory",
      "file": "tests/test_argument_workflow.py",
      "line": 42,
      "language": "python",
      "docstring": "Create ConversationMemory instance for testing.",
      "parameters": [],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "argument_workflow",
      "file": "tests/test_argument_workflow.py",
      "line": 48,
      "language": "python",
      "docstring": "Create ArgumentWorkflow instance for testing.",
      "parameters": [
        {
          "name": "mock_provider",
          "type": null,
          "default": null
        },
        {
          "name": "conversation_memory",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "complete_citation",
      "file": "tests/test_citation.py",
      "line": 26,
      "language": "python",
      "docstring": "Citation with all metadata fields populated.",
      "parameters": [],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "minimal_citation",
      "file": "tests/test_citation.py",
      "line": 42,
      "language": "python",
      "docstring": "Citation with only required fields.",
      "parameters": [],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "file_citation",
      "file": "tests/test_citation.py",
      "line": 51,
      "language": "python",
      "docstring": "Citation referencing a file.",
      "parameters": [],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "doi_citation",
      "file": "tests/test_citation.py",
      "line": 66,
      "language": "python",
      "docstring": "Citation with DOI reference.",
      "parameters": [],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "citation_map_complete",
      "file": "tests/test_citation.py",
      "line": 81,
      "language": "python",
      "docstring": "CitationMap with multiple citations.",
      "parameters": [
        {
          "name": "complete_citation",
          "type": null,
          "default": null
        },
        {
          "name": "file_citation",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "citation_map_empty",
      "file": "tests/test_citation.py",
      "line": 93,
      "language": "python",
      "docstring": "CitationMap with no citations.",
      "parameters": [],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "cli_runner",
      "file": "tests/test_cli_integration.py",
      "line": 34,
      "language": "python",
      "docstring": "Create Typer CLI runner for testing.",
      "parameters": [],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "mock_provider",
      "file": "tests/test_cli_integration.py",
      "line": 40,
      "language": "python",
      "docstring": "Mock provider for CLI testing.",
      "parameters": [],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "mock_workflow_result",
      "file": "tests/test_cli_integration.py",
      "line": 60,
      "language": "python",
      "docstring": "Mock workflow result for CLI testing.",
      "parameters": [],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "temp_test_file",
      "file": "tests/test_cli_integration.py",
      "line": 87,
      "language": "python",
      "docstring": "Create temporary test file for file input tests.",
      "parameters": [
        {
          "name": "tmp_path",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "write_text",
          "file": "unknown",
          "line": 90,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "temp_output_file",
      "file": "tests/test_cli_integration.py",
      "line": 95,
      "language": "python",
      "docstring": "Create temporary output file path.",
      "parameters": [
        {
          "name": "tmp_path",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "_check_sentence_transformers_available",
      "file": "tests/test_clustering.py",
      "line": 24,
      "language": "python",
      "docstring": "Check if sentence-transformers is available.",
      "parameters": [],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": false,
      "callers": [
        {
          "name": "test_real_clustering_with_semantics",
          "file": "tests/test_clustering.py",
          "line": 411,
          "call_type": "function_call"
        }
      ],
      "calls": [],
      "call_count": 1
    },
    {
      "name": "_make_provider",
      "file": "tests/test_consensus_provider_models.py",
      "line": 21,
      "language": "python",
      "docstring": null,
      "parameters": [
        {
          "name": "name",
          "type": "str",
          "default": null
        },
        {
          "name": "response_text",
          "type": "str",
          "default": null
        }
      ],
      "return_type": "AsyncMock",
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": false,
      "callers": [
        {
          "name": "test_consensus_applies_provider_model_override_without_mutation",
          "file": "tests/test_consensus_provider_models.py",
          "line": 39,
          "call_type": "function_call"
        },
        {
          "name": "test_consensus_applies_provider_model_override_without_mutation",
          "file": "tests/test_consensus_provider_models.py",
          "line": 40,
          "call_type": "function_call"
        },
        {
          "name": "test_shared_request_model_overrides_provider_metadata",
          "file": "tests/test_consensus_provider_models.py",
          "line": 74,
          "call_type": "function_call"
        }
      ],
      "calls": [],
      "call_count": 3
    },
    {
      "name": "test_consensus_applies_provider_model_override_without_mutation",
      "file": "tests/test_consensus_provider_models.py",
      "line": 37,
      "language": "python",
      "docstring": "Ensure provider-specific metadata adds model override and preserves shared metadata.",
      "parameters": [],
      "return_type": null,
      "complexity": 3,
      "decorators": [
        "pytest.mark.asyncio"
      ],
      "is_async": true,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "_make_provider",
          "file": "unknown",
          "line": 39,
          "call_type": "function_call"
        },
        {
          "name": "_make_provider",
          "file": "unknown",
          "line": 40,
          "call_type": "function_call"
        },
        {
          "name": "execute",
          "file": "unknown",
          "line": 52,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "test_shared_request_model_overrides_provider_metadata",
      "file": "tests/test_consensus_provider_models.py",
      "line": 72,
      "language": "python",
      "docstring": "Shared request metadata should take precedence over provider-level overrides.",
      "parameters": [],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.mark.asyncio"
      ],
      "is_async": true,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "_make_provider",
          "file": "unknown",
          "line": 74,
          "call_type": "function_call"
        },
        {
          "name": "execute",
          "file": "unknown",
          "line": 84,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "mock_provider",
      "file": "tests/test_ideate_workflow.py",
      "line": 22,
      "language": "python",
      "docstring": "Mock ModelProvider for testing.",
      "parameters": [],
      "return_type": null,
      "complexity": 7,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "conversation_memory",
      "file": "tests/test_ideate_workflow.py",
      "line": 135,
      "language": "python",
      "docstring": "Create ConversationMemory instance for testing.",
      "parameters": [],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "ideate_workflow",
      "file": "tests/test_ideate_workflow.py",
      "line": 141,
      "language": "python",
      "docstring": "Create IdeateWorkflow instance for testing.",
      "parameters": [
        {
          "name": "mock_provider",
          "type": null,
          "default": null
        },
        {
          "name": "conversation_memory",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "cache",
      "file": "tests/workflows/study/memory/test_cache.py",
      "line": 19,
      "language": "python",
      "docstring": "Create a ShortTermCache instance with small size for testing.",
      "parameters": [],
      "return_type": null,
      "complexity": 1,
      "decorators": [
        "pytest.fixture"
      ],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": []
    },
    {
      "name": "test_lru_eviction",
      "file": "tests/workflows/study/memory/test_cache.py",
      "line": 24,
      "language": "python",
      "docstring": "Test that LRU eviction works correctly when cache is full.",
      "parameters": [
        {
          "name": "cache",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "range",
          "file": "unknown",
          "line": 27,
          "call_type": "function_call"
        },
        {
          "name": "put",
          "file": "unknown",
          "line": 34,
          "call_type": "method_call"
        },
        {
          "name": "size",
          "file": "unknown",
          "line": 36,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 39,
          "call_type": "method_call"
        },
        {
          "name": "put",
          "file": "unknown",
          "line": 48,
          "call_type": "method_call"
        },
        {
          "name": "size",
          "file": "unknown",
          "line": 51,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 54,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 57,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 58,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 59,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "test_cache_metrics_hits_and_misses",
      "file": "tests/workflows/study/memory/test_cache.py",
      "line": 62,
      "language": "python",
      "docstring": "Test that cache hit/miss metrics are tracked correctly.",
      "parameters": [
        {
          "name": "cache",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "put",
          "file": "unknown",
          "line": 70,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 73,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 76,
          "call_type": "method_call"
        },
        {
          "name": "get_stats",
          "file": "unknown",
          "line": 79,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "test_cache_eviction_metric",
      "file": "tests/workflows/study/memory/test_cache.py",
      "line": 85,
      "language": "python",
      "docstring": "Test that eviction count is tracked correctly.",
      "parameters": [
        {
          "name": "cache",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "range",
          "file": "unknown",
          "line": 88,
          "call_type": "function_call"
        },
        {
          "name": "put",
          "file": "unknown",
          "line": 95,
          "call_type": "method_call"
        },
        {
          "name": "get_stats",
          "file": "unknown",
          "line": 98,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "test_cache_update_existing",
      "file": "tests/workflows/study/memory/test_cache.py",
      "line": 102,
      "language": "python",
      "docstring": "Test updating an existing cache entry.",
      "parameters": [
        {
          "name": "cache",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "put",
          "file": "unknown",
          "line": 111,
          "call_type": "method_call"
        },
        {
          "name": "put",
          "file": "unknown",
          "line": 120,
          "call_type": "method_call"
        },
        {
          "name": "size",
          "file": "unknown",
          "line": 123,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 126,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "test_cache_delete",
      "file": "tests/workflows/study/memory/test_cache.py",
      "line": 130,
      "language": "python",
      "docstring": "Test deleting entries from cache.",
      "parameters": [
        {
          "name": "cache",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 1,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "put",
          "file": "unknown",
          "line": 138,
          "call_type": "method_call"
        },
        {
          "name": "size",
          "file": "unknown",
          "line": 140,
          "call_type": "method_call"
        },
        {
          "name": "delete",
          "file": "unknown",
          "line": 143,
          "call_type": "method_call"
        },
        {
          "name": "size",
          "file": "unknown",
          "line": 145,
          "call_type": "method_call"
        },
        {
          "name": "delete",
          "file": "unknown",
          "line": 148,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "test_cache_query",
      "file": "tests/workflows/study/memory/test_cache.py",
      "line": 152,
      "language": "python",
      "docstring": "Test querying cache with filters.",
      "parameters": [
        {
          "name": "cache",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "put",
          "file": "unknown",
          "line": 168,
          "call_type": "method_call"
        },
        {
          "name": "query",
          "file": "unknown",
          "line": 171,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 172,
          "call_type": "function_call"
        },
        {
          "name": "query",
          "file": "unknown",
          "line": 175,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 176,
          "call_type": "function_call"
        },
        {
          "name": "query",
          "file": "unknown",
          "line": 179,
          "call_type": "method_call"
        },
        {
          "name": "len",
          "file": "unknown",
          "line": 182,
          "call_type": "function_call"
        }
      ]
    },
    {
      "name": "test_cache_clear",
      "file": "tests/workflows/study/memory/test_cache.py",
      "line": 186,
      "language": "python",
      "docstring": "Test clearing all entries from cache.",
      "parameters": [
        {
          "name": "cache",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "range",
          "file": "unknown",
          "line": 189,
          "call_type": "function_call"
        },
        {
          "name": "put",
          "file": "unknown",
          "line": 196,
          "call_type": "method_call"
        },
        {
          "name": "size",
          "file": "unknown",
          "line": 198,
          "call_type": "method_call"
        },
        {
          "name": "clear",
          "file": "unknown",
          "line": 201,
          "call_type": "method_call"
        },
        {
          "name": "size",
          "file": "unknown",
          "line": 203,
          "call_type": "method_call"
        }
      ]
    },
    {
      "name": "test_cache_metadata",
      "file": "tests/workflows/study/memory/test_cache.py",
      "line": 206,
      "language": "python",
      "docstring": "Test retrieving cache metadata.",
      "parameters": [
        {
          "name": "cache",
          "type": null,
          "default": null
        }
      ],
      "return_type": null,
      "complexity": 2,
      "decorators": [],
      "is_async": false,
      "is_exported": false,
      "is_public": true,
      "callers": [],
      "calls": [
        {
          "name": "range",
          "file": "unknown",
          "line": 209,
          "call_type": "function_call"
        },
        {
          "name": "put",
          "file": "unknown",
          "line": 216,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 219,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 220,
          "call_type": "method_call"
        },
        {
          "name": "get",
          "file": "unknown",
          "line": 221,
          "call_type": "method_call"
        },
        {
          "name": "get_metadata",
          "file": "unknown",
          "line": 223,
          "call_type": "method_call"
        }
      ]
    }
  ],
  "dependencies": {
    "examples/workflow_examples.py": [
      "asyncio",
      "sys",
      "pathlib.Path",
      "typing.Optional",
      "model_chorus.workflows.ArgumentWorkflow",
      "model_chorus.workflows.IdeateWorkflow",
      "model_chorus.providers.ClaudeProvider",
      "model_chorus.providers.GeminiProvider",
      "model_chorus.core.conversation.ConversationMemory"
    ],
    "model_chorus/examples/basic_workflow.py": [
      "asyncio",
      "model_chorus.core.BaseWorkflow",
      "model_chorus.core.WorkflowResult",
      "model_chorus.core.WorkflowRegistry",
      "model_chorus.core.WorkflowRequest"
    ],
    "model_chorus/examples/chat_example.py": [
      "asyncio",
      "pathlib.Path",
      "model_chorus.providers.ClaudeProvider",
      "model_chorus.workflows.ChatWorkflow",
      "model_chorus.core.conversation.ConversationMemory"
    ],
    "model_chorus/examples/provider_integration.py": [
      "asyncio",
      "model_chorus.providers.ModelProvider",
      "model_chorus.providers.ModelConfig",
      "model_chorus.providers.ModelCapability",
      "model_chorus.providers.GenerationRequest",
      "model_chorus.providers.GenerationResponse"
    ],
    "model_chorus/examples/thinkdeep_example.py": [
      "asyncio",
      "pathlib.Path",
      "model_chorus.providers.ClaudeProvider",
      "model_chorus.providers.GeminiProvider",
      "model_chorus.workflows.ThinkDeepWorkflow",
      "model_chorus.workflows.ConfidenceLevel",
      "model_chorus.workflows.Hypothesis",
      "model_chorus.workflows.InvestigationStep",
      "model_chorus.workflows.ThinkDeepState",
      "model_chorus.core.conversation.ConversationMemory"
    ],
    "model_chorus/src/model_chorus/cli/__init__.py": [
      "main.app",
      "main.main"
    ],
    "model_chorus/src/model_chorus/cli/main.py": [
      "asyncio",
      "json",
      "sys",
      "pathlib.Path",
      "typing.List",
      "typing.Optional",
      "typing.Sequence",
      "typing.Tuple",
      "typing.Union",
      "typer",
      "rich.console.Console",
      "rich.table.Table",
      "rich.print",
      "providers.ClaudeProvider",
      "providers.CodexProvider",
      "providers.GeminiProvider",
      "providers.CursorAgentProvider",
      "providers.GenerationRequest",
      "providers.cli_provider.ProviderUnavailableError",
      "workflows.ArgumentWorkflow",
      "workflows.ChatWorkflow",
      "workflows.ConsensusWorkflow",
      "workflows.ConsensusStrategy",
      "workflows.IdeateWorkflow",
      "workflows.ThinkDeepWorkflow",
      "core.conversation.ConversationMemory",
      "core.config.get_config_loader",
      "core.progress.set_progress_enabled",
      "model_chorus.__version__",
      "study_commands.study_app"
    ],
    "model_chorus/src/model_chorus/cli/setup.py": [
      "asyncio",
      "json",
      "subprocess",
      "sys",
      "pathlib.Path",
      "typing.Optional",
      "typing.Dict",
      "typing.Any",
      "typing.List"
    ],
    "model_chorus/src/model_chorus/cli/study_commands.py": [
      "asyncio",
      "json",
      "sys",
      "pathlib.Path",
      "typing.List",
      "typing.Optional",
      "typer",
      "rich.console.Console",
      "rich.print",
      "providers.ClaudeProvider",
      "providers.CodexProvider",
      "providers.GeminiProvider",
      "providers.CursorAgentProvider",
      "providers.cli_provider.ProviderUnavailableError",
      "workflows.study.StudyWorkflow",
      "core.conversation.ConversationMemory",
      "core.config.get_config_loader"
    ],
    "model_chorus/src/model_chorus/core/__init__.py": [
      "base_workflow.BaseWorkflow",
      "base_workflow.WorkflowResult",
      "base_workflow.WorkflowStep",
      "registry.WorkflowRegistry",
      "prompts.get_read_only_system_prompt",
      "prompts.prepend_system_constraints",
      "models.ConfidenceLevel",
      "models.WorkflowRequest",
      "models.WorkflowResponse",
      "models.ModelSelection",
      "models.WorkflowStep",
      "models.ModelResponse",
      "models.ConsensusConfig",
      "models.ConversationMessage",
      "models.ConversationThread",
      "models.ConversationState",
      "models.Hypothesis",
      "models.InvestigationStep",
      "models.ThinkDeepState",
      "conversation.ConversationMemory",
      "gap_analysis.Gap",
      "gap_analysis.GapType",
      "gap_analysis.GapSeverity",
      "gap_analysis.detect_gaps",
      "gap_analysis.detect_missing_evidence",
      "gap_analysis.detect_logical_gaps",
      "gap_analysis.detect_unsupported_claims",
      "gap_analysis.assess_gap_severity",
      "gap_analysis.generate_gap_recommendation",
      "contradiction.Contradiction",
      "contradiction.ContradictionSeverity",
      "contradiction.detect_contradiction",
      "contradiction.detect_contradictions_batch",
      "contradiction.detect_polarity_opposition",
      "contradiction.assess_contradiction_severity",
      "contradiction.generate_contradiction_explanation",
      "contradiction.generate_reconciliation_suggestion"
    ],
    "model_chorus/src/model_chorus/core/base_workflow.py": [
      "asyncio",
      "logging",
      "abc.ABC",
      "abc.abstractmethod",
      "typing.Any",
      "typing.Dict",
      "typing.List",
      "typing.Optional",
      "typing.TYPE_CHECKING",
      "dataclasses.dataclass",
      "dataclasses.field",
      "datetime.datetime",
      "conversation.ConversationMemory",
      "models.ConversationThread",
      "models.ConversationMessage"
    ],
    "model_chorus/src/model_chorus/core/clustering.py": [
      "typing.List",
      "typing.Dict",
      "typing.Any",
      "typing.Optional",
      "typing.Tuple",
      "numpy",
      "dataclasses.dataclass",
      "dataclasses.field"
    ],
    "model_chorus/src/model_chorus/core/config.py": [
      "json",
      "os",
      "pathlib.Path",
      "typing.Any",
      "typing.Dict",
      "typing.List",
      "typing.Optional",
      "pydantic.BaseModel",
      "pydantic.Field",
      "pydantic.field_validator"
    ],
    "model_chorus/src/model_chorus/core/contradiction.py": [
      "enum.Enum",
      "typing.Any",
      "typing.Dict",
      "typing.Optional",
      "typing.List",
      "typing.Tuple",
      "pydantic.BaseModel",
      "pydantic.Field",
      "pydantic.ConfigDict",
      "pydantic.field_validator",
      "re"
    ],
    "model_chorus/src/model_chorus/core/conversation.py": [
      "json",
      "uuid",
      "logging",
      "pathlib.Path",
      "datetime.datetime",
      "datetime.timezone",
      "datetime.timedelta",
      "typing.Optional",
      "typing.List",
      "typing.Tuple",
      "typing.Dict",
      "typing.Any",
      "filelock",
      "models.ConversationMessage",
      "models.ConversationThread",
      "models.ConversationState"
    ],
    "model_chorus/src/model_chorus/core/gap_analysis.py": [
      "enum.Enum",
      "typing.Any",
      "typing.Dict",
      "typing.Optional",
      "typing.List",
      "pydantic.BaseModel",
      "pydantic.Field",
      "pydantic.ConfigDict",
      "pydantic.field_validator"
    ],
    "model_chorus/src/model_chorus/core/models.py": [
      "enum.Enum",
      "typing.Any",
      "typing.Dict",
      "typing.List",
      "typing.Optional",
      "typing.Literal",
      "pydantic.BaseModel",
      "pydantic.Field",
      "pydantic.ConfigDict"
    ],
    "model_chorus/src/model_chorus/core/progress.py": [
      "sys",
      "typing.Optional",
      "rich.console.Console"
    ],
    "model_chorus/src/model_chorus/core/prompts.py": [
      "typing.Optional"
    ],
    "model_chorus/src/model_chorus/core/registry.py": [
      "typing.Dict",
      "typing.Type",
      "typing.Optional",
      "typing.Callable",
      "inspect",
      "base_workflow.BaseWorkflow"
    ],
    "model_chorus/src/model_chorus/core/role_orchestration.py": [
      "asyncio",
      "logging",
      "enum.Enum",
      "typing.Any",
      "typing.Dict",
      "typing.Optional",
      "typing.List",
      "dataclasses.dataclass",
      "dataclasses.field",
      "pydantic.BaseModel",
      "pydantic.Field",
      "pydantic.ConfigDict",
      "pydantic.field_validator"
    ],
    "model_chorus/src/model_chorus/core/state.py": [
      "json",
      "logging",
      "threading",
      "pathlib.Path",
      "typing.Any",
      "typing.Dict",
      "typing.Optional",
      "datetime.datetime",
      "datetime.timezone",
      "models.ConversationState"
    ],
    "model_chorus/src/model_chorus/providers/__init__.py": [
      "base_provider.ModelProvider",
      "base_provider.ModelConfig",
      "base_provider.ModelCapability",
      "base_provider.GenerationRequest",
      "base_provider.GenerationResponse",
      "cli_provider.CLIProvider",
      "claude_provider.ClaudeProvider",
      "codex_provider.CodexProvider",
      "gemini_provider.GeminiProvider",
      "cursor_agent_provider.CursorAgentProvider"
    ],
    "model_chorus/src/model_chorus/providers/base_provider.py": [
      "abc.ABC",
      "abc.abstractmethod",
      "typing.Any",
      "typing.Dict",
      "typing.List",
      "typing.Optional",
      "dataclasses.dataclass",
      "dataclasses.field",
      "enum.Enum"
    ],
    "model_chorus/src/model_chorus/providers/claude_provider.py": [
      "json",
      "logging",
      "typing.Any",
      "typing.Dict",
      "typing.List",
      "typing.Optional",
      "cli_provider.CLIProvider",
      "base_provider.GenerationRequest",
      "base_provider.GenerationResponse",
      "base_provider.ModelConfig",
      "base_provider.ModelCapability",
      "base_provider.TokenUsage"
    ],
    "model_chorus/src/model_chorus/providers/cli_provider.py": [
      "asyncio",
      "json",
      "logging",
      "abc.abstractmethod",
      "pathlib.Path",
      "typing.Any",
      "typing.Dict",
      "typing.List",
      "typing.Optional",
      "base_provider.ModelProvider",
      "base_provider.GenerationRequest",
      "base_provider.GenerationResponse"
    ],
    "model_chorus/src/model_chorus/providers/codex_provider.py": [
      "json",
      "logging",
      "typing.Any",
      "typing.Dict",
      "typing.List",
      "typing.Optional",
      "cli_provider.CLIProvider",
      "base_provider.GenerationRequest",
      "base_provider.GenerationResponse",
      "base_provider.ModelConfig",
      "base_provider.ModelCapability",
      "base_provider.TokenUsage"
    ],
    "model_chorus/src/model_chorus/providers/cursor_agent_provider.py": [
      "json",
      "logging",
      "typing.Any",
      "typing.Dict",
      "typing.List",
      "typing.Optional",
      "cli_provider.CLIProvider",
      "base_provider.GenerationRequest",
      "base_provider.GenerationResponse",
      "base_provider.ModelConfig",
      "base_provider.ModelCapability",
      "base_provider.TokenUsage"
    ],
    "model_chorus/src/model_chorus/providers/gemini_provider.py": [
      "json",
      "logging",
      "typing.Any",
      "typing.Dict",
      "typing.List",
      "typing.Optional",
      "cli_provider.CLIProvider",
      "base_provider.GenerationRequest",
      "base_provider.GenerationResponse",
      "base_provider.ModelConfig",
      "base_provider.ModelCapability"
    ],
    "model_chorus/src/model_chorus/utils/__init__.py": [
      "model_chorus.utils.citation_formatter.CitationStyle",
      "model_chorus.utils.citation_formatter.format_citation",
      "model_chorus.utils.citation_formatter.format_citation_map",
      "model_chorus.utils.citation_formatter.validate_citation",
      "model_chorus.utils.citation_formatter.calculate_citation_confidence",
      "model_chorus.utils.citation_formatter.calculate_citation_map_confidence"
    ],
    "model_chorus/src/model_chorus/utils/citation_formatter.py": [
      "typing.Optional",
      "typing.List",
      "typing.Dict",
      "typing.Any",
      "typing.Tuple",
      "enum.Enum"
    ],
    "model_chorus/src/model_chorus/workflows/__init__.py": [
      "argument.ArgumentWorkflow",
      "chat.ChatWorkflow",
      "consensus.ConsensusWorkflow",
      "consensus.ConsensusStrategy",
      "consensus.ConsensusResult",
      "consensus.ProviderConfig",
      "ideate.IdeateWorkflow",
      "study.StudyWorkflow",
      "thinkdeep.ThinkDeepWorkflow",
      "core.models.ConfidenceLevel",
      "core.models.Hypothesis",
      "core.models.InvestigationStep",
      "core.models.InvestigationPhase",
      "core.models.StudyState",
      "core.models.ThinkDeepState"
    ],
    "model_chorus/src/model_chorus/workflows/argument/__init__.py": [
      "model_chorus.workflows.argument.argument_workflow.ArgumentWorkflow",
      "model_chorus.workflows.argument.semantic.compute_claim_similarity",
      "model_chorus.workflows.argument.semantic.find_similar_claims",
      "model_chorus.workflows.argument.semantic.compute_embedding",
      "model_chorus.workflows.argument.semantic.cosine_similarity",
      "model_chorus.workflows.argument.semantic.cluster_claims_kmeans",
      "model_chorus.workflows.argument.semantic.cluster_claims_hierarchical",
      "model_chorus.workflows.argument.semantic.get_cluster_representative",
      "model_chorus.workflows.argument.semantic.compute_cluster_statistics"
    ],
    "model_chorus/src/model_chorus/workflows/argument/argument_workflow.py": [
      "logging",
      "uuid",
      "typing.Optional",
      "typing.Dict",
      "typing.Any",
      "typing.List",
      "core.base_workflow.BaseWorkflow",
      "core.base_workflow.WorkflowResult",
      "core.base_workflow.WorkflowStep",
      "core.conversation.ConversationMemory",
      "core.prompts.prepend_system_constraints",
      "core.registry.WorkflowRegistry",
      "core.role_orchestration.RoleOrchestrator",
      "core.role_orchestration.ModelRole",
      "core.role_orchestration.OrchestrationPattern",
      "core.role_orchestration.OrchestrationResult",
      "providers.ModelProvider",
      "providers.GenerationRequest",
      "providers.GenerationResponse",
      "core.models.ConversationMessage",
      "core.models.ArgumentMap",
      "core.models.ArgumentPerspective",
      "core.progress.emit_workflow_start",
      "core.progress.emit_stage",
      "core.progress.emit_workflow_complete"
    ],
    "model_chorus/src/model_chorus/workflows/argument/semantic.py": [
      "hashlib",
      "typing.List",
      "typing.Dict",
      "typing.Tuple",
      "typing.Optional",
      "typing.Any",
      "functools.lru_cache",
      "numpy",
      "sentence_transformers.SentenceTransformer",
      "model_chorus.core.models.Citation",
      "model_chorus.core.models.CitationMap"
    ],
    "model_chorus/src/model_chorus/workflows/chat.py": [
      "logging",
      "uuid",
      "typing.Optional",
      "typing.Dict",
      "typing.Any",
      "typing.List",
      "core.base_workflow.BaseWorkflow",
      "core.base_workflow.WorkflowResult",
      "core.base_workflow.WorkflowStep",
      "core.conversation.ConversationMemory",
      "core.prompts.prepend_system_constraints",
      "providers.ModelProvider",
      "providers.GenerationRequest",
      "providers.GenerationResponse",
      "core.models.ConversationMessage",
      "core.progress.emit_workflow_start",
      "core.progress.emit_workflow_complete"
    ],
    "model_chorus/src/model_chorus/workflows/consensus.py": [
      "asyncio",
      "logging",
      "typing.List",
      "typing.Dict",
      "typing.Any",
      "typing.Optional",
      "dataclasses.dataclass",
      "dataclasses.field",
      "dataclasses.replace",
      "enum.Enum",
      "providers.ModelProvider",
      "providers.GenerationRequest",
      "providers.GenerationResponse",
      "core.progress.emit_workflow_start",
      "core.progress.emit_provider_start",
      "core.progress.emit_provider_complete",
      "core.progress.emit_workflow_complete"
    ],
    "model_chorus/src/model_chorus/workflows/ideate/__init__.py": [
      "ideate_workflow.IdeateWorkflow"
    ],
    "model_chorus/src/model_chorus/workflows/ideate/ideate_workflow.py": [
      "logging",
      "uuid",
      "datetime.datetime",
      "datetime.timezone",
      "typing.Optional",
      "typing.Dict",
      "typing.Any",
      "typing.List",
      "core.base_workflow.BaseWorkflow",
      "core.base_workflow.WorkflowResult",
      "core.base_workflow.WorkflowStep",
      "core.conversation.ConversationMemory",
      "core.registry.WorkflowRegistry",
      "core.role_orchestration.RoleOrchestrator",
      "core.role_orchestration.ModelRole",
      "core.role_orchestration.OrchestrationPattern",
      "core.role_orchestration.OrchestrationResult",
      "providers.ModelProvider",
      "providers.GenerationRequest",
      "providers.GenerationResponse",
      "core.models.ConversationMessage",
      "core.progress.emit_workflow_start",
      "core.progress.emit_workflow_complete"
    ],
    "model_chorus/src/model_chorus/workflows/study/__init__.py": [
      "study_workflow.StudyWorkflow"
    ],
    "model_chorus/src/model_chorus/workflows/study/config.py": [
      "dataclasses.dataclass",
      "dataclasses.field",
      "typing.Dict",
      "typing.Any",
      "typing.List",
      "typing.Optional"
    ],
    "model_chorus/src/model_chorus/workflows/study/context_analysis.py": [
      "dataclasses.dataclass",
      "dataclasses.field",
      "dataclasses.asdict",
      "typing.Optional",
      "typing.List",
      "typing.Dict",
      "typing.Any",
      "json",
      "pydantic.BaseModel",
      "pydantic.Field",
      "pydantic.field_validator",
      "core.models.InvestigationPhase",
      "core.models.ConfidenceLevel"
    ],
    "model_chorus/src/model_chorus/workflows/study/memory/__init__.py": [
      "models.MemoryEntry",
      "models.MemoryMetadata",
      "models.MemoryType",
      "models.MemoryQuery",
      "cache.ShortTermCache",
      "persistence.LongTermStorage",
      "controller.MemoryController"
    ],
    "model_chorus/src/model_chorus/workflows/study/memory/cache.py": [
      "logging",
      "threading",
      "collections.OrderedDict",
      "typing.Dict",
      "typing.List",
      "typing.Optional",
      "datetime.datetime",
      "datetime.timezone",
      "models.MemoryEntry",
      "models.MemoryMetadata",
      "models.MemoryQuery"
    ],
    "model_chorus/src/model_chorus/workflows/study/memory/controller.py": [
      "logging",
      "uuid",
      "typing.List",
      "typing.Optional",
      "datetime.datetime",
      "datetime.timezone",
      "models.MemoryEntry",
      "models.MemoryMetadata",
      "models.MemoryQuery",
      "cache.ShortTermCache",
      "persistence.LongTermStorage"
    ],
    "model_chorus/src/model_chorus/workflows/study/memory/models.py": [
      "datetime.datetime",
      "datetime.timezone",
      "typing.Any",
      "typing.Dict",
      "typing.List",
      "typing.Optional",
      "enum.Enum",
      "pydantic.BaseModel",
      "pydantic.Field",
      "pydantic.ConfigDict"
    ],
    "model_chorus/src/model_chorus/workflows/study/memory/persistence.py": [
      "logging",
      "sqlite3",
      "json",
      "pathlib.Path",
      "typing.List",
      "typing.Optional",
      "typing.Dict",
      "typing.Any",
      "datetime.datetime",
      "datetime.timezone",
      "models.MemoryEntry",
      "models.MemoryMetadata",
      "models.MemoryQuery",
      "models.MemoryType"
    ],
    "model_chorus/src/model_chorus/workflows/study/persona_base.py": [
      "dataclasses.dataclass",
      "dataclasses.field",
      "typing.Optional",
      "typing.Dict",
      "typing.List",
      "typing.Any"
    ],
    "model_chorus/src/model_chorus/workflows/study/persona_router.py": [
      "logging",
      "typing.Optional",
      "typing.List",
      "typing.Dict",
      "typing.Any",
      "typing.Tuple",
      "dataclasses.dataclass",
      "dataclasses.field",
      "datetime.datetime",
      "core.models.StudyState",
      "persona_base.Persona",
      "persona_base.PersonaRegistry",
      "context_analysis.ContextAnalysisInput",
      "context_analysis.ContextAnalysisResult",
      "context_analysis.analyze_context"
    ],
    "model_chorus/src/model_chorus/workflows/study/personas/__init__.py": [
      "persona_base.PersonaRegistry",
      "researcher.ResearcherPersona",
      "researcher.create_researcher",
      "critic.CriticPersona",
      "critic.create_critic",
      "planner.PlannerPersona",
      "planner.create_planner"
    ],
    "model_chorus/src/model_chorus/workflows/study/personas/critic.py": [
      "typing.Dict",
      "typing.Any",
      "typing.List",
      "persona_base.Persona",
      "persona_base.PersonaResponse"
    ],
    "model_chorus/src/model_chorus/workflows/study/personas/planner.py": [
      "typing.Dict",
      "typing.Any",
      "typing.List",
      "persona_base.Persona",
      "persona_base.PersonaResponse"
    ],
    "model_chorus/src/model_chorus/workflows/study/personas/researcher.py": [
      "typing.Dict",
      "typing.Any",
      "typing.List",
      "persona_base.Persona",
      "persona_base.PersonaResponse"
    ],
    "model_chorus/src/model_chorus/workflows/study/state_machine.py": [
      "logging",
      "typing.Optional",
      "typing.List",
      "typing.Dict",
      "typing.Any",
      "enum.Enum",
      "core.models.InvestigationPhase",
      "core.models.StudyState",
      "core.models.ConfidenceLevel"
    ],
    "model_chorus/src/model_chorus/workflows/study/study_workflow.py": [
      "logging",
      "uuid",
      "datetime.datetime",
      "datetime.timezone",
      "typing.Optional",
      "typing.Dict",
      "typing.Any",
      "typing.List",
      "core.base_workflow.BaseWorkflow",
      "core.base_workflow.WorkflowResult",
      "core.base_workflow.WorkflowStep",
      "core.conversation.ConversationMemory",
      "core.registry.WorkflowRegistry",
      "core.role_orchestration.RoleOrchestrator",
      "core.role_orchestration.ModelRole",
      "core.role_orchestration.OrchestrationPattern",
      "core.role_orchestration.OrchestrationResult",
      "providers.ModelProvider",
      "providers.GenerationRequest",
      "providers.GenerationResponse",
      "core.models.ConversationMessage",
      "core.progress.emit_workflow_start",
      "core.progress.emit_workflow_complete",
      "persona_router.PersonaRouter",
      "personas.get_default_registry"
    ],
    "model_chorus/src/model_chorus/workflows/thinkdeep.py": [
      "logging",
      "uuid",
      "typing.Optional",
      "typing.Dict",
      "typing.Any",
      "typing.List",
      "core.base_workflow.BaseWorkflow",
      "core.base_workflow.WorkflowResult",
      "core.base_workflow.WorkflowStep",
      "core.conversation.ConversationMemory",
      "providers.ModelProvider",
      "providers.GenerationRequest",
      "providers.GenerationResponse",
      "core.models.ConversationMessage",
      "core.models.ThinkDeepState",
      "core.models.Hypothesis",
      "core.models.InvestigationStep",
      "core.models.ConfidenceLevel",
      "core.progress.emit_workflow_start",
      "core.progress.emit_workflow_complete",
      "core.progress.emit_progress"
    ],
    "model_chorus/tests/conftest.py": [
      "pytest",
      "unittest.mock.AsyncMock",
      "unittest.mock.MagicMock"
    ],
    "model_chorus/tests/test_chat_integration.py": [
      "pytest",
      "os",
      "pathlib.Path",
      "model_chorus.workflows.ChatWorkflow",
      "model_chorus.providers.ClaudeProvider",
      "model_chorus.providers.GeminiProvider",
      "model_chorus.providers.CodexProvider",
      "model_chorus.core.conversation.ConversationMemory"
    ],
    "model_chorus/tests/test_chat_workflow.py": [
      "pytest",
      "uuid",
      "unittest.mock.AsyncMock",
      "unittest.mock.MagicMock",
      "unittest.mock.patch",
      "pathlib.Path",
      "model_chorus.workflows.ChatWorkflow",
      "model_chorus.providers.base_provider.GenerationRequest",
      "model_chorus.providers.base_provider.GenerationResponse",
      "model_chorus.core.conversation.ConversationMemory"
    ],
    "model_chorus/tests/test_citation.py": [
      "json",
      "pytest",
      "pydantic.ValidationError",
      "model_chorus.core.models.Citation",
      "model_chorus.core.models.CitationMap"
    ],
    "model_chorus/tests/test_claude_provider.py": [
      "json",
      "pytest",
      "unittest.mock.AsyncMock",
      "unittest.mock.patch",
      "model_chorus.providers.claude_provider.ClaudeProvider",
      "model_chorus.providers.base_provider.GenerationRequest"
    ],
    "model_chorus/tests/test_codex_provider.py": [
      "json",
      "pytest",
      "unittest.mock.AsyncMock",
      "unittest.mock.patch",
      "model_chorus.providers.codex_provider.CodexProvider",
      "model_chorus.providers.base_provider.GenerationRequest"
    ],
    "model_chorus/tests/test_config.py": [
      "json",
      "pytest",
      "pathlib.Path",
      "model_chorus.core.config.ConfigLoader",
      "model_chorus.core.config.GenerationDefaults",
      "model_chorus.core.config.WorkflowConfig",
      "model_chorus.core.config.ModelChorusConfig",
      "model_chorus.core.config.get_config_loader"
    ],
    "model_chorus/tests/test_consensus_workflow.py": [
      "pytest",
      "unittest.mock.AsyncMock",
      "model_chorus.workflows.consensus.ConsensusWorkflow",
      "model_chorus.workflows.consensus.ConsensusStrategy",
      "model_chorus.providers.base_provider.GenerationResponse",
      "model_chorus.providers.base_provider.GenerationRequest"
    ],
    "model_chorus/tests/test_conversation.py": [
      "json",
      "pytest",
      "uuid",
      "pathlib.Path",
      "datetime.datetime",
      "datetime.timezone",
      "model_chorus.core.conversation.ConversationMemory",
      "model_chorus.core.models.ConversationMessage",
      "model_chorus.core.models.ConversationThread"
    ],
    "model_chorus/tests/test_gemini_integration.py": [
      "pytest",
      "subprocess",
      "model_chorus.providers.gemini_provider.GeminiProvider",
      "model_chorus.providers.base_provider.GenerationRequest"
    ],
    "model_chorus/tests/test_ideate_workflow.py": [
      "pytest",
      "unittest.mock.AsyncMock",
      "unittest.mock.MagicMock",
      "typing.Dict",
      "typing.Any",
      "model_chorus.workflows.ideate.ideate_workflow.IdeateWorkflow",
      "model_chorus.providers.base_provider.GenerationRequest",
      "model_chorus.providers.base_provider.GenerationResponse",
      "model_chorus.core.base_workflow.WorkflowResult",
      "model_chorus.core.base_workflow.WorkflowStep",
      "model_chorus.core.models.ConversationMessage"
    ],
    "model_chorus/tests/test_integration.py": [
      "pytest",
      "unittest.mock.patch",
      "unittest.mock.AsyncMock",
      "model_chorus.workflows.consensus.ConsensusWorkflow",
      "model_chorus.workflows.consensus.ConsensusStrategy",
      "model_chorus.providers.base_provider.GenerationResponse",
      "model_chorus.providers.base_provider.GenerationRequest",
      "model_chorus.providers.claude_provider.ClaudeProvider",
      "model_chorus.providers.codex_provider.CodexProvider"
    ],
    "model_chorus/tests/test_review_response.py": [
      "json",
      "pytest",
      "pathlib.Path"
    ],
    "model_chorus/tests/test_semantic_similarity.py": [
      "pytest",
      "numpy",
      "model_chorus.core.models.Citation",
      "model_chorus.core.models.CitationMap",
      "model_chorus.workflows.argument.semantic.compute_embedding",
      "model_chorus.workflows.argument.semantic.cosine_similarity",
      "model_chorus.workflows.argument.semantic.compute_claim_similarity",
      "model_chorus.workflows.argument.semantic.find_similar_claims",
      "model_chorus.workflows.argument.semantic.compute_claim_similarity_batch",
      "model_chorus.workflows.argument.semantic.add_similarity_to_citation",
      "model_chorus.workflows.argument.semantic.find_duplicate_claims",
      "model_chorus.workflows.argument.semantic.cluster_claims_kmeans",
      "model_chorus.workflows.argument.semantic.cluster_claims_hierarchical",
      "model_chorus.workflows.argument.semantic.get_cluster_representative",
      "model_chorus.workflows.argument.semantic.compute_cluster_statistics"
    ],
    "model_chorus/tests/test_state.py": [
      "json",
      "pytest",
      "threading",
      "time",
      "pathlib.Path",
      "datetime.datetime",
      "datetime.timezone",
      "model_chorus.core.state.StateManager",
      "model_chorus.core.state.get_default_state_manager",
      "model_chorus.core.models.ConversationState"
    ],
    "model_chorus/tests/test_thinkdeep_models.py": [
      "json",
      "pytest",
      "pydantic.ValidationError",
      "model_chorus.core.models.ConfidenceLevel",
      "model_chorus.core.models.Hypothesis",
      "model_chorus.core.models.InvestigationStep",
      "model_chorus.core.models.ThinkDeepState"
    ],
    "model_chorus/tests/workflows/study/memory/test_persistence.py": [
      "pytest",
      "tempfile",
      "os",
      "pathlib.Path",
      "model_chorus.workflows.study.memory.MemoryEntry",
      "model_chorus.workflows.study.memory.MemoryQuery",
      "model_chorus.workflows.study.memory.MemoryType",
      "model_chorus.workflows.study.memory.LongTermStorage"
    ],
    "model_chorus/tests/workflows/study/test_personas.py": [
      "pytest",
      "model_chorus.workflows.study.persona_base.Persona",
      "model_chorus.workflows.study.persona_base.PersonaResponse",
      "model_chorus.workflows.study.persona_base.PersonaRegistry",
      "model_chorus.workflows.study.personas.ResearcherPersona",
      "model_chorus.workflows.study.personas.CriticPersona",
      "model_chorus.workflows.study.personas.PlannerPersona",
      "model_chorus.workflows.study.personas.create_researcher",
      "model_chorus.workflows.study.personas.create_critic",
      "model_chorus.workflows.study.personas.create_planner",
      "model_chorus.workflows.study.personas.get_default_registry",
      "model_chorus.workflows.study.personas.create_default_personas"
    ],
    "model_chorus/tests/workflows/study/test_routing.py": [
      "pytest",
      "unittest.mock.Mock",
      "unittest.mock.patch",
      "model_chorus.workflows.study.persona_router.PersonaRouter",
      "model_chorus.workflows.study.persona_router.RoutingDecision",
      "model_chorus.workflows.study.persona_base.Persona",
      "model_chorus.workflows.study.persona_base.PersonaRegistry",
      "model_chorus.workflows.study.personas.get_default_registry",
      "model_chorus.core.models.StudyState"
    ],
    "model_chorus/tests/workflows/study/test_state_machine.py": [
      "pytest",
      "model_chorus.core.models.InvestigationPhase",
      "model_chorus.core.models.StudyState",
      "model_chorus.core.models.ConfidenceLevel",
      "model_chorus.workflows.study.state_machine.InvestigationStateMachine"
    ],
    "model_chorus/tests/workflows/study/test_study_workflow.py": [
      "pytest",
      "unittest.mock.Mock",
      "unittest.mock.patch",
      "unittest.mock.AsyncMock",
      "unittest.mock.MagicMock",
      "datetime.datetime",
      "datetime.timezone",
      "model_chorus.workflows.study.study_workflow.StudyWorkflow",
      "model_chorus.core.base_workflow.WorkflowResult",
      "model_chorus.core.base_workflow.WorkflowStep",
      "model_chorus.core.conversation.ConversationMemory",
      "model_chorus.core.models.ConversationMessage"
    ],
    "test_backward_compat.py": [
      "json",
      "sys"
    ],
    "test_codex_parse.py": [
      "json",
      "sys"
    ],
    "test_parse_response.py": [
      "json",
      "sys"
    ],
    "tests/test_argument_workflow.py": [
      "pytest",
      "uuid",
      "unittest.mock.AsyncMock",
      "unittest.mock.MagicMock",
      "unittest.mock.patch",
      "pathlib.Path",
      "model_chorus.workflows.argument.ArgumentWorkflow",
      "model_chorus.providers.base_provider.GenerationRequest",
      "model_chorus.providers.base_provider.GenerationResponse",
      "model_chorus.core.conversation.ConversationMemory",
      "model_chorus.core.models.ArgumentMap",
      "model_chorus.core.models.ArgumentPerspective",
      "model_chorus.core.role_orchestration.OrchestrationResult",
      "model_chorus.core.role_orchestration.OrchestrationPattern"
    ],
    "tests/test_citation.py": [
      "pytest",
      "model_chorus.core.models.Citation",
      "model_chorus.core.models.CitationMap",
      "model_chorus.utils.citation_formatter.CitationStyle",
      "model_chorus.utils.citation_formatter.format_citation",
      "model_chorus.utils.citation_formatter.format_citation_map",
      "model_chorus.utils.citation_formatter.validate_citation",
      "model_chorus.utils.citation_formatter.calculate_citation_confidence",
      "model_chorus.utils.citation_formatter.calculate_citation_map_confidence"
    ],
    "tests/test_cli_integration.py": [
      "json",
      "importlib",
      "sys",
      "pytest",
      "pathlib.Path",
      "typer.testing.CliRunner",
      "unittest.mock.AsyncMock",
      "unittest.mock.MagicMock",
      "unittest.mock.patch",
      "unittest.mock.mock_open",
      "model_chorus.cli.main.app",
      "model_chorus.providers.base_provider.GenerationResponse",
      "model_chorus.core.base_workflow.WorkflowResult",
      "model_chorus.core.base_workflow.WorkflowStep"
    ],
    "tests/test_clustering.py": [
      "pytest",
      "numpy",
      "unittest.mock.Mock",
      "unittest.mock.patch",
      "unittest.mock.MagicMock",
      "model_chorus.core.clustering.SemanticClustering",
      "model_chorus.core.clustering.ClusterResult"
    ],
    "tests/test_concurrent_conversations.py": [
      "pytest",
      "asyncio",
      "unittest.mock.AsyncMock",
      "uuid",
      "concurrent.futures.ThreadPoolExecutor",
      "time",
      "datetime.datetime",
      "datetime.timezone",
      "model_chorus.workflows.chat.ChatWorkflow",
      "model_chorus.workflows.thinkdeep.ThinkDeepWorkflow",
      "model_chorus.providers.base_provider.GenerationResponse",
      "model_chorus.core.conversation.ConversationMemory",
      "model_chorus.core.models.ConversationMessage"
    ],
    "tests/test_consensus_provider_models.py": [
      "sys",
      "pathlib.Path",
      "unittest.mock.AsyncMock",
      "pytest",
      "model_chorus.providers.base_provider.GenerationRequest",
      "model_chorus.providers.base_provider.GenerationResponse",
      "model_chorus.workflows.consensus.ConsensusWorkflow"
    ],
    "tests/test_contradiction.py": [
      "pytest",
      "model_chorus.core.contradiction.Contradiction",
      "model_chorus.core.contradiction.ContradictionSeverity",
      "model_chorus.core.contradiction.detect_contradiction",
      "model_chorus.core.contradiction.detect_contradictions_batch",
      "model_chorus.core.contradiction.detect_polarity_opposition",
      "model_chorus.core.contradiction.assess_contradiction_severity",
      "model_chorus.core.contradiction.generate_contradiction_explanation",
      "model_chorus.core.contradiction.generate_reconciliation_suggestion"
    ],
    "tests/test_gap_analysis.py": [
      "pytest",
      "model_chorus.core.gap_analysis.Gap",
      "model_chorus.core.gap_analysis.GapType",
      "model_chorus.core.gap_analysis.GapSeverity",
      "model_chorus.core.gap_analysis.detect_gaps",
      "model_chorus.core.gap_analysis.detect_missing_evidence",
      "model_chorus.core.gap_analysis.detect_logical_gaps",
      "model_chorus.core.gap_analysis.detect_unsupported_claims",
      "model_chorus.core.gap_analysis.assess_gap_severity",
      "model_chorus.core.gap_analysis.generate_gap_recommendation"
    ],
    "tests/test_ideate_workflow.py": [
      "pytest",
      "uuid",
      "unittest.mock.AsyncMock",
      "unittest.mock.MagicMock",
      "unittest.mock.patch",
      "pathlib.Path",
      "model_chorus.workflows.ideate.IdeateWorkflow",
      "model_chorus.providers.base_provider.GenerationRequest",
      "model_chorus.providers.base_provider.GenerationResponse",
      "model_chorus.core.conversation.ConversationMemory",
      "model_chorus.core.models.Idea",
      "model_chorus.core.models.IdeaCluster",
      "model_chorus.core.models.IdeationState",
      "model_chorus.core.role_orchestration.OrchestrationResult",
      "model_chorus.core.role_orchestration.OrchestrationPattern"
    ],
    "tests/test_memory_management.py": [
      "pytest",
      "asyncio",
      "unittest.mock.AsyncMock",
      "uuid",
      "sys",
      "model_chorus.workflows.chat.ChatWorkflow",
      "model_chorus.workflows.thinkdeep.ThinkDeepWorkflow",
      "model_chorus.providers.base_provider.GenerationResponse",
      "model_chorus.core.conversation.ConversationMemory"
    ],
    "tests/test_providers/test_cli_interface.py": [
      "sys",
      "pathlib.Path",
      "pytest",
      "model_chorus.providers.ModelProvider",
      "model_chorus.providers.CLIProvider",
      "model_chorus.providers.ClaudeProvider",
      "model_chorus.providers.CodexProvider",
      "model_chorus.providers.GeminiProvider",
      "model_chorus.providers.CursorAgentProvider",
      "model_chorus.providers.GenerationRequest"
    ],
    "tests/test_role_orchestration.py": [
      "pytest",
      "asyncio",
      "unittest.mock.Mock",
      "unittest.mock.AsyncMock",
      "unittest.mock.patch",
      "dataclasses.dataclass",
      "typing.Optional",
      "typing.Dict",
      "typing.Any",
      "model_chorus.core.role_orchestration.ModelRole",
      "model_chorus.core.role_orchestration.OrchestrationPattern",
      "model_chorus.core.role_orchestration.OrchestrationResult",
      "model_chorus.core.role_orchestration.RoleOrchestrator",
      "model_chorus.core.role_orchestration.SynthesisStrategy"
    ],
    "tests/test_thinkdeep_complex.py": [
      "pytest",
      "unittest.mock.AsyncMock",
      "unittest.mock.MagicMock",
      "unittest.mock.patch",
      "uuid",
      "model_chorus.workflows.thinkdeep.ThinkDeepWorkflow",
      "model_chorus.providers.base_provider.GenerationResponse",
      "model_chorus.providers.base_provider.GenerationRequest",
      "model_chorus.core.conversation.ConversationMemory",
      "model_chorus.core.models.ConfidenceLevel",
      "model_chorus.core.models.Hypothesis",
      "model_chorus.core.models.InvestigationStep",
      "model_chorus.core.models.ThinkDeepState"
    ],
    "tests/test_thinkdeep_expert_validation.py": [
      "pytest",
      "unittest.mock.AsyncMock",
      "unittest.mock.MagicMock",
      "unittest.mock.patch",
      "uuid",
      "model_chorus.workflows.thinkdeep.ThinkDeepWorkflow",
      "model_chorus.providers.base_provider.GenerationResponse",
      "model_chorus.providers.base_provider.GenerationRequest",
      "model_chorus.core.conversation.ConversationMemory",
      "model_chorus.core.models.ConfidenceLevel",
      "model_chorus.core.models.Hypothesis",
      "model_chorus.core.models.InvestigationStep",
      "model_chorus.core.models.ThinkDeepState"
    ],
    "tests/test_thinkdeep_workflow.py": [
      "pytest",
      "unittest.mock.AsyncMock",
      "unittest.mock.MagicMock",
      "unittest.mock.patch",
      "uuid",
      "model_chorus.workflows.thinkdeep.ThinkDeepWorkflow",
      "model_chorus.providers.base_provider.GenerationResponse",
      "model_chorus.providers.base_provider.GenerationRequest",
      "model_chorus.core.conversation.ConversationMemory",
      "model_chorus.core.models.ConfidenceLevel",
      "model_chorus.core.models.Hypothesis",
      "model_chorus.core.models.InvestigationStep",
      "model_chorus.core.models.ThinkDeepState"
    ],
    "tests/test_workflow_integration_chaining.py": [
      "sys",
      "uuid",
      "pathlib.Path",
      "unittest.mock.AsyncMock",
      "unittest.mock.patch",
      "pytest",
      "model_chorus.workflows.consensus.ConsensusWorkflow",
      "model_chorus.workflows.consensus.ConsensusStrategy",
      "model_chorus.workflows.thinkdeep.ThinkDeepWorkflow",
      "model_chorus.workflows.chat.ChatWorkflow",
      "model_chorus.providers.base_provider.GenerationResponse",
      "model_chorus.providers.base_provider.GenerationRequest",
      "model_chorus.core.conversation.ConversationMemory"
    ],
    "tests/workflows/study/memory/test_cache.py": [
      "pytest",
      "model_chorus.workflows.study.memory.MemoryEntry",
      "model_chorus.workflows.study.memory.MemoryQuery",
      "model_chorus.workflows.study.memory.MemoryType",
      "model_chorus.workflows.study.memory.ShortTermCache"
    ]
  }
}